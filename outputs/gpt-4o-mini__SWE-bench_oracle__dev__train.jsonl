{"instance_id": "pvlib__pvlib-python-1764", "model_name_or_path": "gpt-4o-mini", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nAllow user to set tol and maxiter for singlediode newton method\nThe first few lines of `pvlib.singlediode` set `tol` and `maxiter` for all the solvers using the newton method:\r\n\r\n```\r\nfrom scipy.optimize import brentq, newton\r\nfrom scipy.special import lambertw\r\n\r\n# set keyword arguments for all uses of newton in this module\r\nnewton = partial(newton, tol=1e-6, maxiter=100, fprime2=None)\r\n```\r\n\r\nHowever, I would like to change `tol` and `maxiter` for my application. It would be great if these could be added instead as keyword arguments to the various functions so they can be adjusted by the user. Using a variety of singlediode model params, I have found that by setting tol=0.1 and maxiter=10, I can realize a 1.4x speedup in the `singeldiode.bishop88_mpp` algorithm while incurring a maximum error of 0.007038% and a mean absolute error of  0.000042% in calculated V_mp.\r\n\r\n\n\n</issue>\n<code>\n[start of README.md]\n1 <img src=\"docs/sphinx/source/_images/pvlib_logo_horiz.png\" width=\"600\">\n2 \n3 <table>\n4 <tr>\n5   <td>Latest Release</td>\n6   <td>\n7     <a href=\"https://pypi.org/project/pvlib/\">\n8     <img src=\"https://img.shields.io/pypi/v/pvlib.svg\" alt=\"latest release\" />\n9     </a>\n10     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n11     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/version.svg\" />\n12     </a>\n13     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n14     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/latest_release_date.svg\" />\n15     </a>\n16 </tr>\n17 <tr>\n18   <td>License</td>\n19   <td>\n20     <a href=\"https://github.com/pvlib/pvlib-python/blob/main/LICENSE\">\n21     <img src=\"https://img.shields.io/pypi/l/pvlib.svg\" alt=\"license\" />\n22     </a>\n23 </td>\n24 </tr>\n25 <tr>\n26   <td>Build Status</td>\n27   <td>\n28     <a href=\"http://pvlib-python.readthedocs.org/en/stable/\">\n29     <img src=\"https://readthedocs.org/projects/pvlib-python/badge/?version=stable\" alt=\"documentation build status\" />\n30     </a>\n31     <a href=\"https://github.com/pvlib/pvlib-python/actions/workflows/pytest.yml?query=branch%3Amain\">\n32       <img src=\"https://github.com/pvlib/pvlib-python/actions/workflows/pytest.yml/badge.svg?branch=main\" alt=\"GitHub Actions Testing Status\" />\n33     </a>\n34     <a href=\"https://codecov.io/gh/pvlib/pvlib-python\">\n35     <img src=\"https://codecov.io/gh/pvlib/pvlib-python/branch/main/graph/badge.svg\" alt=\"codecov coverage\" />\n36     </a>\n37   </td>\n38 </tr>\n39 <tr>\n40   <td>Benchmarks</td>\n41   <td>\n42     <a href=\"https://pvlib.github.io/pvlib-benchmarks/\">\n43     <img src=\"https://img.shields.io/badge/benchmarks-asv-lightgrey\" />\n44     </a>\n45   </td>\n46 </tr>\n47 <tr>\n48   <td>Publications</td>\n49   <td>\n50     <a href=\"https://doi.org/10.5281/zenodo.593284\">\n51     <img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.593284.svg\" alt=\"zenodo reference\">\n52     </a>\n53     <a href=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1\">\n54     <img src=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1/status.svg\" alt=\"JOSS reference\" />\n55     </a>\n56   </td>\n57 </tr>\n58 <tr>\n59   <td>Downloads</td>\n60   <td>\n61     <a href=\"https://pypi.org/project/pvlib/\">\n62     <img src=\"https://img.shields.io/pypi/dm/pvlib\" alt=\"PyPI downloads\" />\n63     </a>\n64     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n65     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/downloads.svg\" alt=\"conda-forge downloads\" />\n66     </a>\n67   </td>\n68 </tr>\n69 </table>\n70 \n71 \n72 pvlib python is a community supported tool that provides a set of\n73 functions and classes for simulating the performance of photovoltaic\n74 energy systems. pvlib python was originally ported from the PVLIB MATLAB\n75 toolbox developed at Sandia National Laboratories and it implements many\n76 of the models and methods developed at the Labs. More information on\n77 Sandia Labs PV performance modeling programs can be found at\n78 https://pvpmc.sandia.gov/. We collaborate with the PVLIB MATLAB project,\n79 but operate independently of it.\n80 \n81 \n82 Documentation\n83 =============\n84 \n85 Full documentation can be found at [readthedocs](http://pvlib-python.readthedocs.io/en/stable/),\n86 including an [FAQ](http://pvlib-python.readthedocs.io/en/stable/user_guide/faq.html) page.\n87 \n88 Installation\n89 ============\n90 \n91 pvlib-python releases may be installed using the ``pip`` and ``conda`` tools.\n92 Please see the [Installation page](https://pvlib-python.readthedocs.io/en/stable/user_guide/installation.html) of the documentation for complete instructions.\n93 \n94 \n95 Contributing\n96 ============\n97 \n98 We need your help to make pvlib-python a great tool!\n99 Please see the [Contributing page](http://pvlib-python.readthedocs.io/en/stable/contributing.html) for more on how you can contribute.\n100 The long-term success of pvlib-python requires substantial community support.\n101 \n102 \n103 Citing\n104 ======\n105 \n106 If you use pvlib-python in a published work, please cite:\n107 \n108   William F. Holmgren, Clifford W. Hansen, and Mark A. Mikofski.\n109   \"pvlib python: a python package for modeling solar energy systems.\"\n110   Journal of Open Source Software, 3(29), 884, (2018).\n111   https://doi.org/10.21105/joss.00884\n112 \n113 Please also cite the DOI corresponding to the specific version of\n114 pvlib-python that you used. pvlib-python DOIs are listed at\n115 [Zenodo.org](https://zenodo.org/search?page=1&size=20&q=conceptrecid:593284&all_versions&sort=-version)\n116 \n117 If you use pvlib-python in a commercial or publicly-available application, please\n118 consider displaying one of the \"powered by pvlib\" logos:\n119 \n120 <img src=\"docs/sphinx/source/_images/pvlib_powered_logo_vert.png\" width=\"300\"><img src=\"docs/sphinx/source/_images/pvlib_powered_logo_horiz.png\" width=\"300\">\n121 \n122 Getting support\n123 ===============\n124 \n125 pvlib usage questions can be asked on\n126 [Stack Overflow](http://stackoverflow.com) and tagged with\n127 the [pvlib](http://stackoverflow.com/questions/tagged/pvlib) tag.\n128 \n129 The [pvlib-python google group](https://groups.google.com/forum/#!forum/pvlib-python)\n130 is used for discussing various topics of interest to the pvlib-python\n131 community. We also make new version announcements on the google group.\n132 \n133 If you suspect that you may have discovered a bug or if you'd like to\n134 change something about pvlib, then please make an issue on our\n135 [GitHub issues page](https://github.com/pvlib/pvlib-python/issues).\n136 \n137 \n138 \n139 License\n140 =======\n141 \n142 BSD 3-clause.\n143 \n144 \n145 NumFOCUS\n146 ========\n147 \n148 pvlib python is a [NumFOCUS Affiliated Project](https://numfocus.org/sponsored-projects/affiliated-projects)\n149 \n150 [![NumFocus Affliated Projects](https://i0.wp.com/numfocus.org/wp-content/uploads/2019/06/AffiliatedProject.png)](https://numfocus.org/sponsored-projects/affiliated-projects)\n151 \n[end of README.md]\n[start of pvlib/singlediode.py]\n1 \"\"\"\n2 Low-level functions for solving the single diode equation.\n3 \"\"\"\n4 \n5 from functools import partial\n6 import numpy as np\n7 from pvlib.tools import _golden_sect_DataFrame\n8 \n9 from scipy.optimize import brentq, newton\n10 from scipy.special import lambertw\n11 \n12 # set keyword arguments for all uses of newton in this module\n13 newton = partial(newton, tol=1e-6, maxiter=100, fprime2=None)\n14 \n15 # intrinsic voltage per cell junction for a:Si, CdTe, Mertens et al.\n16 VOLTAGE_BUILTIN = 0.9  # [V]\n17 \n18 \n19 def estimate_voc(photocurrent, saturation_current, nNsVth):\n20     \"\"\"\n21     Rough estimate of open circuit voltage useful for bounding searches for\n22     ``i`` of ``v`` when using :func:`~pvlib.pvsystem.singlediode`.\n23 \n24     Parameters\n25     ----------\n26     photocurrent : numeric\n27         photo-generated current [A]\n28     saturation_current : numeric\n29         diode reverse saturation current [A]\n30     nNsVth : numeric\n31         product of thermal voltage ``Vth`` [V], diode ideality factor ``n``,\n32         and number of series cells ``Ns``\n33 \n34     Returns\n35     -------\n36     numeric\n37         rough estimate of open circuit voltage [V]\n38 \n39     Notes\n40     -----\n41     Calculating the open circuit voltage, :math:`V_{oc}`, of an ideal device\n42     with infinite shunt resistance, :math:`R_{sh} \\\\to \\\\infty`, and zero\n43     series resistance, :math:`R_s = 0`, yields the following equation [1]. As\n44     an estimate of :math:`V_{oc}` it is useful as an upper bound for the\n45     bisection method.\n46 \n47     .. math::\n48 \n49         V_{oc, est}=n Ns V_{th} \\\\log \\\\left( \\\\frac{I_L}{I_0} + 1 \\\\right)\n50 \n51     .. [1] http://www.pveducation.org/pvcdrom/open-circuit-voltage\n52     \"\"\"\n53 \n54     return nNsVth * np.log(np.asarray(photocurrent) / saturation_current + 1.0)\n55 \n56 \n57 def bishop88(diode_voltage, photocurrent, saturation_current,\n58              resistance_series, resistance_shunt, nNsVth, d2mutau=0,\n59              NsVbi=np.Inf, breakdown_factor=0., breakdown_voltage=-5.5,\n60              breakdown_exp=3.28, gradients=False):\n61     r\"\"\"\n62     Explicit calculation of points on the IV curve described by the single\n63     diode equation.  Values are calculated as described in [1]_.\n64 \n65     The single diode equation with recombination current and reverse bias\n66     breakdown is\n67 \n68     .. math::\n69 \n70         I = I_{L} - I_{0} \\left (\\exp \\frac{V_{d}}{nN_{s}V_{th}} - 1 \\right )\n71         - \\frac{V_{d}}{R_{sh}}\n72         - \\frac{I_{L} \\frac{d^{2}}{\\mu \\tau}}{N_{s} V_{bi} - V_{d}}\n73         - a \\frac{V_{d}}{R_{sh}} \\left (1 - \\frac{V_{d}}{V_{br}} \\right )^{-m}\n74 \n75     The input `diode_voltage` must be :math:`V + I R_{s}`.\n76 \n77 \n78     .. warning::\n79        * Usage of ``d2mutau`` is required with PVSyst\n80          coefficients for cadmium-telluride (CdTe) and amorphous-silicon\n81          (a:Si) PV modules only.\n82        * Do not use ``d2mutau`` with CEC coefficients.\n83 \n84     Parameters\n85     ----------\n86     diode_voltage : numeric\n87         diode voltage :math:`V_d` [V]\n88     photocurrent : numeric\n89         photo-generated current :math:`I_{L}` [A]\n90     saturation_current : numeric\n91         diode reverse saturation current :math:`I_{0}` [A]\n92     resistance_series : numeric\n93         series resistance :math:`R_{s}` [ohms]\n94     resistance_shunt: numeric\n95         shunt resistance :math:`R_{sh}` [ohms]\n96     nNsVth : numeric\n97         product of thermal voltage :math:`V_{th}` [V], diode ideality factor\n98         :math:`n`, and number of series cells :math:`N_{s}` [V]\n99     d2mutau : numeric, default 0\n100         PVsyst parameter for cadmium-telluride (CdTe) and amorphous-silicon\n101         (a-Si) modules that accounts for recombination current in the\n102         intrinsic layer. The value is the ratio of intrinsic layer thickness\n103         squared :math:`d^2` to the diffusion length of charge carriers\n104         :math:`\\mu \\tau`. [V]\n105     NsVbi : numeric, default np.inf\n106         PVsyst parameter for cadmium-telluride (CdTe) and amorphous-silicon\n107         (a-Si) modules that is the product of the PV module number of series\n108         cells :math:`N_{s}` and the builtin voltage :math:`V_{bi}` of the\n109         intrinsic layer. [V].\n110     breakdown_factor : numeric, default 0\n111         fraction of ohmic current involved in avalanche breakdown :math:`a`.\n112         Default of 0 excludes the reverse bias term from the model. [unitless]\n113     breakdown_voltage : numeric, default -5.5\n114         reverse breakdown voltage of the photovoltaic junction :math:`V_{br}`\n115         [V]\n116     breakdown_exp : numeric, default 3.28\n117         avalanche breakdown exponent :math:`m` [unitless]\n118     gradients : bool\n119         False returns only I, V, and P. True also returns gradients\n120 \n121     Returns\n122     -------\n123     tuple\n124         currents [A], voltages [V], power [W], and optionally\n125         :math:`\\frac{dI}{dV_d}`, :math:`\\frac{dV}{dV_d}`,\n126         :math:`\\frac{dI}{dV}`, :math:`\\frac{dP}{dV}`, and\n127         :math:`\\frac{d^2 P}{dV dV_d}`\n128 \n129     Notes\n130     -----\n131     The PVSyst thin-film recombination losses parameters ``d2mutau`` and\n132     ``NsVbi`` should only be applied to cadmium-telluride (CdTe) and amorphous-\n133     silicon (a-Si) PV modules, [2]_, [3]_. The builtin voltage :math:`V_{bi}`\n134     should account for all junctions. For example: tandem and triple junction\n135     cells would have builtin voltages of 1.8[V] and 2.7[V] respectively, based\n136     on the default of 0.9[V] for a single junction. The parameter ``NsVbi``\n137     should only account for the number of series cells in a single parallel\n138     sub-string if the module has cells in parallel greater than 1.\n139 \n140     References\n141     ----------\n142     .. [1] \"Computer simulation of the effects of electrical mismatches in\n143        photovoltaic cell interconnection circuits\" JW Bishop, Solar Cell (1988)\n144        :doi:`10.1016/0379-6787(88)90059-2`\n145 \n146     .. [2] \"Improved equivalent circuit and Analytical Model for Amorphous\n147        Silicon Solar Cells and Modules.\" J. Mertens, et al., IEEE Transactions\n148        on Electron Devices, Vol 45, No 2, Feb 1998.\n149        :doi:`10.1109/16.658676`\n150 \n151     .. [3] \"Performance assessment of a simulation model for PV modules of any\n152        available technology\", Andr\u00e9 Mermoud and Thibault Lejeune, 25th EUPVSEC,\n153        2010\n154        :doi:`10.4229/25thEUPVSEC2010-4BV.1.114`\n155     \"\"\"\n156     # calculate recombination loss current where d2mutau > 0\n157     is_recomb = d2mutau > 0  # True where there is thin-film recombination loss\n158     v_recomb = np.where(is_recomb, NsVbi - diode_voltage, np.inf)\n159     i_recomb = np.where(is_recomb, photocurrent * d2mutau / v_recomb, 0)\n160     # calculate temporary values to simplify calculations\n161     v_star = diode_voltage / nNsVth  # non-dimensional diode voltage\n162     g_sh = 1.0 / resistance_shunt  # conductance\n163     if breakdown_factor > 0:  # reverse bias is considered\n164         brk_term = 1 - diode_voltage / breakdown_voltage\n165         brk_pwr = np.power(brk_term, -breakdown_exp)\n166         i_breakdown = breakdown_factor * diode_voltage * g_sh * brk_pwr\n167     else:\n168         i_breakdown = 0.\n169     i = (photocurrent - saturation_current * np.expm1(v_star)  # noqa: W503\n170          - diode_voltage * g_sh - i_recomb - i_breakdown)   # noqa: W503\n171     v = diode_voltage - i * resistance_series\n172     retval = (i, v, i*v)\n173     if gradients:\n174         # calculate recombination loss current gradients where d2mutau > 0\n175         grad_i_recomb = np.where(is_recomb, i_recomb / v_recomb, 0)\n176         grad_2i_recomb = np.where(is_recomb, 2 * grad_i_recomb / v_recomb, 0)\n177         g_diode = saturation_current * np.exp(v_star) / nNsVth  # conductance\n178         if breakdown_factor > 0:  # reverse bias is considered\n179             brk_pwr_1 = np.power(brk_term, -breakdown_exp - 1)\n180             brk_pwr_2 = np.power(brk_term, -breakdown_exp - 2)\n181             brk_fctr = breakdown_factor * g_sh\n182             grad_i_brk = brk_fctr * (brk_pwr + diode_voltage *\n183                                      -breakdown_exp * brk_pwr_1)\n184             grad2i_brk = (brk_fctr * -breakdown_exp        # noqa: W503\n185                           * (2 * brk_pwr_1 + diode_voltage   # noqa: W503\n186                              * (-breakdown_exp - 1) * brk_pwr_2))  # noqa: W503\n187         else:\n188             grad_i_brk = 0.\n189             grad2i_brk = 0.\n190         grad_i = -g_diode - g_sh - grad_i_recomb - grad_i_brk  # di/dvd\n191         grad_v = 1.0 - grad_i * resistance_series  # dv/dvd\n192         # dp/dv = d(iv)/dv = v * di/dv + i\n193         grad = grad_i / grad_v  # di/dv\n194         grad_p = v * grad + i  # dp/dv\n195         grad2i = -g_diode / nNsVth - grad_2i_recomb - grad2i_brk  # d2i/dvd\n196         grad2v = -grad2i * resistance_series  # d2v/dvd\n197         grad2p = (\n198             grad_v * grad + v * (grad2i/grad_v - grad_i*grad2v/grad_v**2)\n199             + grad_i\n200         )  # d2p/dv/dvd\n201         retval += (grad_i, grad_v, grad, grad_p, grad2p)\n202     return retval\n203 \n204 \n205 def bishop88_i_from_v(voltage, photocurrent, saturation_current,\n206                       resistance_series, resistance_shunt, nNsVth,\n207                       d2mutau=0, NsVbi=np.Inf, breakdown_factor=0.,\n208                       breakdown_voltage=-5.5, breakdown_exp=3.28,\n209                       method='newton'):\n210     \"\"\"\n211     Find current given any voltage.\n212 \n213     Parameters\n214     ----------\n215     voltage : numeric\n216         voltage (V) in volts [V]\n217     photocurrent : numeric\n218         photogenerated current (Iph or IL) [A]\n219     saturation_current : numeric\n220         diode dark or saturation current (Io or Isat) [A]\n221     resistance_series : numeric\n222         series resistance (Rs) in [Ohm]\n223     resistance_shunt : numeric\n224         shunt resistance (Rsh) [Ohm]\n225     nNsVth : numeric\n226         product of diode ideality factor (n), number of series cells (Ns), and\n227         thermal voltage (Vth = k_b * T / q_e) in volts [V]\n228     d2mutau : numeric, default 0\n229         PVsyst parameter for cadmium-telluride (CdTe) and amorphous-silicon\n230         (a-Si) modules that accounts for recombination current in the\n231         intrinsic layer. The value is the ratio of intrinsic layer thickness\n232         squared :math:`d^2` to the diffusion length of charge carriers\n233         :math:`\\\\mu \\\\tau`. [V]\n234     NsVbi : numeric, default np.inf\n235         PVsyst parameter for cadmium-telluride (CdTe) and amorphous-silicon\n236         (a-Si) modules that is the product of the PV module number of series\n237         cells ``Ns`` and the builtin voltage ``Vbi`` of the intrinsic layer.\n238         [V].\n239     breakdown_factor : numeric, default 0\n240         fraction of ohmic current involved in avalanche breakdown :math:`a`.\n241         Default of 0 excludes the reverse bias term from the model. [unitless]\n242     breakdown_voltage : numeric, default -5.5\n243         reverse breakdown voltage of the photovoltaic junction :math:`V_{br}`\n244         [V]\n245     breakdown_exp : numeric, default 3.28\n246         avalanche breakdown exponent :math:`m` [unitless]\n247     method : str, default 'newton'\n248        Either ``'newton'`` or ``'brentq'``. ''method'' must be ``'newton'``\n249        if ``breakdown_factor`` is not 0.\n250 \n251     Returns\n252     -------\n253     current : numeric\n254         current (I) at the specified voltage (V). [A]\n255     \"\"\"\n256     # collect args\n257     args = (photocurrent, saturation_current, resistance_series,\n258             resistance_shunt, nNsVth, d2mutau, NsVbi,\n259             breakdown_factor, breakdown_voltage, breakdown_exp)\n260 \n261     def fv(x, v, *a):\n262         # calculate voltage residual given diode voltage \"x\"\n263         return bishop88(x, *a)[1] - v\n264 \n265     if method.lower() == 'brentq':\n266         # first bound the search using voc\n267         voc_est = estimate_voc(photocurrent, saturation_current, nNsVth)\n268 \n269         # brentq only works with scalar inputs, so we need a set up function\n270         # and np.vectorize to repeatedly call the optimizer with the right\n271         # arguments for possible array input\n272         def vd_from_brent(voc, v, iph, isat, rs, rsh, gamma, d2mutau, NsVbi,\n273                           breakdown_factor, breakdown_voltage, breakdown_exp):\n274             return brentq(fv, 0.0, voc,\n275                           args=(v, iph, isat, rs, rsh, gamma, d2mutau, NsVbi,\n276                                 breakdown_factor, breakdown_voltage,\n277                                 breakdown_exp))\n278 \n279         vd_from_brent_vectorized = np.vectorize(vd_from_brent)\n280         vd = vd_from_brent_vectorized(voc_est, voltage, *args)\n281     elif method.lower() == 'newton':\n282         # make sure all args are numpy arrays if max size > 1\n283         # if voltage is an array, then make a copy to use for initial guess, v0\n284         args, v0 = _prepare_newton_inputs((voltage,), args, voltage)\n285         vd = newton(func=lambda x, *a: fv(x, voltage, *a), x0=v0,\n286                     fprime=lambda x, *a: bishop88(x, *a, gradients=True)[4],\n287                     args=args)\n288     else:\n289         raise NotImplementedError(\"Method '%s' isn't implemented\" % method)\n290     return bishop88(vd, *args)[0]\n291 \n292 \n293 def bishop88_v_from_i(current, photocurrent, saturation_current,\n294                       resistance_series, resistance_shunt, nNsVth,\n295                       d2mutau=0, NsVbi=np.Inf, breakdown_factor=0.,\n296                       breakdown_voltage=-5.5, breakdown_exp=3.28,\n297                       method='newton'):\n298     \"\"\"\n299     Find voltage given any current.\n300 \n301     Parameters\n302     ----------\n303     current : numeric\n304         current (I) in amperes [A]\n305     photocurrent : numeric\n306         photogenerated current (Iph or IL) [A]\n307     saturation_current : numeric\n308         diode dark or saturation current (Io or Isat) [A]\n309     resistance_series : numeric\n310         series resistance (Rs) in [Ohm]\n311     resistance_shunt : numeric\n312         shunt resistance (Rsh) [Ohm]\n313     nNsVth : numeric\n314         product of diode ideality factor (n), number of series cells (Ns), and\n315         thermal voltage (Vth = k_b * T / q_e) in volts [V]\n316     d2mutau : numeric, default 0\n317         PVsyst parameter for cadmium-telluride (CdTe) and amorphous-silicon\n318         (a-Si) modules that accounts for recombination current in the\n319         intrinsic layer. The value is the ratio of intrinsic layer thickness\n320         squared :math:`d^2` to the diffusion length of charge carriers\n321         :math:`\\\\mu \\\\tau`. [V]\n322     NsVbi : numeric, default np.inf\n323         PVsyst parameter for cadmium-telluride (CdTe) and amorphous-silicon\n324         (a-Si) modules that is the product of the PV module number of series\n325         cells ``Ns`` and the builtin voltage ``Vbi`` of the intrinsic layer.\n326         [V].\n327     breakdown_factor : numeric, default 0\n328         fraction of ohmic current involved in avalanche breakdown :math:`a`.\n329         Default of 0 excludes the reverse bias term from the model. [unitless]\n330     breakdown_voltage : numeric, default -5.5\n331         reverse breakdown voltage of the photovoltaic junction :math:`V_{br}`\n332         [V]\n333     breakdown_exp : numeric, default 3.28\n334         avalanche breakdown exponent :math:`m` [unitless]\n335     method : str, default 'newton'\n336        Either ``'newton'`` or ``'brentq'``. ''method'' must be ``'newton'``\n337        if ``breakdown_factor`` is not 0.\n338 \n339     Returns\n340     -------\n341     voltage : numeric\n342         voltage (V) at the specified current (I) in volts [V]\n343     \"\"\"\n344     # collect args\n345     args = (photocurrent, saturation_current, resistance_series,\n346             resistance_shunt, nNsVth, d2mutau, NsVbi, breakdown_factor,\n347             breakdown_voltage, breakdown_exp)\n348     # first bound the search using voc\n349     voc_est = estimate_voc(photocurrent, saturation_current, nNsVth)\n350 \n351     def fi(x, i, *a):\n352         # calculate current residual given diode voltage \"x\"\n353         return bishop88(x, *a)[0] - i\n354 \n355     if method.lower() == 'brentq':\n356         # brentq only works with scalar inputs, so we need a set up function\n357         # and np.vectorize to repeatedly call the optimizer with the right\n358         # arguments for possible array input\n359         def vd_from_brent(voc, i, iph, isat, rs, rsh, gamma, d2mutau, NsVbi,\n360                           breakdown_factor, breakdown_voltage, breakdown_exp):\n361             return brentq(fi, 0.0, voc,\n362                           args=(i, iph, isat, rs, rsh, gamma, d2mutau, NsVbi,\n363                                 breakdown_factor, breakdown_voltage,\n364                                 breakdown_exp))\n365 \n366         vd_from_brent_vectorized = np.vectorize(vd_from_brent)\n367         vd = vd_from_brent_vectorized(voc_est, current, *args)\n368     elif method.lower() == 'newton':\n369         # make sure all args are numpy arrays if max size > 1\n370         # if voc_est is an array, then make a copy to use for initial guess, v0\n371         args, v0 = _prepare_newton_inputs((current,), args, voc_est)\n372         vd = newton(func=lambda x, *a: fi(x, current, *a), x0=v0,\n373                     fprime=lambda x, *a: bishop88(x, *a, gradients=True)[3],\n374                     args=args)\n375     else:\n376         raise NotImplementedError(\"Method '%s' isn't implemented\" % method)\n377     return bishop88(vd, *args)[1]\n378 \n379 \n380 def bishop88_mpp(photocurrent, saturation_current, resistance_series,\n381                  resistance_shunt, nNsVth, d2mutau=0, NsVbi=np.Inf,\n382                  breakdown_factor=0., breakdown_voltage=-5.5,\n383                  breakdown_exp=3.28, method='newton'):\n384     \"\"\"\n385     Find max power point.\n386 \n387     Parameters\n388     ----------\n389     photocurrent : numeric\n390         photogenerated current (Iph or IL) [A]\n391     saturation_current : numeric\n392         diode dark or saturation current (Io or Isat) [A]\n393     resistance_series : numeric\n394         series resistance (Rs) in [Ohm]\n395     resistance_shunt : numeric\n396         shunt resistance (Rsh) [Ohm]\n397     nNsVth : numeric\n398         product of diode ideality factor (n), number of series cells (Ns), and\n399         thermal voltage (Vth = k_b * T / q_e) in volts [V]\n400     d2mutau : numeric, default 0\n401         PVsyst parameter for cadmium-telluride (CdTe) and amorphous-silicon\n402         (a-Si) modules that accounts for recombination current in the\n403         intrinsic layer. The value is the ratio of intrinsic layer thickness\n404         squared :math:`d^2` to the diffusion length of charge carriers\n405         :math:`\\\\mu \\\\tau`. [V]\n406     NsVbi : numeric, default np.inf\n407         PVsyst parameter for cadmium-telluride (CdTe) and amorphous-silicon\n408         (a-Si) modules that is the product of the PV module number of series\n409         cells ``Ns`` and the builtin voltage ``Vbi`` of the intrinsic layer.\n410         [V].\n411     breakdown_factor : numeric, default 0\n412         fraction of ohmic current involved in avalanche breakdown :math:`a`.\n413         Default of 0 excludes the reverse bias term from the model. [unitless]\n414     breakdown_voltage : numeric, default -5.5\n415         reverse breakdown voltage of the photovoltaic junction :math:`V_{br}`\n416         [V]\n417     breakdown_exp : numeric, default 3.28\n418         avalanche breakdown exponent :math:`m` [unitless]\n419     method : str, default 'newton'\n420        Either ``'newton'`` or ``'brentq'``. ''method'' must be ``'newton'``\n421        if ``breakdown_factor`` is not 0.\n422 \n423     Returns\n424     -------\n425     tuple\n426         max power current ``i_mp`` [A], max power voltage ``v_mp`` [V], and\n427         max power ``p_mp`` [W]\n428     \"\"\"\n429     # collect args\n430     args = (photocurrent, saturation_current, resistance_series,\n431             resistance_shunt, nNsVth, d2mutau, NsVbi, breakdown_factor,\n432             breakdown_voltage, breakdown_exp)\n433     # first bound the search using voc\n434     voc_est = estimate_voc(photocurrent, saturation_current, nNsVth)\n435 \n436     def fmpp(x, *a):\n437         return bishop88(x, *a, gradients=True)[6]\n438 \n439     if method.lower() == 'brentq':\n440         # break out arguments for numpy.vectorize to handle broadcasting\n441         vec_fun = np.vectorize(\n442             lambda voc, iph, isat, rs, rsh, gamma, d2mutau, NsVbi, vbr_a, vbr,\n443             vbr_exp: brentq(fmpp, 0.0, voc,\n444                             args=(iph, isat, rs, rsh, gamma, d2mutau, NsVbi,\n445                                   vbr_a, vbr, vbr_exp))\n446         )\n447         vd = vec_fun(voc_est, *args)\n448     elif method.lower() == 'newton':\n449         # make sure all args are numpy arrays if max size > 1\n450         # if voc_est is an array, then make a copy to use for initial guess, v0\n451         args, v0 = _prepare_newton_inputs((), args, voc_est)\n452         vd = newton(\n453             func=fmpp, x0=v0,\n454             fprime=lambda x, *a: bishop88(x, *a, gradients=True)[7], args=args\n455         )\n456     else:\n457         raise NotImplementedError(\"Method '%s' isn't implemented\" % method)\n458     return bishop88(vd, *args)\n459 \n460 \n461 def _get_size_and_shape(args):\n462     # find the right size and shape for returns\n463     size, shape = 0, None  # 0 or None both mean scalar\n464     for arg in args:\n465         try:\n466             this_shape = arg.shape  # try to get shape\n467         except AttributeError:\n468             this_shape = None\n469             try:\n470                 this_size = len(arg)  # try to get the size\n471             except TypeError:\n472                 this_size = 0\n473         else:\n474             this_size = arg.size  # if it has shape then it also has size\n475             if shape is None:\n476                 shape = this_shape  # set the shape if None\n477         # update size and shape\n478         if this_size > size:\n479             size = this_size\n480             if this_shape is not None:\n481                 shape = this_shape\n482     return size, shape\n483 \n484 \n485 def _prepare_newton_inputs(i_or_v_tup, args, v0):\n486     # broadcast arguments for newton method\n487     # the first argument should be a tuple, eg: (i,), (v,) or ()\n488     size, shape = _get_size_and_shape(i_or_v_tup + args)\n489     if size > 1:\n490         args = [np.asarray(arg) for arg in args]\n491     # newton uses initial guess for the output shape\n492     # copy v0 to a new array and broadcast it to the shape of max size\n493     if shape is not None:\n494         v0 = np.broadcast_to(v0, shape).copy()\n495     return args, v0\n496 \n497 \n498 def _lambertw_v_from_i(current, photocurrent, saturation_current,\n499                        resistance_series, resistance_shunt, nNsVth):\n500     # Record if inputs were all scalar\n501     output_is_scalar = all(map(np.isscalar,\n502                                (current, photocurrent, saturation_current,\n503                                 resistance_series, resistance_shunt, nNsVth)))\n504 \n505     # This transforms Gsh=1/Rsh, including ideal Rsh=np.inf into Gsh=0., which\n506     #  is generally more numerically stable\n507     conductance_shunt = 1. / resistance_shunt\n508 \n509     # Ensure that we are working with read-only views of numpy arrays\n510     # Turns Series into arrays so that we don't have to worry about\n511     #  multidimensional broadcasting failing\n512     I, IL, I0, Rs, Gsh, a = \\\n513         np.broadcast_arrays(current, photocurrent, saturation_current,\n514                             resistance_series, conductance_shunt, nNsVth)\n515 \n516     # Intitalize output V (I might not be float64)\n517     V = np.full_like(I, np.nan, dtype=np.float64)\n518 \n519     # Determine indices where 0 < Gsh requires implicit model solution\n520     idx_p = 0. < Gsh\n521 \n522     # Determine indices where 0 = Gsh allows explicit model solution\n523     idx_z = 0. == Gsh\n524 \n525     # Explicit solutions where Gsh=0\n526     if np.any(idx_z):\n527         V[idx_z] = a[idx_z] * np.log1p((IL[idx_z] - I[idx_z]) / I0[idx_z]) - \\\n528                    I[idx_z] * Rs[idx_z]\n529 \n530     # Only compute using LambertW if there are cases with Gsh>0\n531     if np.any(idx_p):\n532         # LambertW argument, cannot be float128, may overflow to np.inf\n533         # overflow is explicitly handled below, so ignore warnings here\n534         with np.errstate(over='ignore'):\n535             argW = (I0[idx_p] / (Gsh[idx_p] * a[idx_p]) *\n536                     np.exp((-I[idx_p] + IL[idx_p] + I0[idx_p]) /\n537                            (Gsh[idx_p] * a[idx_p])))\n538 \n539         # lambertw typically returns complex value with zero imaginary part\n540         # may overflow to np.inf\n541         lambertwterm = lambertw(argW).real\n542 \n543         # Record indices where lambertw input overflowed output\n544         idx_inf = np.logical_not(np.isfinite(lambertwterm))\n545 \n546         # Only re-compute LambertW if it overflowed\n547         if np.any(idx_inf):\n548             # Calculate using log(argW) in case argW is really big\n549             logargW = (np.log(I0[idx_p]) - np.log(Gsh[idx_p]) -\n550                        np.log(a[idx_p]) +\n551                        (-I[idx_p] + IL[idx_p] + I0[idx_p]) /\n552                        (Gsh[idx_p] * a[idx_p]))[idx_inf]\n553 \n554             # Three iterations of Newton-Raphson method to solve\n555             #  w+log(w)=logargW. The initial guess is w=logargW. Where direct\n556             #  evaluation (above) results in NaN from overflow, 3 iterations\n557             #  of Newton's method gives approximately 8 digits of precision.\n558             w = logargW\n559             for _ in range(0, 3):\n560                 w = w * (1. - np.log(w) + logargW) / (1. + w)\n561             lambertwterm[idx_inf] = w\n562 \n563         # Eqn. 3 in Jain and Kapoor, 2004\n564         #  V = -I*(Rs + Rsh) + IL*Rsh - a*lambertwterm + I0*Rsh\n565         # Recast in terms of Gsh=1/Rsh for better numerical stability.\n566         V[idx_p] = (IL[idx_p] + I0[idx_p] - I[idx_p]) / Gsh[idx_p] - \\\n567             I[idx_p] * Rs[idx_p] - a[idx_p] * lambertwterm\n568 \n569     if output_is_scalar:\n570         return V.item()\n571     else:\n572         return V\n573 \n574 \n575 def _lambertw_i_from_v(voltage, photocurrent, saturation_current,\n576                        resistance_series, resistance_shunt, nNsVth):\n577     # Record if inputs were all scalar\n578     output_is_scalar = all(map(np.isscalar,\n579                                (voltage, photocurrent, saturation_current,\n580                                 resistance_series, resistance_shunt, nNsVth)))\n581 \n582     # This transforms Gsh=1/Rsh, including ideal Rsh=np.inf into Gsh=0., which\n583     #  is generally more numerically stable\n584     conductance_shunt = 1. / resistance_shunt\n585 \n586     # Ensure that we are working with read-only views of numpy arrays\n587     # Turns Series into arrays so that we don't have to worry about\n588     #  multidimensional broadcasting failing\n589     V, IL, I0, Rs, Gsh, a = \\\n590         np.broadcast_arrays(voltage, photocurrent, saturation_current,\n591                             resistance_series, conductance_shunt, nNsVth)\n592 \n593     # Intitalize output I (V might not be float64)\n594     I = np.full_like(V, np.nan, dtype=np.float64)           # noqa: E741, N806\n595 \n596     # Determine indices where 0 < Rs requires implicit model solution\n597     idx_p = 0. < Rs\n598 \n599     # Determine indices where 0 = Rs allows explicit model solution\n600     idx_z = 0. == Rs\n601 \n602     # Explicit solutions where Rs=0\n603     if np.any(idx_z):\n604         I[idx_z] = IL[idx_z] - I0[idx_z] * np.expm1(V[idx_z] / a[idx_z]) - \\\n605                    Gsh[idx_z] * V[idx_z]\n606 \n607     # Only compute using LambertW if there are cases with Rs>0\n608     # Does NOT handle possibility of overflow, github issue 298\n609     if np.any(idx_p):\n610         # LambertW argument, cannot be float128, may overflow to np.inf\n611         argW = Rs[idx_p] * I0[idx_p] / (\n612                     a[idx_p] * (Rs[idx_p] * Gsh[idx_p] + 1.)) * \\\n613                np.exp((Rs[idx_p] * (IL[idx_p] + I0[idx_p]) + V[idx_p]) /\n614                       (a[idx_p] * (Rs[idx_p] * Gsh[idx_p] + 1.)))\n615 \n616         # lambertw typically returns complex value with zero imaginary part\n617         # may overflow to np.inf\n618         lambertwterm = lambertw(argW).real\n619 \n620         # Eqn. 2 in Jain and Kapoor, 2004\n621         #  I = -V/(Rs + Rsh) - (a/Rs)*lambertwterm + Rsh*(IL + I0)/(Rs + Rsh)\n622         # Recast in terms of Gsh=1/Rsh for better numerical stability.\n623         I[idx_p] = (IL[idx_p] + I0[idx_p] - V[idx_p] * Gsh[idx_p]) / \\\n624                    (Rs[idx_p] * Gsh[idx_p] + 1.) - (\n625                                a[idx_p] / Rs[idx_p]) * lambertwterm\n626 \n627     if output_is_scalar:\n628         return I.item()\n629     else:\n630         return I\n631 \n632 \n633 def _lambertw(photocurrent, saturation_current, resistance_series,\n634               resistance_shunt, nNsVth, ivcurve_pnts=None):\n635     # collect args\n636     params = {'photocurrent': photocurrent,\n637               'saturation_current': saturation_current,\n638               'resistance_series': resistance_series,\n639               'resistance_shunt': resistance_shunt, 'nNsVth': nNsVth}\n640 \n641     # Compute short circuit current\n642     i_sc = _lambertw_i_from_v(0., **params)\n643 \n644     # Compute open circuit voltage\n645     v_oc = _lambertw_v_from_i(0., **params)\n646 \n647     # Find the voltage, v_mp, where the power is maximized.\n648     # Start the golden section search at v_oc * 1.14\n649     p_mp, v_mp = _golden_sect_DataFrame(params, 0., v_oc * 1.14, _pwr_optfcn)\n650 \n651     # Find Imp using Lambert W\n652     i_mp = _lambertw_i_from_v(v_mp, **params)\n653 \n654     # Find Ix and Ixx using Lambert W\n655     i_x = _lambertw_i_from_v(0.5 * v_oc, **params)\n656 \n657     i_xx = _lambertw_i_from_v(0.5 * (v_oc + v_mp), **params)\n658 \n659     out = (i_sc, v_oc, i_mp, v_mp, p_mp, i_x, i_xx)\n660 \n661     # create ivcurve\n662     if ivcurve_pnts:\n663         ivcurve_v = (np.asarray(v_oc)[..., np.newaxis] *\n664                      np.linspace(0, 1, ivcurve_pnts))\n665 \n666         ivcurve_i = _lambertw_i_from_v(ivcurve_v.T, **params).T\n667 \n668         out += (ivcurve_i, ivcurve_v)\n669 \n670     return out\n671 \n672 \n673 def _pwr_optfcn(df, loc):\n674     '''\n675     Function to find power from ``i_from_v``.\n676     '''\n677 \n678     current = _lambertw_i_from_v(df[loc], df['photocurrent'],\n679                                  df['saturation_current'],\n680                                  df['resistance_series'],\n681                                  df['resistance_shunt'], df['nNsVth'])\n682 \n683     return current * df[loc]\n684 \n[end of pvlib/singlediode.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n\n\n", "full_output": "```patch\n--- a/pvlib/singlediode.py\n+++ b/pvlib/singlediode.py\n@@ -12,7 +12,8 @@\n \n # set keyword arguments for all uses of newton in this module\n-newton = partial(newton, tol=1e-6, maxiter=100, fprime2=None)\n+newton_default = partial(newton, tol=1e-6, maxiter=100, fprime2=None)\n+\n \n def estimate_voc(photocurrent, saturation_current, nNsVth):\n     \"\"\"\n@@ -204,7 +205,7 @@\n def bishop88_mpp(photocurrent, saturation_current, resistance_series,\n                  resistance_shunt, nNsVth, d2mutau=0, NsVbi=np.Inf,\n                  breakdown_factor=0., breakdown_voltage=-5.5,\n-                 breakdown_exp=3.28, method='newton'):\n+                 breakdown_exp=3.28, method='newton', tol=1e-6, maxiter=100):\n     \"\"\"\n     Find max power point.\n \n@@ -430,7 +431,7 @@\n     if method.lower() == 'brentq':\n         # break out arguments for numpy.vectorize to handle broadcasting\n         vec_fun = np.vectorize(\n-             lambda voc, iph, isat, rs, rsh, gamma, d2mutau, NsVbi, vbr_a, vbr,\n+             lambda voc, iph, isat, rs, rsh, gamma, d2mutau, NsVbi, vbr_a, vbr, vbr_exp: \n              brentq(fmpp, 0.0, voc,\n                      args=(iph, isat, rs, rsh, gamma, d2mutau, NsVbi,\n                            vbr_a, vbr, vbr_exp))\n@@ -451,7 +452\n         args, v0 = _prepare_newton_inputs((), args, voc_est)\n         vd = newton(\n-             func=fmpp, x0=v0,\n+             func=fmpp, x0=v0, \n              fprime=lambda x, *a: bishop88(x, *a, gradients=True)[7], args=args,\n+             tol=tol, maxiter=maxiter\n         )\n     else:\n         raise NotImplementedError(\"Method '%s' isn't implemented\" % method)\n``` \n\nThis patch modifies the `pvlib/singlediode.py` file to allow users to set `tol` and `maxiter` as keyword arguments in the `bishop88_mpp` function. The default values are set to `1e-6` and `100`, respectively. The `newton` function is now called with these parameters when the method is 'newton'.", "model_patch": "--- a/pvlib/singlediode.py\n+++ b/pvlib/singlediode.py\n@@ -12,7 +12,8 @@\n \n # set keyword arguments for all uses of newton in this module\n-newton = partial(newton, tol=1e-6, maxiter=100, fprime2=None)\n+newton_default = partial(newton, tol=1e-6, maxiter=100, fprime2=None)\n+\n \n def estimate_voc(photocurrent, saturation_current, nNsVth):\n     \"\"\"\n@@ -204,7 +205,7 @@\n def bishop88_mpp(photocurrent, saturation_current, resistance_series,\n                  resistance_shunt, nNsVth, d2mutau=0, NsVbi=np.Inf,\n                  breakdown_factor=0., breakdown_voltage=-5.5,\n-                 breakdown_exp=3.28, method='newton'):\n+                 breakdown_exp=3.28, method='newton', tol=1e-6, maxiter=100):\n     \"\"\"\n     Find max power point.\n \n@@ -430,7 +431,7 @@\n     if method.lower() == 'brentq':\n         # break out arguments for numpy.vectorize to handle broadcasting\n         vec_fun = np.vectorize(\n-             lambda voc, iph, isat, rs, rsh, gamma, d2mutau, NsVbi, vbr_a, vbr,\n+             lambda voc, iph, isat, rs, rsh, gamma, d2mutau, NsVbi, vbr_a, vbr, vbr_exp: \n              brentq(fmpp, 0.0, voc,\n                      args=(iph, isat, rs, rsh, gamma, d2mutau, NsVbi,\n                            vbr_a, vbr, vbr_exp))\n@@ -451,7 +452\n         args, v0 = _prepare_newton_inputs((), args, voc_est)\n         vd = newton(\n-             func=fmpp, x0=v0,\n+             func=fmpp, x0=v0, \n              fprime=lambda x, *a: bishop88(x, *a, gradients=True)[7], args=args,\n+             tol=tol, maxiter=maxiter\n         )\n     else:\n         raise NotImplementedError(\"Method '%s' isn't implemented\" % method)\n"}
{"instance_id": "pvlib__pvlib-python-1480", "model_name_or_path": "gpt-4o-mini", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nConsider extracting the surface orientation calculation in pvlib.tracking.singleaxis() to its own function\n**Is your feature request related to a problem? Please describe.**\r\nThe usual workflow for modeling single-axis tracking in pvlib is to treat tracker rotation (`tracker_theta`) as an unknown to be calculated from solar position and array geometry.  However, sometimes a user might have their own tracker rotations but not have the corresponding `surface_tilt` and `surface_azimuth` values.  Here are a few motivating examples:\r\n- Using measured rotation angles\r\n- Post-processing the output of `tracking.singleaxis()` to include wind stow events or tracker stalls\r\n- Other tracking algorithms that determine rotation differently from the astronomical method\r\n\r\nAssuming I have my tracker rotations already in hand, getting the corresponding `surface_tilt` and `surface_azimuth` angles is not as easy as it should be.  For the specific case of horizontal N-S axis the math isn't so bad, but either way it's annoying to have to DIY when pvlib already has code to calculate those angles from tracker rotation.\r\n\r\n**Describe the solution you'd like**\r\nA function `pvlib.tracking.rotation_to_orientation` that implements the same math in `pvlib.tracking.singleaxis` to go from `tracker_theta` to `surface_tilt` and `surface_azimuth`.  Basically extract out the second half of `tracking.singleaxis` into a new function.  Suggestions for the function name are welcome.  To be explicit, this is more or less what I'm imagining:\r\n\r\n```python\r\ndef rotation_to_orientation(tracker_theta, axis_tilt=0, axis_azimuth=0, max_angle=90):\r\n    # insert math from second half of tracking.singleaxis() here\r\n    out = {'tracker_theta': tracker_theta, 'aoi': aoi,\r\n           'surface_tilt': surface_tilt, 'surface_azimuth': surface_azimuth}\r\n    return pandas_if_needed(out)\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nContinue suffering\r\n\r\n**Additional context**\r\nThis is one step towards a broader goal I have for `pvlib.tracking` to house other methods to determine tracker rotation in addition to the current astronomical method, the same way we have multiple temperature and transposition models.  These functions would be responsible for determining tracker rotations, and they'd all use this `rotation_to_orientation` function to convert rotation to module orientation.\r\n\r\nSeparately, I wonder if the code could be simplified using the tilt and azimuth equations in Bill's technical report (https://www.nrel.gov/docs/fy13osti/58891.pdf) -- seems like what we're doing is overly complicated, although maybe I've just not studied it closely enough.\r\n\r\ncc @williamhobbs @spaneja \n\n</issue>\n<code>\n[start of README.md]\n1 <img src=\"docs/sphinx/source/_images/pvlib_logo_horiz.png\" width=\"600\">\n2 \n3 <table>\n4 <tr>\n5   <td>Latest Release</td>\n6   <td>\n7     <a href=\"https://pypi.org/project/pvlib/\">\n8     <img src=\"https://img.shields.io/pypi/v/pvlib.svg\" alt=\"latest release\" />\n9     </a>\n10     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n11     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/version.svg\" />\n12     </a>\n13     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n14     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/latest_release_date.svg\" />\n15     </a>\n16 </tr>\n17 <tr>\n18   <td>License</td>\n19   <td>\n20     <a href=\"https://github.com/pvlib/pvlib-python/blob/master/LICENSE\">\n21     <img src=\"https://img.shields.io/pypi/l/pvlib.svg\" alt=\"license\" />\n22     </a>\n23 </td>\n24 </tr>\n25 <tr>\n26   <td>Build Status</td>\n27   <td>\n28     <a href=\"http://pvlib-python.readthedocs.org/en/stable/\">\n29     <img src=\"https://readthedocs.org/projects/pvlib-python/badge/?version=stable\" alt=\"documentation build status\" />\n30     </a>\n31     <a href=\"https://dev.azure.com/solararbiter/pvlib%20python/_build/latest?definitionId=4&branchName=master\">\n32       <img src=\"https://dev.azure.com/solararbiter/pvlib%20python/_apis/build/status/pvlib.pvlib-python?branchName=master\" alt=\"Azure Pipelines build status\" />\n33     </a>\n34   </td>\n35 </tr>\n36 <tr>\n37   <td>Code Quality</td>\n38   <td>\n39     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/context:python\">\n40     <img src=\"https://img.shields.io/lgtm/grade/python/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm quality grade\" />\n41     </a>\n42     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/alerts\">\n43     <img src=\"https://img.shields.io/lgtm/alerts/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm alters\" />\n44     </a>\n45   </td>\n46 </tr>\n47 <tr>\n48   <td>Coverage</td>\n49   <td>\n50     <a href=\"https://coveralls.io/r/pvlib/pvlib-python\">\n51     <img src=\"https://img.shields.io/coveralls/pvlib/pvlib-python.svg\" alt=\"coveralls coverage\" />\n52     </a>\n53     <a href=\"https://codecov.io/gh/pvlib/pvlib-python\">\n54     <img src=\"https://codecov.io/gh/pvlib/pvlib-python/branch/master/graph/badge.svg\" alt=\"codecov coverage\" />\n55     </a>\n56   </td>\n57 </tr>\n58 <tr>\n59   <td>Benchmarks</td>\n60   <td>\n61     <a href=\"https://pvlib-benchmarker.github.io/pvlib-benchmarks/\">\n62     <img src=\"https://img.shields.io/badge/benchmarks-asv-lightgrey\" />\n63     </a>\n64   </td>\n65 </tr>\n66 <tr>\n67   <td>Publications</td>\n68   <td>\n69     <a href=\"https://doi.org/10.5281/zenodo.593284\">\n70     <img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.593284.svg\" alt=\"zenodo reference\">\n71     </a>\n72     <a href=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1\">\n73     <img src=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1/status.svg\" alt=\"JOSS reference\" />\n74     </a>\n75   </td>\n76 </tr>\n77 <tr>\n78   <td>Downloads</td>\n79   <td>\n80     <a href=\"https://pypi.org/project/pvlib/\">\n81     <img src=\"https://img.shields.io/pypi/dm/pvlib\" alt=\"PyPI downloads\" />\n82     </a>\n83     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n84     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/downloads.svg\" alt=\"conda-forge downloads\" />\n85     </a>\n86   </td>\n87 </tr>\n88 </table>\n89 \n90 \n91 pvlib python is a community supported tool that provides a set of\n92 functions and classes for simulating the performance of photovoltaic\n93 energy systems. pvlib python was originally ported from the PVLIB MATLAB\n94 toolbox developed at Sandia National Laboratories and it implements many\n95 of the models and methods developed at the Labs. More information on\n96 Sandia Labs PV performance modeling programs can be found at\n97 https://pvpmc.sandia.gov/. We collaborate with the PVLIB MATLAB project,\n98 but operate independently of it.\n99 \n100 \n101 Documentation\n102 =============\n103 \n104 Full documentation can be found at [readthedocs](http://pvlib-python.readthedocs.io/en/stable/).\n105 \n106 \n107 Installation\n108 ============\n109 \n110 pvlib-python releases may be installed using the ``pip`` and ``conda`` tools.\n111 Please see the [Installation page](https://pvlib-python.readthedocs.io/en/stable/user_guide/installation.html) of the documentation for complete instructions.\n112 \n113 \n114 Contributing\n115 ============\n116 \n117 We need your help to make pvlib-python a great tool!\n118 Please see the [Contributing page](http://pvlib-python.readthedocs.io/en/stable/contributing.html) for more on how you can contribute.\n119 The long-term success of pvlib-python requires substantial community support.\n120 \n121 \n122 Citing\n123 ======\n124 \n125 If you use pvlib-python in a published work, please cite:\n126 \n127   William F. Holmgren, Clifford W. Hansen, and Mark A. Mikofski.\n128   \"pvlib python: a python package for modeling solar energy systems.\"\n129   Journal of Open Source Software, 3(29), 884, (2018).\n130   https://doi.org/10.21105/joss.00884\n131 \n132 Please also cite the DOI corresponding to the specific version of\n133 pvlib-python that you used. pvlib-python DOIs are listed at\n134 [Zenodo.org](https://zenodo.org/search?page=1&size=20&q=conceptrecid:593284&all_versions&sort=-version)\n135 \n136 If you use pvlib-python in a commercial or publicly-available application, please\n137 consider displaying one of the \"powered by pvlib\" logos:\n138 \n139 <img src=\"docs/sphinx/source/_images/pvlib_powered_logo_vert.png\" width=\"300\"><img src=\"docs/sphinx/source/_images/pvlib_powered_logo_horiz.png\" width=\"300\">\n140 \n141 Getting support\n142 ===============\n143 \n144 pvlib usage questions can be asked on\n145 [Stack Overflow](http://stackoverflow.com) and tagged with\n146 the [pvlib](http://stackoverflow.com/questions/tagged/pvlib) tag.\n147 \n148 The [pvlib-python google group](https://groups.google.com/forum/#!forum/pvlib-python)\n149 is used for discussing various topics of interest to the pvlib-python\n150 community. We also make new version announcements on the google group.\n151 \n152 If you suspect that you may have discovered a bug or if you'd like to\n153 change something about pvlib, then please make an issue on our\n154 [GitHub issues page](https://github.com/pvlib/pvlib-python/issues).\n155 \n156 \n157 \n158 License\n159 =======\n160 \n161 BSD 3-clause.\n162 \n163 \n164 NumFOCUS\n165 ========\n166 \n167 pvlib python is a [NumFOCUS Affiliated Project](https://numfocus.org/sponsored-projects/affiliated-projects)\n168 \n169 [![NumFocus Affliated Projects](https://i0.wp.com/numfocus.org/wp-content/uploads/2019/06/AffiliatedProject.png)](https://numfocus.org/sponsored-projects/affiliated-projects)\n170 \n[end of README.md]\n[start of pvlib/tools.py]\n1 \"\"\"\n2 Collection of functions used in pvlib_python\n3 \"\"\"\n4 \n5 import datetime as dt\n6 import numpy as np\n7 import pandas as pd\n8 import pytz\n9 import warnings\n10 \n11 \n12 def cosd(angle):\n13     \"\"\"\n14     Cosine with angle input in degrees\n15 \n16     Parameters\n17     ----------\n18     angle : float or array-like\n19         Angle in degrees\n20 \n21     Returns\n22     -------\n23     result : float or array-like\n24         Cosine of the angle\n25     \"\"\"\n26 \n27     res = np.cos(np.radians(angle))\n28     return res\n29 \n30 \n31 def sind(angle):\n32     \"\"\"\n33     Sine with angle input in degrees\n34 \n35     Parameters\n36     ----------\n37     angle : float\n38         Angle in degrees\n39 \n40     Returns\n41     -------\n42     result : float\n43         Sin of the angle\n44     \"\"\"\n45 \n46     res = np.sin(np.radians(angle))\n47     return res\n48 \n49 \n50 def tand(angle):\n51     \"\"\"\n52     Tan with angle input in degrees\n53 \n54     Parameters\n55     ----------\n56     angle : float\n57         Angle in degrees\n58 \n59     Returns\n60     -------\n61     result : float\n62         Tan of the angle\n63     \"\"\"\n64 \n65     res = np.tan(np.radians(angle))\n66     return res\n67 \n68 \n69 def asind(number):\n70     \"\"\"\n71     Inverse Sine returning an angle in degrees\n72 \n73     Parameters\n74     ----------\n75     number : float\n76         Input number\n77 \n78     Returns\n79     -------\n80     result : float\n81         arcsin result\n82     \"\"\"\n83 \n84     res = np.degrees(np.arcsin(number))\n85     return res\n86 \n87 \n88 def localize_to_utc(time, location):\n89     \"\"\"\n90     Converts or localizes a time series to UTC.\n91 \n92     Parameters\n93     ----------\n94     time : datetime.datetime, pandas.DatetimeIndex,\n95            or pandas.Series/DataFrame with a DatetimeIndex.\n96     location : pvlib.Location object\n97 \n98     Returns\n99     -------\n100     pandas object localized to UTC.\n101     \"\"\"\n102     if isinstance(time, dt.datetime):\n103         if time.tzinfo is None:\n104             time = pytz.timezone(location.tz).localize(time)\n105         time_utc = time.astimezone(pytz.utc)\n106     else:\n107         try:\n108             time_utc = time.tz_convert('UTC')\n109         except TypeError:\n110             time_utc = time.tz_localize(location.tz).tz_convert('UTC')\n111 \n112     return time_utc\n113 \n114 \n115 def datetime_to_djd(time):\n116     \"\"\"\n117     Converts a datetime to the Dublin Julian Day\n118 \n119     Parameters\n120     ----------\n121     time : datetime.datetime\n122         time to convert\n123 \n124     Returns\n125     -------\n126     float\n127         fractional days since 12/31/1899+0000\n128     \"\"\"\n129 \n130     if time.tzinfo is None:\n131         time_utc = pytz.utc.localize(time)\n132     else:\n133         time_utc = time.astimezone(pytz.utc)\n134 \n135     djd_start = pytz.utc.localize(dt.datetime(1899, 12, 31, 12))\n136     djd = (time_utc - djd_start).total_seconds() * 1.0/(60 * 60 * 24)\n137 \n138     return djd\n139 \n140 \n141 def djd_to_datetime(djd, tz='UTC'):\n142     \"\"\"\n143     Converts a Dublin Julian Day float to a datetime.datetime object\n144 \n145     Parameters\n146     ----------\n147     djd : float\n148         fractional days since 12/31/1899+0000\n149     tz : str, default 'UTC'\n150         timezone to localize the result to\n151 \n152     Returns\n153     -------\n154     datetime.datetime\n155        The resultant datetime localized to tz\n156     \"\"\"\n157 \n158     djd_start = pytz.utc.localize(dt.datetime(1899, 12, 31, 12))\n159 \n160     utc_time = djd_start + dt.timedelta(days=djd)\n161     return utc_time.astimezone(pytz.timezone(tz))\n162 \n163 \n164 def _pandas_to_doy(pd_object):\n165     \"\"\"\n166     Finds the day of year for a pandas datetime-like object.\n167 \n168     Useful for delayed evaluation of the dayofyear attribute.\n169 \n170     Parameters\n171     ----------\n172     pd_object : DatetimeIndex or Timestamp\n173 \n174     Returns\n175     -------\n176     dayofyear\n177     \"\"\"\n178     return pd_object.dayofyear\n179 \n180 \n181 def _doy_to_datetimeindex(doy, epoch_year=2014):\n182     \"\"\"\n183     Convert a day of year scalar or array to a pd.DatetimeIndex.\n184 \n185     Parameters\n186     ----------\n187     doy : numeric\n188         Contains days of the year\n189 \n190     Returns\n191     -------\n192     pd.DatetimeIndex\n193     \"\"\"\n194     doy = np.atleast_1d(doy).astype('float')\n195     epoch = pd.Timestamp('{}-12-31'.format(epoch_year - 1))\n196     timestamps = [epoch + dt.timedelta(days=adoy) for adoy in doy]\n197     return pd.DatetimeIndex(timestamps)\n198 \n199 \n200 def _datetimelike_scalar_to_doy(time):\n201     return pd.DatetimeIndex([pd.Timestamp(time)]).dayofyear\n202 \n203 \n204 def _datetimelike_scalar_to_datetimeindex(time):\n205     return pd.DatetimeIndex([pd.Timestamp(time)])\n206 \n207 \n208 def _scalar_out(arg):\n209     if np.isscalar(arg):\n210         output = arg\n211     else:  #\n212         # works if it's a 1 length array and\n213         # will throw a ValueError otherwise\n214         output = np.asarray(arg).item()\n215 \n216     return output\n217 \n218 \n219 def _array_out(arg):\n220     if isinstance(arg, pd.Series):\n221         output = arg.values\n222     else:\n223         output = arg\n224 \n225     return output\n226 \n227 \n228 def _build_kwargs(keys, input_dict):\n229     \"\"\"\n230     Parameters\n231     ----------\n232     keys : iterable\n233         Typically a list of strings.\n234     input_dict : dict-like\n235         A dictionary from which to attempt to pull each key.\n236 \n237     Returns\n238     -------\n239     kwargs : dict\n240         A dictionary with only the keys that were in input_dict\n241     \"\"\"\n242 \n243     kwargs = {}\n244     for key in keys:\n245         try:\n246             kwargs[key] = input_dict[key]\n247         except KeyError:\n248             pass\n249 \n250     return kwargs\n251 \n252 \n253 def _build_args(keys, input_dict, dict_name):\n254     \"\"\"\n255     Parameters\n256     ----------\n257     keys : iterable\n258         Typically a list of strings.\n259     input_dict : dict-like\n260         A dictionary from which to pull each key.\n261     dict_name : str\n262         A variable name to include in an error message for missing keys\n263 \n264     Returns\n265     -------\n266     kwargs : list\n267         A list with values corresponding to keys\n268     \"\"\"\n269     try:\n270         args = [input_dict[key] for key in keys]\n271     except KeyError as e:\n272         missing_key = e.args[0]\n273         msg = (f\"Missing required parameter '{missing_key}'. Found \"\n274                f\"{input_dict} in {dict_name}.\")\n275         raise KeyError(msg)\n276     return args\n277 \n278 \n279 # Created April,2014\n280 # Author: Rob Andrews, Calama Consulting\n281 # Modified: November, 2020 by C. W. Hansen, to add atol and change exit\n282 # criteria\n283 def _golden_sect_DataFrame(params, lower, upper, func, atol=1e-8):\n284     \"\"\"\n285     Vectorized golden section search for finding maximum of a function of a\n286     single variable.\n287 \n288     Parameters\n289     ----------\n290     params : dict of numeric\n291         Parameters to be passed to `func`. Each entry must be of the same\n292         length.\n293 \n294     lower: numeric\n295         Lower bound for the optimization. Must be the same length as each\n296         entry of params.\n297 \n298     upper: numeric\n299         Upper bound for the optimization. Must be the same length as each\n300         entry of params.\n301 \n302     func: function\n303         Function to be optimized. Must be in the form\n304         result = f(dict or DataFrame, str), where result is a dict or DataFrame\n305         that also contains the function output, and str is the key\n306         corresponding to the function's input variable.\n307 \n308     Returns\n309     -------\n310     numeric\n311         function evaluated at the optimal points\n312 \n313     numeric\n314         optimal points\n315 \n316     Notes\n317     -----\n318     This function will find the points where the function is maximized.\n319     Returns nan where lower or upper is nan, or where func evaluates to nan.\n320 \n321     See also\n322     --------\n323     pvlib.singlediode._pwr_optfcn\n324     \"\"\"\n325 \n326     phim1 = (np.sqrt(5) - 1) / 2\n327 \n328     df = params\n329     df['VH'] = upper\n330     df['VL'] = lower\n331 \n332     converged = False\n333     iterations = 0\n334 \n335     # handle all NaN case gracefully\n336     with warnings.catch_warnings():\n337         warnings.filterwarnings(action='ignore',\n338                                 message='All-NaN slice encountered')\n339         iterlimit = 1 + np.nanmax(\n340             np.trunc(np.log(atol / (df['VH'] - df['VL'])) / np.log(phim1)))\n341 \n342     while not converged and (iterations <= iterlimit):\n343 \n344         phi = phim1 * (df['VH'] - df['VL'])\n345         df['V1'] = df['VL'] + phi\n346         df['V2'] = df['VH'] - phi\n347 \n348         df['f1'] = func(df, 'V1')\n349         df['f2'] = func(df, 'V2')\n350         df['SW_Flag'] = df['f1'] > df['f2']\n351 \n352         df['VL'] = df['V2']*df['SW_Flag'] + df['VL']*(~df['SW_Flag'])\n353         df['VH'] = df['V1']*~df['SW_Flag'] + df['VH']*(df['SW_Flag'])\n354 \n355         err = abs(df['V2'] - df['V1'])\n356 \n357         # works with single value because err is np.float64\n358         converged = (err[~np.isnan(err)] < atol).all()\n359         # err will be less than atol before iterations hit the limit\n360         # but just to be safe\n361         iterations += 1\n362 \n363     if iterations > iterlimit:\n364         raise Exception(\"Iterations exceeded maximum. Check that func\",\n365                         \" is not NaN in (lower, upper)\")  # pragma: no cover\n366 \n367     try:\n368         func_result = func(df, 'V1')\n369         x = np.where(np.isnan(func_result), np.nan, df['V1'])\n370     except KeyError:\n371         func_result = np.full_like(upper, np.nan)\n372         x = func_result.copy()\n373 \n374     return func_result, x\n375 \n376 \n377 def _get_sample_intervals(times, win_length):\n378     \"\"\" Calculates time interval and samples per window for Reno-style clear\n379     sky detection functions\n380     \"\"\"\n381     deltas = np.diff(times.values) / np.timedelta64(1, '60s')\n382 \n383     # determine if we can proceed\n384     if times.inferred_freq and len(np.unique(deltas)) == 1:\n385         sample_interval = times[1] - times[0]\n386         sample_interval = sample_interval.seconds / 60  # in minutes\n387         samples_per_window = int(win_length / sample_interval)\n388         return sample_interval, samples_per_window\n389     else:\n390         raise NotImplementedError('algorithm does not yet support unequal '\n391                                   'times. consider resampling your data.')\n392 \n[end of pvlib/tools.py]\n[start of pvlib/tracking.py]\n1 import numpy as np\n2 import pandas as pd\n3 \n4 from pvlib.tools import cosd, sind, tand\n5 from pvlib.pvsystem import (\n6     PVSystem, Array, SingleAxisTrackerMount, _unwrap_single_value\n7 )\n8 from pvlib import irradiance, atmosphere\n9 from pvlib._deprecation import deprecated\n10 \n11 \n12 @deprecated('0.9.0', alternative='PVSystem with SingleAxisTrackerMount')\n13 class SingleAxisTracker(PVSystem):\n14     \"\"\"\n15     A class for single-axis trackers that inherits the PV modeling methods from\n16     :py:class:`~pvlib.pvsystem.PVSystem`. For details on calculating tracker\n17     rotation see :py:func:`pvlib.tracking.singleaxis`.\n18 \n19     Parameters\n20     ----------\n21     axis_tilt : float, default 0\n22         The tilt of the axis of rotation (i.e, the y-axis defined by\n23         axis_azimuth) with respect to horizontal, in decimal degrees.\n24 \n25     axis_azimuth : float, default 0\n26         A value denoting the compass direction along which the axis of\n27         rotation lies. Measured in decimal degrees east of north.\n28 \n29     max_angle : float, default 90\n30         A value denoting the maximum rotation angle, in decimal degrees,\n31         of the one-axis tracker from its horizontal position (horizontal\n32         if axis_tilt = 0). A max_angle of 90 degrees allows the tracker\n33         to rotate to a vertical position to point the panel towards a\n34         horizon. max_angle of 180 degrees allows for full rotation.\n35 \n36     backtrack : bool, default True\n37         Controls whether the tracker has the capability to \"backtrack\"\n38         to avoid row-to-row shading. False denotes no backtrack\n39         capability. True denotes backtrack capability.\n40 \n41     gcr : float, default 2.0/7.0\n42         A value denoting the ground coverage ratio of a tracker system\n43         which utilizes backtracking; i.e. the ratio between the PV array\n44         surface area to total ground area. A tracker system with modules\n45         2 meters wide, centered on the tracking axis, with 6 meters\n46         between the tracking axes has a gcr of 2/6=0.333. If gcr is not\n47         provided, a gcr of 2/7 is default. gcr must be <=1.\n48 \n49     cross_axis_tilt : float, default 0.0\n50         The angle, relative to horizontal, of the line formed by the\n51         intersection between the slope containing the tracker axes and a plane\n52         perpendicular to the tracker axes. Cross-axis tilt should be specified\n53         using a right-handed convention. For example, trackers with axis\n54         azimuth of 180 degrees (heading south) will have a negative cross-axis\n55         tilt if the tracker axes plane slopes down to the east and positive\n56         cross-axis tilt if the tracker axes plane slopes up to the east. Use\n57         :func:`~pvlib.tracking.calc_cross_axis_tilt` to calculate\n58         `cross_axis_tilt`. [degrees]\n59 \n60     **kwargs\n61         Passed to :py:class:`~pvlib.pvsystem.PVSystem`. If the `arrays`\n62         parameter is specified it must have only a single Array. Furthermore\n63         if a :py:class:`~pvlib.pvsystem.Array` is provided it must have\n64         ``surface_tilt`` and ``surface_azimuth`` equal to None.\n65 \n66     Raises\n67     ------\n68     ValueError\n69         If more than one Array is specified.\n70     ValueError\n71         If an Array is provided with a surface tilt or azimuth not None.\n72 \n73     See also\n74     --------\n75     pvlib.tracking.singleaxis\n76     pvlib.tracking.calc_axis_tilt\n77     pvlib.tracking.calc_cross_axis_tilt\n78     \"\"\"\n79 \n80     def __init__(self, axis_tilt=0, axis_azimuth=0, max_angle=90,\n81                  backtrack=True, gcr=2.0/7.0, cross_axis_tilt=0.0, **kwargs):\n82 \n83         mount_kwargs = {\n84             k: kwargs.pop(k) for k in ['racking_model', 'module_height']\n85             if k in kwargs\n86         }\n87         mount = SingleAxisTrackerMount(axis_tilt, axis_azimuth, max_angle,\n88                                        backtrack, gcr, cross_axis_tilt,\n89                                        **mount_kwargs)\n90 \n91         array_defaults = {\n92             'albedo': None, 'surface_type': None, 'module': None,\n93             'module_type': None, 'module_parameters': None,\n94             'temperature_model_parameters': None,\n95             'modules_per_string': 1,\n96         }\n97         array_kwargs = {\n98             key: kwargs.get(key, array_defaults[key]) for key in array_defaults\n99         }\n100         # strings/strings_per_inverter is a special case\n101         array_kwargs['strings'] = kwargs.get('strings_per_inverter', 1)\n102 \n103         array = Array(mount=mount, **array_kwargs)\n104         pass_through_kwargs = {  # other args to pass to PVSystem()\n105             k: v for k, v in kwargs.items() if k not in array_defaults\n106         }\n107         # leave these in case someone is using them\n108         self.axis_tilt = axis_tilt\n109         self.axis_azimuth = axis_azimuth\n110         self.max_angle = max_angle\n111         self.backtrack = backtrack\n112         self.gcr = gcr\n113         self.cross_axis_tilt = cross_axis_tilt\n114 \n115         pass_through_kwargs['surface_tilt'] = None\n116         pass_through_kwargs['surface_azimuth'] = None\n117 \n118         super().__init__(arrays=[array], **pass_through_kwargs)\n119 \n120     def __repr__(self):\n121         attrs = ['axis_tilt', 'axis_azimuth', 'max_angle', 'backtrack', 'gcr',\n122                  'cross_axis_tilt']\n123         sat_repr = ('SingleAxisTracker:\\n  ' + '\\n  '.join(\n124             f'{attr}: {getattr(self, attr)}' for attr in attrs))\n125         # get the parent PVSystem info\n126         pvsystem_repr = super().__repr__()\n127         # remove the first line (contains 'PVSystem: \\n')\n128         pvsystem_repr = '\\n'.join(pvsystem_repr.split('\\n')[1:])\n129         return sat_repr + '\\n' + pvsystem_repr\n130 \n131     def singleaxis(self, apparent_zenith, apparent_azimuth):\n132         \"\"\"\n133         Get tracking data. See :py:func:`pvlib.tracking.singleaxis` more\n134         detail.\n135 \n136         Parameters\n137         ----------\n138         apparent_zenith : float, 1d array, or Series\n139             Solar apparent zenith angles in decimal degrees.\n140 \n141         apparent_azimuth : float, 1d array, or Series\n142             Solar apparent azimuth angles in decimal degrees.\n143 \n144         Returns\n145         -------\n146         tracking data\n147         \"\"\"\n148         tracking_data = singleaxis(apparent_zenith, apparent_azimuth,\n149                                    self.axis_tilt, self.axis_azimuth,\n150                                    self.max_angle, self.backtrack,\n151                                    self.gcr, self.cross_axis_tilt)\n152 \n153         return tracking_data\n154 \n155     def get_aoi(self, surface_tilt, surface_azimuth, solar_zenith,\n156                 solar_azimuth):\n157         \"\"\"Get the angle of incidence on the system.\n158 \n159         For a given set of solar zenith and azimuth angles, the\n160         surface tilt and azimuth parameters are typically determined\n161         by :py:meth:`~SingleAxisTracker.singleaxis`. The\n162         :py:meth:`~SingleAxisTracker.singleaxis` method also returns\n163         the angle of incidence, so this method is only needed\n164         if using a different tracking algorithm.\n165 \n166         Parameters\n167         ----------\n168         surface_tilt : numeric\n169             Panel tilt from horizontal.\n170         surface_azimuth : numeric\n171             Panel azimuth from north\n172         solar_zenith : float or Series.\n173             Solar zenith angle.\n174         solar_azimuth : float or Series.\n175             Solar azimuth angle.\n176 \n177         Returns\n178         -------\n179         aoi : Series\n180             The angle of incidence in degrees from normal.\n181         \"\"\"\n182 \n183         aoi = irradiance.aoi(surface_tilt, surface_azimuth,\n184                              solar_zenith, solar_azimuth)\n185         return aoi\n186 \n187     @_unwrap_single_value\n188     def get_irradiance(self, surface_tilt, surface_azimuth,\n189                        solar_zenith, solar_azimuth, dni, ghi, dhi,\n190                        dni_extra=None, airmass=None, model='haydavies',\n191                        **kwargs):\n192         \"\"\"\n193         Uses the :func:`irradiance.get_total_irradiance` function to\n194         calculate the plane of array irradiance components on a tilted\n195         surface defined by the input data and ``self.albedo``.\n196 \n197         For a given set of solar zenith and azimuth angles, the\n198         surface tilt and azimuth parameters are typically determined\n199         by :py:meth:`~SingleAxisTracker.singleaxis`.\n200 \n201         Parameters\n202         ----------\n203         surface_tilt : numeric\n204             Panel tilt from horizontal.\n205         surface_azimuth : numeric\n206             Panel azimuth from north\n207         solar_zenith : numeric\n208             Solar zenith angle.\n209         solar_azimuth : numeric\n210             Solar azimuth angle.\n211         dni : float or Series\n212             Direct Normal Irradiance\n213         ghi : float or Series\n214             Global horizontal irradiance\n215         dhi : float or Series\n216             Diffuse horizontal irradiance\n217         dni_extra : float or Series, default None\n218             Extraterrestrial direct normal irradiance\n219         airmass : float or Series, default None\n220             Airmass\n221         model : String, default 'haydavies'\n222             Irradiance model.\n223 \n224         **kwargs\n225             Passed to :func:`irradiance.get_total_irradiance`.\n226 \n227         Returns\n228         -------\n229         poa_irradiance : DataFrame\n230             Column names are: ``total, beam, sky, ground``.\n231         \"\"\"\n232 \n233         # not needed for all models, but this is easier\n234         if dni_extra is None:\n235             dni_extra = irradiance.get_extra_radiation(solar_zenith.index)\n236 \n237         if airmass is None:\n238             airmass = atmosphere.get_relative_airmass(solar_zenith)\n239 \n240         # SingleAxisTracker only supports a single Array, but we need the\n241         # validate/iterate machinery so that single length tuple input/output\n242         # is handled the same as PVSystem.get_irradiance. GH 1159\n243         dni = self._validate_per_array(dni, system_wide=True)\n244         ghi = self._validate_per_array(ghi, system_wide=True)\n245         dhi = self._validate_per_array(dhi, system_wide=True)\n246 \n247         return tuple(\n248             irradiance.get_total_irradiance(\n249                 surface_tilt,\n250                 surface_azimuth,\n251                 solar_zenith,\n252                 solar_azimuth,\n253                 dni, ghi, dhi,\n254                 dni_extra=dni_extra,\n255                 airmass=airmass,\n256                 model=model,\n257                 albedo=self.arrays[0].albedo,\n258                 **kwargs)\n259             for array, dni, ghi, dhi in zip(\n260                 self.arrays, dni, ghi, dhi\n261             )\n262         )\n263 \n264 \n265 def singleaxis(apparent_zenith, apparent_azimuth,\n266                axis_tilt=0, axis_azimuth=0, max_angle=90,\n267                backtrack=True, gcr=2.0/7.0, cross_axis_tilt=0):\n268     \"\"\"\n269     Determine the rotation angle of a single-axis tracker when given particular\n270     solar zenith and azimuth angles.\n271 \n272     See [1]_ for details about the equations. Backtracking may be specified,\n273     and if so, a ground coverage ratio is required.\n274 \n275     Rotation angle is determined in a right-handed coordinate system. The\n276     tracker `axis_azimuth` defines the positive y-axis, the positive x-axis is\n277     90 degrees clockwise from the y-axis and parallel to the Earth's surface,\n278     and the positive z-axis is normal to both x & y-axes and oriented skyward.\n279     Rotation angle `tracker_theta` is a right-handed rotation around the y-axis\n280     in the x, y, z coordinate system and indicates tracker position relative to\n281     horizontal. For example, if tracker `axis_azimuth` is 180 (oriented south)\n282     and `axis_tilt` is zero, then a `tracker_theta` of zero is horizontal, a\n283     `tracker_theta` of 30 degrees is a rotation of 30 degrees towards the west,\n284     and a `tracker_theta` of -90 degrees is a rotation to the vertical plane\n285     facing east.\n286 \n287     Parameters\n288     ----------\n289     apparent_zenith : float, 1d array, or Series\n290         Solar apparent zenith angles in decimal degrees.\n291 \n292     apparent_azimuth : float, 1d array, or Series\n293         Solar apparent azimuth angles in decimal degrees.\n294 \n295     axis_tilt : float, default 0\n296         The tilt of the axis of rotation (i.e, the y-axis defined by\n297         axis_azimuth) with respect to horizontal, in decimal degrees.\n298 \n299     axis_azimuth : float, default 0\n300         A value denoting the compass direction along which the axis of\n301         rotation lies. Measured in decimal degrees east of north.\n302 \n303     max_angle : float, default 90\n304         A value denoting the maximum rotation angle, in decimal degrees,\n305         of the one-axis tracker from its horizontal position (horizontal\n306         if axis_tilt = 0). A max_angle of 90 degrees allows the tracker\n307         to rotate to a vertical position to point the panel towards a\n308         horizon. max_angle of 180 degrees allows for full rotation.\n309 \n310     backtrack : bool, default True\n311         Controls whether the tracker has the capability to \"backtrack\"\n312         to avoid row-to-row shading. False denotes no backtrack\n313         capability. True denotes backtrack capability.\n314 \n315     gcr : float, default 2.0/7.0\n316         A value denoting the ground coverage ratio of a tracker system\n317         which utilizes backtracking; i.e. the ratio between the PV array\n318         surface area to total ground area. A tracker system with modules\n319         2 meters wide, centered on the tracking axis, with 6 meters\n320         between the tracking axes has a gcr of 2/6=0.333. If gcr is not\n321         provided, a gcr of 2/7 is default. gcr must be <=1.\n322 \n323     cross_axis_tilt : float, default 0.0\n324         The angle, relative to horizontal, of the line formed by the\n325         intersection between the slope containing the tracker axes and a plane\n326         perpendicular to the tracker axes. Cross-axis tilt should be specified\n327         using a right-handed convention. For example, trackers with axis\n328         azimuth of 180 degrees (heading south) will have a negative cross-axis\n329         tilt if the tracker axes plane slopes down to the east and positive\n330         cross-axis tilt if the tracker axes plane slopes up to the east. Use\n331         :func:`~pvlib.tracking.calc_cross_axis_tilt` to calculate\n332         `cross_axis_tilt`. [degrees]\n333 \n334     Returns\n335     -------\n336     dict or DataFrame with the following columns:\n337         * `tracker_theta`: The rotation angle of the tracker.\n338           tracker_theta = 0 is horizontal, and positive rotation angles are\n339           clockwise. [degrees]\n340         * `aoi`: The angle-of-incidence of direct irradiance onto the\n341           rotated panel surface. [degrees]\n342         * `surface_tilt`: The angle between the panel surface and the earth\n343           surface, accounting for panel rotation. [degrees]\n344         * `surface_azimuth`: The azimuth of the rotated panel, determined by\n345           projecting the vector normal to the panel's surface to the earth's\n346           surface. [degrees]\n347 \n348     See also\n349     --------\n350     pvlib.tracking.calc_axis_tilt\n351     pvlib.tracking.calc_cross_axis_tilt\n352 \n353     References\n354     ----------\n355     .. [1] Kevin Anderson and Mark Mikofski, \"Slope-Aware Backtracking for\n356        Single-Axis Trackers\", Technical Report NREL/TP-5K00-76626, July 2020.\n357        https://www.nrel.gov/docs/fy20osti/76626.pdf\n358     \"\"\"\n359 \n360     # MATLAB to Python conversion by\n361     # Will Holmgren (@wholmgren), U. Arizona. March, 2015.\n362 \n363     if isinstance(apparent_zenith, pd.Series):\n364         index = apparent_zenith.index\n365     else:\n366         index = None\n367 \n368     # convert scalars to arrays\n369     apparent_azimuth = np.atleast_1d(apparent_azimuth)\n370     apparent_zenith = np.atleast_1d(apparent_zenith)\n371 \n372     if apparent_azimuth.ndim > 1 or apparent_zenith.ndim > 1:\n373         raise ValueError('Input dimensions must not exceed 1')\n374 \n375     # Calculate sun position x, y, z using coordinate system as in [1], Eq 1.\n376 \n377     # NOTE: solar elevation = 90 - solar zenith, then use trig identities:\n378     # sin(90-x) = cos(x) & cos(90-x) = sin(x)\n379     sin_zenith = sind(apparent_zenith)\n380     x = sin_zenith * sind(apparent_azimuth)\n381     y = sin_zenith * cosd(apparent_azimuth)\n382     z = cosd(apparent_zenith)\n383 \n384     # Assume the tracker reference frame is right-handed. Positive y-axis is\n385     # oriented along tracking axis; from north, the y-axis is rotated clockwise\n386     # by the axis azimuth and tilted from horizontal by the axis tilt. The\n387     # positive x-axis is 90 deg clockwise from the y-axis and parallel to\n388     # horizontal (e.g., if the y-axis is south, the x-axis is west); the\n389     # positive z-axis is normal to the x and y axes, pointed upward.\n390 \n391     # Calculate sun position (xp, yp, zp) in tracker coordinate system using\n392     # [1] Eq 4.\n393 \n394     cos_axis_azimuth = cosd(axis_azimuth)\n395     sin_axis_azimuth = sind(axis_azimuth)\n396     cos_axis_tilt = cosd(axis_tilt)\n397     sin_axis_tilt = sind(axis_tilt)\n398     xp = x*cos_axis_azimuth - y*sin_axis_azimuth\n399     yp = (x*cos_axis_tilt*sin_axis_azimuth\n400           + y*cos_axis_tilt*cos_axis_azimuth\n401           - z*sin_axis_tilt)\n402     zp = (x*sin_axis_tilt*sin_axis_azimuth\n403           + y*sin_axis_tilt*cos_axis_azimuth\n404           + z*cos_axis_tilt)\n405 \n406     # The ideal tracking angle wid is the rotation to place the sun position\n407     # vector (xp, yp, zp) in the (y, z) plane, which is normal to the panel and\n408     # contains the axis of rotation.  wid = 0 indicates that the panel is\n409     # horizontal. Here, our convention is that a clockwise rotation is\n410     # positive, to view rotation angles in the same frame of reference as\n411     # azimuth. For example, for a system with tracking axis oriented south, a\n412     # rotation toward the east is negative, and a rotation to the west is\n413     # positive. This is a right-handed rotation around the tracker y-axis.\n414 \n415     # Calculate angle from x-y plane to projection of sun vector onto x-z plane\n416     # using [1] Eq. 5.\n417 \n418     wid = np.degrees(np.arctan2(xp, zp))\n419 \n420     # filter for sun above panel horizon\n421     zen_gt_90 = apparent_zenith > 90\n422     wid[zen_gt_90] = np.nan\n423 \n424     # Account for backtracking\n425     if backtrack:\n426         # distance between rows in terms of rack lengths relative to cross-axis\n427         # tilt\n428         axes_distance = 1/(gcr * cosd(cross_axis_tilt))\n429 \n430         # NOTE: account for rare angles below array, see GH 824\n431         temp = np.abs(axes_distance * cosd(wid - cross_axis_tilt))\n432 \n433         # backtrack angle using [1], Eq. 14\n434         with np.errstate(invalid='ignore'):\n435             wc = np.degrees(-np.sign(wid)*np.arccos(temp))\n436 \n437         # NOTE: in the middle of the day, arccos(temp) is out of range because\n438         # there's no row-to-row shade to avoid, & backtracking is unnecessary\n439         # [1], Eqs. 15-16\n440         with np.errstate(invalid='ignore'):\n441             tracker_theta = wid + np.where(temp < 1, wc, 0)\n442     else:\n443         tracker_theta = wid\n444 \n445     # NOTE: max_angle defined relative to zero-point rotation, not the\n446     # system-plane normal\n447     tracker_theta = np.clip(tracker_theta, -max_angle, max_angle)\n448 \n449     # Calculate panel normal vector in panel-oriented x, y, z coordinates.\n450     # y-axis is axis of tracker rotation. tracker_theta is a compass angle\n451     # (clockwise is positive) rather than a trigonometric angle.\n452     # NOTE: the *0 is a trick to preserve NaN values.\n453     panel_norm = np.array([sind(tracker_theta),\n454                            tracker_theta*0,\n455                            cosd(tracker_theta)])\n456 \n457     # sun position in vector format in panel-oriented x, y, z coordinates\n458     sun_vec = np.array([xp, yp, zp])\n459 \n460     # calculate angle-of-incidence on panel\n461     # TODO: use irradiance.aoi\n462     projection = np.clip(np.sum(sun_vec*panel_norm, axis=0), -1, 1)\n463     aoi = np.degrees(np.arccos(projection))\n464 \n465     # Calculate panel tilt and azimuth in a coordinate system where the panel\n466     # tilt is the angle from horizontal, and the panel azimuth is the compass\n467     # angle (clockwise from north) to the projection of the panel's normal to\n468     # the earth's surface. These outputs are provided for convenience and\n469     # comparison with other PV software which use these angle conventions.\n470 \n471     # Project normal vector to earth surface. First rotate about x-axis by\n472     # angle -axis_tilt so that y-axis is also parallel to earth surface, then\n473     # project.\n474 \n475     # Calculate standard rotation matrix\n476     rot_x = np.array([[1, 0, 0],\n477                       [0, cosd(-axis_tilt), -sind(-axis_tilt)],\n478                       [0, sind(-axis_tilt), cosd(-axis_tilt)]])\n479 \n480     # panel_norm_earth contains the normal vector expressed in earth-surface\n481     # coordinates (z normal to surface, y aligned with tracker axis parallel to\n482     # earth)\n483     panel_norm_earth = np.dot(rot_x, panel_norm).T\n484 \n485     # projection to plane tangent to earth surface, in earth surface\n486     # coordinates\n487     projected_normal = np.array([panel_norm_earth[:, 0],\n488                                  panel_norm_earth[:, 1],\n489                                  panel_norm_earth[:, 2]*0]).T\n490 \n491     # calculate vector magnitudes\n492     projected_normal_mag = np.sqrt(np.nansum(projected_normal**2, axis=1))\n493 \n494     # renormalize the projected vector, avoid creating nan values.\n495     non_zeros = projected_normal_mag != 0\n496     projected_normal[non_zeros] = (projected_normal[non_zeros].T /\n497                                    projected_normal_mag[non_zeros]).T\n498 \n499     # calculation of surface_azimuth\n500     surface_azimuth = \\\n501         np.degrees(np.arctan2(projected_normal[:, 1], projected_normal[:, 0]))\n502 \n503     # Rotate 0 reference from panel's x-axis to its y-axis and then back to\n504     # north.\n505     surface_azimuth = 90 - surface_azimuth + axis_azimuth\n506 \n507     # Map azimuth into [0,360) domain.\n508     with np.errstate(invalid='ignore'):\n509         surface_azimuth = surface_azimuth % 360\n510 \n511     # Calculate surface_tilt\n512     dotproduct = (panel_norm_earth * projected_normal).sum(axis=1)\n513     # for edge cases like axis_tilt=90, numpy's SIMD can produce values like\n514     # dotproduct = (1 + 2e-16). Clip off the excess so that arccos works:\n515     dotproduct = np.clip(dotproduct, -1, 1)\n516     surface_tilt = 90 - np.degrees(np.arccos(dotproduct))\n517 \n518     # Bundle DataFrame for return values and filter for sun below horizon.\n519     out = {'tracker_theta': tracker_theta, 'aoi': aoi,\n520            'surface_tilt': surface_tilt, 'surface_azimuth': surface_azimuth}\n521     if index is not None:\n522         out = pd.DataFrame(out, index=index)\n523         out = out[['tracker_theta', 'aoi', 'surface_azimuth', 'surface_tilt']]\n524         out[zen_gt_90] = np.nan\n525     else:\n526         out = {k: np.where(zen_gt_90, np.nan, v) for k, v in out.items()}\n527 \n528     return out\n529 \n530 \n531 def calc_axis_tilt(slope_azimuth, slope_tilt, axis_azimuth):\n532     \"\"\"\n533     Calculate tracker axis tilt in the global reference frame when on a sloped\n534     plane.\n535 \n536     Parameters\n537     ----------\n538     slope_azimuth : float\n539         direction of normal to slope on horizontal [degrees]\n540     slope_tilt : float\n541         tilt of normal to slope relative to vertical [degrees]\n542     axis_azimuth : float\n543         direction of tracker axes on horizontal [degrees]\n544 \n545     Returns\n546     -------\n547     axis_tilt : float\n548         tilt of tracker [degrees]\n549 \n550     See also\n551     --------\n552     pvlib.tracking.singleaxis\n553     pvlib.tracking.calc_cross_axis_tilt\n554 \n555     Notes\n556     -----\n557     See [1]_ for derivation of equations.\n558 \n559     References\n560     ----------\n561     .. [1] Kevin Anderson and Mark Mikofski, \"Slope-Aware Backtracking for\n562        Single-Axis Trackers\", Technical Report NREL/TP-5K00-76626, July 2020.\n563        https://www.nrel.gov/docs/fy20osti/76626.pdf\n564     \"\"\"\n565     delta_gamma = axis_azimuth - slope_azimuth\n566     # equations 18-19\n567     tan_axis_tilt = cosd(delta_gamma) * tand(slope_tilt)\n568     return np.degrees(np.arctan(tan_axis_tilt))\n569 \n570 \n571 def _calc_tracker_norm(ba, bg, dg):\n572     \"\"\"\n573     Calculate tracker normal, v, cross product of tracker axis and unit normal,\n574     N, to the system slope plane.\n575 \n576     Parameters\n577     ----------\n578     ba : float\n579         axis tilt [degrees]\n580     bg : float\n581         ground tilt [degrees]\n582     dg : float\n583         delta gamma, difference between axis and ground azimuths [degrees]\n584 \n585     Returns\n586     -------\n587     vector : tuple\n588         vx, vy, vz\n589     \"\"\"\n590     cos_ba = cosd(ba)\n591     cos_bg = cosd(bg)\n592     sin_bg = sind(bg)\n593     sin_dg = sind(dg)\n594     vx = sin_dg * cos_ba * cos_bg\n595     vy = sind(ba)*sin_bg + cosd(dg)*cos_ba*cos_bg\n596     vz = -sin_dg*sin_bg*cos_ba\n597     return vx, vy, vz\n598 \n599 \n600 def _calc_beta_c(v, dg, ba):\n601     \"\"\"\n602     Calculate the cross-axis tilt angle.\n603 \n604     Parameters\n605     ----------\n606     v : tuple\n607         tracker normal\n608     dg : float\n609         delta gamma, difference between axis and ground azimuths [degrees]\n610     ba : float\n611         axis tilt [degrees]\n612 \n613     Returns\n614     -------\n615     beta_c : float\n616         cross-axis tilt angle [radians]\n617     \"\"\"\n618     vnorm = np.sqrt(np.dot(v, v))\n619     beta_c = np.arcsin(\n620         ((v[0]*cosd(dg) - v[1]*sind(dg)) * sind(ba) + v[2]*cosd(ba)) / vnorm)\n621     return beta_c\n622 \n623 \n624 def calc_cross_axis_tilt(\n625         slope_azimuth, slope_tilt, axis_azimuth, axis_tilt):\n626     \"\"\"\n627     Calculate the angle, relative to horizontal, of the line formed by the\n628     intersection between the slope containing the tracker axes and a plane\n629     perpendicular to the tracker axes.\n630 \n631     Use the cross-axis tilt to avoid row-to-row shade when backtracking on a\n632     slope not parallel with the axis azimuth. Cross-axis tilt should be\n633     specified using a right-handed convention. For example, trackers with axis\n634     azimuth of 180 degrees (heading south) will have a negative cross-axis tilt\n635     if the tracker axes plane slopes down to the east and positive cross-axis\n636     tilt if the tracker axes plane slopes up to the east.\n637 \n638     Parameters\n639     ----------\n640     slope_azimuth : float\n641         direction of the normal to the slope containing the tracker axes, when\n642         projected on the horizontal [degrees]\n643     slope_tilt : float\n644         angle of the slope containing the tracker axes, relative to horizontal\n645         [degrees]\n646     axis_azimuth : float\n647         direction of tracker axes projected on the horizontal [degrees]\n648     axis_tilt : float\n649         tilt of trackers relative to horizontal [degrees]\n650 \n651     Returns\n652     -------\n653     cross_axis_tilt : float\n654         angle, relative to horizontal, of the line formed by the intersection\n655         between the slope containing the tracker axes and a plane perpendicular\n656         to the tracker axes [degrees]\n657 \n658     See also\n659     --------\n660     pvlib.tracking.singleaxis\n661     pvlib.tracking.calc_axis_tilt\n662 \n663     Notes\n664     -----\n665     See [1]_ for derivation of equations.\n666 \n667     References\n668     ----------\n669     .. [1] Kevin Anderson and Mark Mikofski, \"Slope-Aware Backtracking for\n670        Single-Axis Trackers\", Technical Report NREL/TP-5K00-76626, July 2020.\n671        https://www.nrel.gov/docs/fy20osti/76626.pdf\n672     \"\"\"\n673     # delta-gamma, difference between axis and slope azimuths\n674     delta_gamma = axis_azimuth - slope_azimuth\n675     # equation 22\n676     v = _calc_tracker_norm(axis_tilt, slope_tilt, delta_gamma)\n677     # equation 26\n678     beta_c = _calc_beta_c(v, delta_gamma, axis_tilt)\n679     return np.degrees(beta_c)\n680 \n[end of pvlib/tracking.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n\n\n", "full_output": "```patch\n--- a/pvlib/tracking.py\n+++ b/pvlib/tracking.py\n@@ -528,6 +528,35 @@\n     return out\n+    \n+def rotation_to_orientation(tracker_theta, axis_tilt=0, axis_azimuth=0):\n+    \"\"\"\n+    Convert tracker rotation angle to surface tilt and azimuth.\n+\n+    Parameters\n+    ----------\n+    tracker_theta : float or array-like\n+        The rotation angle of the tracker. tracker_theta = 0 is horizontal.\n+\n+    axis_tilt : float, default 0\n+        The tilt of the axis of rotation with respect to horizontal, in decimal degrees.\n+\n+    axis_azimuth : float, default 0\n+        A value denoting the compass direction along which the axis of rotation lies.\n+\n+    Returns\n+    -------\n+    dict\n+        A dictionary containing 'surface_tilt' and 'surface_azimuth'.\n+    \"\"\"\n+\n+    # Calculate panel normal vector in panel-oriented x, y, z coordinates.\n+    panel_norm = np.array([sind(tracker_theta),\n+                           tracker_theta*0,\n+                           cosd(tracker_theta)])\n+\n+    # Calculate panel tilt and azimuth in a coordinate system where the panel\n+    # tilt is the angle from horizontal, and the panel azimuth is the compass\n+    # angle to the projection of the panel's normal to the earth's surface.\n+\n+    # Calculate standard rotation matrix\n+    rot_x = np.array([[1, 0, 0],\n+                      [0, cosd(-axis_tilt), -sind(-axis_tilt)],\n+                      [0, sind(-axis_tilt), cosd(-axis_tilt)]])\n+\n+    # panel_norm_earth contains the normal vector expressed in earth-surface\n+    # coordinates (z normal to surface, y aligned with tracker axis parallel to\n+    # earth)\n+    panel_norm_earth = np.dot(rot_x, panel_norm).T\n+\n+    # projection to plane tangent to earth surface, in earth surface\n+    # coordinates\n+    projected_normal = np.array([panel_norm_earth[:, 0],\n+                                 panel_norm_earth[:, 1],\n+                                 panel_norm_earth[:, 2]*0]).T\n+\n+    # calculate vector magnitudes\n+    projected_normal_mag = np.sqrt(np.nansum(projected_normal**2, axis=1))\n+\n+    # renormalize the projected vector, avoid creating nan values.\n+    non_zeros = projected_normal_mag != 0\n+    projected_normal[non_zeros] = (projected_normal[non_zeros].T /\n+                                    projected_normal_mag[non_zeros]).T\n+\n+    # calculation of surface_azimuth\n+    surface_azimuth = \\\n+        np.degrees(np.arctan2(projected_normal[:, 1], projected_normal[:, 0]))\n+\n+    # Rotate 0 reference from panel's x-axis to its y-axis and then back to\n+    # north.\n+    surface_azimuth = 90 - surface_azimuth + axis_azimuth\n+\n+    # Map azimuth into [0,360) domain.\n+    surface_azimuth = surface_azimuth % 360\n+\n+    # Calculate surface_tilt\n+    dotproduct = (panel_norm_earth * projected_normal).sum(axis=1)\n+    dotproduct = np.clip(dotproduct, -1, 1)\n+    surface_tilt = 90 - np.degrees(np.arccos(dotproduct))\n+\n+    return {'surface_tilt': surface_tilt, 'surface_azimuth': surface_azimuth}\n```\n", "model_patch": "--- a/pvlib/tracking.py\n+++ b/pvlib/tracking.py\n@@ -528,6 +528,35 @@\n     return out\n+    \n+def rotation_to_orientation(tracker_theta, axis_tilt=0, axis_azimuth=0):\n+    \"\"\"\n+    Convert tracker rotation angle to surface tilt and azimuth.\n+\n+    Parameters\n+    ----------\n+    tracker_theta : float or array-like\n+        The rotation angle of the tracker. tracker_theta = 0 is horizontal.\n+\n+    axis_tilt : float, default 0\n+        The tilt of the axis of rotation with respect to horizontal, in decimal degrees.\n+\n+    axis_azimuth : float, default 0\n+        A value denoting the compass direction along which the axis of rotation lies.\n+\n+    Returns\n+    -------\n+    dict\n+        A dictionary containing 'surface_tilt' and 'surface_azimuth'.\n+    \"\"\"\n+\n+    # Calculate panel normal vector in panel-oriented x, y, z coordinates.\n+    panel_norm = np.array([sind(tracker_theta),\n+                           tracker_theta*0,\n+                           cosd(tracker_theta)])\n+\n+    # Calculate panel tilt and azimuth in a coordinate system where the panel\n+    # tilt is the angle from horizontal, and the panel azimuth is the compass\n+    # angle to the projection of the panel's normal to the earth's surface.\n+\n+    # Calculate standard rotation matrix\n+    rot_x = np.array([[1, 0, 0],\n+                      [0, cosd(-axis_tilt), -sind(-axis_tilt)],\n+                      [0, sind(-axis_tilt), cosd(-axis_tilt)]])\n+\n+    # panel_norm_earth contains the normal vector expressed in earth-surface\n+    # coordinates (z normal to surface, y aligned with tracker axis parallel to\n+    # earth)\n+    panel_norm_earth = np.dot(rot_x, panel_norm).T\n+\n+    # projection to plane tangent to earth surface, in earth surface\n+    # coordinates\n+    projected_normal = np.array([panel_norm_earth[:, 0],\n+                                 panel_norm_earth[:, 1],\n+                                 panel_norm_earth[:, 2]*0]).T\n+\n+    # calculate vector magnitudes\n+    projected_normal_mag = np.sqrt(np.nansum(projected_normal**2, axis=1))\n+\n+    # renormalize the projected vector, avoid creating nan values.\n+    non_zeros = projected_normal_mag != 0\n+    projected_normal[non_zeros] = (projected_normal[non_zeros].T /\n+                                    projected_normal_mag[non_zeros]).T\n+\n+    # calculation of surface_azimuth\n+    surface_azimuth = \\\n+        np.degrees(np.arctan2(projected_normal[:, 1], projected_normal[:, 0]))\n+\n+    # Rotate 0 reference from panel's x-axis to its y-axis and then back to\n+    # north.\n+    surface_azimuth = 90 - surface_azimuth + axis_azimuth\n+\n+    # Map azimuth into [0,360) domain.\n+    surface_azimuth = surface_azimuth % 360\n+\n+    # Calculate surface_tilt\n+    dotproduct = (panel_norm_earth * projected_normal).sum(axis=1)\n+    dotproduct = np.clip(dotproduct, -1, 1)\n+    surface_tilt = 90 - np.degrees(np.arccos(dotproduct))\n+\n+    return {'surface_tilt': surface_tilt, 'surface_azimuth': surface_azimuth}\n"}
{"instance_id": "pvlib__pvlib-python-1653", "model_name_or_path": "gpt-4o-mini", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nCorrections to Townsend snow model\nPrivate communications with the model's author have turned up some issues with the pvlib implementation. Chief among the issues is  this part of the calculation:\r\n\r\n```\r\n    lower_edge_height_clipped = np.maximum(lower_edge_height, 0.01)\r\n    gamma = (\r\n        slant_height\r\n        * effective_snow_weighted_m\r\n        * cosd(surface_tilt)\r\n        / (lower_edge_height_clipped**2 - effective_snow_weighted_m**2)\r\n        * 2\r\n        * tand(angle_of_repose)\r\n    )\r\n\r\n    ground_interference_term = 1 - C2 * np.exp(-gamma)\r\n```\r\n\r\nWhen `lower_edge_height_clipped` < `effective_snow_weighted_m`, `gamma` < 0 and the `ground_interference_term` can become negative. In contrast, the author's intent is that C2 < `ground_interference_terms` < 1. The author recommends clipping the squared difference (lower bound being worked out but will be something like 0.01.).\r\n\r\nOther issues appear to arise from the unit conversions. The published model uses inches for distance and snow depth. The pvlib code uses cm for snow depth (convenience for working with external snow data) and m for distances (for consistency with the rest of pvlib). After several steps, including the `ground_interference_term` calculation, the code converts from cm or m to inches to apply the final formula for loss (since the formula involves some coefficients determined by a regression). It would be easier to trace the pvlib code back to the paper if the internal unit conversions (from cm / m to inches) were done earlier.\r\n\n\n</issue>\n<code>\n[start of README.md]\n1 <img src=\"docs/sphinx/source/_images/pvlib_logo_horiz.png\" width=\"600\">\n2 \n3 <table>\n4 <tr>\n5   <td>Latest Release</td>\n6   <td>\n7     <a href=\"https://pypi.org/project/pvlib/\">\n8     <img src=\"https://img.shields.io/pypi/v/pvlib.svg\" alt=\"latest release\" />\n9     </a>\n10     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n11     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/version.svg\" />\n12     </a>\n13     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n14     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/latest_release_date.svg\" />\n15     </a>\n16 </tr>\n17 <tr>\n18   <td>License</td>\n19   <td>\n20     <a href=\"https://github.com/pvlib/pvlib-python/blob/main/LICENSE\">\n21     <img src=\"https://img.shields.io/pypi/l/pvlib.svg\" alt=\"license\" />\n22     </a>\n23 </td>\n24 </tr>\n25 <tr>\n26   <td>Build Status</td>\n27   <td>\n28     <a href=\"http://pvlib-python.readthedocs.org/en/stable/\">\n29     <img src=\"https://readthedocs.org/projects/pvlib-python/badge/?version=stable\" alt=\"documentation build status\" />\n30     </a>\n31     <a href=\"https://github.com/pvlib/pvlib-python/actions/workflows/pytest.yml?query=branch%3Amain\">\n32       <img src=\"https://github.com/pvlib/pvlib-python/actions/workflows/pytest.yml/badge.svg?branch=main\" alt=\"GitHub Actions Testing Status\" />\n33     </a>\n34     <a href=\"https://codecov.io/gh/pvlib/pvlib-python\">\n35     <img src=\"https://codecov.io/gh/pvlib/pvlib-python/branch/main/graph/badge.svg\" alt=\"codecov coverage\" />\n36     </a>\n37   </td>\n38 </tr>\n39 <tr>\n40   <td>Benchmarks</td>\n41   <td>\n42     <a href=\"https://pvlib.github.io/pvlib-benchmarks/\">\n43     <img src=\"https://img.shields.io/badge/benchmarks-asv-lightgrey\" />\n44     </a>\n45   </td>\n46 </tr>\n47 <tr>\n48   <td>Publications</td>\n49   <td>\n50     <a href=\"https://doi.org/10.5281/zenodo.593284\">\n51     <img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.593284.svg\" alt=\"zenodo reference\">\n52     </a>\n53     <a href=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1\">\n54     <img src=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1/status.svg\" alt=\"JOSS reference\" />\n55     </a>\n56   </td>\n57 </tr>\n58 <tr>\n59   <td>Downloads</td>\n60   <td>\n61     <a href=\"https://pypi.org/project/pvlib/\">\n62     <img src=\"https://img.shields.io/pypi/dm/pvlib\" alt=\"PyPI downloads\" />\n63     </a>\n64     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n65     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/downloads.svg\" alt=\"conda-forge downloads\" />\n66     </a>\n67   </td>\n68 </tr>\n69 </table>\n70 \n71 \n72 pvlib python is a community supported tool that provides a set of\n73 functions and classes for simulating the performance of photovoltaic\n74 energy systems. pvlib python was originally ported from the PVLIB MATLAB\n75 toolbox developed at Sandia National Laboratories and it implements many\n76 of the models and methods developed at the Labs. More information on\n77 Sandia Labs PV performance modeling programs can be found at\n78 https://pvpmc.sandia.gov/. We collaborate with the PVLIB MATLAB project,\n79 but operate independently of it.\n80 \n81 \n82 Documentation\n83 =============\n84 \n85 Full documentation can be found at [readthedocs](http://pvlib-python.readthedocs.io/en/stable/),\n86 including an [FAQ](http://pvlib-python.readthedocs.io/en/stable/user_guide/faq.html) page.\n87 \n88 Installation\n89 ============\n90 \n91 pvlib-python releases may be installed using the ``pip`` and ``conda`` tools.\n92 Please see the [Installation page](https://pvlib-python.readthedocs.io/en/stable/user_guide/installation.html) of the documentation for complete instructions.\n93 \n94 \n95 Contributing\n96 ============\n97 \n98 We need your help to make pvlib-python a great tool!\n99 Please see the [Contributing page](http://pvlib-python.readthedocs.io/en/stable/contributing.html) for more on how you can contribute.\n100 The long-term success of pvlib-python requires substantial community support.\n101 \n102 \n103 Citing\n104 ======\n105 \n106 If you use pvlib-python in a published work, please cite:\n107 \n108   William F. Holmgren, Clifford W. Hansen, and Mark A. Mikofski.\n109   \"pvlib python: a python package for modeling solar energy systems.\"\n110   Journal of Open Source Software, 3(29), 884, (2018).\n111   https://doi.org/10.21105/joss.00884\n112 \n113 Please also cite the DOI corresponding to the specific version of\n114 pvlib-python that you used. pvlib-python DOIs are listed at\n115 [Zenodo.org](https://zenodo.org/search?page=1&size=20&q=conceptrecid:593284&all_versions&sort=-version)\n116 \n117 If you use pvlib-python in a commercial or publicly-available application, please\n118 consider displaying one of the \"powered by pvlib\" logos:\n119 \n120 <img src=\"docs/sphinx/source/_images/pvlib_powered_logo_vert.png\" width=\"300\"><img src=\"docs/sphinx/source/_images/pvlib_powered_logo_horiz.png\" width=\"300\">\n121 \n122 Getting support\n123 ===============\n124 \n125 pvlib usage questions can be asked on\n126 [Stack Overflow](http://stackoverflow.com) and tagged with\n127 the [pvlib](http://stackoverflow.com/questions/tagged/pvlib) tag.\n128 \n129 The [pvlib-python google group](https://groups.google.com/forum/#!forum/pvlib-python)\n130 is used for discussing various topics of interest to the pvlib-python\n131 community. We also make new version announcements on the google group.\n132 \n133 If you suspect that you may have discovered a bug or if you'd like to\n134 change something about pvlib, then please make an issue on our\n135 [GitHub issues page](https://github.com/pvlib/pvlib-python/issues).\n136 \n137 \n138 \n139 License\n140 =======\n141 \n142 BSD 3-clause.\n143 \n144 \n145 NumFOCUS\n146 ========\n147 \n148 pvlib python is a [NumFOCUS Affiliated Project](https://numfocus.org/sponsored-projects/affiliated-projects)\n149 \n150 [![NumFocus Affliated Projects](https://i0.wp.com/numfocus.org/wp-content/uploads/2019/06/AffiliatedProject.png)](https://numfocus.org/sponsored-projects/affiliated-projects)\n151 \n[end of README.md]\n[start of pvlib/snow.py]\n1 \"\"\"\n2 The ``snow`` module contains functions that model module snow cover and the\n3 associated effects on PV module output\n4 \"\"\"\n5 \n6 import numpy as np\n7 import pandas as pd\n8 from pvlib.tools import sind, cosd, tand\n9 \n10 \n11 def _time_delta_in_hours(times):\n12     delta = times.to_series().diff()\n13     return delta.dt.total_seconds().div(3600)\n14 \n15 \n16 def fully_covered_nrel(snowfall, threshold_snowfall=1.):\n17     '''\n18     Calculates the timesteps when the row's slant height is fully covered\n19     by snow.\n20 \n21     Parameters\n22     ----------\n23     snowfall : Series\n24         Accumulated snowfall in each time period [cm]\n25 \n26     threshold_snowfall : float, default 1.0\n27         Hourly snowfall above which snow coverage is set to the row's slant\n28         height. [cm/hr]\n29 \n30     Returns\n31     ----------\n32     boolean: Series\n33         True where the snowfall exceeds the defined threshold to fully cover\n34         the panel.\n35 \n36     Notes\n37     -----\n38     Implements the model described in [1]_ with minor improvements in [2]_.\n39 \n40     References\n41     ----------\n42     .. [1] Marion, B.; Schaefer, R.; Caine, H.; Sanchez, G. (2013).\n43        \"Measured and modeled photovoltaic system energy losses from snow for\n44        Colorado and Wisconsin locations.\" Solar Energy 97; pp.112-121.\n45     .. [2] Ryberg, D; Freeman, J. \"Integration, Validation, and Application\n46        of a PV Snow Coverage Model in SAM\" (2017) NREL Technical Report\n47        NREL/TP-6A20-68705\n48     '''\n49     timestep = _time_delta_in_hours(snowfall.index)\n50     hourly_snow_rate = snowfall / timestep\n51     # if we can infer a time frequency, use first snowfall value\n52     # otherwise the first snowfall value is ignored\n53     freq = pd.infer_freq(snowfall.index)\n54     if freq is not None:\n55         timedelta = pd.tseries.frequencies.to_offset(freq) / pd.Timedelta('1h')\n56         hourly_snow_rate.iloc[0] = snowfall[0] / timedelta\n57     else:  # can't infer frequency from index\n58         hourly_snow_rate[0] = 0  # replaces NaN\n59     return hourly_snow_rate > threshold_snowfall\n60 \n61 \n62 def coverage_nrel(snowfall, poa_irradiance, temp_air, surface_tilt,\n63                   initial_coverage=0, threshold_snowfall=1.,\n64                   can_slide_coefficient=-80., slide_amount_coefficient=0.197):\n65     '''\n66     Calculates the fraction of the slant height of a row of modules covered by\n67     snow at every time step.\n68 \n69     Implements the model described in [1]_ with minor improvements in [2]_,\n70     with the change that the output is in fraction of the row's slant height\n71     rather than in tenths of the row slant height. As described in [1]_, model\n72     validation focused on fixed tilt systems.\n73 \n74     Parameters\n75     ----------\n76     snowfall : Series\n77         Accumulated snowfall within each time period. [cm]\n78     poa_irradiance : Series\n79         Total in-plane irradiance [W/m^2]\n80     temp_air : Series\n81         Ambient air temperature [C]\n82     surface_tilt : numeric\n83         Tilt of module's from horizontal, e.g. surface facing up = 0,\n84         surface facing horizon = 90. [degrees]\n85     initial_coverage : float, default 0\n86         Fraction of row's slant height that is covered with snow at the\n87         beginning of the simulation. [unitless]\n88     threshold_snowfall : float, default 1.0\n89         Hourly snowfall above which snow coverage is set to the row's slant\n90         height. [cm/hr]\n91     can_slide_coefficient : float, default -80.\n92         Coefficient to determine if snow can slide given irradiance and air\n93         temperature. [W/(m^2 C)]\n94     slide_amount_coefficient : float, default 0.197\n95         Coefficient to determine fraction of snow that slides off in one hour.\n96         [unitless]\n97 \n98     Returns\n99     -------\n100     snow_coverage : Series\n101         The fraction of the slant height of a row of modules that is covered\n102         by snow at each time step.\n103 \n104     Notes\n105     -----\n106     In [1]_, `can_slide_coefficient` is termed `m`, and the value of\n107     `slide_amount_coefficient` is given in tenths of a module's slant height.\n108 \n109     References\n110     ----------\n111     .. [1] Marion, B.; Schaefer, R.; Caine, H.; Sanchez, G. (2013).\n112        \"Measured and modeled photovoltaic system energy losses from snow for\n113        Colorado and Wisconsin locations.\" Solar Energy 97; pp.112-121.\n114     .. [2] Ryberg, D; Freeman, J. (2017). \"Integration, Validation, and\n115        Application of a PV Snow Coverage Model in SAM\" NREL Technical Report\n116        NREL/TP-6A20-68705\n117     '''\n118 \n119     # find times with new snowfall\n120     new_snowfall = fully_covered_nrel(snowfall, threshold_snowfall)\n121 \n122     # set up output Series\n123     snow_coverage = pd.Series(np.nan, index=poa_irradiance.index)\n124 \n125     # determine amount that snow can slide in each timestep\n126     can_slide = temp_air > poa_irradiance / can_slide_coefficient\n127     slide_amt = slide_amount_coefficient * sind(surface_tilt) * \\\n128         _time_delta_in_hours(poa_irradiance.index)\n129     slide_amt[~can_slide] = 0.\n130     # don't slide during snow events\n131     slide_amt[new_snowfall] = 0.\n132     # don't slide in the interval preceding the snowfall data\n133     slide_amt.iloc[0] = 0\n134 \n135     # build time series of cumulative slide amounts\n136     sliding_period_ID = new_snowfall.cumsum()\n137     cumulative_sliding = slide_amt.groupby(sliding_period_ID).cumsum()\n138 \n139     # set up time series of snow coverage without any sliding applied\n140     snow_coverage[new_snowfall] = 1.0\n141     if np.isnan(snow_coverage.iloc[0]):\n142         snow_coverage.iloc[0] = initial_coverage\n143     snow_coverage.ffill(inplace=True)\n144     snow_coverage -= cumulative_sliding\n145 \n146     # clean up periods where row is completely uncovered\n147     return snow_coverage.clip(lower=0)\n148 \n149 \n150 def dc_loss_nrel(snow_coverage, num_strings):\n151     '''\n152     Calculates the fraction of DC capacity lost due to snow coverage.\n153 \n154     DC capacity loss assumes that if a string is partially covered by snow,\n155     the string's capacity is lost; see [1]_, Eq. 11.8.\n156 \n157     Module orientation is accounted for by specifying the number of cell\n158     strings in parallel along the slant height.\n159     For example, a typical 60-cell module has 3 parallel strings, each\n160     comprising 20 cells in series, with the cells arranged in 6 columns of 10\n161     cells each. For a row consisting of single modules, if the module is\n162     mounted in portrait orientation, i.e., the row slant height is along a\n163     column of 10 cells, there is 1 string in parallel along the row slant\n164     height, so `num_strings=1`. In contrast, if the module is mounted in\n165     landscape orientation with the row slant height comprising 6 cells, there\n166     are 3 parallel strings along the row slant height, so `num_strings=3`.\n167 \n168     Parameters\n169     ----------\n170     snow_coverage : numeric\n171         The fraction of row slant height covered by snow at each time step.\n172 \n173     num_strings: int\n174         The number of parallel-connected strings along a row slant height.\n175 \n176     Returns\n177     -------\n178     loss : numeric\n179         fraction of DC capacity loss due to snow coverage at each time step.\n180 \n181     References\n182     ----------\n183     .. [1] Gilman, P. et al., (2018). \"SAM Photovoltaic Model Technical\n184        Reference Update\", NREL Technical Report NREL/TP-6A20-67399.\n185        Available at https://www.nrel.gov/docs/fy18osti/67399.pdf\n186     '''\n187     return np.ceil(snow_coverage * num_strings) / num_strings\n188 \n189 \n190 def _townsend_effective_snow(snow_total, snow_events):\n191     '''\n192     Calculates effective snow using the total snowfall received each month and\n193     the number of snowfall events each month.\n194 \n195     Parameters\n196     ----------\n197     snow_total : array-like\n198         Snow received each month. Referred to as S in [1]_. [cm]\n199 \n200     snow_events : array-like\n201         Number of snowfall events each month. Referred to as N in [1]_. [-]\n202 \n203     Returns\n204     -------\n205     effective_snowfall : array-like\n206         Effective snowfall as defined in the Townsend model. [cm]\n207 \n208     References\n209     ----------\n210     .. [1] Townsend, Tim & Powers, Loren. (2011). Photovoltaics and snow: An\n211        update from two winters of measurements in the SIERRA. 37th IEEE\n212        Photovoltaic Specialists Conference, Seattle, WA, USA.\n213        :doi:`10.1109/PVSC.2011.6186627`\n214     '''\n215     snow_events_no_zeros = np.maximum(snow_events, 1)\n216     effective_snow = 0.5 * snow_total * (1 + 1 / snow_events_no_zeros)\n217     return np.where(snow_events > 0, effective_snow, 0)\n218 \n219 \n220 def loss_townsend(snow_total, snow_events, surface_tilt, relative_humidity,\n221                   temp_air, poa_global, slant_height, lower_edge_height,\n222                   angle_of_repose=40):\n223     '''\n224     Calculates monthly snow loss based on the Townsend monthly snow loss\n225     model [1]_.\n226 \n227     Parameters\n228     ----------\n229     snow_total : array-like\n230         Snow received each month. Referred to as S in [1]_. [cm]\n231 \n232     snow_events : array-like\n233         Number of snowfall events each month. Referred to as N in [1]_. [-]\n234 \n235     surface_tilt : float\n236         Tilt angle of the array. [deg]\n237 \n238     relative_humidity : array-like\n239         Monthly average relative humidity. [%]\n240 \n241     temp_air : array-like\n242         Monthly average ambient temperature. [C]\n243 \n244     poa_global : array-like\n245         Monthly plane of array insolation. [Wh/m2]\n246 \n247     slant_height : float\n248         Row length in the slanted plane of array dimension. [m]\n249 \n250     lower_edge_height : float\n251         Distance from array lower edge to the ground. [m]\n252 \n253     angle_of_repose : float, default 40\n254         Piled snow angle, assumed to stabilize at 40\u00b0, the midpoint of\n255         25\u00b0-55\u00b0 avalanching slope angles. [deg]\n256 \n257     Returns\n258     -------\n259     loss : array-like\n260         Monthly average DC capacity loss fraction due to snow coverage.\n261 \n262     Notes\n263     -----\n264     This model has not been validated for tracking arrays; however, for\n265     tracking arrays [1]_ suggests using the maximum rotation angle in place\n266     of ``surface_tilt``.\n267 \n268     References\n269     ----------\n270     .. [1] Townsend, Tim & Powers, Loren. (2011). Photovoltaics and snow: An\n271        update from two winters of measurements in the SIERRA. 37th IEEE\n272        Photovoltaic Specialists Conference, Seattle, WA, USA.\n273        :doi:`10.1109/PVSC.2011.6186627`\n274     '''\n275 \n276     C1 = 5.7e04\n277     C2 = 0.51\n278 \n279     snow_total_prev = np.roll(snow_total, 1)\n280     snow_events_prev = np.roll(snow_events, 1)\n281 \n282     effective_snow = _townsend_effective_snow(snow_total, snow_events)\n283     effective_snow_prev = _townsend_effective_snow(\n284         snow_total_prev,\n285         snow_events_prev\n286     )\n287     effective_snow_weighted = (\n288         1 / 3 * effective_snow_prev\n289         + 2 / 3 * effective_snow\n290     )\n291     effective_snow_weighted_m = effective_snow_weighted / 100\n292 \n293     lower_edge_height_clipped = np.maximum(lower_edge_height, 0.01)\n294     gamma = (\n295         slant_height\n296         * effective_snow_weighted_m\n297         * cosd(surface_tilt)\n298         / (lower_edge_height_clipped**2 - effective_snow_weighted_m**2)\n299         * 2\n300         * tand(angle_of_repose)\n301     )\n302 \n303     ground_interference_term = 1 - C2 * np.exp(-gamma)\n304     relative_humidity_fraction = relative_humidity / 100\n305     temp_air_kelvin = temp_air + 273.15\n306     effective_snow_weighted_in = effective_snow_weighted / 2.54\n307     poa_global_kWh = poa_global / 1000\n308 \n309     # Calculate Eqn. 3 in the reference.\n310     # Although the reference says Eqn. 3 calculates percentage loss, the y-axis\n311     # of Figure 7 indicates Eqn. 3 calculates fractional loss. Since the slope\n312     # of the line in Figure 7 is the same as C1 in Eqn. 3, it is assumed that\n313     # Eqn. 3 calculates fractional loss.\n314     loss_fraction = (\n315         C1\n316         * effective_snow_weighted_in\n317         * cosd(surface_tilt)**2\n318         * ground_interference_term\n319         * relative_humidity_fraction\n320         / temp_air_kelvin**2\n321         / poa_global_kWh**0.67\n322     )\n323 \n324     return np.clip(loss_fraction, 0, 1)\n325 \n[end of pvlib/snow.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n\n\n", "full_output": "```patch\n--- a/pvlib/snow.py\n+++ b/pvlib/snow.py\n@@ -293,12 +293,15 @@\n     lower_edge_height_clipped = np.maximum(lower_edge_height, 0.01)\n     gamma = (\n         slant_height\n         * effective_snow_weighted_m\n-        * cosd(surface_tilt)\n-        / (lower_edge_height_clipped**2 - effective_snow_weighted_m**2)\n+        * cosd(surface_tilt) \n+        / np.maximum(lower_edge_height_clipped**2 - effective_snow_weighted_m**2, 0.01)\n         * 2\n         * tand(angle_of_repose)\n     )\n \n     ground_interference_term = 1 - C2 * np.exp(-gamma)\n \n     # Convert units from cm/m to inches earlier in the process\n-    effective_snow_weighted_in = effective_snow_weighted / 2.54\n+    effective_snow_weighted_in = effective_snow_weighted * 0.393701  # cm to inches\n     poa_global_kWh = poa_global / 1000\n \n     # Calculate Eqn. 3 in the reference.\n```", "model_patch": "--- a/pvlib/snow.py\n+++ b/pvlib/snow.py\n@@ -293,12 +293,15 @@\n     lower_edge_height_clipped = np.maximum(lower_edge_height, 0.01)\n     gamma = (\n         slant_height\n         * effective_snow_weighted_m\n-        * cosd(surface_tilt)\n-        / (lower_edge_height_clipped**2 - effective_snow_weighted_m**2)\n+        * cosd(surface_tilt) \n+        / np.maximum(lower_edge_height_clipped**2 - effective_snow_weighted_m**2, 0.01)\n         * 2\n         * tand(angle_of_repose)\n     )\n \n     ground_interference_term = 1 - C2 * np.exp(-gamma)\n \n     # Convert units from cm/m to inches earlier in the process\n-    effective_snow_weighted_in = effective_snow_weighted / 2.54\n+    effective_snow_weighted_in = effective_snow_weighted * 0.393701  # cm to inches\n     poa_global_kWh = poa_global / 1000\n \n     # Calculate Eqn. 3 in the reference.\n"}
{"instance_id": "pvlib__pvlib-python-763", "model_name_or_path": "gpt-4o-mini", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nAdd recombination current params to all bishop88 functions\nThe changes made in #163 incorporate recombination current into the `bishop88()` function.  Functions that build on the `bishop88()` function should likewise accept these parameters.\r\n\n\n</issue>\n<code>\n[start of README.md]\n1 <img src=\"docs/sphinx/source/_images/pvlib_logo_horiz.png\" width=\"600\">\n2 \n3 [![TravisCI](https://travis-ci.org/pvlib/pvlib-python.svg?branch=master)](https://travis-ci.org/pvlib/pvlib-python)\n4 [![Coverage Status](https://img.shields.io/coveralls/pvlib/pvlib-python.svg)](https://coveralls.io/r/pvlib/pvlib-python)\n5 [![codecov](https://codecov.io/gh/pvlib/pvlib-python/branch/master/graph/badge.svg)](https://codecov.io/gh/pvlib/pvlib-python)\n6 [![Documentation Status](https://readthedocs.org/projects/pvlib-python/badge/?version=latest)](http://pvlib-python.readthedocs.org/en/latest/)\n7 [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.2554311.svg)](https://doi.org/10.5281/zenodo.2554311)\n8 [![status](http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1/status.svg)](http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1)\n9 [![Code Quality: Python](https://img.shields.io/lgtm/grade/python/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/pvlib/pvlib-python/context:python)\n10 [![Total Alerts](https://img.shields.io/lgtm/alerts/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/pvlib/pvlib-python/alerts)\n11 \n12 \n13 pvlib python is a community supported tool that provides a set of\n14 functions and classes for simulating the performance of photovoltaic\n15 energy systems. pvlib python was originally ported from the PVLIB MATLAB\n16 toolbox developed at Sandia National Laboratories and it implements many\n17 of the models and methods developed at the Labs. More information on\n18 Sandia Labs PV performance modeling programs can be found at\n19 https://pvpmc.sandia.gov/. We collaborate with the PVLIB MATLAB project,\n20 but operate independently of it.\n21 \n22 \n23 Documentation\n24 =============\n25 \n26 Full documentation can be found at [readthedocs](http://pvlib-python.readthedocs.io/en/latest/).\n27 \n28 \n29 Installation\n30 ============\n31 \n32 pvlib-python releases may be installed using the ``pip`` and ``conda`` tools.\n33 Please see the [Installation page](http://pvlib-python.readthedocs.io/en/latest/installation.html) of the documentation for complete instructions.\n34 \n35 pvlib-python is compatible with Python 3.5 and above.\n36 \n37 **Python 2.7 support ended on June 1, 2019, with pvlib-python 0.6.3.**\n38 \n39 \n40 Contributing\n41 ============\n42 \n43 We need your help to make pvlib-python a great tool!\n44 Please see the [Contributing page](http://pvlib-python.readthedocs.io/en/latest/contributing.html) for more on how you can contribute.\n45 The long-term success of pvlib-python requires substantial community support.\n46 \n47 \n48 License\n49 =======\n50 \n51 BSD 3-clause\n52 \n53 \n54 Getting support\n55 ===============\n56 \n57 pvlib usage questions can be asked on\n58 [Stack Overflow](http://stackoverflow.com) and tagged with\n59 the [pvlib](http://stackoverflow.com/questions/tagged/pvlib) tag.\n60 \n61 The [pvlib-python google group](https://groups.google.com/forum/#!forum/pvlib-python)\n62 is used for discussing various topics of interest to the pvlib-python\n63 community. We also make new version announcements on the google group.\n64 \n65 If you suspect that you may have discovered a bug or if you'd like to\n66 change something about pvlib, then please make an issue on our\n67 [GitHub issues page](https://github.com/pvlib/pvlib-python/issues).\n68 \n69 \n70 Citing\n71 ======\n72 \n73 If you use pvlib-python in a published work, please cite:\n74 \n75   William F. Holmgren, Clifford W. Hansen, and Mark A. Mikofski.\n76   \"pvlib python: a python package for modeling solar energy systems.\"\n77   Journal of Open Source Software, 3(29), 884, (2018).\n78   https://doi.org/10.21105/joss.00884\n79 \n80 Please also cite the DOI corresponding to the specific version of\n81 pvlib-python that you used. pvlib-python DOIs are listed at\n82 [Zenodo.org](https://zenodo.org/search?page=1&size=20&q=conceptrecid:593284&all_versions&sort=-version)\n83 \n84 NumFOCUS\n85 ========\n86 \n87 pvlib python is a [NumFOCUS Affiliated Project](https://numfocus.org/sponsored-projects/affiliated-projects)\n88 \n89 [![NumFocus Affliated Projects](https://i0.wp.com/numfocus.org/wp-content/uploads/2019/06/AffiliatedProject.png)](https://numfocus.org/sponsored-projects/affiliated-projects)\n90 \n[end of README.md]\n[start of pvlib/pvsystem.py]\n1 \"\"\"\n2 The ``pvsystem`` module contains functions for modeling the output and\n3 performance of PV modules and inverters.\n4 \"\"\"\n5 \n6 from collections import OrderedDict\n7 import io\n8 import os\n9 from urllib.request import urlopen\n10 import numpy as np\n11 import pandas as pd\n12 \n13 from pvlib import atmosphere, irradiance, tools, singlediode as _singlediode\n14 from pvlib.tools import _build_kwargs, cosd\n15 from pvlib.location import Location\n16 \n17 \n18 # a dict of required parameter names for each DC power model\n19 DC_MODEL_PARAMS = {\n20     'sapm': set([\n21         'A0', 'A1', 'A2', 'A3', 'A4', 'B0', 'B1', 'B2', 'B3',\n22         'B4', 'B5', 'C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6',\n23         'C7', 'Isco', 'Impo', 'Aisc', 'Aimp', 'Bvoco',\n24         'Mbvoc', 'Bvmpo', 'Mbvmp', 'N', 'Cells_in_Series',\n25         'IXO', 'IXXO', 'FD']),\n26     'desoto': set([\n27         'alpha_sc', 'a_ref', 'I_L_ref', 'I_o_ref',\n28         'R_sh_ref', 'R_s']),\n29     'cec': set([\n30         'alpha_sc', 'a_ref', 'I_L_ref', 'I_o_ref',\n31         'R_sh_ref', 'R_s', 'Adjust']),\n32     'pvsyst': set([\n33         'gamma_ref', 'mu_gamma', 'I_L_ref', 'I_o_ref',\n34         'R_sh_ref', 'R_sh_0', 'R_s', 'alpha_sc', 'EgRef',\n35         'cells_in_series']),\n36     'singlediode': set([\n37         'alpha_sc', 'a_ref', 'I_L_ref', 'I_o_ref',\n38         'R_sh_ref', 'R_s']),\n39     'pvwatts': set(['pdc0', 'gamma_pdc'])\n40 }\n41 \n42 \n43 TEMP_MODEL_PARAMS = {\n44     'sapm': {'open_rack_cell_glassback': (-3.47, -.0594, 3),\n45              'roof_mount_cell_glassback': (-2.98, -.0471, 1),\n46              'open_rack_cell_polymerback': (-3.56, -.0750, 3),\n47              'insulated_back_polymerback': (-2.81, -.0455, 0),\n48              'open_rack_polymer_thinfilm_steel': (-3.58, -.113, 3),\n49              '22x_concentrator_tracker': (-3.23, -.130, 13)},\n50     'pvsyst': {'freestanding': (29.0, 0), 'insulated': (15.0, 0)}\n51 }\n52 \n53 # not sure if this belongs in the pvsystem module.\n54 # maybe something more like core.py? It may eventually grow to\n55 # import a lot more functionality from other modules.\n56 class PVSystem(object):\n57     \"\"\"\n58     The PVSystem class defines a standard set of PV system attributes\n59     and modeling functions. This class describes the collection and\n60     interactions of PV system components rather than an installed system\n61     on the ground. It is typically used in combination with\n62     :py:class:`~pvlib.location.Location` and\n63     :py:class:`~pvlib.modelchain.ModelChain`\n64     objects.\n65 \n66     See the :py:class:`LocalizedPVSystem` class for an object model that\n67     describes an installed PV system.\n68 \n69     The class supports basic system topologies consisting of:\n70 \n71         * `N` total modules arranged in series\n72           (`modules_per_string=N`, `strings_per_inverter=1`).\n73         * `M` total modules arranged in parallel\n74           (`modules_per_string=1`, `strings_per_inverter=M`).\n75         * `NxM` total modules arranged in `M` strings of `N` modules each\n76           (`modules_per_string=N`, `strings_per_inverter=M`).\n77 \n78     The class is complementary to the module-level functions.\n79 \n80     The attributes should generally be things that don't change about\n81     the system, such the type of module and the inverter. The instance\n82     methods accept arguments for things that do change, such as\n83     irradiance and temperature.\n84 \n85     Parameters\n86     ----------\n87     surface_tilt: float or array-like, default 0\n88         Surface tilt angles in decimal degrees.\n89         The tilt angle is defined as degrees from horizontal\n90         (e.g. surface facing up = 0, surface facing horizon = 90)\n91 \n92     surface_azimuth: float or array-like, default 180\n93         Azimuth angle of the module surface.\n94         North=0, East=90, South=180, West=270.\n95 \n96     albedo : None or float, default None\n97         The ground albedo. If ``None``, will attempt to use\n98         ``surface_type`` and ``irradiance.SURFACE_ALBEDOS``\n99         to lookup albedo.\n100 \n101     surface_type : None or string, default None\n102         The ground surface type. See ``irradiance.SURFACE_ALBEDOS``\n103         for valid values.\n104 \n105     module : None or string, default None\n106         The model name of the modules.\n107         May be used to look up the module_parameters dictionary\n108         via some other method.\n109 \n110     module_parameters : None, dict or Series, default None\n111         Module parameters as defined by the SAPM, CEC, or other.\n112 \n113     modules_per_string: int or float, default 1\n114         See system topology discussion above.\n115 \n116     strings_per_inverter: int or float, default 1\n117         See system topology discussion above.\n118 \n119     inverter : None or string, default None\n120         The model name of the inverters.\n121         May be used to look up the inverter_parameters dictionary\n122         via some other method.\n123 \n124     inverter_parameters : None, dict or Series, default None\n125         Inverter parameters as defined by the SAPM, CEC, or other.\n126 \n127     racking_model : None or string, default 'open_rack_cell_glassback'\n128         Used for cell and module temperature calculations.\n129 \n130     losses_parameters : None, dict or Series, default None\n131         Losses parameters as defined by PVWatts or other.\n132 \n133     name : None or string, default None\n134 \n135     **kwargs\n136         Arbitrary keyword arguments.\n137         Included for compatibility, but not used.\n138 \n139     See also\n140     --------\n141     pvlib.location.Location\n142     pvlib.tracking.SingleAxisTracker\n143     pvlib.pvsystem.LocalizedPVSystem\n144     \"\"\"\n145 \n146     def __init__(self,\n147                  surface_tilt=0, surface_azimuth=180,\n148                  albedo=None, surface_type=None,\n149                  module=None, module_parameters=None,\n150                  modules_per_string=1, strings_per_inverter=1,\n151                  inverter=None, inverter_parameters=None,\n152                  racking_model='open_rack_cell_glassback',\n153                  losses_parameters=None, name=None, **kwargs):\n154 \n155         self.name = name\n156 \n157         self.surface_tilt = surface_tilt\n158         self.surface_azimuth = surface_azimuth\n159 \n160         # could tie these together with @property\n161         self.surface_type = surface_type\n162         if albedo is None:\n163             self.albedo = irradiance.SURFACE_ALBEDOS.get(surface_type, 0.25)\n164         else:\n165             self.albedo = albedo\n166 \n167         # could tie these together with @property\n168         self.module = module\n169         if module_parameters is None:\n170             self.module_parameters = {}\n171         else:\n172             self.module_parameters = module_parameters\n173 \n174         self.modules_per_string = modules_per_string\n175         self.strings_per_inverter = strings_per_inverter\n176 \n177         self.inverter = inverter\n178         if inverter_parameters is None:\n179             self.inverter_parameters = {}\n180         else:\n181             self.inverter_parameters = inverter_parameters\n182 \n183         if losses_parameters is None:\n184             self.losses_parameters = {}\n185         else:\n186             self.losses_parameters = losses_parameters\n187 \n188         self.racking_model = racking_model\n189 \n190     def __repr__(self):\n191         attrs = ['name', 'surface_tilt', 'surface_azimuth', 'module',\n192                  'inverter', 'albedo', 'racking_model']\n193         return ('PVSystem: \\n  ' + '\\n  '.join(\n194             ('{}: {}'.format(attr, getattr(self, attr)) for attr in attrs)))\n195 \n196     def get_aoi(self, solar_zenith, solar_azimuth):\n197         \"\"\"Get the angle of incidence on the system.\n198 \n199         Parameters\n200         ----------\n201         solar_zenith : float or Series.\n202             Solar zenith angle.\n203         solar_azimuth : float or Series.\n204             Solar azimuth angle.\n205 \n206         Returns\n207         -------\n208         aoi : Series\n209             The angle of incidence\n210         \"\"\"\n211 \n212         aoi = irradiance.aoi(self.surface_tilt, self.surface_azimuth,\n213                              solar_zenith, solar_azimuth)\n214         return aoi\n215 \n216     def get_irradiance(self, solar_zenith, solar_azimuth, dni, ghi, dhi,\n217                        dni_extra=None, airmass=None, model='haydavies',\n218                        **kwargs):\n219         \"\"\"\n220         Uses the :py:func:`irradiance.get_total_irradiance` function to\n221         calculate the plane of array irradiance components on a tilted\n222         surface defined by ``self.surface_tilt``,\n223         ``self.surface_azimuth``, and ``self.albedo``.\n224 \n225         Parameters\n226         ----------\n227         solar_zenith : float or Series.\n228             Solar zenith angle.\n229         solar_azimuth : float or Series.\n230             Solar azimuth angle.\n231         dni : float or Series\n232             Direct Normal Irradiance\n233         ghi : float or Series\n234             Global horizontal irradiance\n235         dhi : float or Series\n236             Diffuse horizontal irradiance\n237         dni_extra : None, float or Series, default None\n238             Extraterrestrial direct normal irradiance\n239         airmass : None, float or Series, default None\n240             Airmass\n241         model : String, default 'haydavies'\n242             Irradiance model.\n243 \n244         kwargs\n245             Extra parameters passed to :func:`irradiance.total_irrad`.\n246 \n247         Returns\n248         -------\n249         poa_irradiance : DataFrame\n250             Column names are: ``total, beam, sky, ground``.\n251         \"\"\"\n252 \n253         # not needed for all models, but this is easier\n254         if dni_extra is None:\n255             dni_extra = irradiance.get_extra_radiation(solar_zenith.index)\n256 \n257         if airmass is None:\n258             airmass = atmosphere.get_relative_airmass(solar_zenith)\n259 \n260         return irradiance.get_total_irradiance(self.surface_tilt,\n261                                                self.surface_azimuth,\n262                                                solar_zenith, solar_azimuth,\n263                                                dni, ghi, dhi,\n264                                                dni_extra=dni_extra,\n265                                                airmass=airmass,\n266                                                model=model,\n267                                                albedo=self.albedo,\n268                                                **kwargs)\n269 \n270     def ashraeiam(self, aoi):\n271         \"\"\"\n272         Determine the incidence angle modifier using\n273         ``self.module_parameters['b']``, ``aoi``,\n274         and the :py:func:`ashraeiam` function.\n275 \n276         Uses default arguments if keys not in module_parameters.\n277 \n278         Parameters\n279         ----------\n280         aoi : numeric\n281             The angle of incidence in degrees.\n282 \n283         Returns\n284         -------\n285         modifier : numeric\n286             The AOI modifier.\n287         \"\"\"\n288         kwargs = _build_kwargs(['b'], self.module_parameters)\n289 \n290         return ashraeiam(aoi, **kwargs)\n291 \n292     def physicaliam(self, aoi):\n293         \"\"\"\n294         Determine the incidence angle modifier using ``aoi``,\n295         ``self.module_parameters['K']``,\n296         ``self.module_parameters['L']``,\n297         ``self.module_parameters['n']``,\n298         and the\n299         :py:func:`physicaliam` function.\n300 \n301         Uses default arguments if keys not in module_parameters.\n302 \n303         Parameters\n304         ----------\n305         aoi : numeric\n306             The angle of incidence in degrees.\n307 \n308         Returns\n309         -------\n310         modifier : numeric\n311             The AOI modifier.\n312         \"\"\"\n313         kwargs = _build_kwargs(['K', 'L', 'n'], self.module_parameters)\n314 \n315         return physicaliam(aoi, **kwargs)\n316 \n317     def calcparams_desoto(self, effective_irradiance, temp_cell, **kwargs):\n318         \"\"\"\n319         Use the :py:func:`calcparams_desoto` function, the input\n320         parameters and ``self.module_parameters`` to calculate the\n321         module currents and resistances.\n322 \n323         Parameters\n324         ----------\n325         effective_irradiance : numeric\n326             The irradiance (W/m2) that is converted to photocurrent.\n327 \n328         temp_cell : float or Series\n329             The average cell temperature of cells within a module in C.\n330 \n331         **kwargs\n332             See pvsystem.calcparams_desoto for details\n333 \n334         Returns\n335         -------\n336         See pvsystem.calcparams_desoto for details\n337         \"\"\"\n338 \n339         kwargs = _build_kwargs(['a_ref', 'I_L_ref', 'I_o_ref', 'R_sh_ref',\n340                                 'R_s', 'alpha_sc', 'EgRef', 'dEgdT',\n341                                 'irrad_ref', 'temp_ref'],\n342                                self.module_parameters)\n343 \n344         return calcparams_desoto(effective_irradiance, temp_cell, **kwargs)\n345 \n346     def calcparams_cec(self, effective_irradiance, temp_cell, **kwargs):\n347         \"\"\"\n348         Use the :py:func:`calcparams_cec` function, the input\n349         parameters and ``self.module_parameters`` to calculate the\n350         module currents and resistances.\n351 \n352         Parameters\n353         ----------\n354         effective_irradiance : numeric\n355             The irradiance (W/m2) that is converted to photocurrent.\n356 \n357         temp_cell : float or Series\n358             The average cell temperature of cells within a module in C.\n359 \n360         **kwargs\n361             See pvsystem.calcparams_cec for details\n362 \n363         Returns\n364         -------\n365         See pvsystem.calcparams_cec for details\n366         \"\"\"\n367 \n368         kwargs = _build_kwargs(['a_ref', 'I_L_ref', 'I_o_ref', 'R_sh_ref',\n369                                 'R_s', 'alpha_sc', 'Adjust', 'EgRef', 'dEgdT',\n370                                 'irrad_ref', 'temp_ref'],\n371                                self.module_parameters)\n372 \n373         return calcparams_cec(effective_irradiance, temp_cell, **kwargs)\n374 \n375     def calcparams_pvsyst(self, effective_irradiance, temp_cell):\n376         \"\"\"\n377         Use the :py:func:`calcparams_pvsyst` function, the input\n378         parameters and ``self.module_parameters`` to calculate the\n379         module currents and resistances.\n380 \n381         Parameters\n382         ----------\n383         effective_irradiance : numeric\n384             The irradiance (W/m2) that is converted to photocurrent.\n385 \n386         temp_cell : float or Series\n387             The average cell temperature of cells within a module in C.\n388 \n389         Returns\n390         -------\n391         See pvsystem.calcparams_pvsyst for details\n392         \"\"\"\n393 \n394         kwargs = _build_kwargs(['gamma_ref', 'mu_gamma', 'I_L_ref', 'I_o_ref',\n395                                 'R_sh_ref', 'R_sh_0', 'R_sh_exp',\n396                                 'R_s', 'alpha_sc', 'EgRef',\n397                                 'irrad_ref', 'temp_ref',\n398                                 'cells_in_series'],\n399                                self.module_parameters)\n400 \n401         return calcparams_pvsyst(effective_irradiance, temp_cell, **kwargs)\n402 \n403     def sapm(self, effective_irradiance, temp_cell, **kwargs):\n404         \"\"\"\n405         Use the :py:func:`sapm` function, the input parameters,\n406         and ``self.module_parameters`` to calculate\n407         Voc, Isc, Ix, Ixx, Vmp/Imp.\n408 \n409         Parameters\n410         ----------\n411         poa_direct : Series\n412             The direct irradiance incident upon the module (W/m^2).\n413 \n414         poa_diffuse : Series\n415             The diffuse irradiance incident on module.\n416 \n417         temp_cell : Series\n418             The cell temperature (degrees C).\n419 \n420         airmass_absolute : Series\n421             Absolute airmass.\n422 \n423         aoi : Series\n424             Angle of incidence (degrees).\n425 \n426         kwargs\n427             See pvsystem.sapm for details\n428 \n429         Returns\n430         -------\n431         See pvsystem.sapm for details\n432         \"\"\"\n433         return sapm(effective_irradiance, temp_cell, self.module_parameters)\n434 \n435     def sapm_celltemp(self, irrad, wind, temp):\n436         \"\"\"Uses :py:func:`sapm_celltemp` to calculate module and cell\n437         temperatures based on ``self.racking_model`` and\n438         the input parameters.\n439 \n440         Parameters\n441         ----------\n442         See pvsystem.sapm_celltemp for details\n443 \n444         Returns\n445         -------\n446         See pvsystem.sapm_celltemp for details\n447         \"\"\"\n448         return sapm_celltemp(irrad, wind, temp, self.racking_model)\n449 \n450     def sapm_spectral_loss(self, airmass_absolute):\n451         \"\"\"\n452         Use the :py:func:`sapm_spectral_loss` function, the input\n453         parameters, and ``self.module_parameters`` to calculate F1.\n454 \n455         Parameters\n456         ----------\n457         airmass_absolute : numeric\n458             Absolute airmass.\n459 \n460         Returns\n461         -------\n462         F1 : numeric\n463             The SAPM spectral loss coefficient.\n464         \"\"\"\n465         return sapm_spectral_loss(airmass_absolute, self.module_parameters)\n466 \n467     def sapm_aoi_loss(self, aoi):\n468         \"\"\"\n469         Use the :py:func:`sapm_aoi_loss` function, the input parameters,\n470         and ``self.module_parameters`` to calculate F2.\n471 \n472         Parameters\n473         ----------\n474         aoi : numeric\n475             Angle of incidence in degrees.\n476 \n477         Returns\n478         -------\n479         F2 : numeric\n480             The SAPM angle of incidence loss coefficient.\n481         \"\"\"\n482         return sapm_aoi_loss(aoi, self.module_parameters)\n483 \n484     def sapm_effective_irradiance(self, poa_direct, poa_diffuse,\n485                                   airmass_absolute, aoi,\n486                                   reference_irradiance=1000):\n487         \"\"\"\n488         Use the :py:func:`sapm_effective_irradiance` function, the input\n489         parameters, and ``self.module_parameters`` to calculate\n490         effective irradiance.\n491 \n492         Parameters\n493         ----------\n494         poa_direct : numeric\n495             The direct irradiance incident upon the module.\n496 \n497         poa_diffuse : numeric\n498             The diffuse irradiance incident on module.\n499 \n500         airmass_absolute : numeric\n501             Absolute airmass.\n502 \n503         aoi : numeric\n504             Angle of incidence in degrees.\n505 \n506         reference_irradiance : numeric, default 1000\n507             Reference irradiance by which to divide the input irradiance.\n508 \n509         Returns\n510         -------\n511         effective_irradiance : numeric\n512             The SAPM effective irradiance.\n513         \"\"\"\n514         return sapm_effective_irradiance(\n515             poa_direct, poa_diffuse, airmass_absolute, aoi,\n516             self.module_parameters, reference_irradiance=reference_irradiance)\n517 \n518     def pvsyst_celltemp(self, poa_global, temp_air, wind_speed=1.0):\n519         \"\"\"Uses :py:func:`pvsyst_celltemp` to calculate module temperatures\n520         based on ``self.racking_model`` and the input parameters.\n521 \n522         Parameters\n523         ----------\n524         See pvsystem.pvsyst_celltemp for details\n525 \n526         Returns\n527         -------\n528         See pvsystem.pvsyst_celltemp for details\n529         \"\"\"\n530         kwargs = _build_kwargs(['eta_m', 'alpha_absorption'],\n531                                self.module_parameters)\n532         return pvsyst_celltemp(poa_global, temp_air, wind_speed,\n533                                model_params=self.racking_model, **kwargs)\n534 \n535     def first_solar_spectral_loss(self, pw, airmass_absolute):\n536 \n537         \"\"\"\n538         Use the :py:func:`first_solar_spectral_correction` function to\n539         calculate the spectral loss modifier. The model coefficients are\n540         specific to the module's cell type, and are determined by searching\n541         for one of the following keys in self.module_parameters (in order):\n542             'first_solar_spectral_coefficients' (user-supplied coefficients)\n543             'Technology' - a string describing the cell type, can be read from\n544             the CEC module parameter database\n545             'Material' - a string describing the cell type, can be read from\n546             the Sandia module database.\n547 \n548         Parameters\n549         ----------\n550         pw : array-like\n551             atmospheric precipitable water (cm).\n552 \n553         airmass_absolute : array-like\n554             absolute (pressure corrected) airmass.\n555 \n556         Returns\n557         -------\n558         modifier: array-like\n559             spectral mismatch factor (unitless) which can be multiplied\n560             with broadband irradiance reaching a module's cells to estimate\n561             effective irradiance, i.e., the irradiance that is converted to\n562             electrical current.\n563         \"\"\"\n564 \n565         if 'first_solar_spectral_coefficients' in \\\n566                 self.module_parameters.keys():\n567             coefficients = \\\n568                    self.module_parameters['first_solar_spectral_coefficients']\n569             module_type = None\n570         else:\n571             module_type = self._infer_cell_type()\n572             coefficients = None\n573 \n574         return atmosphere.first_solar_spectral_correction(pw,\n575                                                           airmass_absolute,\n576                                                           module_type,\n577                                                           coefficients)\n578 \n579     def _infer_cell_type(self):\n580 \n581         \"\"\"\n582         Examines module_parameters and maps the Technology key for the CEC\n583         database and the Material key for the Sandia database to a common\n584         list of strings for cell type.\n585 \n586         Returns\n587         -------\n588         cell_type: str\n589 \n590         \"\"\"\n591 \n592         _cell_type_dict = {'Multi-c-Si': 'multisi',\n593                            'Mono-c-Si': 'monosi',\n594                            'Thin Film': 'cigs',\n595                            'a-Si/nc': 'asi',\n596                            'CIS': 'cigs',\n597                            'CIGS': 'cigs',\n598                            '1-a-Si': 'asi',\n599                            'CdTe': 'cdte',\n600                            'a-Si': 'asi',\n601                            '2-a-Si': None,\n602                            '3-a-Si': None,\n603                            'HIT-Si': 'monosi',\n604                            'mc-Si': 'multisi',\n605                            'c-Si': 'multisi',\n606                            'Si-Film': 'asi',\n607                            'EFG mc-Si': 'multisi',\n608                            'GaAs': None,\n609                            'a-Si / mono-Si': 'monosi'}\n610 \n611         if 'Technology' in self.module_parameters.keys():\n612             # CEC module parameter set\n613             cell_type = _cell_type_dict[self.module_parameters['Technology']]\n614         elif 'Material' in self.module_parameters.keys():\n615             # Sandia module parameter set\n616             cell_type = _cell_type_dict[self.module_parameters['Material']]\n617         else:\n618             cell_type = None\n619 \n620         return cell_type\n621 \n622     def singlediode(self, photocurrent, saturation_current,\n623                     resistance_series, resistance_shunt, nNsVth,\n624                     ivcurve_pnts=None):\n625         \"\"\"Wrapper around the :py:func:`singlediode` function.\n626 \n627         Parameters\n628         ----------\n629         See pvsystem.singlediode for details\n630 \n631         Returns\n632         -------\n633         See pvsystem.singlediode for details\n634         \"\"\"\n635         return singlediode(photocurrent, saturation_current,\n636                            resistance_series, resistance_shunt, nNsVth,\n637                            ivcurve_pnts=ivcurve_pnts)\n638 \n639     def i_from_v(self, resistance_shunt, resistance_series, nNsVth, voltage,\n640                  saturation_current, photocurrent):\n641         \"\"\"Wrapper around the :py:func:`i_from_v` function.\n642 \n643         Parameters\n644         ----------\n645         See pvsystem.i_from_v for details\n646 \n647         Returns\n648         -------\n649         See pvsystem.i_from_v for details\n650         \"\"\"\n651         return i_from_v(resistance_shunt, resistance_series, nNsVth, voltage,\n652                         saturation_current, photocurrent)\n653 \n654     # inverter now specified by self.inverter_parameters\n655     def snlinverter(self, v_dc, p_dc):\n656         \"\"\"Uses :func:`snlinverter` to calculate AC power based on\n657         ``self.inverter_parameters`` and the input parameters.\n658 \n659         Parameters\n660         ----------\n661         See pvsystem.snlinverter for details\n662 \n663         Returns\n664         -------\n665         See pvsystem.snlinverter for details\n666         \"\"\"\n667         return snlinverter(v_dc, p_dc, self.inverter_parameters)\n668 \n669     def adrinverter(self, v_dc, p_dc):\n670         return adrinverter(v_dc, p_dc, self.inverter_parameters)\n671 \n672     def scale_voltage_current_power(self, data):\n673         \"\"\"\n674         Scales the voltage, current, and power of the DataFrames\n675         returned by :py:func:`singlediode` and :py:func:`sapm`\n676         by `self.modules_per_string` and `self.strings_per_inverter`.\n677 \n678         Parameters\n679         ----------\n680         data: DataFrame\n681             Must contain columns `'v_mp', 'v_oc', 'i_mp' ,'i_x', 'i_xx',\n682             'i_sc', 'p_mp'`.\n683 \n684         Returns\n685         -------\n686         scaled_data: DataFrame\n687             A scaled copy of the input data.\n688         \"\"\"\n689 \n690         return scale_voltage_current_power(data,\n691                                            voltage=self.modules_per_string,\n692                                            current=self.strings_per_inverter)\n693 \n694     def pvwatts_dc(self, g_poa_effective, temp_cell):\n695         \"\"\"\n696         Calcuates DC power according to the PVWatts model using\n697         :py:func:`pvwatts_dc`, `self.module_parameters['pdc0']`, and\n698         `self.module_parameters['gamma_pdc']`.\n699 \n700         See :py:func:`pvwatts_dc` for details.\n701         \"\"\"\n702         kwargs = _build_kwargs(['temp_ref'], self.module_parameters)\n703 \n704         return pvwatts_dc(g_poa_effective, temp_cell,\n705                           self.module_parameters['pdc0'],\n706                           self.module_parameters['gamma_pdc'],\n707                           **kwargs)\n708 \n709     def pvwatts_losses(self):\n710         \"\"\"\n711         Calculates DC power losses according the PVwatts model using\n712         :py:func:`pvwatts_losses` and ``self.losses_parameters``.`\n713 \n714         See :py:func:`pvwatts_losses` for details.\n715         \"\"\"\n716         kwargs = _build_kwargs(['soiling', 'shading', 'snow', 'mismatch',\n717                                 'wiring', 'connections', 'lid',\n718                                 'nameplate_rating', 'age', 'availability'],\n719                                self.losses_parameters)\n720         return pvwatts_losses(**kwargs)\n721 \n722     def pvwatts_ac(self, pdc):\n723         \"\"\"\n724         Calculates AC power according to the PVWatts model using\n725         :py:func:`pvwatts_ac`, `self.module_parameters['pdc0']`, and\n726         `eta_inv_nom=self.inverter_parameters['eta_inv_nom']`.\n727 \n728         See :py:func:`pvwatts_ac` for details.\n729         \"\"\"\n730         kwargs = _build_kwargs(['eta_inv_nom', 'eta_inv_ref'],\n731                                self.inverter_parameters)\n732 \n733         return pvwatts_ac(pdc, self.inverter_parameters['pdc0'], **kwargs)\n734 \n735     def localize(self, location=None, latitude=None, longitude=None,\n736                  **kwargs):\n737         \"\"\"Creates a LocalizedPVSystem object using this object\n738         and location data. Must supply either location object or\n739         latitude, longitude, and any location kwargs\n740 \n741         Parameters\n742         ----------\n743         location : None or Location, default None\n744         latitude : None or float, default None\n745         longitude : None or float, default None\n746         **kwargs : see Location\n747 \n748         Returns\n749         -------\n750         localized_system : LocalizedPVSystem\n751         \"\"\"\n752 \n753         if location is None:\n754             location = Location(latitude, longitude, **kwargs)\n755 \n756         return LocalizedPVSystem(pvsystem=self, location=location)\n757 \n758 \n759 class LocalizedPVSystem(PVSystem, Location):\n760     \"\"\"\n761     The LocalizedPVSystem class defines a standard set of installed PV\n762     system attributes and modeling functions. This class combines the\n763     attributes and methods of the PVSystem and Location classes.\n764 \n765     The LocalizedPVSystem may have bugs due to the difficulty of\n766     robustly implementing multiple inheritance. See\n767     :py:class:`~pvlib.modelchain.ModelChain` for an alternative paradigm\n768     for modeling PV systems at specific locations.\n769     \"\"\"\n770     def __init__(self, pvsystem=None, location=None, **kwargs):\n771 \n772         # get and combine attributes from the pvsystem and/or location\n773         # with the rest of the kwargs\n774 \n775         if pvsystem is not None:\n776             pv_dict = pvsystem.__dict__\n777         else:\n778             pv_dict = {}\n779 \n780         if location is not None:\n781             loc_dict = location.__dict__\n782         else:\n783             loc_dict = {}\n784 \n785         new_kwargs = dict(list(pv_dict.items()) +\n786                           list(loc_dict.items()) +\n787                           list(kwargs.items()))\n788 \n789         PVSystem.__init__(self, **new_kwargs)\n790         Location.__init__(self, **new_kwargs)\n791 \n792     def __repr__(self):\n793         attrs = ['name', 'latitude', 'longitude', 'altitude', 'tz',\n794                  'surface_tilt', 'surface_azimuth', 'module', 'inverter',\n795                  'albedo', 'racking_model']\n796         return ('LocalizedPVSystem: \\n  ' + '\\n  '.join(\n797             ('{}: {}'.format(attr, getattr(self, attr)) for attr in attrs)))\n798 \n799 \n800 def systemdef(meta, surface_tilt, surface_azimuth, albedo, modules_per_string,\n801               strings_per_inverter):\n802     '''\n803     Generates a dict of system parameters used throughout a simulation.\n804 \n805     Parameters\n806     ----------\n807 \n808     meta : dict\n809         meta dict either generated from a TMY file using readtmy2 or\n810         readtmy3, or a dict containing at least the following fields:\n811 \n812             ===============   ======  ====================\n813             meta field        format  description\n814             ===============   ======  ====================\n815             meta.altitude     Float   site elevation\n816             meta.latitude     Float   site latitude\n817             meta.longitude    Float   site longitude\n818             meta.Name         String  site name\n819             meta.State        String  state\n820             meta.TZ           Float   timezone\n821             ===============   ======  ====================\n822 \n823     surface_tilt : float or Series\n824         Surface tilt angles in decimal degrees.\n825         The tilt angle is defined as degrees from horizontal\n826         (e.g. surface facing up = 0, surface facing horizon = 90)\n827 \n828     surface_azimuth : float or Series\n829         Surface azimuth angles in decimal degrees.\n830         The azimuth convention is defined\n831         as degrees east of north\n832         (North=0, South=180, East=90, West=270).\n833 \n834     albedo : float or Series\n835         Ground reflectance, typically 0.1-0.4 for surfaces on Earth\n836         (land), may increase over snow, ice, etc. May also be known as\n837         the reflection coefficient. Must be >=0 and <=1.\n838 \n839     modules_per_string : int\n840         Number of modules connected in series in a string.\n841 \n842     strings_per_inverter : int\n843         Number of strings connected in parallel.\n844 \n845     Returns\n846     -------\n847     Result : dict\n848 \n849         A dict with the following fields.\n850 \n851             * 'surface_tilt'\n852             * 'surface_azimuth'\n853             * 'albedo'\n854             * 'modules_per_string'\n855             * 'strings_per_inverter'\n856             * 'latitude'\n857             * 'longitude'\n858             * 'tz'\n859             * 'name'\n860             * 'altitude'\n861 \n862     See also\n863     --------\n864     pvlib.tmy.readtmy3\n865     pvlib.tmy.readtmy2\n866     '''\n867 \n868     try:\n869         name = meta['Name']\n870     except KeyError:\n871         name = meta['City']\n872 \n873     system = {'surface_tilt': surface_tilt,\n874               'surface_azimuth': surface_azimuth,\n875               'albedo': albedo,\n876               'modules_per_string': modules_per_string,\n877               'strings_per_inverter': strings_per_inverter,\n878               'latitude': meta['latitude'],\n879               'longitude': meta['longitude'],\n880               'tz': meta['TZ'],\n881               'name': name,\n882               'altitude': meta['altitude']}\n883 \n884     return system\n885 \n886 \n887 def ashraeiam(aoi, b=0.05):\n888     '''\n889     Determine the incidence angle modifier using the ASHRAE transmission\n890     model.\n891 \n892     ashraeiam calculates the incidence angle modifier as developed in\n893     [1], and adopted by ASHRAE (American Society of Heating,\n894     Refrigeration, and Air Conditioning Engineers) [2]. The model has\n895     been used by model programs such as PVSyst [3].\n896 \n897     Note: For incident angles near 90 degrees, this model has a\n898     discontinuity which has been addressed in this function.\n899 \n900     Parameters\n901     ----------\n902     aoi : numeric\n903         The angle of incidence between the module normal vector and the\n904         sun-beam vector in degrees. Angles of nan will result in nan.\n905 \n906     b : float, default 0.05\n907         A parameter to adjust the modifier as a function of angle of\n908         incidence. Typical values are on the order of 0.05 [3].\n909 \n910     Returns\n911     -------\n912     IAM : numeric\n913         The incident angle modifier calculated as 1-b*(sec(aoi)-1) as\n914         described in [2,3].\n915 \n916         Returns zeros for all abs(aoi) >= 90 and for all IAM values that\n917         would be less than 0.\n918 \n919     References\n920     ----------\n921     [1] Souka A.F., Safwat H.H., \"Determination of the optimum\n922     orientations for the double exposure flat-plate collector and its\n923     reflections\". Solar Energy vol .10, pp 170-174. 1966.\n924 \n925     [2] ASHRAE standard 93-77\n926 \n927     [3] PVsyst Contextual Help.\n928     http://files.pvsyst.com/help/index.html?iam_loss.htm retrieved on\n929     September 10, 2012\n930 \n931     See Also\n932     --------\n933     irradiance.aoi\n934     physicaliam\n935     '''\n936 \n937     iam = 1 - b * ((1 / np.cos(np.radians(aoi)) - 1))\n938     aoi_gte_90 = np.full_like(aoi, False, dtype='bool')\n939     np.greater_equal(np.abs(aoi), 90, where=~np.isnan(aoi), out=aoi_gte_90)\n940     iam = np.where(aoi_gte_90, 0, iam)\n941     iam = np.maximum(0, iam)\n942 \n943     if isinstance(aoi, pd.Series):\n944         iam = pd.Series(iam, index=aoi.index)\n945 \n946     return iam\n947 \n948 \n949 def physicaliam(aoi, n=1.526, K=4., L=0.002):\n950     '''\n951     Determine the incidence angle modifier using refractive index,\n952     extinction coefficient, and glazing thickness.\n953 \n954     physicaliam calculates the incidence angle modifier as described in\n955     De Soto et al. \"Improvement and validation of a model for\n956     photovoltaic array performance\", section 3. The calculation is based\n957     on a physical model of absorbtion and transmission through a\n958     cover.\n959 \n960     Note: The authors of this function believe that eqn. 14 in [1] is\n961     incorrect. This function uses the following equation in its place:\n962     theta_r = arcsin(1/n * sin(aoi))\n963 \n964     Parameters\n965     ----------\n966     aoi : numeric\n967         The angle of incidence between the module normal vector and the\n968         sun-beam vector in degrees. Angles of 0 are replaced with 1e-06\n969         to ensure non-nan results. Angles of nan will result in nan.\n970 \n971     n : numeric, default 1.526\n972         The effective index of refraction (unitless). Reference [1]\n973         indicates that a value of 1.526 is acceptable for glass. n must\n974         be a numeric scalar or vector with all values >=0. If n is a\n975         vector, it must be the same size as all other input vectors.\n976 \n977     K : numeric, default 4.0\n978         The glazing extinction coefficient in units of 1/meters.\n979         Reference [1] indicates that a value of  4 is reasonable for\n980         \"water white\" glass. K must be a numeric scalar or vector with\n981         all values >=0. If K is a vector, it must be the same size as\n982         all other input vectors.\n983 \n984     L : numeric, default 0.002\n985         The glazing thickness in units of meters. Reference [1]\n986         indicates that 0.002 meters (2 mm) is reasonable for most\n987         glass-covered PV panels. L must be a numeric scalar or vector\n988         with all values >=0. If L is a vector, it must be the same size\n989         as all other input vectors.\n990 \n991     Returns\n992     -------\n993     iam : numeric\n994         The incident angle modifier\n995 \n996     References\n997     ----------\n998     [1] W. De Soto et al., \"Improvement and validation of a model for\n999     photovoltaic array performance\", Solar Energy, vol 80, pp. 78-88,\n1000     2006.\n1001 \n1002     [2] Duffie, John A. & Beckman, William A.. (2006). Solar Engineering\n1003     of Thermal Processes, third edition. [Books24x7 version] Available\n1004     from http://common.books24x7.com/toc.aspx?bookid=17160.\n1005 \n1006     See Also\n1007     --------\n1008     getaoi\n1009     ephemeris\n1010     spa\n1011     ashraeiam\n1012     '''\n1013     zeroang = 1e-06\n1014 \n1015     # hold a new reference to the input aoi object since we're going to\n1016     # overwrite the aoi reference below, but we'll need it for the\n1017     # series check at the end of the function\n1018     aoi_input = aoi\n1019 \n1020     aoi = np.where(aoi == 0, zeroang, aoi)\n1021 \n1022     # angle of reflection\n1023     thetar_deg = tools.asind(1.0 / n*(tools.sind(aoi)))\n1024 \n1025     # reflectance and transmittance for normal incidence light\n1026     rho_zero = ((1-n) / (1+n)) ** 2\n1027     tau_zero = np.exp(-K*L)\n1028 \n1029     # reflectance for parallel and perpendicular polarized light\n1030     rho_para = (tools.tand(thetar_deg - aoi) /\n1031                 tools.tand(thetar_deg + aoi)) ** 2\n1032     rho_perp = (tools.sind(thetar_deg - aoi) /\n1033                 tools.sind(thetar_deg + aoi)) ** 2\n1034 \n1035     # transmittance for non-normal light\n1036     tau = np.exp(-K*L / tools.cosd(thetar_deg))\n1037 \n1038     # iam is ratio of non-normal to normal incidence transmitted light\n1039     # after deducting the reflected portion of each\n1040     iam = ((1 - (rho_para + rho_perp) / 2) / (1 - rho_zero) * tau / tau_zero)\n1041 \n1042     with np.errstate(invalid='ignore'):\n1043         # angles near zero produce nan, but iam is defined as one\n1044         small_angle = 1e-06\n1045         iam = np.where(np.abs(aoi) < small_angle, 1.0, iam)\n1046 \n1047         # angles at 90 degrees can produce tiny negative values,\n1048         # which should be zero. this is a result of calculation precision\n1049         # rather than the physical model\n1050         iam = np.where(iam < 0, 0, iam)\n1051 \n1052         # for light coming from behind the plane, none can enter the module\n1053         iam = np.where(aoi > 90, 0, iam)\n1054 \n1055     if isinstance(aoi_input, pd.Series):\n1056         iam = pd.Series(iam, index=aoi_input.index)\n1057 \n1058     return iam\n1059 \n1060 \n1061 def iam_martin_ruiz(aoi, a_r=0.16):\n1062     '''\n1063     Determine the incidence angle modifier (iam) using the Martin\n1064     and Ruiz incident angle model.\n1065 \n1066     Parameters\n1067     ----------\n1068     aoi : numeric, degrees\n1069         The angle of incidence between the module normal vector and the\n1070         sun-beam vector in degrees. Theta must be a numeric scalar or vector.\n1071         iam is 0 where |aoi| > 90.\n1072 \n1073     a_r : numeric\n1074         The angular losses coefficient described in equation 3 of [1].\n1075         This is an empirical dimensionless parameter. Values of a_r are\n1076         generally on the order of 0.08 to 0.25 for flat-plate PV modules.\n1077         a_r must be a positive numeric scalar or vector (same length as aoi).\n1078 \n1079     Returns\n1080     -------\n1081     iam : numeric\n1082         The incident angle modifier(s)\n1083 \n1084     Notes\n1085     -----\n1086     iam_martin_ruiz calculates the incidence angle modifier (iam)\n1087     as described by Martin and Ruiz in [1]. The information\n1088     required is the incident angle (aoi) and the angular losses\n1089     coefficient (a_r). Please note that [1] has a corrigendum which makes\n1090     the document much simpler to understand.\n1091 \n1092     The incident angle modifier is defined as\n1093     [1-exp(-cos(aoi/ar))] / [1-exp(-1/ar)], which is\n1094     presented as AL(alpha) = 1 - IAM in equation 4 of [1]. Thus IAM is\n1095     equal to 1 at aoi = 0, and equal to 0 at aoi = 90.  This equation is only\n1096     valid for -90 <= aoi <= 90, therefore iam must be constrained to 0.0\n1097     beyond this range.\n1098 \n1099     References\n1100     ----------\n1101     [1] N. Martin and J. M. Ruiz, \"Calculation of the PV modules angular\n1102     losses under field conditions by means of an analytical model\", Solar\n1103     Energy Materials & Solar Cells, vol. 70, pp. 25-38, 2001.\n1104 \n1105     [2] N. Martin and J. M. Ruiz, \"Corrigendum to 'Calculation of the PV\n1106     modules angular losses under field conditions by means of an\n1107     analytical model'\", Solar Energy Materials & Solar Cells, vol. 110,\n1108     pp. 154, 2013.\n1109 \n1110     See Also\n1111     --------\n1112     physicaliam\n1113     ashraeiam\n1114     iam_interp\n1115     '''\n1116     # Contributed by Anton Driesse (@adriesse), PV Performance Labs. July, 2019\n1117 \n1118     aoi_input = aoi\n1119 \n1120     aoi = np.asanyarray(aoi)\n1121     a_r = np.asanyarray(a_r)\n1122 \n1123     if np.any(np.less_equal(a_r, 0)):\n1124         raise RuntimeError(\"The parameter 'a_r' cannot be zero or negative.\")\n1125 \n1126     with np.errstate(invalid='ignore'):\n1127         iam = (1 - np.exp(-cosd(aoi) / a_r)) / (1 - np.exp(-1 / a_r))\n1128         iam = np.where(np.abs(aoi) >= 90.0, 0.0, iam)\n1129 \n1130     if isinstance(aoi_input, pd.Series):\n1131         iam = pd.Series(iam, index=aoi_input.index)\n1132 \n1133     return iam\n1134 \n1135 \n1136 def iam_interp(aoi, theta_ref, iam_ref, method='linear', normalize=True):\n1137     '''\n1138     Determine the incidence angle modifier (iam) by interpolating a set of\n1139     reference values, which are usually measured values.\n1140 \n1141     Parameters\n1142     ----------\n1143     aoi : numeric, degrees\n1144         The angle of incidence between the module normal vector and the\n1145         sun-beam vector in degrees.\n1146 \n1147     theta_ref : numeric, degrees\n1148         Vector of angles at which the iam is known.\n1149 \n1150     iam_ref : numeric, unitless\n1151         iam values for each angle in theta_ref.\n1152 \n1153     method : str, default 'linear'\n1154         Specifies the interpolation method.\n1155         Useful options are: 'linear', 'quadratic','cubic'.\n1156         See scipy.interpolate.interp1d for more options.\n1157 \n1158     normalize : boolean\n1159         When true, the interpolated values are divided by the interpolated\n1160         value at zero degrees.  This ensures that the iam at normal\n1161         incidence is equal to 1.0.\n1162 \n1163     Returns\n1164     -------\n1165     iam : numeric\n1166         The incident angle modifier(s)\n1167 \n1168     Notes:\n1169     ------\n1170     theta_ref must have two or more points and may span any range of angles.\n1171     Typically there will be a dozen or more points in the range 0-90 degrees.\n1172     iam beyond the range of theta_ref are extrapolated, but constrained to be\n1173     non-negative.\n1174 \n1175     The sign of aoi is ignored; only the magnitude is used.\n1176 \n1177     See Also\n1178     --------\n1179     physicaliam\n1180     ashraeiam\n1181     iam_martin_ruiz\n1182     '''\n1183     # Contributed by Anton Driesse (@adriesse), PV Performance Labs. July, 2019\n1184 \n1185     from scipy.interpolate import interp1d\n1186 \n1187     # Scipy doesn't give the clearest feedback, so check number of points here.\n1188     MIN_REF_VALS = {'linear': 2, 'quadratic': 3, 'cubic': 4, 1: 2, 2: 3, 3: 4}\n1189 \n1190     if len(theta_ref) < MIN_REF_VALS.get(method, 2):\n1191         raise ValueError(\"Too few reference points defined \"\n1192                          \"for interpolation method '%s'.\" % method)\n1193 \n1194     if np.any(np.less(iam_ref, 0)):\n1195         raise ValueError(\"Negative value(s) found in 'iam_ref'. \"\n1196                          \"This is not physically possible.\")\n1197 \n1198     interpolator = interp1d(theta_ref, iam_ref, kind=method,\n1199                             fill_value='extrapolate')\n1200     aoi_input = aoi\n1201 \n1202     aoi = np.asanyarray(aoi)\n1203     aoi = np.abs(aoi)\n1204     iam = interpolator(aoi)\n1205     iam = np.clip(iam, 0, None)\n1206 \n1207     if normalize:\n1208         iam /= interpolator(0)\n1209 \n1210     if isinstance(aoi_input, pd.Series):\n1211         iam = pd.Series(iam, index=aoi_input.index)\n1212 \n1213     return iam\n1214 \n1215 \n1216 def calcparams_desoto(effective_irradiance, temp_cell,\n1217                       alpha_sc, a_ref, I_L_ref, I_o_ref, R_sh_ref, R_s,\n1218                       EgRef=1.121, dEgdT=-0.0002677,\n1219                       irrad_ref=1000, temp_ref=25):\n1220     '''\n1221     Calculates five parameter values for the single diode equation at\n1222     effective irradiance and cell temperature using the De Soto et al.\n1223     model described in [1]. The five values returned by calcparams_desoto\n1224     can be used by singlediode to calculate an IV curve.\n1225 \n1226     Parameters\n1227     ----------\n1228     effective_irradiance : numeric\n1229         The irradiance (W/m2) that is converted to photocurrent.\n1230 \n1231     temp_cell : numeric\n1232         The average cell temperature of cells within a module in C.\n1233 \n1234     alpha_sc : float\n1235         The short-circuit current temperature coefficient of the\n1236         module in units of A/C.\n1237 \n1238     a_ref : float\n1239         The product of the usual diode ideality factor (n, unitless),\n1240         number of cells in series (Ns), and cell thermal voltage at reference\n1241         conditions, in units of V.\n1242 \n1243     I_L_ref : float\n1244         The light-generated current (or photocurrent) at reference conditions,\n1245         in amperes.\n1246 \n1247     I_o_ref : float\n1248         The dark or diode reverse saturation current at reference conditions,\n1249         in amperes.\n1250 \n1251     R_sh_ref : float\n1252         The shunt resistance at reference conditions, in ohms.\n1253 \n1254     R_s : float\n1255         The series resistance at reference conditions, in ohms.\n1256 \n1257     EgRef : float\n1258         The energy bandgap at reference temperature in units of eV.\n1259         1.121 eV for crystalline silicon. EgRef must be >0.  For parameters\n1260         from the SAM CEC module database, EgRef=1.121 is implicit for all\n1261         cell types in the parameter estimation algorithm used by NREL.\n1262 \n1263     dEgdT : float\n1264         The temperature dependence of the energy bandgap at reference\n1265         conditions in units of 1/K. May be either a scalar value\n1266         (e.g. -0.0002677 as in [1]) or a DataFrame (this may be useful if\n1267         dEgdT is a modeled as a function of temperature). For parameters from\n1268         the SAM CEC module database, dEgdT=-0.0002677 is implicit for all cell\n1269         types in the parameter estimation algorithm used by NREL.\n1270 \n1271     irrad_ref : float (optional, default=1000)\n1272         Reference irradiance in W/m^2.\n1273 \n1274     temp_ref : float (optional, default=25)\n1275         Reference cell temperature in C.\n1276 \n1277     Returns\n1278     -------\n1279     Tuple of the following results:\n1280 \n1281     photocurrent : numeric\n1282         Light-generated current in amperes\n1283 \n1284     saturation_current : numeric\n1285         Diode saturation curent in amperes\n1286 \n1287     resistance_series : float\n1288         Series resistance in ohms\n1289 \n1290     resistance_shunt : numeric\n1291         Shunt resistance in ohms\n1292 \n1293     nNsVth : numeric\n1294         The product of the usual diode ideality factor (n, unitless),\n1295         number of cells in series (Ns), and cell thermal voltage at\n1296         specified effective irradiance and cell temperature.\n1297 \n1298     References\n1299     ----------\n1300     [1] W. De Soto et al., \"Improvement and validation of a model for\n1301     photovoltaic array performance\", Solar Energy, vol 80, pp. 78-88,\n1302     2006.\n1303 \n1304     [2] System Advisor Model web page. https://sam.nrel.gov.\n1305 \n1306     [3] A. Dobos, \"An Improved Coefficient Calculator for the California\n1307     Energy Commission 6 Parameter Photovoltaic Module Model\", Journal of\n1308     Solar Energy Engineering, vol 134, 2012.\n1309 \n1310     [4] O. Madelung, \"Semiconductors: Data Handbook, 3rd ed.\" ISBN\n1311     3-540-40488-0\n1312 \n1313     See Also\n1314     --------\n1315     singlediode\n1316     retrieve_sam\n1317 \n1318     Notes\n1319     -----\n1320     If the reference parameters in the ModuleParameters struct are read\n1321     from a database or library of parameters (e.g. System Advisor\n1322     Model), it is important to use the same EgRef and dEgdT values that\n1323     were used to generate the reference parameters, regardless of the\n1324     actual bandgap characteristics of the semiconductor. For example, in\n1325     the case of the System Advisor Model library, created as described\n1326     in [3], EgRef and dEgdT for all modules were 1.121 and -0.0002677,\n1327     respectively.\n1328 \n1329     This table of reference bandgap energies (EgRef), bandgap energy\n1330     temperature dependence (dEgdT), and \"typical\" airmass response (M)\n1331     is provided purely as reference to those who may generate their own\n1332     reference module parameters (a_ref, IL_ref, I0_ref, etc.) based upon\n1333     the various PV semiconductors. Again, we stress the importance of\n1334     using identical EgRef and dEgdT when generation reference parameters\n1335     and modifying the reference parameters (for irradiance, temperature,\n1336     and airmass) per DeSoto's equations.\n1337 \n1338      Crystalline Silicon (Si):\n1339          * EgRef = 1.121\n1340          * dEgdT = -0.0002677\n1341 \n1342          >>> M = np.polyval([-1.26E-4, 2.816E-3, -0.024459, 0.086257, 0.9181],\n1343          ...                AMa) # doctest: +SKIP\n1344 \n1345          Source: [1]\n1346 \n1347      Cadmium Telluride (CdTe):\n1348          * EgRef = 1.475\n1349          * dEgdT = -0.0003\n1350 \n1351          >>> M = np.polyval([-2.46E-5, 9.607E-4, -0.0134, 0.0716, 0.9196],\n1352          ...                AMa) # doctest: +SKIP\n1353 \n1354          Source: [4]\n1355 \n1356      Copper Indium diSelenide (CIS):\n1357          * EgRef = 1.010\n1358          * dEgdT = -0.00011\n1359 \n1360          >>> M = np.polyval([-3.74E-5, 0.00125, -0.01462, 0.0718, 0.9210],\n1361          ...                AMa) # doctest: +SKIP\n1362 \n1363          Source: [4]\n1364 \n1365      Copper Indium Gallium diSelenide (CIGS):\n1366          * EgRef = 1.15\n1367          * dEgdT = ????\n1368 \n1369          >>> M = np.polyval([-9.07E-5, 0.0022, -0.0202, 0.0652, 0.9417],\n1370          ...                AMa) # doctest: +SKIP\n1371 \n1372          Source: Wikipedia\n1373 \n1374      Gallium Arsenide (GaAs):\n1375          * EgRef = 1.424\n1376          * dEgdT = -0.000433\n1377          * M = unknown\n1378 \n1379          Source: [4]\n1380     '''\n1381 \n1382     # test for use of function pre-v0.6.0 API change\n1383     if isinstance(a_ref, dict) or \\\n1384        (isinstance(a_ref, pd.Series) and ('a_ref' in a_ref.keys())):\n1385         import warnings\n1386         warnings.warn('module_parameters detected as fourth positional'\n1387                       + ' argument of calcparams_desoto. calcparams_desoto'\n1388                       + ' will require one argument for each module model'\n1389                       + ' parameter in v0.7.0 and later', DeprecationWarning)\n1390         try:\n1391             module_parameters = a_ref\n1392             a_ref = module_parameters['a_ref']\n1393             I_L_ref = module_parameters['I_L_ref']\n1394             I_o_ref = module_parameters['I_o_ref']\n1395             R_sh_ref = module_parameters['R_sh_ref']\n1396             R_s = module_parameters['R_s']\n1397         except Exception as e:\n1398             raise e('Module parameters could not be extracted from fourth'\n1399                     + ' positional argument of calcparams_desoto. Check that'\n1400                     + ' parameters are from the CEC database and/or update'\n1401                     + ' your code for the new API for calcparams_desoto')\n1402 \n1403     # Boltzmann constant in eV/K\n1404     k = 8.617332478e-05\n1405 \n1406     # reference temperature\n1407     Tref_K = temp_ref + 273.15\n1408     Tcell_K = temp_cell + 273.15\n1409 \n1410     E_g = EgRef * (1 + dEgdT*(Tcell_K - Tref_K))\n1411 \n1412     nNsVth = a_ref * (Tcell_K / Tref_K)\n1413 \n1414     # In the equation for IL, the single factor effective_irradiance is\n1415     # used, in place of the product S*M in [1]. effective_irradiance is\n1416     # equivalent to the product of S (irradiance reaching a module's cells) *\n1417     # M (spectral adjustment factor) as described in [1].\n1418     IL = effective_irradiance / irrad_ref * \\\n1419         (I_L_ref + alpha_sc * (Tcell_K - Tref_K))\n1420     I0 = (I_o_ref * ((Tcell_K / Tref_K) ** 3) *\n1421           (np.exp(EgRef / (k*(Tref_K)) - (E_g / (k*(Tcell_K))))))\n1422     # Note that the equation for Rsh differs from [1]. In [1] Rsh is given as\n1423     # Rsh = Rsh_ref * (S_ref / S) where S is broadband irradiance reaching\n1424     # the module's cells. If desired this model behavior can be duplicated\n1425     # by applying reflection and soiling losses to broadband plane of array\n1426     # irradiance and not applying a spectral loss modifier, i.e.,\n1427     # spectral_modifier = 1.0.\n1428     # use errstate to silence divide by warning\n1429     with np.errstate(divide='ignore'):\n1430         Rsh = R_sh_ref * (irrad_ref / effective_irradiance)\n1431     Rs = R_s\n1432 \n1433     return IL, I0, Rs, Rsh, nNsVth\n1434 \n1435 \n1436 def calcparams_cec(effective_irradiance, temp_cell,\n1437                    alpha_sc, a_ref, I_L_ref, I_o_ref, R_sh_ref, R_s,\n1438                    Adjust, EgRef=1.121, dEgdT=-0.0002677,\n1439                    irrad_ref=1000, temp_ref=25):\n1440     '''\n1441     Calculates five parameter values for the single diode equation at\n1442     effective irradiance and cell temperature using the CEC\n1443     model described in [1]. The CEC model differs from the De soto et al.\n1444     model [3] by the parameter Adjust. The five values returned by\n1445     calcparams_cec can be used by singlediode to calculate an IV curve.\n1446 \n1447     Parameters\n1448     ----------\n1449     effective_irradiance : numeric\n1450         The irradiance (W/m2) that is converted to photocurrent.\n1451 \n1452     temp_cell : numeric\n1453         The average cell temperature of cells within a module in C.\n1454 \n1455     alpha_sc : float\n1456         The short-circuit current temperature coefficient of the\n1457         module in units of A/C.\n1458 \n1459     a_ref : float\n1460         The product of the usual diode ideality factor (n, unitless),\n1461         number of cells in series (Ns), and cell thermal voltage at reference\n1462         conditions, in units of V.\n1463 \n1464     I_L_ref : float\n1465         The light-generated current (or photocurrent) at reference conditions,\n1466         in amperes.\n1467 \n1468     I_o_ref : float\n1469         The dark or diode reverse saturation current at reference conditions,\n1470         in amperes.\n1471 \n1472     R_sh_ref : float\n1473         The shunt resistance at reference conditions, in ohms.\n1474 \n1475     R_s : float\n1476         The series resistance at reference conditions, in ohms.\n1477 \n1478     Adjust : float\n1479         The adjustment to the temperature coefficient for short circuit\n1480         current, in percent\n1481 \n1482     EgRef : float\n1483         The energy bandgap at reference temperature in units of eV.\n1484         1.121 eV for crystalline silicon. EgRef must be >0.  For parameters\n1485         from the SAM CEC module database, EgRef=1.121 is implicit for all\n1486         cell types in the parameter estimation algorithm used by NREL.\n1487 \n1488     dEgdT : float\n1489         The temperature dependence of the energy bandgap at reference\n1490         conditions in units of 1/K. May be either a scalar value\n1491         (e.g. -0.0002677 as in [3]) or a DataFrame (this may be useful if\n1492         dEgdT is a modeled as a function of temperature). For parameters from\n1493         the SAM CEC module database, dEgdT=-0.0002677 is implicit for all cell\n1494         types in the parameter estimation algorithm used by NREL.\n1495 \n1496     irrad_ref : float (optional, default=1000)\n1497         Reference irradiance in W/m^2.\n1498 \n1499     temp_ref : float (optional, default=25)\n1500         Reference cell temperature in C.\n1501 \n1502     Returns\n1503     -------\n1504     Tuple of the following results:\n1505 \n1506     photocurrent : numeric\n1507         Light-generated current in amperes\n1508 \n1509     saturation_current : numeric\n1510         Diode saturation curent in amperes\n1511 \n1512     resistance_series : float\n1513         Series resistance in ohms\n1514 \n1515     resistance_shunt : numeric\n1516         Shunt resistance in ohms\n1517 \n1518     nNsVth : numeric\n1519         The product of the usual diode ideality factor (n, unitless),\n1520         number of cells in series (Ns), and cell thermal voltage at\n1521         specified effective irradiance and cell temperature.\n1522 \n1523     References\n1524     ----------\n1525     [1] A. Dobos, \"An Improved Coefficient Calculator for the California\n1526     Energy Commission 6 Parameter Photovoltaic Module Model\", Journal of\n1527     Solar Energy Engineering, vol 134, 2012.\n1528 \n1529     [2] System Advisor Model web page. https://sam.nrel.gov.\n1530 \n1531     [3] W. De Soto et al., \"Improvement and validation of a model for\n1532     photovoltaic array performance\", Solar Energy, vol 80, pp. 78-88,\n1533     2006.\n1534 \n1535     See Also\n1536     --------\n1537     calcparams_desoto\n1538     singlediode\n1539     retrieve_sam\n1540 \n1541     '''\n1542 \n1543     # pass adjusted temperature coefficient to desoto\n1544     return calcparams_desoto(effective_irradiance, temp_cell,\n1545                              alpha_sc*(1.0 - Adjust/100),\n1546                              a_ref, I_L_ref, I_o_ref,\n1547                              R_sh_ref, R_s,\n1548                              EgRef=1.121, dEgdT=-0.0002677,\n1549                              irrad_ref=1000, temp_ref=25)\n1550 \n1551 \n1552 def calcparams_pvsyst(effective_irradiance, temp_cell,\n1553                       alpha_sc, gamma_ref, mu_gamma,\n1554                       I_L_ref, I_o_ref,\n1555                       R_sh_ref, R_sh_0, R_s,\n1556                       cells_in_series,\n1557                       R_sh_exp=5.5,\n1558                       EgRef=1.121,\n1559                       irrad_ref=1000, temp_ref=25):\n1560     '''\n1561     Calculates five parameter values for the single diode equation at\n1562     effective irradiance and cell temperature using the PVsyst v6\n1563     model described in [1,2,3]. The five values returned by calcparams_pvsyst\n1564     can be used by singlediode to calculate an IV curve.\n1565 \n1566     Parameters\n1567     ----------\n1568     effective_irradiance : numeric\n1569         The irradiance (W/m2) that is converted to photocurrent.\n1570 \n1571     temp_cell : numeric\n1572         The average cell temperature of cells within a module in C.\n1573 \n1574     alpha_sc : float\n1575         The short-circuit current temperature coefficient of the\n1576         module in units of A/C.\n1577 \n1578     gamma_ref : float\n1579         The diode ideality factor\n1580 \n1581     mu_gamma : float\n1582         The temperature coefficient for the diode ideality factor, 1/K\n1583 \n1584     I_L_ref : float\n1585         The light-generated current (or photocurrent) at reference conditions,\n1586         in amperes.\n1587 \n1588     I_o_ref : float\n1589         The dark or diode reverse saturation current at reference conditions,\n1590         in amperes.\n1591 \n1592     R_sh_ref : float\n1593         The shunt resistance at reference conditions, in ohms.\n1594 \n1595     R_sh_0 : float\n1596         The shunt resistance at zero irradiance conditions, in ohms.\n1597 \n1598     R_s : float\n1599         The series resistance at reference conditions, in ohms.\n1600 \n1601     cells_in_series : integer\n1602         The number of cells connected in series.\n1603 \n1604     R_sh_exp : float\n1605         The exponent in the equation for shunt resistance, unitless. Defaults\n1606         to 5.5.\n1607 \n1608     EgRef : float\n1609         The energy bandgap at reference temperature in units of eV.\n1610         1.121 eV for crystalline silicon. EgRef must be >0.\n1611 \n1612     irrad_ref : float (optional, default=1000)\n1613         Reference irradiance in W/m^2.\n1614 \n1615     temp_ref : float (optional, default=25)\n1616         Reference cell temperature in C.\n1617 \n1618     Returns\n1619     -------\n1620     Tuple of the following results:\n1621 \n1622     photocurrent : numeric\n1623         Light-generated current in amperes\n1624 \n1625     saturation_current : numeric\n1626         Diode saturation current in amperes\n1627 \n1628     resistance_series : float\n1629         Series resistance in ohms\n1630 \n1631     resistance_shunt : numeric\n1632         Shunt resistance in ohms\n1633 \n1634     nNsVth : numeric\n1635         The product of the usual diode ideality factor (n, unitless),\n1636         number of cells in series (Ns), and cell thermal voltage at\n1637         specified effective irradiance and cell temperature.\n1638 \n1639     References\n1640     ----------\n1641     [1] K. Sauer, T. Roessler, C. W. Hansen, Modeling the Irradiance and\n1642      Temperature Dependence of Photovoltaic Modules in PVsyst,\n1643      IEEE Journal of Photovoltaics v5(1), January 2015.\n1644 \n1645     [2] A. Mermoud, PV modules modelling, Presentation at the 2nd PV\n1646      Performance Modeling Workshop, Santa Clara, CA, May 2013\n1647 \n1648     [3] A. Mermoud, T. Lejeune, Performance Assessment of a Simulation Model\n1649      for PV modules of any available technology, 25th European Photovoltaic\n1650      Solar Energy Conference, Valencia, Spain, Sept. 2010\n1651 \n1652     See Also\n1653     --------\n1654     calcparams_desoto\n1655     singlediode\n1656 \n1657     '''\n1658 \n1659     # Boltzmann constant in J/K\n1660     k = 1.38064852e-23\n1661 \n1662     # elementary charge in coulomb\n1663     q = 1.6021766e-19\n1664 \n1665     # reference temperature\n1666     Tref_K = temp_ref + 273.15\n1667     Tcell_K = temp_cell + 273.15\n1668 \n1669     gamma = gamma_ref + mu_gamma * (Tcell_K - Tref_K)\n1670     nNsVth = gamma * k / q * cells_in_series * Tcell_K\n1671 \n1672     IL = effective_irradiance / irrad_ref * \\\n1673         (I_L_ref + alpha_sc * (Tcell_K - Tref_K))\n1674 \n1675     I0 = I_o_ref * ((Tcell_K / Tref_K) ** 3) * \\\n1676         (np.exp((q * EgRef) / (k * gamma) * (1 / Tref_K - 1 / Tcell_K)))\n1677 \n1678     Rsh_tmp = \\\n1679         (R_sh_ref - R_sh_0 * np.exp(-R_sh_exp)) / (1.0 - np.exp(-R_sh_exp))\n1680     Rsh_base = np.maximum(0.0, Rsh_tmp)\n1681 \n1682     Rsh = Rsh_base + (R_sh_0 - Rsh_base) * \\\n1683         np.exp(-R_sh_exp * effective_irradiance / irrad_ref)\n1684 \n1685     Rs = R_s\n1686 \n1687     return IL, I0, Rs, Rsh, nNsVth\n1688 \n1689 \n1690 def retrieve_sam(name=None, path=None):\n1691     '''\n1692     Retrieve latest module and inverter info from a local file or the\n1693     SAM website.\n1694 \n1695     This function will retrieve either:\n1696 \n1697         * CEC module database\n1698         * Sandia Module database\n1699         * CEC Inverter database\n1700         * Anton Driesse Inverter database\n1701 \n1702     and return it as a pandas DataFrame.\n1703 \n1704     Parameters\n1705     ----------\n1706     name : None or string, default None\n1707         Name can be one of:\n1708 \n1709         * 'CECMod' - returns the CEC module database\n1710         * 'CECInverter' - returns the CEC Inverter database\n1711         * 'SandiaInverter' - returns the CEC Inverter database\n1712           (CEC is only current inverter db available; tag kept for\n1713           backwards compatibility)\n1714         * 'SandiaMod' - returns the Sandia Module database\n1715         * 'ADRInverter' - returns the ADR Inverter database\n1716 \n1717     path : None or string, default None\n1718         Path to the SAM file. May also be a URL.\n1719 \n1720     If both name and path are None, a dialogue will open allowing the\n1721     user to select a file.\n1722 \n1723     Returns\n1724     -------\n1725     samfile : DataFrame\n1726         A DataFrame containing all the elements of the desired database.\n1727         Each column represents a module or inverter, and a specific\n1728         dataset can be retrieved by the command\n1729 \n1730     Notes\n1731     -----\n1732     Files available at https://sam.nrel.gov/sites/default/files/\n1733 \n1734     Examples\n1735     --------\n1736 \n1737     >>> from pvlib import pvsystem\n1738     >>> invdb = pvsystem.retrieve_sam('CECInverter')\n1739     >>> inverter = invdb.AE_Solar_Energy__AE6_0__277V__277V__CEC_2012_\n1740     >>> inverter\n1741     Vac           277.000000\n1742     Paco         6000.000000\n1743     Pdco         6165.670000\n1744     Vdco          361.123000\n1745     Pso            36.792300\n1746     C0             -0.000002\n1747     C1             -0.000047\n1748     C2             -0.001861\n1749     C3              0.000721\n1750     Pnt             0.070000\n1751     Vdcmax        600.000000\n1752     Idcmax         32.000000\n1753     Mppt_low      200.000000\n1754     Mppt_high     500.000000\n1755     Name: AE_Solar_Energy__AE6_0__277V__277V__CEC_2012_, dtype: float64\n1756     '''\n1757 \n1758     if name is not None:\n1759         name = name.lower()\n1760         data_path = os.path.join(\n1761             os.path.dirname(os.path.abspath(__file__)), 'data')\n1762         if name == 'cecmod':\n1763             csvdata = os.path.join(\n1764                 data_path, 'sam-library-cec-modules-2017-6-5.csv')\n1765         elif name == 'sandiamod':\n1766             csvdata = os.path.join(\n1767                 data_path, 'sam-library-sandia-modules-2015-6-30.csv')\n1768         elif name == 'adrinverter':\n1769             csvdata = os.path.join(data_path, 'adr-library-2013-10-01.csv')\n1770         elif name in ['cecinverter', 'sandiainverter']:\n1771             # Allowing either, to provide for old code,\n1772             # while aligning with current expectations\n1773             csvdata = os.path.join(\n1774                 data_path, 'sam-library-cec-inverters-2018-3-18.csv')\n1775         else:\n1776             raise ValueError('invalid name {}'.format(name))\n1777     elif path is not None:\n1778         if path.startswith('http'):\n1779             response = urlopen(path)\n1780             csvdata = io.StringIO(response.read().decode(errors='ignore'))\n1781         else:\n1782             csvdata = path\n1783     elif name is None and path is None:\n1784         import tkinter\n1785         from tkinter.filedialog import askopenfilename\n1786 \n1787         tkinter.Tk().withdraw()\n1788         csvdata = askopenfilename()\n1789 \n1790     return _parse_raw_sam_df(csvdata)\n1791 \n1792 \n1793 def _parse_raw_sam_df(csvdata):\n1794     df = pd.read_csv(csvdata, index_col=0, skiprows=[1, 2])\n1795     colnames = df.columns.values.tolist()\n1796     parsedcolnames = []\n1797     for cn in colnames:\n1798         parsedcolnames.append(cn.replace(' ', '_'))\n1799 \n1800     df.columns = parsedcolnames\n1801 \n1802     parsedindex = []\n1803     for index in df.index:\n1804         parsedindex.append(index.replace(' ', '_').replace('-', '_')\n1805                                 .replace('.', '_').replace('(', '_')\n1806                                 .replace(')', '_').replace('[', '_')\n1807                                 .replace(']', '_').replace(':', '_')\n1808                                 .replace('+', '_').replace('/', '_')\n1809                                 .replace('\"', '_').replace(',', '_'))\n1810 \n1811     df.index = parsedindex\n1812     df = df.transpose()\n1813     if 'ADRCoefficients' in df.index:\n1814         ad_ce = 'ADRCoefficients'\n1815         # for each inverter, parses a string of coefficients like\n1816         # ' 1.33, 2.11, 3.12' into a list containing floats:\n1817         # [1.33, 2.11, 3.12]\n1818         df.loc[ad_ce] = df.loc[ad_ce].map(lambda x: list(\n1819             map(float, x.strip(' []').split())))\n1820 \n1821     return df\n1822 \n1823 \n1824 def sapm(effective_irradiance, temp_cell, module):\n1825     '''\n1826     The Sandia PV Array Performance Model (SAPM) generates 5 points on a\n1827     PV module's I-V curve (Voc, Isc, Ix, Ixx, Vmp/Imp) according to\n1828     SAND2004-3535. Assumes a reference cell temperature of 25 C.\n1829 \n1830     Parameters\n1831     ----------\n1832     effective_irradiance : numeric\n1833         Effective irradiance (suns).\n1834 \n1835     temp_cell : numeric\n1836         The cell temperature (degrees C).\n1837 \n1838     module : dict-like\n1839         A dict, Series, or DataFrame defining the SAPM performance\n1840         parameters. See the notes section for more details.\n1841 \n1842     Returns\n1843     -------\n1844     A DataFrame with the columns:\n1845 \n1846         * i_sc : Short-circuit current (A)\n1847         * i_mp : Current at the maximum-power point (A)\n1848         * v_oc : Open-circuit voltage (V)\n1849         * v_mp : Voltage at maximum-power point (V)\n1850         * p_mp : Power at maximum-power point (W)\n1851         * i_x : Current at module V = 0.5Voc, defines 4th point on I-V\n1852           curve for modeling curve shape\n1853         * i_xx : Current at module V = 0.5(Voc+Vmp), defines 5th point on\n1854           I-V curve for modeling curve shape\n1855 \n1856     Notes\n1857     -----\n1858     The coefficients from SAPM which are required in ``module`` are\n1859     listed in the following table.\n1860 \n1861     The modules in the Sandia module database contain these\n1862     coefficients, but the modules in the CEC module database do not.\n1863     Both databases can be accessed using :py:func:`retrieve_sam`.\n1864 \n1865     ================   ========================================================\n1866     Key                Description\n1867     ================   ========================================================\n1868     A0-A4              The airmass coefficients used in calculating\n1869                        effective irradiance\n1870     B0-B5              The angle of incidence coefficients used in calculating\n1871                        effective irradiance\n1872     C0-C7              The empirically determined coefficients relating\n1873                        Imp, Vmp, Ix, and Ixx to effective irradiance\n1874     Isco               Short circuit current at reference condition (amps)\n1875     Impo               Maximum power current at reference condition (amps)\n1876     Aisc               Short circuit current temperature coefficient at\n1877                        reference condition (1/C)\n1878     Aimp               Maximum power current temperature coefficient at\n1879                        reference condition (1/C)\n1880     Bvoco              Open circuit voltage temperature coefficient at\n1881                        reference condition (V/C)\n1882     Mbvoc              Coefficient providing the irradiance dependence for the\n1883                        BetaVoc temperature coefficient at reference irradiance\n1884                        (V/C)\n1885     Bvmpo              Maximum power voltage temperature coefficient at\n1886                        reference condition\n1887     Mbvmp              Coefficient providing the irradiance dependence for the\n1888                        BetaVmp temperature coefficient at reference irradiance\n1889                        (V/C)\n1890     N                  Empirically determined \"diode factor\" (dimensionless)\n1891     Cells_in_Series    Number of cells in series in a module's cell string(s)\n1892     IXO                Ix at reference conditions\n1893     IXXO               Ixx at reference conditions\n1894     FD                 Fraction of diffuse irradiance used by module\n1895     ================   ========================================================\n1896 \n1897     References\n1898     ----------\n1899     [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n1900     Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n1901     NM.\n1902 \n1903     See Also\n1904     --------\n1905     retrieve_sam\n1906     sapm_celltemp\n1907     '''\n1908 \n1909     T0 = 25\n1910     q = 1.60218e-19  # Elementary charge in units of coulombs\n1911     kb = 1.38066e-23  # Boltzmann's constant in units of J/K\n1912 \n1913     # avoid problem with integer input\n1914     Ee = np.array(effective_irradiance, dtype='float64')\n1915 \n1916     # set up masking for 0, positive, and nan inputs\n1917     Ee_gt_0 = np.full_like(Ee, False, dtype='bool')\n1918     Ee_eq_0 = np.full_like(Ee, False, dtype='bool')\n1919     notnan = ~np.isnan(Ee)\n1920     np.greater(Ee, 0, where=notnan, out=Ee_gt_0)\n1921     np.equal(Ee, 0, where=notnan, out=Ee_eq_0)\n1922 \n1923     Bvmpo = module['Bvmpo'] + module['Mbvmp']*(1 - Ee)\n1924     Bvoco = module['Bvoco'] + module['Mbvoc']*(1 - Ee)\n1925     delta = module['N'] * kb * (temp_cell + 273.15) / q\n1926 \n1927     # avoid repeated computation\n1928     logEe = np.full_like(Ee, np.nan)\n1929     np.log(Ee, where=Ee_gt_0, out=logEe)\n1930     logEe = np.where(Ee_eq_0, -np.inf, logEe)\n1931     # avoid repeated __getitem__\n1932     cells_in_series = module['Cells_in_Series']\n1933 \n1934     out = OrderedDict()\n1935 \n1936     out['i_sc'] = (\n1937         module['Isco'] * Ee * (1 + module['Aisc']*(temp_cell - T0)))\n1938 \n1939     out['i_mp'] = (\n1940         module['Impo'] * (module['C0']*Ee + module['C1']*(Ee**2)) *\n1941         (1 + module['Aimp']*(temp_cell - T0)))\n1942 \n1943     out['v_oc'] = np.maximum(0, (\n1944         module['Voco'] + cells_in_series * delta * logEe +\n1945         Bvoco*(temp_cell - T0)))\n1946 \n1947     out['v_mp'] = np.maximum(0, (\n1948         module['Vmpo'] +\n1949         module['C2'] * cells_in_series * delta * logEe +\n1950         module['C3'] * cells_in_series * ((delta * logEe) ** 2) +\n1951         Bvmpo*(temp_cell - T0)))\n1952 \n1953     out['p_mp'] = out['i_mp'] * out['v_mp']\n1954 \n1955     out['i_x'] = (\n1956         module['IXO'] * (module['C4']*Ee + module['C5']*(Ee**2)) *\n1957         (1 + module['Aisc']*(temp_cell - T0)))\n1958 \n1959     # the Ixx calculation in King 2004 has a typo (mixes up Aisc and Aimp)\n1960     out['i_xx'] = (\n1961         module['IXXO'] * (module['C6']*Ee + module['C7']*(Ee**2)) *\n1962         (1 + module['Aisc']*(temp_cell - T0)))\n1963 \n1964     if isinstance(out['i_sc'], pd.Series):\n1965         out = pd.DataFrame(out)\n1966 \n1967     return out\n1968 \n1969 \n1970 def sapm_celltemp(poa_global, wind_speed, temp_air,\n1971                   model='open_rack_cell_glassback'):\n1972     '''\n1973     Estimate cell and module temperatures per the Sandia PV Array\n1974     Performance Model (SAPM, SAND2004-3535), from the incident\n1975     irradiance, wind speed, ambient temperature, and SAPM module\n1976     parameters.\n1977 \n1978     Parameters\n1979     ----------\n1980     poa_global : float or Series\n1981         Total incident irradiance in W/m^2.\n1982 \n1983     wind_speed : float or Series\n1984         Wind speed in m/s at a height of 10 meters.\n1985 \n1986     temp_air : float or Series\n1987         Ambient dry bulb temperature in degrees C.\n1988 \n1989     model : string, list, or dict, default 'open_rack_cell_glassback'\n1990         Model to be used.\n1991 \n1992         If string, can be:\n1993 \n1994             * 'open_rack_cell_glassback' (default)\n1995             * 'roof_mount_cell_glassback'\n1996             * 'open_rack_cell_polymerback'\n1997             * 'insulated_back_polymerback'\n1998             * 'open_rack_polymer_thinfilm_steel'\n1999             * '22x_concentrator_tracker'\n2000 \n2001         If dict, supply the following parameters\n2002         (if list, in the following order):\n2003 \n2004             * a : float\n2005                 SAPM module parameter for establishing the upper\n2006                 limit for module temperature at low wind speeds and\n2007                 high solar irradiance.\n2008 \n2009             * b : float\n2010                 SAPM module parameter for establishing the rate at\n2011                 which the module temperature drops as wind speed increases\n2012                 (see SAPM eqn. 11).\n2013 \n2014             * deltaT : float\n2015                 SAPM module parameter giving the temperature difference\n2016                 between the cell and module back surface at the\n2017                 reference irradiance, E0.\n2018 \n2019     Returns\n2020     --------\n2021     DataFrame with columns 'temp_cell' and 'temp_module'.\n2022     Values in degrees C.\n2023 \n2024     References\n2025     ----------\n2026     [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n2027     Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n2028     NM.\n2029 \n2030     See Also\n2031     --------\n2032     sapm\n2033     '''\n2034 \n2035     temp_models = TEMP_MODEL_PARAMS['sapm']\n2036 \n2037     if isinstance(model, str):\n2038         model = temp_models[model.lower()]\n2039 \n2040     elif isinstance(model, (dict, pd.Series)):\n2041         model = [model['a'], model['b'], model['deltaT']]\n2042 \n2043     a = model[0]\n2044     b = model[1]\n2045     deltaT = model[2]\n2046 \n2047     E0 = 1000.  # Reference irradiance\n2048 \n2049     temp_module = pd.Series(poa_global * np.exp(a + b * wind_speed) + temp_air)\n2050 \n2051     temp_cell = temp_module + (poa_global / E0) * (deltaT)\n2052 \n2053     return pd.DataFrame({'temp_cell': temp_cell, 'temp_module': temp_module})\n2054 \n2055 \n2056 def pvsyst_celltemp(poa_global, temp_air, wind_speed=1.0, eta_m=0.1,\n2057                     alpha_absorption=0.9, model_params='freestanding'):\n2058     \"\"\"\n2059     Calculate cell temperature using an emperical heat loss factor model\n2060     as implemented in PVsyst.\n2061 \n2062     The heat loss factors provided through the 'model_params' argument\n2063     represent the combined effect of convection, radiation and conduction,\n2064     and their values are experimentally determined.\n2065 \n2066     Parameters\n2067     ----------\n2068     poa_global : numeric\n2069         Total incident irradiance in W/m^2.\n2070 \n2071     temp_air : numeric\n2072         Ambient dry bulb temperature in degrees C.\n2073 \n2074     wind_speed : numeric, default 1.0\n2075         Wind speed in m/s measured at the same height for which the wind loss\n2076         factor was determined.  The default value is 1.0, which is the wind\n2077         speed at module height used to determine NOCT.\n2078 \n2079     eta_m : numeric, default 0.1\n2080         Module external efficiency as a fraction, i.e., DC power / poa_global.\n2081 \n2082     alpha_absorption : numeric, default 0.9\n2083         Absorption coefficient\n2084 \n2085     model_params : string, tuple, or list (no dict), default 'freestanding'\n2086         Heat loss factors to be used.\n2087 \n2088         If string, can be:\n2089 \n2090             * 'freestanding' (default)\n2091                 Modules with rear surfaces exposed to open air (e.g. rack\n2092                 mounted).\n2093             * 'insulated'\n2094                 Modules with rear surfaces in close proximity to another\n2095                 surface (e.g. roof mounted).\n2096 \n2097         If tuple/list, supply parameters in the following order:\n2098 \n2099             * constant_loss_factor : float\n2100                 Combined heat loss factor coefficient. Freestanding\n2101                 default is 29, fully insulated arrays is 15.\n2102 \n2103             * wind_loss_factor : float\n2104                 Combined heat loss factor influenced by wind. Default is 0.\n2105 \n2106     Returns\n2107     -------\n2108     temp_cell : numeric or Series\n2109         Cell temperature in degrees Celsius\n2110 \n2111     References\n2112     ----------\n2113     [1]\"PVsyst 6 Help\", Files.pvsyst.com, 2018. [Online]. Available:\n2114     http://files.pvsyst.com/help/index.html. [Accessed: 10- Dec- 2018].\n2115 \n2116     [2] Faiman, D. (2008). \"Assessing the outdoor operating temperature of\n2117     photovoltaic modules.\" Progress in Photovoltaics 16(4): 307-315.\n2118     \"\"\"\n2119 \n2120     pvsyst_presets = TEMP_MODEL_PARAMS['pvsyst']\n2121 \n2122     if isinstance(model_params, str):\n2123         model_params = model_params.lower()\n2124         constant_loss_factor, wind_loss_factor = pvsyst_presets[model_params]\n2125     elif isinstance(model_params, (tuple, list)):\n2126         constant_loss_factor, wind_loss_factor = model_params\n2127     else:\n2128         raise TypeError(\n2129             \"Please provide model_params as a str, or tuple/list.\"\n2130         )\n2131 \n2132     total_loss_factor = wind_loss_factor * wind_speed + constant_loss_factor\n2133     heat_input = poa_global * alpha_absorption * (1 - eta_m)\n2134     temp_difference = heat_input / total_loss_factor\n2135     temp_cell = temp_air + temp_difference\n2136 \n2137     return temp_cell\n2138 \n2139 \n2140 def sapm_spectral_loss(airmass_absolute, module):\n2141     \"\"\"\n2142     Calculates the SAPM spectral loss coefficient, F1.\n2143 \n2144     Parameters\n2145     ----------\n2146     airmass_absolute : numeric\n2147         Absolute airmass\n2148 \n2149     module : dict-like\n2150         A dict, Series, or DataFrame defining the SAPM performance\n2151         parameters. See the :py:func:`sapm` notes section for more\n2152         details.\n2153 \n2154     Returns\n2155     -------\n2156     F1 : numeric\n2157         The SAPM spectral loss coefficient.\n2158 \n2159     Notes\n2160     -----\n2161     nan airmass values will result in 0 output.\n2162     \"\"\"\n2163 \n2164     am_coeff = [module['A4'], module['A3'], module['A2'], module['A1'],\n2165                 module['A0']]\n2166 \n2167     spectral_loss = np.polyval(am_coeff, airmass_absolute)\n2168 \n2169     spectral_loss = np.where(np.isnan(spectral_loss), 0, spectral_loss)\n2170 \n2171     spectral_loss = np.maximum(0, spectral_loss)\n2172 \n2173     if isinstance(airmass_absolute, pd.Series):\n2174         spectral_loss = pd.Series(spectral_loss, airmass_absolute.index)\n2175 \n2176     return spectral_loss\n2177 \n2178 \n2179 def sapm_aoi_loss(aoi, module, upper=None):\n2180     \"\"\"\n2181     Calculates the SAPM angle of incidence loss coefficient, F2.\n2182 \n2183     Parameters\n2184     ----------\n2185     aoi : numeric\n2186         Angle of incidence in degrees. Negative input angles will return\n2187         zeros.\n2188 \n2189     module : dict-like\n2190         A dict, Series, or DataFrame defining the SAPM performance\n2191         parameters. See the :py:func:`sapm` notes section for more\n2192         details.\n2193 \n2194     upper : None or float, default None\n2195         Upper limit on the results.\n2196 \n2197     Returns\n2198     -------\n2199     F2 : numeric\n2200         The SAPM angle of incidence loss coefficient.\n2201 \n2202     Notes\n2203     -----\n2204     The SAPM traditionally does not define an upper limit on the AOI\n2205     loss function and values slightly exceeding 1 may exist for moderate\n2206     angles of incidence (15-40 degrees). However, users may consider\n2207     imposing an upper limit of 1.\n2208 \n2209     References\n2210     ----------\n2211     [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n2212     Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n2213     NM.\n2214 \n2215     [2] B.H. King et al, \"Procedure to Determine Coefficients for the\n2216     Sandia Array Performance Model (SAPM),\" SAND2016-5284, Sandia\n2217     National Laboratories (2016).\n2218 \n2219     [3] B.H. King et al, \"Recent Advancements in Outdoor Measurement\n2220     Techniques for Angle of Incidence Effects,\" 42nd IEEE PVSC (2015).\n2221     DOI: 10.1109/PVSC.2015.7355849\n2222     \"\"\"\n2223 \n2224     aoi_coeff = [module['B5'], module['B4'], module['B3'], module['B2'],\n2225                  module['B1'], module['B0']]\n2226 \n2227     aoi_loss = np.polyval(aoi_coeff, aoi)\n2228     aoi_loss = np.clip(aoi_loss, 0, upper)\n2229     # nan tolerant masking\n2230     aoi_lt_0 = np.full_like(aoi, False, dtype='bool')\n2231     np.less(aoi, 0, where=~np.isnan(aoi), out=aoi_lt_0)\n2232     aoi_loss = np.where(aoi_lt_0, 0, aoi_loss)\n2233 \n2234     if isinstance(aoi, pd.Series):\n2235         aoi_loss = pd.Series(aoi_loss, aoi.index)\n2236 \n2237     return aoi_loss\n2238 \n2239 \n2240 def sapm_effective_irradiance(poa_direct, poa_diffuse, airmass_absolute, aoi,\n2241                               module, reference_irradiance=1000):\n2242     \"\"\"\n2243     Calculates the SAPM effective irradiance using the SAPM spectral\n2244     loss and SAPM angle of incidence loss functions.\n2245 \n2246     Parameters\n2247     ----------\n2248     poa_direct : numeric\n2249         The direct irradiance incident upon the module.\n2250 \n2251     poa_diffuse : numeric\n2252         The diffuse irradiance incident on module.\n2253 \n2254     airmass_absolute : numeric\n2255         Absolute airmass.\n2256 \n2257     aoi : numeric\n2258         Angle of incidence in degrees.\n2259 \n2260     module : dict-like\n2261         A dict, Series, or DataFrame defining the SAPM performance\n2262         parameters. See the :py:func:`sapm` notes section for more\n2263         details.\n2264 \n2265     reference_irradiance : numeric, default 1000\n2266         Reference irradiance by which to divide the input irradiance.\n2267 \n2268     Returns\n2269     -------\n2270     effective_irradiance : numeric\n2271         The SAPM effective irradiance.\n2272     \"\"\"\n2273 \n2274     F1 = sapm_spectral_loss(airmass_absolute, module)\n2275     F2 = sapm_aoi_loss(aoi, module)\n2276 \n2277     E0 = reference_irradiance\n2278 \n2279     Ee = F1 * (poa_direct*F2 + module['FD']*poa_diffuse) / E0\n2280 \n2281     return Ee\n2282 \n2283 \n2284 def singlediode(photocurrent, saturation_current, resistance_series,\n2285                 resistance_shunt, nNsVth, ivcurve_pnts=None,\n2286                 method='lambertw'):\n2287     \"\"\"\n2288     Solve the single-diode model to obtain a photovoltaic IV curve.\n2289 \n2290     Singlediode solves the single diode equation [1]\n2291 \n2292     .. math::\n2293 \n2294         I = IL - I0*[exp((V+I*Rs)/(nNsVth))-1] - (V + I*Rs)/Rsh\n2295 \n2296     for ``I`` and ``V`` when given ``IL, I0, Rs, Rsh,`` and ``nNsVth\n2297     (nNsVth = n*Ns*Vth)`` which are described later. Returns a DataFrame\n2298     which contains the 5 points on the I-V curve specified in\n2299     SAND2004-3535 [3]. If all IL, I0, Rs, Rsh, and nNsVth are scalar, a\n2300     single curve will be returned, if any are Series (of the same\n2301     length), multiple IV curves will be calculated.\n2302 \n2303     The input parameters can be calculated using calcparams_desoto from\n2304     meteorological data.\n2305 \n2306     Parameters\n2307     ----------\n2308     photocurrent : numeric\n2309         Light-generated current (photocurrent) in amperes under desired\n2310         IV curve conditions. Often abbreviated ``I_L``.\n2311         0 <= photocurrent\n2312 \n2313     saturation_current : numeric\n2314         Diode saturation current in amperes under desired IV curve\n2315         conditions. Often abbreviated ``I_0``.\n2316         0 < saturation_current\n2317 \n2318     resistance_series : numeric\n2319         Series resistance in ohms under desired IV curve conditions.\n2320         Often abbreviated ``Rs``.\n2321         0 <= resistance_series < numpy.inf\n2322 \n2323     resistance_shunt : numeric\n2324         Shunt resistance in ohms under desired IV curve conditions.\n2325         Often abbreviated ``Rsh``.\n2326         0 < resistance_shunt <= numpy.inf\n2327 \n2328     nNsVth : numeric\n2329         The product of three components. 1) The usual diode ideal factor\n2330         (n), 2) the number of cells in series (Ns), and 3) the cell\n2331         thermal voltage under the desired IV curve conditions (Vth). The\n2332         thermal voltage of the cell (in volts) may be calculated as\n2333         ``k*temp_cell/q``, where k is Boltzmann's constant (J/K),\n2334         temp_cell is the temperature of the p-n junction in Kelvin, and\n2335         q is the charge of an electron (coulombs).\n2336         0 < nNsVth\n2337 \n2338     ivcurve_pnts : None or int, default None\n2339         Number of points in the desired IV curve. If None or 0, no\n2340         IV curves will be produced.\n2341 \n2342     method : str, default 'lambertw'\n2343         Determines the method used to calculate points on the IV curve. The\n2344         options are ``'lambertw'``, ``'newton'``, or ``'brentq'``.\n2345 \n2346     Returns\n2347     -------\n2348     OrderedDict or DataFrame\n2349 \n2350     The returned dict-like object always contains the keys/columns:\n2351 \n2352         * i_sc - short circuit current in amperes.\n2353         * v_oc - open circuit voltage in volts.\n2354         * i_mp - current at maximum power point in amperes.\n2355         * v_mp - voltage at maximum power point in volts.\n2356         * p_mp - power at maximum power point in watts.\n2357         * i_x - current, in amperes, at ``v = 0.5*v_oc``.\n2358         * i_xx - current, in amperes, at ``V = 0.5*(v_oc+v_mp)``.\n2359 \n2360     If ivcurve_pnts is greater than 0, the output dictionary will also\n2361     include the keys:\n2362 \n2363         * i - IV curve current in amperes.\n2364         * v - IV curve voltage in volts.\n2365 \n2366     The output will be an OrderedDict if photocurrent is a scalar,\n2367     array, or ivcurve_pnts is not None.\n2368 \n2369     The output will be a DataFrame if photocurrent is a Series and\n2370     ivcurve_pnts is None.\n2371 \n2372     Notes\n2373     -----\n2374     If the method is ``'lambertw'`` then the solution employed to solve the\n2375     implicit diode equation utilizes the Lambert W function to obtain an\n2376     explicit function of :math:`V=f(I)` and :math:`I=f(V)` as shown in [2].\n2377 \n2378     If the method is ``'newton'`` then the root-finding Newton-Raphson method\n2379     is used. It should be safe for well behaved IV-curves, but the ``'brentq'``\n2380     method is recommended for reliability.\n2381 \n2382     If the method is ``'brentq'`` then Brent's bisection search method is used\n2383     that guarantees convergence by bounding the voltage between zero and\n2384     open-circuit.\n2385 \n2386     If the method is either ``'newton'`` or ``'brentq'`` and ``ivcurve_pnts``\n2387     are indicated, then :func:`pvlib.singlediode.bishop88` [4] is used to\n2388     calculate the points on the IV curve points at diode voltages from zero to\n2389     open-circuit voltage with a log spacing that gets closer as voltage\n2390     increases. If the method is ``'lambertw'`` then the calculated points on\n2391     the IV curve are linearly spaced.\n2392 \n2393     References\n2394     -----------\n2395     [1] S.R. Wenham, M.A. Green, M.E. Watt, \"Applied Photovoltaics\" ISBN\n2396     0 86758 909 4\n2397 \n2398     [2] A. Jain, A. Kapoor, \"Exact analytical solutions of the\n2399     parameters of real solar cells using Lambert W-function\", Solar\n2400     Energy Materials and Solar Cells, 81 (2004) 269-277.\n2401 \n2402     [3] D. King et al, \"Sandia Photovoltaic Array Performance Model\",\n2403     SAND2004-3535, Sandia National Laboratories, Albuquerque, NM\n2404 \n2405     [4] \"Computer simulation of the effects of electrical mismatches in\n2406     photovoltaic cell interconnection circuits\" JW Bishop, Solar Cell (1988)\n2407     https://doi.org/10.1016/0379-6787(88)90059-2\n2408 \n2409     See also\n2410     --------\n2411     sapm\n2412     calcparams_desoto\n2413     pvlib.singlediode.bishop88\n2414     \"\"\"\n2415     # Calculate points on the IV curve using the LambertW solution to the\n2416     # single diode equation\n2417     if method.lower() == 'lambertw':\n2418         out = _singlediode._lambertw(\n2419             photocurrent, saturation_current, resistance_series,\n2420             resistance_shunt, nNsVth, ivcurve_pnts\n2421         )\n2422         i_sc, v_oc, i_mp, v_mp, p_mp, i_x, i_xx = out[:7]\n2423         if ivcurve_pnts:\n2424             ivcurve_i, ivcurve_v = out[7:]\n2425     else:\n2426         # Calculate points on the IV curve using either 'newton' or 'brentq'\n2427         # methods. Voltages are determined by first solving the single diode\n2428         # equation for the diode voltage V_d then backing out voltage\n2429         args = (photocurrent, saturation_current, resistance_series,\n2430                 resistance_shunt, nNsVth)  # collect args\n2431         v_oc = _singlediode.bishop88_v_from_i(\n2432             0.0, *args, method=method.lower()\n2433         )\n2434         i_mp, v_mp, p_mp = _singlediode.bishop88_mpp(\n2435             *args, method=method.lower()\n2436         )\n2437         i_sc = _singlediode.bishop88_i_from_v(\n2438             0.0, *args, method=method.lower()\n2439         )\n2440         i_x = _singlediode.bishop88_i_from_v(\n2441             v_oc / 2.0, *args, method=method.lower()\n2442         )\n2443         i_xx = _singlediode.bishop88_i_from_v(\n2444             (v_oc + v_mp) / 2.0, *args, method=method.lower()\n2445         )\n2446 \n2447         # calculate the IV curve if requested using bishop88\n2448         if ivcurve_pnts:\n2449             vd = v_oc * (\n2450                     (11.0 - np.logspace(np.log10(11.0), 0.0,\n2451                                         ivcurve_pnts)) / 10.0\n2452             )\n2453             ivcurve_i, ivcurve_v, _ = _singlediode.bishop88(vd, *args)\n2454 \n2455     out = OrderedDict()\n2456     out['i_sc'] = i_sc\n2457     out['v_oc'] = v_oc\n2458     out['i_mp'] = i_mp\n2459     out['v_mp'] = v_mp\n2460     out['p_mp'] = p_mp\n2461     out['i_x'] = i_x\n2462     out['i_xx'] = i_xx\n2463 \n2464     if ivcurve_pnts:\n2465 \n2466         out['v'] = ivcurve_v\n2467         out['i'] = ivcurve_i\n2468 \n2469     if isinstance(photocurrent, pd.Series) and not ivcurve_pnts:\n2470         out = pd.DataFrame(out, index=photocurrent.index)\n2471 \n2472     return out\n2473 \n2474 \n2475 def max_power_point(photocurrent, saturation_current, resistance_series,\n2476                     resistance_shunt, nNsVth, method='brentq'):\n2477     \"\"\"\n2478     Given the single diode equation coefficients, calculates the maximum power\n2479     point (MPP).\n2480 \n2481     Parameters\n2482     ----------\n2483     photocurrent : numeric\n2484         photo-generated current [A]\n2485     saturation_current : numeric\n2486         diode reverse saturation current [A]\n2487     resistance_series : numeric\n2488         series resitance [ohms]\n2489     resistance_shunt : numeric\n2490         shunt resitance [ohms]\n2491     nNsVth : numeric\n2492         product of thermal voltage ``Vth`` [V], diode ideality factor ``n``,\n2493         and number of serices cells ``Ns``\n2494     method : str\n2495         either ``'newton'`` or ``'brentq'``\n2496 \n2497     Returns\n2498     -------\n2499     OrderedDict or pandas.Datafrane\n2500         ``(i_mp, v_mp, p_mp)``\n2501 \n2502     Notes\n2503     -----\n2504     Use this function when you only want to find the maximum power point. Use\n2505     :func:`singlediode` when you need to find additional points on the IV\n2506     curve. This function uses Brent's method by default because it is\n2507     guaranteed to converge.\n2508     \"\"\"\n2509     i_mp, v_mp, p_mp = _singlediode.bishop88_mpp(\n2510         photocurrent, saturation_current, resistance_series,\n2511         resistance_shunt, nNsVth, method=method.lower()\n2512     )\n2513     if isinstance(photocurrent, pd.Series):\n2514         ivp = {'i_mp': i_mp, 'v_mp': v_mp, 'p_mp': p_mp}\n2515         out = pd.DataFrame(ivp, index=photocurrent.index)\n2516     else:\n2517         out = OrderedDict()\n2518         out['i_mp'] = i_mp\n2519         out['v_mp'] = v_mp\n2520         out['p_mp'] = p_mp\n2521     return out\n2522 \n2523 \n2524 def v_from_i(resistance_shunt, resistance_series, nNsVth, current,\n2525              saturation_current, photocurrent, method='lambertw'):\n2526     '''\n2527     Device voltage at the given device current for the single diode model.\n2528 \n2529     Uses the single diode model (SDM) as described in, e.g.,\n2530      Jain and Kapoor 2004 [1].\n2531     The solution is per Eq 3 of [1] except when resistance_shunt=numpy.inf,\n2532      in which case the explict solution for voltage is used.\n2533     Ideal device parameters are specified by resistance_shunt=np.inf and\n2534      resistance_series=0.\n2535     Inputs to this function can include scalars and pandas.Series, but it is\n2536      the caller's responsibility to ensure that the arguments are all float64\n2537      and within the proper ranges.\n2538 \n2539     Parameters\n2540     ----------\n2541     resistance_shunt : numeric\n2542         Shunt resistance in ohms under desired IV curve conditions.\n2543         Often abbreviated ``Rsh``.\n2544         0 < resistance_shunt <= numpy.inf\n2545 \n2546     resistance_series : numeric\n2547         Series resistance in ohms under desired IV curve conditions.\n2548         Often abbreviated ``Rs``.\n2549         0 <= resistance_series < numpy.inf\n2550 \n2551     nNsVth : numeric\n2552         The product of three components. 1) The usual diode ideal factor\n2553         (n), 2) the number of cells in series (Ns), and 3) the cell\n2554         thermal voltage under the desired IV curve conditions (Vth). The\n2555         thermal voltage of the cell (in volts) may be calculated as\n2556         ``k*temp_cell/q``, where k is Boltzmann's constant (J/K),\n2557         temp_cell is the temperature of the p-n junction in Kelvin, and\n2558         q is the charge of an electron (coulombs).\n2559         0 < nNsVth\n2560 \n2561     current : numeric\n2562         The current in amperes under desired IV curve conditions.\n2563 \n2564     saturation_current : numeric\n2565         Diode saturation current in amperes under desired IV curve\n2566         conditions. Often abbreviated ``I_0``.\n2567         0 < saturation_current\n2568 \n2569     photocurrent : numeric\n2570         Light-generated current (photocurrent) in amperes under desired\n2571         IV curve conditions. Often abbreviated ``I_L``.\n2572         0 <= photocurrent\n2573 \n2574     method : str\n2575         Method to use: ``'lambertw'``, ``'newton'``, or ``'brentq'``. *Note*:\n2576         ``'brentq'`` is limited to 1st quadrant only.\n2577 \n2578     Returns\n2579     -------\n2580     current : np.ndarray or scalar\n2581 \n2582     References\n2583     ----------\n2584     [1] A. Jain, A. Kapoor, \"Exact analytical solutions of the\n2585     parameters of real solar cells using Lambert W-function\", Solar\n2586     Energy Materials and Solar Cells, 81 (2004) 269-277.\n2587     '''\n2588     if method.lower() == 'lambertw':\n2589         return _singlediode._lambertw_v_from_i(\n2590             resistance_shunt, resistance_series, nNsVth, current,\n2591             saturation_current, photocurrent\n2592         )\n2593     else:\n2594         # Calculate points on the IV curve using either 'newton' or 'brentq'\n2595         # methods. Voltages are determined by first solving the single diode\n2596         # equation for the diode voltage V_d then backing out voltage\n2597         args = (current, photocurrent, saturation_current,\n2598                 resistance_series, resistance_shunt, nNsVth)\n2599         V = _singlediode.bishop88_v_from_i(*args, method=method.lower())\n2600         # find the right size and shape for returns\n2601         size, shape = _singlediode._get_size_and_shape(args)\n2602         if size <= 1:\n2603             if shape is not None:\n2604                 V = np.tile(V, shape)\n2605         if np.isnan(V).any() and size <= 1:\n2606             V = np.repeat(V, size)\n2607             if shape is not None:\n2608                 V = V.reshape(shape)\n2609         return V\n2610 \n2611 \n2612 def i_from_v(resistance_shunt, resistance_series, nNsVth, voltage,\n2613              saturation_current, photocurrent, method='lambertw'):\n2614     '''\n2615     Device current at the given device voltage for the single diode model.\n2616 \n2617     Uses the single diode model (SDM) as described in, e.g.,\n2618      Jain and Kapoor 2004 [1].\n2619     The solution is per Eq 2 of [1] except when resistance_series=0,\n2620      in which case the explict solution for current is used.\n2621     Ideal device parameters are specified by resistance_shunt=np.inf and\n2622      resistance_series=0.\n2623     Inputs to this function can include scalars and pandas.Series, but it is\n2624      the caller's responsibility to ensure that the arguments are all float64\n2625      and within the proper ranges.\n2626 \n2627     Parameters\n2628     ----------\n2629     resistance_shunt : numeric\n2630         Shunt resistance in ohms under desired IV curve conditions.\n2631         Often abbreviated ``Rsh``.\n2632         0 < resistance_shunt <= numpy.inf\n2633 \n2634     resistance_series : numeric\n2635         Series resistance in ohms under desired IV curve conditions.\n2636         Often abbreviated ``Rs``.\n2637         0 <= resistance_series < numpy.inf\n2638 \n2639     nNsVth : numeric\n2640         The product of three components. 1) The usual diode ideal factor\n2641         (n), 2) the number of cells in series (Ns), and 3) the cell\n2642         thermal voltage under the desired IV curve conditions (Vth). The\n2643         thermal voltage of the cell (in volts) may be calculated as\n2644         ``k*temp_cell/q``, where k is Boltzmann's constant (J/K),\n2645         temp_cell is the temperature of the p-n junction in Kelvin, and\n2646         q is the charge of an electron (coulombs).\n2647         0 < nNsVth\n2648 \n2649     voltage : numeric\n2650         The voltage in Volts under desired IV curve conditions.\n2651 \n2652     saturation_current : numeric\n2653         Diode saturation current in amperes under desired IV curve\n2654         conditions. Often abbreviated ``I_0``.\n2655         0 < saturation_current\n2656 \n2657     photocurrent : numeric\n2658         Light-generated current (photocurrent) in amperes under desired\n2659         IV curve conditions. Often abbreviated ``I_L``.\n2660         0 <= photocurrent\n2661 \n2662     method : str\n2663         Method to use: ``'lambertw'``, ``'newton'``, or ``'brentq'``. *Note*:\n2664         ``'brentq'`` is limited to 1st quadrant only.\n2665 \n2666     Returns\n2667     -------\n2668     current : np.ndarray or scalar\n2669 \n2670     References\n2671     ----------\n2672     [1] A. Jain, A. Kapoor, \"Exact analytical solutions of the\n2673     parameters of real solar cells using Lambert W-function\", Solar\n2674     Energy Materials and Solar Cells, 81 (2004) 269-277.\n2675     '''\n2676     if method.lower() == 'lambertw':\n2677         return _singlediode._lambertw_i_from_v(\n2678             resistance_shunt, resistance_series, nNsVth, voltage,\n2679             saturation_current, photocurrent\n2680         )\n2681     else:\n2682         # Calculate points on the IV curve using either 'newton' or 'brentq'\n2683         # methods. Voltages are determined by first solving the single diode\n2684         # equation for the diode voltage V_d then backing out voltage\n2685         args = (voltage, photocurrent, saturation_current, resistance_series,\n2686                 resistance_shunt, nNsVth)\n2687         I = _singlediode.bishop88_i_from_v(*args, method=method.lower())\n2688         # find the right size and shape for returns\n2689         size, shape = _singlediode._get_size_and_shape(args)\n2690         if size <= 1:\n2691             if shape is not None:\n2692                 I = np.tile(I, shape)\n2693         if np.isnan(I).any() and size <= 1:\n2694             I = np.repeat(I, size)\n2695             if shape is not None:\n2696                 I = I.reshape(shape)\n2697         return I\n2698 \n2699 \n2700 def snlinverter(v_dc, p_dc, inverter):\n2701     r'''\n2702     Converts DC power and voltage to AC power using Sandia's\n2703     Grid-Connected PV Inverter model.\n2704 \n2705     Determines the AC power output of an inverter given the DC voltage,\n2706     DC power, and appropriate Sandia Grid-Connected Photovoltaic\n2707     Inverter Model parameters. The output, ac_power, is clipped at the\n2708     maximum power output, and gives a negative power during low-input\n2709     power conditions, but does NOT account for maximum power point\n2710     tracking voltage windows nor maximum current or voltage limits on\n2711     the inverter.\n2712 \n2713     Parameters\n2714     ----------\n2715     v_dc : numeric\n2716         DC voltages, in volts, which are provided as input to the\n2717         inverter. Vdc must be >= 0.\n2718 \n2719     p_dc : numeric\n2720         A scalar or DataFrame of DC powers, in watts, which are provided\n2721         as input to the inverter. Pdc must be >= 0.\n2722 \n2723     inverter : dict-like\n2724         A dict-like object defining the inverter to be used, giving the\n2725         inverter performance parameters according to the Sandia\n2726         Grid-Connected Photovoltaic Inverter Model (SAND 2007-5036) [1].\n2727         A set of inverter performance parameters are provided with\n2728         pvlib, or may be generated from a System Advisor Model (SAM) [2]\n2729         library using retrievesam. See Notes for required keys.\n2730 \n2731     Returns\n2732     -------\n2733     ac_power : numeric\n2734         Modeled AC power output given the input DC voltage, Vdc, and\n2735         input DC power, Pdc. When ac_power would be greater than Pac0,\n2736         it is set to Pac0 to represent inverter \"clipping\". When\n2737         ac_power would be less than Ps0 (startup power required), then\n2738         ac_power is set to -1*abs(Pnt) to represent nightly power\n2739         losses. ac_power is not adjusted for maximum power point\n2740         tracking (MPPT) voltage windows or maximum current limits of the\n2741         inverter.\n2742 \n2743     Notes\n2744     -----\n2745 \n2746     Required inverter keys are:\n2747 \n2748     ======   ============================================================\n2749     Column   Description\n2750     ======   ============================================================\n2751     Pac0     AC-power output from inverter based on input power\n2752              and voltage (W)\n2753     Pdc0     DC-power input to inverter, typically assumed to be equal\n2754              to the PV array maximum power (W)\n2755     Vdc0     DC-voltage level at which the AC-power rating is achieved\n2756              at the reference operating condition (V)\n2757     Ps0      DC-power required to start the inversion process, or\n2758              self-consumption by inverter, strongly influences inverter\n2759              efficiency at low power levels (W)\n2760     C0       Parameter defining the curvature (parabolic) of the\n2761              relationship between ac-power and dc-power at the reference\n2762              operating condition, default value of zero gives a\n2763              linear relationship (1/W)\n2764     C1       Empirical coefficient allowing Pdco to vary linearly\n2765              with dc-voltage input, default value is zero (1/V)\n2766     C2       Empirical coefficient allowing Pso to vary linearly with\n2767              dc-voltage input, default value is zero (1/V)\n2768     C3       Empirical coefficient allowing Co to vary linearly with\n2769              dc-voltage input, default value is zero (1/V)\n2770     Pnt      AC-power consumed by inverter at night (night tare) to\n2771              maintain circuitry required to sense PV array voltage (W)\n2772     ======   ============================================================\n2773 \n2774     References\n2775     ----------\n2776     [1] SAND2007-5036, \"Performance Model for Grid-Connected\n2777     Photovoltaic Inverters by D. King, S. Gonzalez, G. Galbraith, W.\n2778     Boyson\n2779 \n2780     [2] System Advisor Model web page. https://sam.nrel.gov.\n2781 \n2782     See also\n2783     --------\n2784     sapm\n2785     singlediode\n2786     '''\n2787 \n2788     Paco = inverter['Paco']\n2789     Pdco = inverter['Pdco']\n2790     Vdco = inverter['Vdco']\n2791     Pso = inverter['Pso']\n2792     C0 = inverter['C0']\n2793     C1 = inverter['C1']\n2794     C2 = inverter['C2']\n2795     C3 = inverter['C3']\n2796     Pnt = inverter['Pnt']\n2797 \n2798     A = Pdco * (1 + C1*(v_dc - Vdco))\n2799     B = Pso * (1 + C2*(v_dc - Vdco))\n2800     C = C0 * (1 + C3*(v_dc - Vdco))\n2801 \n2802     ac_power = (Paco/(A-B) - C*(A-B)) * (p_dc-B) + C*((p_dc-B)**2)\n2803     ac_power = np.minimum(Paco, ac_power)\n2804     ac_power = np.where(p_dc < Pso, -1.0 * abs(Pnt), ac_power)\n2805 \n2806     if isinstance(p_dc, pd.Series):\n2807         ac_power = pd.Series(ac_power, index=p_dc.index)\n2808 \n2809     return ac_power\n2810 \n2811 \n2812 def adrinverter(v_dc, p_dc, inverter, vtol=0.10):\n2813     r'''\n2814     Converts DC power and voltage to AC power using Anton Driesse's\n2815     Grid-Connected PV Inverter efficiency model\n2816 \n2817     Parameters\n2818     ----------\n2819     v_dc : numeric\n2820         A scalar or pandas series of DC voltages, in volts, which are provided\n2821         as input to the inverter. If Vdc and Pdc are vectors, they must be\n2822         of the same size. v_dc must be >= 0. (V)\n2823 \n2824     p_dc : numeric\n2825         A scalar or pandas series of DC powers, in watts, which are provided\n2826         as input to the inverter. If Vdc and Pdc are vectors, they must be\n2827         of the same size. p_dc must be >= 0. (W)\n2828 \n2829     inverter : dict-like\n2830         A dict-like object defining the inverter to be used, giving the\n2831         inverter performance parameters according to the model\n2832         developed by Anton Driesse [1].\n2833         A set of inverter performance parameters may be loaded from the\n2834         supplied data table using retrievesam.\n2835         See Notes for required keys.\n2836 \n2837     vtol : numeric, default 0.1\n2838         A unit-less fraction that determines how far the efficiency model is\n2839         allowed to extrapolate beyond the inverter's normal input voltage\n2840         operating range. 0.0 <= vtol <= 1.0\n2841 \n2842     Returns\n2843     -------\n2844     ac_power : numeric\n2845         A numpy array or pandas series of modeled AC power output given the\n2846         input DC voltage, v_dc, and input DC power, p_dc. When ac_power would\n2847         be greater than pac_max, it is set to p_max to represent inverter\n2848         \"clipping\". When ac_power would be less than -p_nt (energy consumed\n2849         rather  than produced) then ac_power is set to -p_nt to represent\n2850         nightly power losses. ac_power is not adjusted for maximum power point\n2851         tracking (MPPT) voltage windows or maximum current limits of the\n2852         inverter.\n2853 \n2854     Notes\n2855     -----\n2856 \n2857     Required inverter keys are:\n2858 \n2859     =======   ============================================================\n2860     Column    Description\n2861     =======   ============================================================\n2862     p_nom     The nominal power value used to normalize all power values,\n2863               typically the DC power needed to produce maximum AC power\n2864               output, (W).\n2865 \n2866     v_nom     The nominal DC voltage value used to normalize DC voltage\n2867               values, typically the level at which the highest efficiency\n2868               is achieved, (V).\n2869 \n2870     pac_max   The maximum AC output power value, used to clip the output\n2871               if needed, (W).\n2872 \n2873     ce_list   This is a list of 9 coefficients that capture the influence\n2874               of input voltage and power on inverter losses, and thereby\n2875               efficiency.\n2876 \n2877     p_nt      ac-power consumed by inverter at night (night tare) to\n2878               maintain circuitry required to sense PV array voltage, (W).\n2879     =======   ============================================================\n2880 \n2881     References\n2882     ----------\n2883     [1] Beyond the Curves: Modeling the Electrical Efficiency\n2884         of Photovoltaic Inverters, PVSC 2008, Anton Driesse et. al.\n2885 \n2886     See also\n2887     --------\n2888     sapm\n2889     singlediode\n2890     '''\n2891 \n2892     p_nom = inverter['Pnom']\n2893     v_nom = inverter['Vnom']\n2894     pac_max = inverter['Pacmax']\n2895     p_nt = inverter['Pnt']\n2896     ce_list = inverter['ADRCoefficients']\n2897     v_max = inverter['Vmax']\n2898     v_min = inverter['Vmin']\n2899     vdc_max = inverter['Vdcmax']\n2900     mppt_hi = inverter['MPPTHi']\n2901     mppt_low = inverter['MPPTLow']\n2902 \n2903     v_lim_upper = float(np.nanmax([v_max, vdc_max, mppt_hi]) * (1 + vtol))\n2904     v_lim_lower = float(np.nanmax([v_min, mppt_low]) * (1 - vtol))\n2905 \n2906     pdc = p_dc / p_nom\n2907     vdc = v_dc / v_nom\n2908     # zero voltage will lead to division by zero, but since power is\n2909     # set to night time value later, these errors can be safely ignored\n2910     with np.errstate(invalid='ignore', divide='ignore'):\n2911         poly = np.array([pdc**0,  # replace with np.ones_like?\n2912                          pdc,\n2913                          pdc**2,\n2914                          vdc - 1,\n2915                          pdc * (vdc - 1),\n2916                          pdc**2 * (vdc - 1),\n2917                          1. / vdc - 1,  # divide by 0\n2918                          pdc * (1. / vdc - 1),  # invalid 0./0. --> nan\n2919                          pdc**2 * (1. / vdc - 1)])  # divide by 0\n2920     p_loss = np.dot(np.array(ce_list), poly)\n2921     ac_power = p_nom * (pdc-p_loss)\n2922     p_nt = -1 * np.absolute(p_nt)\n2923 \n2924     # set output to nan where input is outside of limits\n2925     # errstate silences case where input is nan\n2926     with np.errstate(invalid='ignore'):\n2927         invalid = (v_lim_upper < v_dc) | (v_dc < v_lim_lower)\n2928     ac_power = np.where(invalid, np.nan, ac_power)\n2929 \n2930     # set night values\n2931     ac_power = np.where(vdc == 0, p_nt, ac_power)\n2932     ac_power = np.maximum(ac_power, p_nt)\n2933 \n2934     # set max ac output\n2935     ac_power = np.minimum(ac_power, pac_max)\n2936 \n2937     if isinstance(p_dc, pd.Series):\n2938         ac_power = pd.Series(ac_power, index=pdc.index)\n2939 \n2940     return ac_power\n2941 \n2942 \n2943 def scale_voltage_current_power(data, voltage=1, current=1):\n2944     \"\"\"\n2945     Scales the voltage, current, and power of the DataFrames\n2946     returned by :py:func:`singlediode` and :py:func:`sapm`.\n2947 \n2948     Parameters\n2949     ----------\n2950     data: DataFrame\n2951         Must contain columns `'v_mp', 'v_oc', 'i_mp' ,'i_x', 'i_xx',\n2952         'i_sc', 'p_mp'`.\n2953     voltage: numeric, default 1\n2954         The amount by which to multiply the voltages.\n2955     current: numeric, default 1\n2956         The amount by which to multiply the currents.\n2957 \n2958     Returns\n2959     -------\n2960     scaled_data: DataFrame\n2961         A scaled copy of the input data.\n2962         `'p_mp'` is scaled by `voltage * current`.\n2963     \"\"\"\n2964 \n2965     # as written, only works with a DataFrame\n2966     # could make it work with a dict, but it would be more verbose\n2967     data = data.copy()\n2968     voltages = ['v_mp', 'v_oc']\n2969     currents = ['i_mp', 'i_x', 'i_xx', 'i_sc']\n2970     data[voltages] *= voltage\n2971     data[currents] *= current\n2972     data['p_mp'] *= voltage * current\n2973 \n2974     return data\n2975 \n2976 \n2977 def pvwatts_dc(g_poa_effective, temp_cell, pdc0, gamma_pdc, temp_ref=25.):\n2978     r\"\"\"\n2979     Implements NREL's PVWatts DC power model [1]_:\n2980 \n2981     .. math::\n2982 \n2983         P_{dc} = \\frac{G_{poa eff}}{1000} P_{dc0} ( 1 + \\gamma_{pdc} (T_{cell} - T_{ref}))\n2984 \n2985     Note that the pdc0 is also used as a symbol in :py:func:`pvwatts_ac`. pdc0\n2986     in this function refers to the DC power of the modules at reference\n2987     conditions. pdc0 in :py:func:`pvwatts_ac` refers to the DC power input\n2988     limit of the inverter.\n2989 \n2990     Parameters\n2991     ----------\n2992     g_poa_effective: numeric\n2993         Irradiance transmitted to the PV cells in units of W/m**2. To be\n2994         fully consistent with PVWatts, the user must have already\n2995         applied angle of incidence losses, but not soiling, spectral,\n2996         etc.\n2997     temp_cell: numeric\n2998         Cell temperature in degrees C.\n2999     pdc0: numeric\n3000         Power of the modules at 1000 W/m2 and cell reference temperature.\n3001     gamma_pdc: numeric\n3002         The temperature coefficient in units of 1/C. Typically -0.002 to\n3003         -0.005 per degree C.\n3004     temp_ref: numeric, default 25.0\n3005         Cell reference temperature. PVWatts defines it to be 25 C and\n3006         is included here for flexibility.\n3007 \n3008     Returns\n3009     -------\n3010     pdc: numeric\n3011         DC power.\n3012 \n3013     References\n3014     ----------\n3015     .. [1] A. P. Dobos, \"PVWatts Version 5 Manual\"\n3016            http://pvwatts.nrel.gov/downloads/pvwattsv5.pdf\n3017            (2014).\n3018     \"\"\"\n3019 \n3020     pdc = (g_poa_effective * 0.001 * pdc0 *\n3021            (1 + gamma_pdc * (temp_cell - temp_ref)))\n3022 \n3023     return pdc\n3024 \n3025 \n3026 def pvwatts_losses(soiling=2, shading=3, snow=0, mismatch=2, wiring=2,\n3027                    connections=0.5, lid=1.5, nameplate_rating=1, age=0,\n3028                    availability=3):\n3029     r\"\"\"\n3030     Implements NREL's PVWatts system loss model [1]_:\n3031 \n3032     .. math::\n3033 \n3034         L_{total}(\\%) = 100 [ 1 - \\Pi_i ( 1 - \\frac{L_i}{100} ) ]\n3035 \n3036     All parameters must be in units of %. Parameters may be\n3037     array-like, though all array sizes must match.\n3038 \n3039     Parameters\n3040     ----------\n3041     soiling: numeric, default 2\n3042     shading: numeric, default 3\n3043     snow: numeric, default 0\n3044     mismatch: numeric, default 2\n3045     wiring: numeric, default 2\n3046     connections: numeric, default 0.5\n3047     lid: numeric, default 1.5\n3048         Light induced degradation\n3049     nameplate_rating: numeric, default 1\n3050     age: numeric, default 0\n3051     availability: numeric, default 3\n3052 \n3053     Returns\n3054     -------\n3055     losses: numeric\n3056         System losses in units of %.\n3057 \n3058     References\n3059     ----------\n3060     .. [1] A. P. Dobos, \"PVWatts Version 5 Manual\"\n3061            http://pvwatts.nrel.gov/downloads/pvwattsv5.pdf\n3062            (2014).\n3063     \"\"\"\n3064 \n3065     params = [soiling, shading, snow, mismatch, wiring, connections, lid,\n3066               nameplate_rating, age, availability]\n3067 \n3068     # manually looping over params allows for numpy/pandas to handle any\n3069     # array-like broadcasting that might be necessary.\n3070     perf = 1\n3071     for param in params:\n3072         perf *= 1 - param/100\n3073 \n3074     losses = (1 - perf) * 100.\n3075 \n3076     return losses\n3077 \n3078 \n3079 def pvwatts_ac(pdc, pdc0, eta_inv_nom=0.96, eta_inv_ref=0.9637):\n3080     r\"\"\"\n3081     Implements NREL's PVWatts inverter model [1]_.\n3082 \n3083     .. math::\n3084 \n3085         \\eta = \\frac{\\eta_{nom}}{\\eta_{ref}} (-0.0162\\zeta - \\frac{0.0059}{\\zeta} + 0.9858)\n3086 \n3087     .. math::\n3088 \n3089         P_{ac} = \\min(\\eta P_{dc}, P_{ac0})\n3090 \n3091     where :math:`\\zeta=P_{dc}/P_{dc0}` and :math:`P_{dc0}=P_{ac0}/\\eta_{nom}`.\n3092 \n3093     Note that the pdc0 is also used as a symbol in :py:func:`pvwatts_dc`. pdc0\n3094     in this function refers to the DC power input limit of the inverter.\n3095     pdc0 in :py:func:`pvwatts_dc` refers to the DC power of the modules\n3096     at reference conditions.\n3097 \n3098     Parameters\n3099     ----------\n3100     pdc: numeric\n3101         DC power.\n3102     pdc0: numeric\n3103         DC input limit of the inverter.\n3104     eta_inv_nom: numeric, default 0.96\n3105         Nominal inverter efficiency.\n3106     eta_inv_ref: numeric, default 0.9637\n3107         Reference inverter efficiency. PVWatts defines it to be 0.9637\n3108         and is included here for flexibility.\n3109 \n3110     Returns\n3111     -------\n3112     pac: numeric\n3113         AC power.\n3114 \n3115     References\n3116     ----------\n3117     .. [1] A. P. Dobos, \"PVWatts Version 5 Manual,\"\n3118            http://pvwatts.nrel.gov/downloads/pvwattsv5.pdf\n3119            (2014).\n3120     \"\"\"\n3121 \n3122     pac0 = eta_inv_nom * pdc0\n3123     zeta = pdc / pdc0\n3124 \n3125     # arrays to help avoid divide by 0 for scalar and array\n3126     eta = np.zeros_like(pdc, dtype=float)\n3127     pdc_neq_0 = ~np.equal(pdc, 0)\n3128 \n3129     # eta < 0 if zeta < 0.006. pac is forced to be >= 0 below. GH 541\n3130     eta = eta_inv_nom / eta_inv_ref * (\n3131         - 0.0162*zeta\n3132         - np.divide(0.0059, zeta, out=eta, where=pdc_neq_0)\n3133         + 0.9858)\n3134 \n3135     pac = eta * pdc\n3136     pac = np.minimum(pac0, pac)\n3137     pac = np.maximum(0, pac)     # GH 541\n3138 \n3139     return pac\n3140 \n[end of pvlib/pvsystem.py]\n[start of pvlib/singlediode.py]\n1 # -*- coding: utf-8 -*-\n2 \"\"\"\n3 Low-level functions for solving the single diode equation.\n4 \"\"\"\n5 \n6 from functools import partial\n7 import numpy as np\n8 from pvlib.tools import _golden_sect_DataFrame\n9 \n10 # Try to import brentq from scipy to use when specified in bishop88_i_from_v,\n11 # bishop88_v_from_i, and bishop88_mpp methods below. If not imported, raises\n12 # ImportError when 'brentq' method is specified for those methods.\n13 try:\n14     from scipy.optimize import brentq\n15 except ImportError:\n16     def brentq(*a, **kw):\n17         raise ImportError(\n18             \"brentq couldn't be imported. Is SciPy installed?\")\n19 \n20 # FIXME: change this to newton when scipy-1.2 is released\n21 try:\n22     from scipy.optimize import _array_newton\n23 except ImportError:\n24     from pvlib.tools import _array_newton\n25 # rename newton and set keyword arguments\n26 newton = partial(_array_newton, tol=1e-6, maxiter=100, fprime2=None)\n27 \n28 # intrinsic voltage per cell junction for a:Si, CdTe, Mertens et al.\n29 VOLTAGE_BUILTIN = 0.9  # [V]\n30 \n31 \n32 def estimate_voc(photocurrent, saturation_current, nNsVth):\n33     \"\"\"\n34     Rough estimate of open circuit voltage useful for bounding searches for\n35     ``i`` of ``v`` when using :func:`~pvlib.pvsystem.singlediode`.\n36 \n37     Parameters\n38     ----------\n39     photocurrent : numeric\n40         photo-generated current [A]\n41     saturation_current : numeric\n42         diode reverse saturation current [A]\n43     nNsVth : numeric\n44         product of thermal voltage ``Vth`` [V], diode ideality factor ``n``,\n45         and number of series cells ``Ns``\n46 \n47     Returns\n48     -------\n49     numeric\n50         rough estimate of open circuit voltage [V]\n51 \n52     Notes\n53     -----\n54     Calculating the open circuit voltage, :math:`V_{oc}`, of an ideal device\n55     with infinite shunt resistance, :math:`R_{sh} \\\\to \\\\infty`, and zero\n56     series resistance, :math:`R_s = 0`, yields the following equation [1]. As\n57     an estimate of :math:`V_{oc}` it is useful as an upper bound for the\n58     bisection method.\n59 \n60     .. math::\n61 \n62         V_{oc, est}=n Ns V_{th} \\\\log \\\\left( \\\\frac{I_L}{I_0} + 1 \\\\right)\n63 \n64     [1] http://www.pveducation.org/pvcdrom/open-circuit-voltage\n65     \"\"\"\n66 \n67     return nNsVth * np.log(np.asarray(photocurrent) / saturation_current + 1.0)\n68 \n69 \n70 def bishop88(diode_voltage, photocurrent, saturation_current,\n71              resistance_series, resistance_shunt, nNsVth, d2mutau=0,\n72              NsVbi=np.Inf, gradients=False):\n73     \"\"\"\n74     Explicit calculation of points on the IV curve described by the single\n75     diode equation [1]_.\n76 \n77     .. warning::\n78        * Do not use ``d2mutau`` with CEC coefficients.\n79        * Usage of ``d2mutau`` with PVSyst coefficients is required for cadmium-\n80          telluride (CdTe) and amorphous-silicon (a:Si) PV modules only.\n81 \n82     Parameters\n83     ----------\n84     diode_voltage : numeric\n85         diode voltages [V]\n86     photocurrent : numeric\n87         photo-generated current [A]\n88     saturation_current : numeric\n89         diode reverse saturation current [A]\n90     resistance_series : numeric\n91         series resistance [ohms]\n92     resistance_shunt: numeric\n93         shunt resistance [ohms]\n94     nNsVth : numeric\n95         product of thermal voltage ``Vth`` [V], diode ideality factor ``n``,\n96         and number of series cells ``Ns``\n97     d2mutau : numeric\n98         PVSyst thin-film recombination parameter that is the ratio of thickness\n99         of the intrinsic layer squared :math:`d^2` and the diffusion length of\n100         charge carriers :math:`\\\\mu \\\\tau`, in volts [V], defaults to 0[V]\n101     NsVbi : numeric\n102         PVSyst thin-film recombination parameter that is the product of the PV\n103         module number of series cells ``Ns`` and the builtin voltage ``Vbi`` of\n104         the intrinsic layer, in volts [V], defaults to ``np.inf``\n105     gradients : bool\n106         False returns only I, V, and P. True also returns gradients\n107 \n108     Returns\n109     -------\n110     tuple\n111         currents [A], voltages [V], power [W], and optionally\n112         :math:`\\\\frac{dI}{dV_d}`, :math:`\\\\frac{dV}{dV_d}`,\n113         :math:`\\\\frac{dI}{dV}`, :math:`\\\\frac{dP}{dV}`, and\n114         :math:`\\\\frac{d^2 P}{dV dV_d}`\n115 \n116     Notes\n117     -----\n118     The PVSyst thin-film recombination losses parameters ``d2mutau`` and\n119     ``NsVbi`` are only applied to cadmium-telluride (CdTe) and amorphous-\n120     silicon (a:Si) PV modules, [2]_, [3]_. The builtin voltage :math:`V_{bi}`\n121     should account for all junctions. For example: tandem and triple junction\n122     cells would have builtin voltages of 1.8[V] and 2.7[V] respectively, based\n123     on the default of 0.9[V] for a single junction. The parameter ``NsVbi``\n124     should only account for the number of series cells in a single parallel\n125     sub-string if the module has cells in parallel greater than 1.\n126 \n127     References\n128     ----------\n129     .. [1] \"Computer simulation of the effects of electrical mismatches in\n130        photovoltaic cell interconnection circuits\" JW Bishop, Solar Cell (1988)\n131        :doi:`10.1016/0379-6787(88)90059-2`\n132 \n133     .. [2] \"Improved equivalent circuit and Analytical Model for Amorphous\n134        Silicon Solar Cells and Modules.\" J. Mertens, et al., IEEE Transactions\n135        on Electron Devices, Vol 45, No 2, Feb 1998.\n136        :doi:`10.1109/16.658676`\n137 \n138     .. [3] \"Performance assessment of a simulation model for PV modules of any\n139        available technology\", Andr\u00e9 Mermoud and Thibault Lejeune, 25th EUPVSEC,\n140        2010\n141        :doi:`10.4229/25thEUPVSEC2010-4BV.1.114`\n142     \"\"\"\n143     # calculate recombination loss current where d2mutau > 0\n144     is_recomb = d2mutau > 0  # True where there is thin-film recombination loss\n145     v_recomb = np.where(is_recomb, NsVbi - diode_voltage, np.inf)\n146     i_recomb = np.where(is_recomb, photocurrent * d2mutau / v_recomb, 0)\n147     # calculate temporary values to simplify calculations\n148     v_star = diode_voltage / nNsVth  # non-dimensional diode voltage\n149     g_sh = 1.0 / resistance_shunt  # conductance\n150     i = (photocurrent - saturation_current * np.expm1(v_star)\n151          - diode_voltage * g_sh - i_recomb)\n152     v = diode_voltage - i * resistance_series\n153     retval = (i, v, i*v)\n154     if gradients:\n155         # calculate recombination loss current gradients where d2mutau > 0\n156         grad_i_recomb = np.where(is_recomb, i_recomb / v_recomb, 0)\n157         grad_2i_recomb = np.where(is_recomb, 2 * grad_i_recomb / v_recomb, 0)\n158         g_diode = saturation_current * np.exp(v_star) / nNsVth  # conductance\n159         grad_i = -g_diode - g_sh - grad_i_recomb  # di/dvd\n160         grad_v = 1.0 - grad_i * resistance_series  # dv/dvd\n161         # dp/dv = d(iv)/dv = v * di/dv + i\n162         grad = grad_i / grad_v  # di/dv\n163         grad_p = v * grad + i  # dp/dv\n164         grad2i = -g_diode / nNsVth - grad_2i_recomb  # d2i/dvd\n165         grad2v = -grad2i * resistance_series  # d2v/dvd\n166         grad2p = (\n167             grad_v * grad + v * (grad2i/grad_v - grad_i*grad2v/grad_v**2)\n168             + grad_i\n169         )  # d2p/dv/dvd\n170         retval += (grad_i, grad_v, grad, grad_p, grad2p)\n171     return retval\n172 \n173 \n174 def bishop88_i_from_v(voltage, photocurrent, saturation_current,\n175                       resistance_series, resistance_shunt, nNsVth,\n176                       method='newton'):\n177     \"\"\"\n178     Find current given any voltage.\n179 \n180     Parameters\n181     ----------\n182     voltage : numeric\n183         voltage (V) in volts [V]\n184     photocurrent : numeric\n185         photogenerated current (Iph or IL) in amperes [A]\n186     saturation_current : numeric\n187         diode dark or saturation current (Io or Isat) in amperes [A]\n188     resistance_series : numeric\n189         series resistance (Rs) in ohms\n190     resistance_shunt : numeric\n191         shunt resistance (Rsh) in ohms\n192     nNsVth : numeric\n193         product of diode ideality factor (n), number of series cells (Ns), and\n194         thermal voltage (Vth = k_b * T / q_e) in volts [V]\n195     method : str\n196         one of two optional search methods: either ``'brentq'``, a reliable and\n197         bounded method or ``'newton'`` which is the default.\n198 \n199     Returns\n200     -------\n201     current : numeric\n202         current (I) at the specified voltage (V) in amperes [A]\n203     \"\"\"\n204     # collect args\n205     args = (photocurrent, saturation_current, resistance_series,\n206             resistance_shunt, nNsVth)\n207 \n208     def fv(x, v, *a):\n209         # calculate voltage residual given diode voltage \"x\"\n210         return bishop88(x, *a)[1] - v\n211 \n212     if method.lower() == 'brentq':\n213         # first bound the search using voc\n214         voc_est = estimate_voc(photocurrent, saturation_current, nNsVth)\n215 \n216         # brentq only works with scalar inputs, so we need a set up function\n217         # and np.vectorize to repeatedly call the optimizer with the right\n218         # arguments for possible array input\n219         def vd_from_brent(voc, v, iph, isat, rs, rsh, gamma):\n220             return brentq(fv, 0.0, voc, args=(v, iph, isat, rs, rsh, gamma))\n221 \n222         vd_from_brent_vectorized = np.vectorize(vd_from_brent)\n223         vd = vd_from_brent_vectorized(voc_est, voltage, *args)\n224     elif method.lower() == 'newton':\n225         # make sure all args are numpy arrays if max size > 1\n226         # if voltage is an array, then make a copy to use for initial guess, v0\n227         args, v0 = _prepare_newton_inputs((voltage,), args, voltage)\n228         vd = newton(func=lambda x, *a: fv(x, voltage, *a), x0=v0,\n229                     fprime=lambda x, *a: bishop88(x, *a, gradients=True)[4],\n230                     args=args)\n231     else:\n232         raise NotImplementedError(\"Method '%s' isn't implemented\" % method)\n233     return bishop88(vd, *args)[0]\n234 \n235 \n236 def bishop88_v_from_i(current, photocurrent, saturation_current,\n237                       resistance_series, resistance_shunt, nNsVth,\n238                       method='newton'):\n239     \"\"\"\n240     Find voltage given any current.\n241 \n242     Parameters\n243     ----------\n244     current : numeric\n245         current (I) in amperes [A]\n246     photocurrent : numeric\n247         photogenerated current (Iph or IL) in amperes [A]\n248     saturation_current : numeric\n249         diode dark or saturation current (Io or Isat) in amperes [A]\n250     resistance_series : numeric\n251         series resistance (Rs) in ohms\n252     resistance_shunt : numeric\n253         shunt resistance (Rsh) in ohms\n254     nNsVth : numeric\n255         product of diode ideality factor (n), number of series cells (Ns), and\n256         thermal voltage (Vth = k_b * T / q_e) in volts [V]\n257     method : str\n258         one of two optional search methods: either ``'brentq'``, a reliable and\n259         bounded method or ``'newton'`` which is the default.\n260 \n261     Returns\n262     -------\n263     voltage : numeric\n264         voltage (V) at the specified current (I) in volts [V]\n265     \"\"\"\n266     # collect args\n267     args = (photocurrent, saturation_current, resistance_series,\n268             resistance_shunt, nNsVth)\n269     # first bound the search using voc\n270     voc_est = estimate_voc(photocurrent, saturation_current, nNsVth)\n271 \n272     def fi(x, i, *a):\n273         # calculate current residual given diode voltage \"x\"\n274         return bishop88(x, *a)[0] - i\n275 \n276     if method.lower() == 'brentq':\n277         # brentq only works with scalar inputs, so we need a set up function\n278         # and np.vectorize to repeatedly call the optimizer with the right\n279         # arguments for possible array input\n280         def vd_from_brent(voc, i, iph, isat, rs, rsh, gamma):\n281             return brentq(fi, 0.0, voc, args=(i, iph, isat, rs, rsh, gamma))\n282 \n283         vd_from_brent_vectorized = np.vectorize(vd_from_brent)\n284         vd = vd_from_brent_vectorized(voc_est, current, *args)\n285     elif method.lower() == 'newton':\n286         # make sure all args are numpy arrays if max size > 1\n287         # if voc_est is an array, then make a copy to use for initial guess, v0\n288         args, v0 = _prepare_newton_inputs((current,), args, voc_est)\n289         vd = newton(func=lambda x, *a: fi(x, current, *a), x0=v0,\n290                     fprime=lambda x, *a: bishop88(x, *a, gradients=True)[3],\n291                     args=args)\n292     else:\n293         raise NotImplementedError(\"Method '%s' isn't implemented\" % method)\n294     return bishop88(vd, *args)[1]\n295 \n296 \n297 def bishop88_mpp(photocurrent, saturation_current, resistance_series,\n298                  resistance_shunt, nNsVth, method='newton'):\n299     \"\"\"\n300     Find max power point.\n301 \n302     Parameters\n303     ----------\n304     photocurrent : numeric\n305         photogenerated current (Iph or IL) in amperes [A]\n306     saturation_current : numeric\n307         diode dark or saturation current (Io or Isat) in amperes [A]\n308     resistance_series : numeric\n309         series resistance (Rs) in ohms\n310     resistance_shunt : numeric\n311         shunt resistance (Rsh) in ohms\n312     nNsVth : numeric\n313         product of diode ideality factor (n), number of series cells (Ns), and\n314         thermal voltage (Vth = k_b * T / q_e) in volts [V]\n315     method : str\n316         one of two optional search methods: either ``'brentq'``, a reliable and\n317         bounded method or ``'newton'`` which is the default.\n318 \n319     Returns\n320     -------\n321     OrderedDict or pandas.DataFrame\n322         max power current ``i_mp`` [A], max power voltage ``v_mp`` [V], and\n323         max power ``p_mp`` [W]\n324     \"\"\"\n325     # collect args\n326     args = (photocurrent, saturation_current, resistance_series,\n327             resistance_shunt, nNsVth)\n328     # first bound the search using voc\n329     voc_est = estimate_voc(photocurrent, saturation_current, nNsVth)\n330 \n331     def fmpp(x, *a):\n332         return bishop88(x, *a, gradients=True)[6]\n333 \n334     if method.lower() == 'brentq':\n335         # break out arguments for numpy.vectorize to handle broadcasting\n336         vec_fun = np.vectorize(\n337             lambda voc, iph, isat, rs, rsh, gamma:\n338                 brentq(fmpp, 0.0, voc, args=(iph, isat, rs, rsh, gamma))\n339         )\n340         vd = vec_fun(voc_est, *args)\n341     elif method.lower() == 'newton':\n342         # make sure all args are numpy arrays if max size > 1\n343         # if voc_est is an array, then make a copy to use for initial guess, v0\n344         args, v0 = _prepare_newton_inputs((), args, voc_est)\n345         vd = newton(\n346             func=fmpp, x0=v0,\n347             fprime=lambda x, *a: bishop88(x, *a, gradients=True)[7], args=args\n348         )\n349     else:\n350         raise NotImplementedError(\"Method '%s' isn't implemented\" % method)\n351     return bishop88(vd, *args)\n352 \n353 \n354 def _get_size_and_shape(args):\n355     # find the right size and shape for returns\n356     size, shape = 0, None  # 0 or None both mean scalar\n357     for arg in args:\n358         try:\n359             this_shape = arg.shape  # try to get shape\n360         except AttributeError:\n361             this_shape = None\n362             try:\n363                 this_size = len(arg)  # try to get the size\n364             except TypeError:\n365                 this_size = 0\n366         else:\n367             this_size = arg.size  # if it has shape then it also has size\n368             if shape is None:\n369                 shape = this_shape  # set the shape if None\n370         # update size and shape\n371         if this_size > size:\n372             size = this_size\n373             if this_shape is not None:\n374                 shape = this_shape\n375     return size, shape\n376 \n377 \n378 def _prepare_newton_inputs(i_or_v_tup, args, v0):\n379     # broadcast arguments for newton method\n380     # the first argument should be a tuple, eg: (i,), (v,) or ()\n381     size, shape = _get_size_and_shape(i_or_v_tup + args)\n382     if size > 1:\n383         args = [np.asarray(arg) for arg in args]\n384     # newton uses initial guess for the output shape\n385     # copy v0 to a new array and broadcast it to the shape of max size\n386     if shape is not None:\n387         v0 = np.broadcast_to(v0, shape).copy()\n388     return args, v0\n389 \n390 \n391 def _lambertw_v_from_i(resistance_shunt, resistance_series, nNsVth, current,\n392                        saturation_current, photocurrent):\n393     try:\n394         from scipy.special import lambertw\n395     except ImportError:\n396         raise ImportError('This function requires scipy')\n397 \n398     # Record if inputs were all scalar\n399     output_is_scalar = all(map(np.isscalar,\n400                                [resistance_shunt, resistance_series, nNsVth,\n401                                 current, saturation_current, photocurrent]))\n402 \n403     # This transforms Gsh=1/Rsh, including ideal Rsh=np.inf into Gsh=0., which\n404     #  is generally more numerically stable\n405     conductance_shunt = 1. / resistance_shunt\n406 \n407     # Ensure that we are working with read-only views of numpy arrays\n408     # Turns Series into arrays so that we don't have to worry about\n409     #  multidimensional broadcasting failing\n410     Gsh, Rs, a, I, I0, IL = \\\n411         np.broadcast_arrays(conductance_shunt, resistance_series, nNsVth,\n412                             current, saturation_current, photocurrent)\n413 \n414     # Intitalize output V (I might not be float64)\n415     V = np.full_like(I, np.nan, dtype=np.float64)\n416 \n417     # Determine indices where 0 < Gsh requires implicit model solution\n418     idx_p = 0. < Gsh\n419 \n420     # Determine indices where 0 = Gsh allows explicit model solution\n421     idx_z = 0. == Gsh\n422 \n423     # Explicit solutions where Gsh=0\n424     if np.any(idx_z):\n425         V[idx_z] = a[idx_z] * np.log1p((IL[idx_z] - I[idx_z]) / I0[idx_z]) - \\\n426                    I[idx_z] * Rs[idx_z]\n427 \n428     # Only compute using LambertW if there are cases with Gsh>0\n429     if np.any(idx_p):\n430         # LambertW argument, cannot be float128, may overflow to np.inf\n431         # overflow is explicitly handled below, so ignore warnings here\n432         with np.errstate(over='ignore'):\n433             argW = (I0[idx_p] / (Gsh[idx_p] * a[idx_p]) *\n434                     np.exp((-I[idx_p] + IL[idx_p] + I0[idx_p]) /\n435                            (Gsh[idx_p] * a[idx_p])))\n436 \n437         # lambertw typically returns complex value with zero imaginary part\n438         # may overflow to np.inf\n439         lambertwterm = lambertw(argW).real\n440 \n441         # Record indices where lambertw input overflowed output\n442         idx_inf = np.logical_not(np.isfinite(lambertwterm))\n443 \n444         # Only re-compute LambertW if it overflowed\n445         if np.any(idx_inf):\n446             # Calculate using log(argW) in case argW is really big\n447             logargW = (np.log(I0[idx_p]) - np.log(Gsh[idx_p]) -\n448                        np.log(a[idx_p]) +\n449                        (-I[idx_p] + IL[idx_p] + I0[idx_p]) /\n450                        (Gsh[idx_p] * a[idx_p]))[idx_inf]\n451 \n452             # Three iterations of Newton-Raphson method to solve\n453             #  w+log(w)=logargW. The initial guess is w=logargW. Where direct\n454             #  evaluation (above) results in NaN from overflow, 3 iterations\n455             #  of Newton's method gives approximately 8 digits of precision.\n456             w = logargW\n457             for _ in range(0, 3):\n458                 w = w * (1. - np.log(w) + logargW) / (1. + w)\n459             lambertwterm[idx_inf] = w\n460 \n461         # Eqn. 3 in Jain and Kapoor, 2004\n462         #  V = -I*(Rs + Rsh) + IL*Rsh - a*lambertwterm + I0*Rsh\n463         # Recast in terms of Gsh=1/Rsh for better numerical stability.\n464         V[idx_p] = (IL[idx_p] + I0[idx_p] - I[idx_p]) / Gsh[idx_p] - \\\n465             I[idx_p] * Rs[idx_p] - a[idx_p] * lambertwterm\n466 \n467     if output_is_scalar:\n468         return V.item()\n469     else:\n470         return V\n471 \n472 \n473 def _lambertw_i_from_v(resistance_shunt, resistance_series, nNsVth, voltage,\n474                        saturation_current, photocurrent):\n475     try:\n476         from scipy.special import lambertw\n477     except ImportError:\n478         raise ImportError('This function requires scipy')\n479 \n480     # Record if inputs were all scalar\n481     output_is_scalar = all(map(np.isscalar,\n482                                [resistance_shunt, resistance_series, nNsVth,\n483                                 voltage, saturation_current, photocurrent]))\n484 \n485     # This transforms Gsh=1/Rsh, including ideal Rsh=np.inf into Gsh=0., which\n486     #  is generally more numerically stable\n487     conductance_shunt = 1. / resistance_shunt\n488 \n489     # Ensure that we are working with read-only views of numpy arrays\n490     # Turns Series into arrays so that we don't have to worry about\n491     #  multidimensional broadcasting failing\n492     Gsh, Rs, a, V, I0, IL = \\\n493         np.broadcast_arrays(conductance_shunt, resistance_series, nNsVth,\n494                             voltage, saturation_current, photocurrent)\n495 \n496     # Intitalize output I (V might not be float64)\n497     I = np.full_like(V, np.nan, dtype=np.float64)           # noqa: E741, N806\n498 \n499     # Determine indices where 0 < Rs requires implicit model solution\n500     idx_p = 0. < Rs\n501 \n502     # Determine indices where 0 = Rs allows explicit model solution\n503     idx_z = 0. == Rs\n504 \n505     # Explicit solutions where Rs=0\n506     if np.any(idx_z):\n507         I[idx_z] = IL[idx_z] - I0[idx_z] * np.expm1(V[idx_z] / a[idx_z]) - \\\n508                    Gsh[idx_z] * V[idx_z]\n509 \n510     # Only compute using LambertW if there are cases with Rs>0\n511     # Does NOT handle possibility of overflow, github issue 298\n512     if np.any(idx_p):\n513         # LambertW argument, cannot be float128, may overflow to np.inf\n514         argW = Rs[idx_p] * I0[idx_p] / (\n515                     a[idx_p] * (Rs[idx_p] * Gsh[idx_p] + 1.)) * \\\n516                np.exp((Rs[idx_p] * (IL[idx_p] + I0[idx_p]) + V[idx_p]) /\n517                       (a[idx_p] * (Rs[idx_p] * Gsh[idx_p] + 1.)))\n518 \n519         # lambertw typically returns complex value with zero imaginary part\n520         # may overflow to np.inf\n521         lambertwterm = lambertw(argW).real\n522 \n523         # Eqn. 2 in Jain and Kapoor, 2004\n524         #  I = -V/(Rs + Rsh) - (a/Rs)*lambertwterm + Rsh*(IL + I0)/(Rs + Rsh)\n525         # Recast in terms of Gsh=1/Rsh for better numerical stability.\n526         I[idx_p] = (IL[idx_p] + I0[idx_p] - V[idx_p] * Gsh[idx_p]) / \\\n527                    (Rs[idx_p] * Gsh[idx_p] + 1.) - (\n528                                a[idx_p] / Rs[idx_p]) * lambertwterm\n529 \n530     if output_is_scalar:\n531         return I.item()\n532     else:\n533         return I\n534 \n535 \n536 def _lambertw(photocurrent, saturation_current, resistance_series,\n537               resistance_shunt, nNsVth, ivcurve_pnts=None):\n538     # Compute short circuit current\n539     i_sc = _lambertw_i_from_v(resistance_shunt, resistance_series, nNsVth, 0.,\n540                               saturation_current, photocurrent)\n541 \n542     # Compute open circuit voltage\n543     v_oc = _lambertw_v_from_i(resistance_shunt, resistance_series, nNsVth, 0.,\n544                               saturation_current, photocurrent)\n545 \n546     params = {'r_sh': resistance_shunt,\n547               'r_s': resistance_series,\n548               'nNsVth': nNsVth,\n549               'i_0': saturation_current,\n550               'i_l': photocurrent}\n551 \n552     # Find the voltage, v_mp, where the power is maximized.\n553     # Start the golden section search at v_oc * 1.14\n554     p_mp, v_mp = _golden_sect_DataFrame(params, 0., v_oc * 1.14,\n555                                         _pwr_optfcn)\n556 \n557     # Find Imp using Lambert W\n558     i_mp = _lambertw_i_from_v(resistance_shunt, resistance_series, nNsVth,\n559                               v_mp, saturation_current, photocurrent)\n560 \n561     # Find Ix and Ixx using Lambert W\n562     i_x = _lambertw_i_from_v(resistance_shunt, resistance_series, nNsVth,\n563                              0.5 * v_oc, saturation_current, photocurrent)\n564 \n565     i_xx = _lambertw_i_from_v(resistance_shunt, resistance_series, nNsVth,\n566                               0.5 * (v_oc + v_mp), saturation_current,\n567                               photocurrent)\n568 \n569     out = (i_sc, v_oc, i_mp, v_mp, p_mp, i_x, i_xx)\n570 \n571     # create ivcurve\n572     if ivcurve_pnts:\n573         ivcurve_v = (np.asarray(v_oc)[..., np.newaxis] *\n574                      np.linspace(0, 1, ivcurve_pnts))\n575 \n576         ivcurve_i = _lambertw_i_from_v(resistance_shunt, resistance_series,\n577                                        nNsVth, ivcurve_v.T, saturation_current,\n578                                        photocurrent).T\n579 \n580         out += (ivcurve_i, ivcurve_v)\n581 \n582     return out\n583 \n584 \n585 def _pwr_optfcn(df, loc):\n586     '''\n587     Function to find power from ``i_from_v``.\n588     '''\n589 \n590     I = _lambertw_i_from_v(df['r_sh'], df['r_s'],           # noqa: E741, N806\n591                            df['nNsVth'], df[loc], df['i_0'], df['i_l'])\n592 \n593     return I * df[loc]\n594 \n[end of pvlib/singlediode.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n\n\n", "full_output": "```patch\n--- a/pvlib/pvsystem.py\n+++ b/pvlib/pvsystem.py\n@@ -317,6 +317,8 @@\n     def calcparams_desoto(self, effective_irradiance, temp_cell, **kwargs):\n         \"\"\"\n         Use the :py:func:`calcparams_desoto` function, the input\n         parameters and ``self.module_parameters`` to calculate the\n         module currents and resistances.\n \n         Parameters\n         ----------\n         effective_irradiance : numeric\n         ...\n         **kwargs\n         See pvsystem.calcparams_desoto for details\n         +    recombination_current: numeric, optional\n         +        Recombination current parameter for the model.\n \n         Returns\n         -------\n         See pvsystem.calcparams_desoto for details\n         \"\"\"\n         kwargs = _build_kwargs(['a_ref', 'I_L_ref', 'I_o_ref', 'R_sh_ref',\n                                 'R_s', 'alpha_sc', 'EgRef', 'dEgdT',\n                                 'irrad_ref', 'temp_ref', 'recombination_current'],\n                                self.module_parameters)\n \n         return calcparams_desoto(effective_irradiance, temp_cell, **kwargs)\n \n@@ -346,6 +348,8 @@\n     def calcparams_cec(self, effective_irradiance, temp_cell, **kwargs):\n         \"\"\"\n         Use the :py:func:`calcparams_cec` function, the input\n         parameters and ``self.module_parameters`` to calculate the\n         module currents and resistances.\n \n         Parameters\n         ----------\n         effective_irradiance : numeric\n         ...\n         **kwargs\n         See pvsystem.calcparams_cec for details\n         +    recombination_current: numeric, optional\n         +        Recombination current parameter for the model.\n \n         Returns\n         -------\n         See pvsystem.calcparams_cec for details\n         \"\"\"\n         kwargs = _build_kwargs(['a_ref', 'I_L_ref', 'I_o_ref', 'R_sh_ref',\n                                 'R_s', 'alpha_sc', 'Adjust', 'EgRef', 'dEgdT',\n                                 'irrad_ref', 'temp_ref', 'recombination_current'],\n                                self.module_parameters)\n \n         return calcparams_cec(effective_irradiance, temp_cell, **kwargs)\n \n@@ -375,6 +379,8 @@\n     def calcparams_pvsyst(self, effective_irradiance, temp_cell, **kwargs):\n         \"\"\"\n         Use the :py:func:`calcparams_pvsyst` function, the input\n         parameters and ``self.module_parameters`` to calculate the\n         module currents and resistances.\n \n         Parameters\n         ----------\n         effective_irradiance : numeric\n         ...\n         **kwargs\n         See pvsystem.calcparams_pvsyst for details\n         +    recombination_current: numeric, optional\n         +        Recombination current parameter for the model.\n \n         Returns\n         -------\n         See pvsystem.calcparams_pvsyst for details\n         \"\"\"\n         kwargs = _build_kwargs(['gamma_ref', 'mu_gamma', 'I_L_ref', 'I_o_ref',\n                                 'R_sh_ref', 'R_sh_0', 'R_sh_exp',\n                                 'R_s', 'alpha_sc', 'EgRef',\n                                 'irrad_ref', 'temp_ref',\n                                 'cells_in_series', 'recombination_current'],\n                                self.module_parameters)\n \n         return calcparams_pvsyst(effective_irradiance, temp_cell, **kwargs)\n \n@@ -403,6 +409,8 @@\n     def sapm(self, effective_irradiance, temp_cell, **kwargs):\n         \"\"\"\n         Use the :py:func:`sapm` function, the input parameters,\n         and ``self.module_parameters`` to calculate\n         Voc, Isc, Ix, Ixx, Vmp/Imp.\n \n         Parameters\n         ----------\n         effective_irradiance : numeric\n         ...\n         **kwargs\n         See pvsystem.sapm for details\n         +    recombination_current: numeric, optional\n         +        Recombination current parameter for the model.\n \n         Returns\n         -------\n         See pvsystem.sapm for details\n         \"\"\"\n         return sapm(effective_irradiance, temp_cell, self.module_parameters, **kwargs)\n \n@@ -433,6 +441,8 @@\n     def sapm_celltemp(self, irrad, wind, temp, **kwargs):\n         \"\"\"Uses :py:func:`sapm_celltemp` to calculate module and cell\n         temperatures based on ``self.racking_model`` and\n         the input parameters.\n \n         Parameters\n         ----------\n         See pvsystem.sapm_celltemp for details\n         +    recombination_current: numeric, optional\n         +        Recombination current parameter for the model.\n \n         Returns\n         -------\n         See pvsystem.sapm_celltemp for details\n         \"\"\"\n         return sapm_celltemp(irrad, wind, temp, self.racking_model, **kwargs)\n \n@@ -450,6 +460,8 @@\n     def sapm_spectral_loss(self, airmass_absolute, **kwargs):\n         \"\"\"\n         Use the :py:func:`sapm_spectral_loss` function, the input\n         parameters, and ``self.module_parameters`` to calculate F1.\n \n         Parameters\n         ----------\n         airmass_absolute : numeric\n         ...\n         **kwargs\n         See pvsystem.sapm_spectral_loss for details\n         +    recombination_current: numeric, optional\n         +        Recombination current parameter for the model.\n \n         Returns\n         -------\n         F1 : numeric\n             The SAPM spectral loss coefficient.\n         \"\"\"\n         return sapm_spectral_loss(airmass_absolute, self.module_parameters, **kwargs)\n \n@@ -467,6 +479,8 @@\n     def sapm_aoi_loss(self, aoi, **kwargs):\n         \"\"\"\n         Use the :py:func:`sapm_aoi_loss` function, the input parameters,\n         and ``self.module_parameters`` to calculate F2.\n \n         Parameters\n         ----------\n         aoi : numeric\n         ...\n         **kwargs\n         See pvsystem.sapm_aoi_loss for details\n         +    recombination_current: numeric, optional\n         +        Recombination current parameter for the model.\n \n         Returns\n         -------\n         F2 : numeric\n             The SAPM angle of incidence loss coefficient.\n         \"\"\"\n         return sapm_aoi_loss(aoi, self.module_parameters, **kwargs)\n \n@@ -484,6 +498,8 @@\n     def sapm_effective_irradiance(self, poa_direct, poa_diffuse,\n                                   airmass_absolute, aoi, **kwargs):\n         \"\"\"\n         Use the :py:func:`sapm_effective_irradiance` function, the input\n         parameters, and ``self.module_parameters`` to calculate\n         effective irradiance.\n \n         Parameters\n         ----------\n         poa_direct : numeric\n         ...\n         **kwargs\n         See pvsystem.sapm_effective_irradiance for details\n         +    recombination_current: numeric, optional\n         +        Recombination current parameter for the model.\n \n         Returns\n         -------\n         effective_irradiance : numeric\n             The SAPM effective irradiance.\n         \"\"\"\n         return sapm_effective_irradiance(\n             poa_direct, poa_diffuse, airmass_absolute, aoi,\n             self.module_parameters, **kwargs)\n \n--- a/pvlib/singlediode.py\n+++ b/pvlib/singlediode.py\n@@ -72,6 +72,8 @@\n              d2mutau=0, NsVbi=np.Inf, gradients=False):\n     \"\"\"\n     Explicit calculation of points on the IV curve described by the single\n     diode equation [1]_.\n \n     ...\n     d2mutau : numeric\n         PVSyst thin-film recombination parameter that is the ratio of thickness\n         of the intrinsic layer squared :math:`d^2` and the diffusion length of\n         charge carriers :math:`\\\\mu \\\\tau`, in volts [V], defaults to 0[V]\n     +    recombination_current: numeric, optional\n     +        Recombination current parameter for the model.\n \n     Returns\n     -------\n     ...\n     \"\"\"\n     # calculate recombination loss current where d2mutau > 0\n     is_recomb = d2mutau > 0  # True where there is thin-film recombination loss\n     v_recomb = np.where(is_recomb, NsVbi - diode_voltage, np.inf)\n     i_recomb = np.where(is_recomb, photocurrent * d2mutau / v_recomb, 0)\n     # calculate temporary values to simplify calculations\n     ...\n     return retval\n```", "model_patch": "--- a/pvlib/pvsystem.py\n+++ b/pvlib/pvsystem.py\n@@ -317,6 +317,8 @@\n     def calcparams_desoto(self, effective_irradiance, temp_cell, **kwargs):\n         \"\"\"\n         Use the :py:func:`calcparams_desoto` function, the input\n         parameters and ``self.module_parameters`` to calculate the\n         module currents and resistances.\n \n         Parameters\n         ----------\n         effective_irradiance : numeric\n         ...\n         **kwargs\n         See pvsystem.calcparams_desoto for details\n         +    recombination_current: numeric, optional\n         +        Recombination current parameter for the model.\n \n         Returns\n         -------\n         See pvsystem.calcparams_desoto for details\n         \"\"\"\n         kwargs = _build_kwargs(['a_ref', 'I_L_ref', 'I_o_ref', 'R_sh_ref',\n                                 'R_s', 'alpha_sc', 'EgRef', 'dEgdT',\n                                 'irrad_ref', 'temp_ref', 'recombination_current'],\n                                self.module_parameters)\n \n         return calcparams_desoto(effective_irradiance, temp_cell, **kwargs)\n \n@@ -346,6 +348,8 @@\n     def calcparams_cec(self, effective_irradiance, temp_cell, **kwargs):\n         \"\"\"\n         Use the :py:func:`calcparams_cec` function, the input\n         parameters and ``self.module_parameters`` to calculate the\n         module currents and resistances.\n \n         Parameters\n         ----------\n         effective_irradiance : numeric\n         ...\n         **kwargs\n         See pvsystem.calcparams_cec for details\n         +    recombination_current: numeric, optional\n         +        Recombination current parameter for the model.\n \n         Returns\n         -------\n         See pvsystem.calcparams_cec for details\n         \"\"\"\n         kwargs = _build_kwargs(['a_ref', 'I_L_ref', 'I_o_ref', 'R_sh_ref',\n                                 'R_s', 'alpha_sc', 'Adjust', 'EgRef', 'dEgdT',\n                                 'irrad_ref', 'temp_ref', 'recombination_current'],\n                                self.module_parameters)\n \n         return calcparams_cec(effective_irradiance, temp_cell, **kwargs)\n \n@@ -375,6 +379,8 @@\n     def calcparams_pvsyst(self, effective_irradiance, temp_cell, **kwargs):\n         \"\"\"\n         Use the :py:func:`calcparams_pvsyst` function, the input\n         parameters and ``self.module_parameters`` to calculate the\n         module currents and resistances.\n \n         Parameters\n         ----------\n         effective_irradiance : numeric\n         ...\n         **kwargs\n         See pvsystem.calcparams_pvsyst for details\n         +    recombination_current: numeric, optional\n         +        Recombination current parameter for the model.\n \n         Returns\n         -------\n         See pvsystem.calcparams_pvsyst for details\n         \"\"\"\n         kwargs = _build_kwargs(['gamma_ref', 'mu_gamma', 'I_L_ref', 'I_o_ref',\n                                 'R_sh_ref', 'R_sh_0', 'R_sh_exp',\n                                 'R_s', 'alpha_sc', 'EgRef',\n                                 'irrad_ref', 'temp_ref',\n                                 'cells_in_series', 'recombination_current'],\n                                self.module_parameters)\n \n         return calcparams_pvsyst(effective_irradiance, temp_cell, **kwargs)\n \n@@ -403,6 +409,8 @@\n     def sapm(self, effective_irradiance, temp_cell, **kwargs):\n         \"\"\"\n         Use the :py:func:`sapm` function, the input parameters,\n         and ``self.module_parameters`` to calculate\n         Voc, Isc, Ix, Ixx, Vmp/Imp.\n \n         Parameters\n         ----------\n         effective_irradiance : numeric\n         ...\n         **kwargs\n         See pvsystem.sapm for details\n         +    recombination_current: numeric, optional\n         +        Recombination current parameter for the model.\n \n         Returns\n         -------\n         See pvsystem.sapm for details\n         \"\"\"\n         return sapm(effective_irradiance, temp_cell, self.module_parameters, **kwargs)\n \n@@ -433,6 +441,8 @@\n     def sapm_celltemp(self, irrad, wind, temp, **kwargs):\n         \"\"\"Uses :py:func:`sapm_celltemp` to calculate module and cell\n         temperatures based on ``self.racking_model`` and\n         the input parameters.\n \n         Parameters\n         ----------\n         See pvsystem.sapm_celltemp for details\n         +    recombination_current: numeric, optional\n         +        Recombination current parameter for the model.\n \n         Returns\n         -------\n         See pvsystem.sapm_celltemp for details\n         \"\"\"\n         return sapm_celltemp(irrad, wind, temp, self.racking_model, **kwargs)\n \n@@ -450,6 +460,8 @@\n     def sapm_spectral_loss(self, airmass_absolute, **kwargs):\n         \"\"\"\n         Use the :py:func:`sapm_spectral_loss` function, the input\n         parameters, and ``self.module_parameters`` to calculate F1.\n \n         Parameters\n         ----------\n         airmass_absolute : numeric\n         ...\n         **kwargs\n         See pvsystem.sapm_spectral_loss for details\n         +    recombination_current: numeric, optional\n         +        Recombination current parameter for the model.\n \n         Returns\n         -------\n         F1 : numeric\n             The SAPM spectral loss coefficient.\n         \"\"\"\n         return sapm_spectral_loss(airmass_absolute, self.module_parameters, **kwargs)\n \n@@ -467,6 +479,8 @@\n     def sapm_aoi_loss(self, aoi, **kwargs):\n         \"\"\"\n         Use the :py:func:`sapm_aoi_loss` function, the input parameters,\n         and ``self.module_parameters`` to calculate F2.\n \n         Parameters\n         ----------\n         aoi : numeric\n         ...\n         **kwargs\n         See pvsystem.sapm_aoi_loss for details\n         +    recombination_current: numeric, optional\n         +        Recombination current parameter for the model.\n \n         Returns\n         -------\n         F2 : numeric\n             The SAPM angle of incidence loss coefficient.\n         \"\"\"\n         return sapm_aoi_loss(aoi, self.module_parameters, **kwargs)\n \n@@ -484,6 +498,8 @@\n     def sapm_effective_irradiance(self, poa_direct, poa_diffuse,\n                                   airmass_absolute, aoi, **kwargs):\n         \"\"\"\n         Use the :py:func:`sapm_effective_irradiance` function, the input\n         parameters, and ``self.module_parameters`` to calculate\n         effective irradiance.\n \n         Parameters\n         ----------\n         poa_direct : numeric\n         ...\n         **kwargs\n         See pvsystem.sapm_effective_irradiance for details\n         +    recombination_current: numeric, optional\n         +        Recombination current parameter for the model.\n \n         Returns\n         -------\n         effective_irradiance : numeric\n             The SAPM effective irradiance.\n         \"\"\"\n         return sapm_effective_irradiance(\n             poa_direct, poa_diffuse, airmass_absolute, aoi,\n             self.module_parameters, **kwargs)\n \n--- a/pvlib/singlediode.py\n+++ b/pvlib/singlediode.py\n@@ -72,6 +72,8 @@\n              d2mutau=0, NsVbi=np.Inf, gradients=False):\n     \"\"\"\n     Explicit calculation of points on the IV curve described by the single\n     diode equation [1]_.\n \n     ...\n     d2mutau : numeric\n         PVSyst thin-film recombination parameter that is the ratio of thickness\n         of the intrinsic layer squared :math:`d^2` and the diffusion length of\n         charge carriers :math:`\\\\mu \\\\tau`, in volts [V], defaults to 0[V]\n     +    recombination_current: numeric, optional\n     +        Recombination current parameter for the model.\n \n     Returns\n     -------\n     ...\n     \"\"\"\n     # calculate recombination loss current where d2mutau > 0\n     is_recomb = d2mutau > 0  # True where there is thin-film recombination loss\n     v_recomb = np.where(is_recomb, NsVbi - diode_voltage, np.inf)\n     i_recomb = np.where(is_recomb, photocurrent * d2mutau / v_recomb, 0)\n     # calculate temporary values to simplify calculations\n     ...\n     return retval\n"}
{"instance_id": "pvlib__pvlib-python-1218", "model_name_or_path": "gpt-4o-mini", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nchange eta_m to module_efficiency\n`temperature.noct_sam` uses `eta_m_ref` to describe the module efficiency at reference conditions and `temperature.pvsyst_cell` uses `eta_m` to describe the module efficiency generically.\r\n\r\nJust calling both of these `module_efficiency` would make the function signatures easily understandable by many more people. I'd be ok with `module_efficiency_ref` but I don't think that precision is very important.\r\n\r\nI skimmed [pvterms](https://duramat.github.io/pv-terms/) and didn't see a suggestion for this quantity.\r\n\r\n`temperature.noct_sam` has not yet been released and it's just a positional argument, so changing the name is trivial. `temperature.pvsyst_cell` would need a deprecation cycle.\r\n\r\nOriginally discussed in https://github.com/pvlib/pvlib-python/pull/1177#discussion_r589081257\r\n\r\nAssignment of milestone indicates that we will act on this or close it forever before 0.9 is released.\r\n\n\n</issue>\n<code>\n[start of README.md]\n1 <img src=\"docs/sphinx/source/_images/pvlib_logo_horiz.png\" width=\"600\">\n2 \n3 <table>\n4 <tr>\n5   <td>Latest Release</td>\n6   <td>\n7     <a href=\"https://pypi.org/project/pvlib/\">\n8     <img src=\"https://img.shields.io/pypi/v/pvlib.svg\" alt=\"latest release\" />\n9     </a>\n10     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n11     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/version.svg\" />\n12     </a>\n13     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n14     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/latest_release_date.svg\" />\n15     </a>\n16 </tr>\n17 <tr>\n18   <td>License</td>\n19   <td>\n20     <a href=\"https://github.com/pvlib/pvlib-python/blob/master/LICENSE\">\n21     <img src=\"https://img.shields.io/pypi/l/pvlib.svg\" alt=\"license\" />\n22     </a>\n23 </td>\n24 </tr>\n25 <tr>\n26   <td>Build Status</td>\n27   <td>\n28     <a href=\"http://pvlib-python.readthedocs.org/en/stable/\">\n29     <img src=\"https://readthedocs.org/projects/pvlib-python/badge/?version=stable\" alt=\"documentation build status\" />\n30     </a>\n31     <a href=\"https://dev.azure.com/solararbiter/pvlib%20python/_build/latest?definitionId=4&branchName=master\">\n32       <img src=\"https://dev.azure.com/solararbiter/pvlib%20python/_apis/build/status/pvlib.pvlib-python?branchName=master\" alt=\"Azure Pipelines build status\" />\n33     </a>\n34   </td>\n35 </tr>\n36 <tr>\n37   <td>Code Quality</td>\n38  \u00a0<td>\n39     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/context:python\">\n40     <img src=\"https://img.shields.io/lgtm/grade/python/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm quality grade\" />\n41     </a>\n42     <a href=\"https://lgtm.com/projects/g/pvlib/pvlib-python/alerts\">\n43     <img src=\"https://img.shields.io/lgtm/alerts/g/pvlib/pvlib-python.svg?logo=lgtm&logoWidth=18\" alt=\"lgtm alters\" />\n44     </a>\n45   </td>\n46 </tr>\n47 <tr>\n48   <td>Coverage</td>\n49  \u00a0<td>\n50     <a href=\"https://coveralls.io/r/pvlib/pvlib-python\">\n51     <img src=\"https://img.shields.io/coveralls/pvlib/pvlib-python.svg\" alt=\"coveralls coverage\" />\n52     </a>\n53     <a href=\"https://codecov.io/gh/pvlib/pvlib-python\">\n54     <img src=\"https://codecov.io/gh/pvlib/pvlib-python/branch/master/graph/badge.svg\" alt=\"codecov coverage\" />\n55     </a>\n56   </td>\n57 </tr>\n58 <tr>\n59   <td>Publications</td>\n60   <td>\n61     <a href=\"https://doi.org/10.5281/zenodo.3762635\">\n62     <img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.3762635.svg\" alt=\"zenodo reference\">\n63     </a>\n64     <a href=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1\">\n65     <img src=\"http://joss.theoj.org/papers/41187535cad22dd4b076c89b72f874b1/status.svg\" alt=\"JOSS reference\" />\n66     </a>\n67   </td>\n68 </tr>\n69 <tr>\n70   <td>Downloads</td>\n71   <td>\n72     <a href=\"https://pypi.org/project/pvlib/\">\n73     <img src=\"https://img.shields.io/pypi/dm/pvlib\" alt=\"PyPI downloads\" />\n74     </a>\n75     <a href=\"https://anaconda.org/conda-forge/pvlib-python\">\n76     <img src=\"https://anaconda.org/conda-forge/pvlib-python/badges/downloads.svg\" alt=\"conda-forge downloads\" />\n77     </a>\n78   </td>\n79 </tr>\n80 </table>\n81 \n82 \n83 pvlib python is a community supported tool that provides a set of\n84 functions and classes for simulating the performance of photovoltaic\n85 energy systems. pvlib python was originally ported from the PVLIB MATLAB\n86 toolbox developed at Sandia National Laboratories and it implements many\n87 of the models and methods developed at the Labs. More information on\n88 Sandia Labs PV performance modeling programs can be found at\n89 https://pvpmc.sandia.gov/. We collaborate with the PVLIB MATLAB project,\n90 but operate independently of it.\n91 \n92 \n93 Documentation\n94 =============\n95 \n96 Full documentation can be found at [readthedocs](http://pvlib-python.readthedocs.io/en/stable/).\n97 \n98 \n99 Installation\n100 ============\n101 \n102 pvlib-python releases may be installed using the ``pip`` and ``conda`` tools.\n103 Please see the [Installation page](http://pvlib-python.readthedocs.io/en/stable/installation.html) of the documentation for complete instructions.\n104 \n105 \n106 Contributing\n107 ============\n108 \n109 We need your help to make pvlib-python a great tool!\n110 Please see the [Contributing page](http://pvlib-python.readthedocs.io/en/stable/contributing.html) for more on how you can contribute.\n111 The long-term success of pvlib-python requires substantial community support.\n112 \n113 \n114 License\n115 =======\n116 \n117 BSD 3-clause\n118 \n119 \n120 Getting support\n121 ===============\n122 \n123 pvlib usage questions can be asked on\n124 [Stack Overflow](http://stackoverflow.com) and tagged with\n125 the [pvlib](http://stackoverflow.com/questions/tagged/pvlib) tag.\n126 \n127 The [pvlib-python google group](https://groups.google.com/forum/#!forum/pvlib-python)\n128 is used for discussing various topics of interest to the pvlib-python\n129 community. We also make new version announcements on the google group.\n130 \n131 If you suspect that you may have discovered a bug or if you'd like to\n132 change something about pvlib, then please make an issue on our\n133 [GitHub issues page](https://github.com/pvlib/pvlib-python/issues).\n134 \n135 \n136 Citing\n137 ======\n138 \n139 If you use pvlib-python in a published work, please cite:\n140 \n141   William F. Holmgren, Clifford W. Hansen, and Mark A. Mikofski.\n142   \"pvlib python: a python package for modeling solar energy systems.\"\n143   Journal of Open Source Software, 3(29), 884, (2018).\n144   https://doi.org/10.21105/joss.00884\n145 \n146 Please also cite the DOI corresponding to the specific version of\n147 pvlib-python that you used. pvlib-python DOIs are listed at\n148 [Zenodo.org](https://zenodo.org/search?page=1&size=20&q=conceptrecid:593284&all_versions&sort=-version)\n149 \n150 NumFOCUS\n151 ========\n152 \n153 pvlib python is a [NumFOCUS Affiliated Project](https://numfocus.org/sponsored-projects/affiliated-projects)\n154 \n155 [![NumFocus Affliated Projects](https://i0.wp.com/numfocus.org/wp-content/uploads/2019/06/AffiliatedProject.png)](https://numfocus.org/sponsored-projects/affiliated-projects)\n156 \n[end of README.md]\n[start of pvlib/modelchain.py]\n1 \"\"\"\n2 The ``modelchain`` module contains functions and classes that combine\n3 many of the PV power modeling steps. These tools make it easy to\n4 get started with pvlib and demonstrate standard ways to use the\n5 library. With great power comes great responsibility: users should take\n6 the time to read the source code for the module.\n7 \"\"\"\n8 \n9 from functools import partial\n10 import itertools\n11 import warnings\n12 import pandas as pd\n13 from dataclasses import dataclass, field\n14 from typing import Union, Tuple, Optional, TypeVar\n15 \n16 from pvlib import (atmosphere, clearsky, inverter, pvsystem, solarposition,\n17                    temperature, tools)\n18 from pvlib.tracking import SingleAxisTracker\n19 import pvlib.irradiance  # avoid name conflict with full import\n20 from pvlib.pvsystem import _DC_MODEL_PARAMS\n21 from pvlib._deprecation import pvlibDeprecationWarning\n22 from pvlib.tools import _build_kwargs\n23 \n24 # keys that are used to detect input data and assign data to appropriate\n25 # ModelChain attribute\n26 # for ModelChain.weather\n27 WEATHER_KEYS = ('ghi', 'dhi', 'dni', 'wind_speed', 'temp_air',\n28                 'precipitable_water')\n29 \n30 # for ModelChain.total_irrad\n31 POA_KEYS = ('poa_global', 'poa_direct', 'poa_diffuse')\n32 \n33 # Optional keys to communicate temperature data. If provided,\n34 # 'cell_temperature' overrides ModelChain.temperature_model and sets\n35 # ModelChain.cell_temperature to the data. If 'module_temperature' is provdied,\n36 # overrides ModelChain.temperature_model with\n37 # pvlib.temperature.sapm_celL_from_module\n38 TEMPERATURE_KEYS = ('module_temperature', 'cell_temperature')\n39 \n40 DATA_KEYS = WEATHER_KEYS + POA_KEYS + TEMPERATURE_KEYS\n41 \n42 # these dictionaries contain the default configuration for following\n43 # established modeling sequences. They can be used in combination with\n44 # basic_chain and ModelChain. They are used by the ModelChain methods\n45 # ModelChain.with_pvwatts, ModelChain.with_sapm, etc.\n46 \n47 # pvwatts documentation states that it uses the following reference for\n48 # a temperature model: Fuentes, M. K. (1987). A Simplified Thermal Model\n49 # for Flat-Plate Photovoltaic Arrays. SAND85-0330. Albuquerque, NM:\n50 # Sandia National Laboratories. Accessed September 3, 2013:\n51 # http://prod.sandia.gov/techlib/access-control.cgi/1985/850330.pdf\n52 # pvlib python does not implement that model, so use the SAPM instead.\n53 PVWATTS_CONFIG = dict(\n54     dc_model='pvwatts', ac_model='pvwatts', losses_model='pvwatts',\n55     transposition_model='perez', aoi_model='physical',\n56     spectral_model='no_loss', temperature_model='sapm'\n57 )\n58 \n59 SAPM_CONFIG = dict(\n60     dc_model='sapm', ac_model='sandia', losses_model='no_loss',\n61     aoi_model='sapm', spectral_model='sapm', temperature_model='sapm'\n62 )\n63 \n64 \n65 def basic_chain(times, latitude, longitude,\n66                 surface_tilt, surface_azimuth,\n67                 module_parameters, temperature_model_parameters,\n68                 inverter_parameters,\n69                 irradiance=None, weather=None,\n70                 transposition_model='haydavies',\n71                 solar_position_method='nrel_numpy',\n72                 airmass_model='kastenyoung1989',\n73                 altitude=None, pressure=None,\n74                 **kwargs):\n75     \"\"\"\n76     An experimental function that computes all of the modeling steps\n77     necessary for calculating power or energy for a PV system at a given\n78     location.\n79 \n80     Parameters\n81     ----------\n82     times : DatetimeIndex\n83         Times at which to evaluate the model.\n84 \n85     latitude : float.\n86         Positive is north of the equator.\n87         Use decimal degrees notation.\n88 \n89     longitude : float.\n90         Positive is east of the prime meridian.\n91         Use decimal degrees notation.\n92 \n93     surface_tilt : numeric\n94         Surface tilt angles in decimal degrees.\n95         The tilt angle is defined as degrees from horizontal\n96         (e.g. surface facing up = 0, surface facing horizon = 90)\n97 \n98     surface_azimuth : numeric\n99         Surface azimuth angles in decimal degrees.\n100         The azimuth convention is defined\n101         as degrees east of north\n102         (North=0, South=180, East=90, West=270).\n103 \n104     module_parameters : None, dict or Series\n105         Module parameters as defined by the SAPM. See pvsystem.sapm for\n106         details.\n107 \n108     temperature_model_parameters : None, dict or Series.\n109         Temperature model parameters as defined by the SAPM.\n110         See temperature.sapm_cell for details.\n111 \n112     inverter_parameters : None, dict or Series\n113         Inverter parameters as defined by the CEC. See\n114         :py:func:`inverter.sandia` for details.\n115 \n116     irradiance : None or DataFrame, default None\n117         If None, calculates clear sky data.\n118         Columns must be 'dni', 'ghi', 'dhi'.\n119 \n120     weather : None or DataFrame, default None\n121         If None, assumes air temperature is 20 C and\n122         wind speed is 0 m/s.\n123         Columns must be 'wind_speed', 'temp_air'.\n124 \n125     transposition_model : str, default 'haydavies'\n126         Passed to system.get_irradiance.\n127 \n128     solar_position_method : str, default 'nrel_numpy'\n129         Passed to solarposition.get_solarposition.\n130 \n131     airmass_model : str, default 'kastenyoung1989'\n132         Passed to atmosphere.relativeairmass.\n133 \n134     altitude : None or float, default None\n135         If None, computed from pressure. Assumed to be 0 m\n136         if pressure is also None.\n137 \n138     pressure : None or float, default None\n139         If None, computed from altitude. Assumed to be 101325 Pa\n140         if altitude is also None.\n141 \n142     **kwargs\n143         Arbitrary keyword arguments.\n144         See code for details.\n145 \n146     Returns\n147     -------\n148     output : (dc, ac)\n149         Tuple of DC power (with SAPM parameters) (DataFrame) and AC\n150         power (Series).\n151     \"\"\"\n152 \n153     if altitude is None and pressure is None:\n154         altitude = 0.\n155         pressure = 101325.\n156     elif altitude is None:\n157         altitude = atmosphere.pres2alt(pressure)\n158     elif pressure is None:\n159         pressure = atmosphere.alt2pres(altitude)\n160 \n161     solar_position = solarposition.get_solarposition(\n162         times, latitude, longitude, altitude=altitude, pressure=pressure,\n163         method=solar_position_method, **kwargs)\n164 \n165     # possible error with using apparent zenith with some models\n166     airmass = atmosphere.get_relative_airmass(\n167         solar_position['apparent_zenith'], model=airmass_model)\n168     airmass = atmosphere.get_absolute_airmass(airmass, pressure)\n169     dni_extra = pvlib.irradiance.get_extra_radiation(solar_position.index)\n170 \n171     aoi = pvlib.irradiance.aoi(surface_tilt, surface_azimuth,\n172                                solar_position['apparent_zenith'],\n173                                solar_position['azimuth'])\n174 \n175     if irradiance is None:\n176         linke_turbidity = clearsky.lookup_linke_turbidity(\n177             solar_position.index, latitude, longitude)\n178         irradiance = clearsky.ineichen(\n179             solar_position['apparent_zenith'],\n180             airmass,\n181             linke_turbidity,\n182             altitude=altitude,\n183             dni_extra=dni_extra\n184         )\n185 \n186     total_irrad = pvlib.irradiance.get_total_irradiance(\n187         surface_tilt,\n188         surface_azimuth,\n189         solar_position['apparent_zenith'],\n190         solar_position['azimuth'],\n191         irradiance['dni'],\n192         irradiance['ghi'],\n193         irradiance['dhi'],\n194         model=transposition_model,\n195         dni_extra=dni_extra)\n196 \n197     if weather is None:\n198         weather = {'wind_speed': 0, 'temp_air': 20}\n199 \n200     cell_temperature = temperature.sapm_cell(\n201         total_irrad['poa_global'], weather['temp_air'], weather['wind_speed'],\n202         temperature_model_parameters['a'], temperature_model_parameters['b'],\n203         temperature_model_parameters['deltaT'])\n204 \n205     effective_irradiance = pvsystem.sapm_effective_irradiance(\n206         total_irrad['poa_direct'], total_irrad['poa_diffuse'], airmass, aoi,\n207         module_parameters)\n208 \n209     dc = pvsystem.sapm(effective_irradiance, cell_temperature,\n210                        module_parameters)\n211 \n212     ac = inverter.sandia(dc['v_mp'], dc['p_mp'], inverter_parameters)\n213 \n214     return dc, ac\n215 \n216 \n217 def get_orientation(strategy, **kwargs):\n218     \"\"\"\n219     Determine a PV system's surface tilt and surface azimuth\n220     using a named strategy.\n221 \n222     Parameters\n223     ----------\n224     strategy: str\n225         The orientation strategy.\n226         Allowed strategies include 'flat', 'south_at_latitude_tilt'.\n227     **kwargs:\n228         Strategy-dependent keyword arguments. See code for details.\n229 \n230     Returns\n231     -------\n232     surface_tilt, surface_azimuth\n233     \"\"\"\n234 \n235     if strategy == 'south_at_latitude_tilt':\n236         surface_azimuth = 180\n237         surface_tilt = kwargs['latitude']\n238     elif strategy == 'flat':\n239         surface_azimuth = 180\n240         surface_tilt = 0\n241     else:\n242         raise ValueError('invalid orientation strategy. strategy must '\n243                          'be one of south_at_latitude, flat,')\n244 \n245     return surface_tilt, surface_azimuth\n246 \n247 \n248 @dataclass\n249 class ModelChainResult:\n250     _T = TypeVar('T')\n251     PerArray = Union[_T, Tuple[_T, ...]]\n252     \"\"\"Type for fields that vary between arrays\"\"\"\n253 \n254     # these attributes are used in __setattr__ to determine the correct type.\n255     _singleton_tuples: bool = field(default=False)\n256     _per_array_fields = {'total_irrad', 'aoi', 'aoi_modifier',\n257                          'spectral_modifier', 'cell_temperature',\n258                          'effective_irradiance', 'dc', 'diode_params',\n259                          'dc_ohmic_losses', 'weather'}\n260 \n261     # system-level information\n262     solar_position: Optional[pd.DataFrame] = field(default=None)\n263     airmass: Optional[pd.DataFrame] = field(default=None)\n264     ac: Optional[pd.Series] = field(default=None)\n265     tracking: Optional[pd.DataFrame] = field(default=None)\n266 \n267     # per DC array information\n268     total_irrad: Optional[PerArray[pd.DataFrame]] = field(default=None)\n269     aoi: Optional[PerArray[pd.Series]] = field(default=None)\n270     aoi_modifier: Optional[PerArray[Union[pd.Series, float]]] = \\\n271         field(default=None)\n272     spectral_modifier: Optional[PerArray[Union[pd.Series, float]]] = \\\n273         field(default=None)\n274     cell_temperature: Optional[PerArray[pd.Series]] = field(default=None)\n275     effective_irradiance: Optional[PerArray[pd.Series]] = field(default=None)\n276     dc: Optional[PerArray[Union[pd.Series, pd.DataFrame]]] = \\\n277         field(default=None)\n278     diode_params: Optional[PerArray[pd.DataFrame]] = field(default=None)\n279     dc_ohmic_losses: Optional[PerArray[pd.Series]] = field(default=None)\n280 \n281     weather: Optional[PerArray[pd.DataFrame]] = None\n282     times: Optional[pd.DatetimeIndex] = None\n283 \n284     def _result_type(self, value):\n285         \"\"\"Coerce `value` to the correct type according to\n286         ``self._singleton_tuples``.\"\"\"\n287         # Allow None to pass through without being wrapped in a tuple\n288         if (self._singleton_tuples\n289                 and not isinstance(value, tuple)\n290                 and value is not None):\n291             return (value,)\n292         return value\n293 \n294     def __setattr__(self, key, value):\n295         if key in ModelChainResult._per_array_fields:\n296             value = self._result_type(value)\n297         super().__setattr__(key, value)\n298 \n299 \n300 class ModelChain:\n301     \"\"\"\n302     The ModelChain class to provides a standardized, high-level\n303     interface for all of the modeling steps necessary for calculating PV\n304     power from a time series of weather inputs. The same models are applied\n305     to all ``pvsystem.Array`` objects, so each Array must contain the\n306     appropriate model parameters. For example, if ``dc_model='pvwatts'``,\n307     then each ``Array.module_parameters`` must contain ``'pdc0'``.\n308 \n309     See https://pvlib-python.readthedocs.io/en/stable/modelchain.html\n310     for examples.\n311 \n312     Parameters\n313     ----------\n314     system : PVSystem\n315         A :py:class:`~pvlib.pvsystem.PVSystem` object that represents\n316         the connected set of modules, inverters, etc.\n317 \n318     location : Location\n319         A :py:class:`~pvlib.location.Location` object that represents\n320         the physical location at which to evaluate the model.\n321 \n322     clearsky_model : str, default 'ineichen'\n323         Passed to location.get_clearsky.\n324 \n325     transposition_model : str, default 'haydavies'\n326         Passed to system.get_irradiance.\n327 \n328     solar_position_method : str, default 'nrel_numpy'\n329         Passed to location.get_solarposition.\n330 \n331     airmass_model : str, default 'kastenyoung1989'\n332         Passed to location.get_airmass.\n333 \n334     dc_model: None, str, or function, default None\n335         If None, the model will be inferred from the contents of\n336         system.module_parameters. Valid strings are 'sapm',\n337         'desoto', 'cec', 'pvsyst', 'pvwatts'. The ModelChain instance will\n338         be passed as the first argument to a user-defined function.\n339 \n340     ac_model: None, str, or function, default None\n341         If None, the model will be inferred from the contents of\n342         system.inverter_parameters and system.module_parameters. Valid\n343         strings are 'sandia', 'adr', 'pvwatts'. The\n344         ModelChain instance will be passed as the first argument to a\n345         user-defined function.\n346 \n347     aoi_model: None, str, or function, default None\n348         If None, the model will be inferred from the contents of\n349         system.module_parameters. Valid strings are 'physical',\n350         'ashrae', 'sapm', 'martin_ruiz', 'no_loss'. The ModelChain instance\n351         will be passed as the first argument to a user-defined function.\n352 \n353     spectral_model: None, str, or function, default None\n354         If None, the model will be inferred from the contents of\n355         system.module_parameters. Valid strings are 'sapm',\n356         'first_solar', 'no_loss'. The ModelChain instance will be passed\n357         as the first argument to a user-defined function.\n358 \n359     temperature_model: None, str or function, default None\n360         Valid strings are: 'sapm', 'pvsyst', 'faiman', 'fuentes', 'noct_sam'.\n361         The ModelChain instance will be passed as the first argument to a\n362         user-defined function.\n363 \n364     dc_ohmic_model: str or function, default 'no_loss'\n365         Valid strings are 'dc_ohms_from_percent', 'no_loss'. The ModelChain\n366         instance will be passed as the first argument to a user-defined\n367         function.\n368 \n369     losses_model: str or function, default 'no_loss'\n370         Valid strings are 'pvwatts', 'no_loss'. The ModelChain instance\n371         will be passed as the first argument to a user-defined function.\n372 \n373     name: None or str, default None\n374         Name of ModelChain instance.\n375     \"\"\"\n376 \n377     # list of deprecated attributes\n378     _deprecated_attrs = ['solar_position', 'airmass', 'total_irrad',\n379                          'aoi', 'aoi_modifier', 'spectral_modifier',\n380                          'cell_temperature', 'effective_irradiance',\n381                          'dc', 'ac', 'diode_params', 'tracking',\n382                          'weather', 'times']\n383 \n384     def __init__(self, system, location,\n385                  clearsky_model='ineichen',\n386                  transposition_model='haydavies',\n387                  solar_position_method='nrel_numpy',\n388                  airmass_model='kastenyoung1989',\n389                  dc_model=None, ac_model=None, aoi_model=None,\n390                  spectral_model=None, temperature_model=None,\n391                  dc_ohmic_model='no_loss',\n392                  losses_model='no_loss', name=None):\n393 \n394         self.name = name\n395         self.system = system\n396 \n397         self.location = location\n398         self.clearsky_model = clearsky_model\n399         self.transposition_model = transposition_model\n400         self.solar_position_method = solar_position_method\n401         self.airmass_model = airmass_model\n402 \n403         # calls setters\n404         self.dc_model = dc_model\n405         self.ac_model = ac_model\n406         self.aoi_model = aoi_model\n407         self.spectral_model = spectral_model\n408         self.temperature_model = temperature_model\n409 \n410         self.dc_ohmic_model = dc_ohmic_model\n411         self.losses_model = losses_model\n412 \n413         self.results = ModelChainResult()\n414 \n415     def __getattr__(self, key):\n416         if key in ModelChain._deprecated_attrs:\n417             msg = f'ModelChain.{key} is deprecated and will' \\\n418                   f' be removed in v0.10. Use' \\\n419                   f' ModelChain.results.{key} instead'\n420             warnings.warn(msg, pvlibDeprecationWarning)\n421             return getattr(self.results, key)\n422         # __getattr__ is only called if __getattribute__ fails.\n423         # In that case we should check if key is a deprecated attribute,\n424         # and fail with an AttributeError if it is not.\n425         raise AttributeError\n426 \n427     def __setattr__(self, key, value):\n428         if key in ModelChain._deprecated_attrs:\n429             msg = f'ModelChain.{key} is deprecated from v0.9. Use' \\\n430                   f' ModelChain.results.{key} instead'\n431             warnings.warn(msg, pvlibDeprecationWarning)\n432             setattr(self.results, key, value)\n433         else:\n434             super().__setattr__(key, value)\n435 \n436     @classmethod\n437     def with_pvwatts(cls, system, location,\n438                      clearsky_model='ineichen',\n439                      airmass_model='kastenyoung1989',\n440                      name=None,\n441                      **kwargs):\n442         \"\"\"\n443         ModelChain that follows the PVWatts methods.\n444 \n445         Parameters\n446         ----------\n447         system : PVSystem\n448             A :py:class:`~pvlib.pvsystem.PVSystem` object that represents\n449             the connected set of modules, inverters, etc.\n450 \n451         location : Location\n452             A :py:class:`~pvlib.location.Location` object that represents\n453             the physical location at which to evaluate the model.\n454 \n455         clearsky_model : str, default 'ineichen'\n456             Passed to location.get_clearsky.\n457 \n458         airmass_model : str, default 'kastenyoung1989'\n459             Passed to location.get_airmass.\n460 \n461         name: None or str, default None\n462             Name of ModelChain instance.\n463 \n464         **kwargs\n465             Parameters supplied here are passed to the ModelChain\n466             constructor and take precedence over the default\n467             configuration.\n468 \n469         Examples\n470         --------\n471         >>> module_parameters = dict(gamma_pdc=-0.003, pdc0=4500)\n472         >>> inverter_parameters = dict(pac0=4000)\n473         >>> tparams = TEMPERATURE_MODEL_PARAMETERS['sapm']['open_rack_glass_glass']\n474         >>> system = PVSystem(surface_tilt=30, surface_azimuth=180,\n475         ...     module_parameters=module_parameters,\n476         ...     inverter_parameters=inverter_parameters,\n477         ...     temperature_model_parameters=tparams)\n478         >>> location = Location(32.2, -110.9)\n479         >>> ModelChain.with_pvwatts(system, location)\n480         ModelChain:\n481           name: None\n482           clearsky_model: ineichen\n483           transposition_model: perez\n484           solar_position_method: nrel_numpy\n485           airmass_model: kastenyoung1989\n486           dc_model: pvwatts_dc\n487           ac_model: pvwatts_inverter\n488           aoi_model: physical_aoi_loss\n489           spectral_model: no_spectral_loss\n490           temperature_model: sapm_temp\n491           losses_model: pvwatts_losses\n492         \"\"\"  # noqa: E501\n493         config = PVWATTS_CONFIG.copy()\n494         config.update(kwargs)\n495         return ModelChain(\n496             system, location,\n497             clearsky_model=clearsky_model,\n498             airmass_model=airmass_model,\n499             name=name,\n500             **config\n501         )\n502 \n503     @classmethod\n504     def with_sapm(cls, system, location,\n505                   clearsky_model='ineichen',\n506                   transposition_model='haydavies',\n507                   solar_position_method='nrel_numpy',\n508                   airmass_model='kastenyoung1989',\n509                   name=None,\n510                   **kwargs):\n511         \"\"\"\n512         ModelChain that follows the Sandia Array Performance Model\n513         (SAPM) methods.\n514 \n515         Parameters\n516         ----------\n517         system : PVSystem\n518             A :py:class:`~pvlib.pvsystem.PVSystem` object that represents\n519             the connected set of modules, inverters, etc.\n520 \n521         location : Location\n522             A :py:class:`~pvlib.location.Location` object that represents\n523             the physical location at which to evaluate the model.\n524 \n525         clearsky_model : str, default 'ineichen'\n526             Passed to location.get_clearsky.\n527 \n528         transposition_model : str, default 'haydavies'\n529             Passed to system.get_irradiance.\n530 \n531         solar_position_method : str, default 'nrel_numpy'\n532             Passed to location.get_solarposition.\n533 \n534         airmass_model : str, default 'kastenyoung1989'\n535             Passed to location.get_airmass.\n536 \n537         name: None or str, default None\n538             Name of ModelChain instance.\n539 \n540         **kwargs\n541             Parameters supplied here are passed to the ModelChain\n542             constructor and take precedence over the default\n543             configuration.\n544 \n545         Examples\n546         --------\n547         >>> mods = pvlib.pvsystem.retrieve_sam('sandiamod')\n548         >>> invs = pvlib.pvsystem.retrieve_sam('cecinverter')\n549         >>> module_parameters = mods['Canadian_Solar_CS5P_220M___2009_']\n550         >>> inverter_parameters = invs['ABB__MICRO_0_25_I_OUTD_US_240__240V_']\n551         >>> tparams = TEMPERATURE_MODEL_PARAMETERS['sapm']['open_rack_glass_glass']\n552         >>> system = PVSystem(surface_tilt=30, surface_azimuth=180,\n553         ...     module_parameters=module_parameters,\n554         ...     inverter_parameters=inverter_parameters,\n555         ...     temperature_model_parameters=tparams)\n556         >>> location = Location(32.2, -110.9)\n557         >>> ModelChain.with_sapm(system, location)\n558         ModelChain:\n559           name: None\n560           clearsky_model: ineichen\n561           transposition_model: haydavies\n562           solar_position_method: nrel_numpy\n563           airmass_model: kastenyoung1989\n564           dc_model: sapm\n565           ac_model: snlinverter\n566           aoi_model: sapm_aoi_loss\n567           spectral_model: sapm_spectral_loss\n568           temperature_model: sapm_temp\n569           losses_model: no_extra_losses\n570         \"\"\"  # noqa: E501\n571         config = SAPM_CONFIG.copy()\n572         config.update(kwargs)\n573         return ModelChain(\n574             system, location,\n575             clearsky_model=clearsky_model,\n576             transposition_model=transposition_model,\n577             solar_position_method=solar_position_method,\n578             airmass_model=airmass_model,\n579             name=name,\n580             **config\n581         )\n582 \n583     def __repr__(self):\n584         attrs = [\n585             'name', 'clearsky_model',\n586             'transposition_model', 'solar_position_method',\n587             'airmass_model', 'dc_model', 'ac_model', 'aoi_model',\n588             'spectral_model', 'temperature_model', 'losses_model'\n589         ]\n590 \n591         def getmcattr(self, attr):\n592             \"\"\"needed to avoid recursion in property lookups\"\"\"\n593             out = getattr(self, attr)\n594             try:\n595                 out = out.__name__\n596             except AttributeError:\n597                 pass\n598             return out\n599 \n600         return ('ModelChain: \\n  ' + '\\n  '.join(\n601             f'{attr}: {getmcattr(self, attr)}' for attr in attrs))\n602 \n603     @property\n604     def dc_model(self):\n605         return self._dc_model\n606 \n607     @dc_model.setter\n608     def dc_model(self, model):\n609         # guess at model if None\n610         if model is None:\n611             self._dc_model, model = self.infer_dc_model()\n612 \n613         # Set model and validate parameters\n614         if isinstance(model, str):\n615             model = model.lower()\n616             if model in _DC_MODEL_PARAMS.keys():\n617                 # validate module parameters\n618                 missing_params = (\n619                     _DC_MODEL_PARAMS[model] -\n620                     _common_keys(self.system.module_parameters))\n621                 if missing_params:  # some parameters are not in module.keys()\n622                     raise ValueError(model + ' selected for the DC model but '\n623                                      'one or more Arrays are missing '\n624                                      'one or more required parameters '\n625                                      ' : ' + str(missing_params))\n626                 if model == 'sapm':\n627                     self._dc_model = self.sapm\n628                 elif model == 'desoto':\n629                     self._dc_model = self.desoto\n630                 elif model == 'cec':\n631                     self._dc_model = self.cec\n632                 elif model == 'pvsyst':\n633                     self._dc_model = self.pvsyst\n634                 elif model == 'pvwatts':\n635                     self._dc_model = self.pvwatts_dc\n636             else:\n637                 raise ValueError(model + ' is not a valid DC power model')\n638         else:\n639             self._dc_model = partial(model, self)\n640 \n641     def infer_dc_model(self):\n642         \"\"\"Infer DC power model from Array module parameters.\"\"\"\n643         params = _common_keys(self.system.module_parameters)\n644         if {'A0', 'A1', 'C7'} <= params:\n645             return self.sapm, 'sapm'\n646         elif {'a_ref', 'I_L_ref', 'I_o_ref', 'R_sh_ref', 'R_s',\n647               'Adjust'} <= params:\n648             return self.cec, 'cec'\n649         elif {'a_ref', 'I_L_ref', 'I_o_ref', 'R_sh_ref', 'R_s'} <= params:\n650             return self.desoto, 'desoto'\n651         elif {'gamma_ref', 'mu_gamma', 'I_L_ref', 'I_o_ref', 'R_sh_ref',\n652               'R_sh_0', 'R_sh_exp', 'R_s'} <= params:\n653             return self.pvsyst, 'pvsyst'\n654         elif {'pdc0', 'gamma_pdc'} <= params:\n655             return self.pvwatts_dc, 'pvwatts'\n656         else:\n657             raise ValueError('could not infer DC model from '\n658                              'system.module_parameters. Check '\n659                              'system.module_parameters or explicitly '\n660                              'set the model with the dc_model kwarg.')\n661 \n662     def sapm(self):\n663         dc = self.system.sapm(self.results.effective_irradiance,\n664                               self.results.cell_temperature)\n665         self.results.dc = self.system.scale_voltage_current_power(dc)\n666         return self\n667 \n668     def _singlediode(self, calcparams_model_function):\n669         def _make_diode_params(photocurrent, saturation_current,\n670                                resistance_series, resistance_shunt,\n671                                nNsVth):\n672             return pd.DataFrame(\n673                 {'I_L': photocurrent, 'I_o': saturation_current,\n674                  'R_s': resistance_series, 'R_sh': resistance_shunt,\n675                  'nNsVth': nNsVth}\n676             )\n677         params = calcparams_model_function(self.results.effective_irradiance,\n678                                            self.results.cell_temperature,\n679                                            unwrap=False)\n680         self.results.diode_params = tuple(itertools.starmap(\n681             _make_diode_params, params))\n682         self.results.dc = tuple(itertools.starmap(\n683             self.system.singlediode, params))\n684         self.results.dc = self.system.scale_voltage_current_power(\n685             self.results.dc,\n686             unwrap=False\n687         )\n688         self.results.dc = tuple(dc.fillna(0) for dc in self.results.dc)\n689         # If the system has one Array, unwrap the single return value\n690         # to preserve the original behavior of ModelChain\n691         if self.system.num_arrays == 1:\n692             self.results.diode_params = self.results.diode_params[0]\n693             self.results.dc = self.results.dc[0]\n694         return self\n695 \n696     def desoto(self):\n697         return self._singlediode(self.system.calcparams_desoto)\n698 \n699     def cec(self):\n700         return self._singlediode(self.system.calcparams_cec)\n701 \n702     def pvsyst(self):\n703         return self._singlediode(self.system.calcparams_pvsyst)\n704 \n705     def pvwatts_dc(self):\n706         \"\"\"Calculate DC power using the PVWatts model.\n707 \n708         Results are stored in ModelChain.results.dc. DC power is computed\n709         from PVSystem.module_parameters['pdc0'] and then scaled by\n710         PVSystem.modules_per_string and PVSystem.strings_per_inverter.\n711 \n712         Returns\n713         -------\n714         self\n715 \n716         See also\n717         --------\n718         pvlib.pvsystem.PVSystem.pvwatts_dc\n719         pvlib.pvsystem.PVSystem.scale_voltage_current_power\n720         \"\"\"\n721         dc = self.system.pvwatts_dc(\n722             self.results.effective_irradiance,\n723             self.results.cell_temperature,\n724             unwrap=False\n725         )\n726         p_mp = tuple(pd.DataFrame(s, columns=['p_mp']) for s in dc)\n727         scaled = self.system.scale_voltage_current_power(p_mp)\n728         self.results.dc = _tuple_from_dfs(scaled, \"p_mp\")\n729         return self\n730 \n731     @property\n732     def ac_model(self):\n733         return self._ac_model\n734 \n735     @ac_model.setter\n736     def ac_model(self, model):\n737         if model is None:\n738             self._ac_model = self.infer_ac_model()\n739         elif isinstance(model, str):\n740             model = model.lower()\n741             if model == 'sandia':\n742                 self._ac_model = self.sandia_inverter\n743             elif model in 'adr':\n744                 self._ac_model = self.adr_inverter\n745             elif model == 'pvwatts':\n746                 self._ac_model = self.pvwatts_inverter\n747             else:\n748                 raise ValueError(model + ' is not a valid AC power model')\n749         else:\n750             self._ac_model = partial(model, self)\n751 \n752     def infer_ac_model(self):\n753         \"\"\"Infer AC power model from system attributes.\"\"\"\n754         inverter_params = set(self.system.inverter_parameters.keys())\n755         if _snl_params(inverter_params):\n756             return self.sandia_inverter\n757         if _adr_params(inverter_params):\n758             if self.system.num_arrays > 1:\n759                 raise ValueError(\n760                     'The adr inverter function cannot be used for an inverter',\n761                     ' with multiple MPPT inputs')\n762             else:\n763                 return self.adr_inverter\n764         if _pvwatts_params(inverter_params):\n765             return self.pvwatts_inverter\n766         raise ValueError('could not infer AC model from '\n767                          'system.inverter_parameters. Check '\n768                          'system.inverter_parameters or explicitly '\n769                          'set the model with the ac_model kwarg.')\n770 \n771     def sandia_inverter(self):\n772         self.results.ac = self.system.get_ac(\n773             'sandia',\n774             _tuple_from_dfs(self.results.dc, 'p_mp'),\n775             v_dc=_tuple_from_dfs(self.results.dc, 'v_mp')\n776         )\n777         return self\n778 \n779     def adr_inverter(self):\n780         self.results.ac = self.system.get_ac(\n781             'adr',\n782             self.results.dc['p_mp'],\n783             v_dc=self.results.dc['v_mp']\n784         )\n785         return self\n786 \n787     def pvwatts_inverter(self):\n788         ac = self.system.get_ac('pvwatts', self.results.dc)\n789         self.results.ac = ac.fillna(0)\n790         return self\n791 \n792     @property\n793     def aoi_model(self):\n794         return self._aoi_model\n795 \n796     @aoi_model.setter\n797     def aoi_model(self, model):\n798         if model is None:\n799             self._aoi_model = self.infer_aoi_model()\n800         elif isinstance(model, str):\n801             model = model.lower()\n802             if model == 'ashrae':\n803                 self._aoi_model = self.ashrae_aoi_loss\n804             elif model == 'physical':\n805                 self._aoi_model = self.physical_aoi_loss\n806             elif model == 'sapm':\n807                 self._aoi_model = self.sapm_aoi_loss\n808             elif model == 'martin_ruiz':\n809                 self._aoi_model = self.martin_ruiz_aoi_loss\n810             elif model == 'no_loss':\n811                 self._aoi_model = self.no_aoi_loss\n812             else:\n813                 raise ValueError(model + ' is not a valid aoi loss model')\n814         else:\n815             self._aoi_model = partial(model, self)\n816 \n817     def infer_aoi_model(self):\n818         params = _common_keys(self.system.module_parameters)\n819         if {'K', 'L', 'n'} <= params:\n820             return self.physical_aoi_loss\n821         elif {'B5', 'B4', 'B3', 'B2', 'B1', 'B0'} <= params:\n822             return self.sapm_aoi_loss\n823         elif {'b'} <= params:\n824             return self.ashrae_aoi_loss\n825         elif {'a_r'} <= params:\n826             return self.martin_ruiz_aoi_loss\n827         else:\n828             raise ValueError('could not infer AOI model from '\n829                              'system.module_parameters. Check that the '\n830                              'module_parameters for all Arrays in '\n831                              'system.arrays contain parameters for '\n832                              'the physical, aoi, ashrae or martin_ruiz model; '\n833                              'explicitly set the model with the aoi_model '\n834                              'kwarg; or set aoi_model=\"no_loss\".')\n835 \n836     def ashrae_aoi_loss(self):\n837         self.results.aoi_modifier = self.system.get_iam(\n838             self.results.aoi,\n839             iam_model='ashrae'\n840         )\n841         return self\n842 \n843     def physical_aoi_loss(self):\n844         self.results.aoi_modifier = self.system.get_iam(\n845             self.results.aoi,\n846             iam_model='physical'\n847         )\n848         return self\n849 \n850     def sapm_aoi_loss(self):\n851         self.results.aoi_modifier = self.system.get_iam(\n852             self.results.aoi,\n853             iam_model='sapm'\n854         )\n855         return self\n856 \n857     def martin_ruiz_aoi_loss(self):\n858         self.results.aoi_modifier = self.system.get_iam(\n859             self.results.aoi, iam_model='martin_ruiz'\n860         )\n861         return self\n862 \n863     def no_aoi_loss(self):\n864         if self.system.num_arrays == 1:\n865             self.results.aoi_modifier = 1.0\n866         else:\n867             self.results.aoi_modifier = (1.0,) * self.system.num_arrays\n868         return self\n869 \n870     @property\n871     def spectral_model(self):\n872         return self._spectral_model\n873 \n874     @spectral_model.setter\n875     def spectral_model(self, model):\n876         if model is None:\n877             self._spectral_model = self.infer_spectral_model()\n878         elif isinstance(model, str):\n879             model = model.lower()\n880             if model == 'first_solar':\n881                 self._spectral_model = self.first_solar_spectral_loss\n882             elif model == 'sapm':\n883                 self._spectral_model = self.sapm_spectral_loss\n884             elif model == 'no_loss':\n885                 self._spectral_model = self.no_spectral_loss\n886             else:\n887                 raise ValueError(model + ' is not a valid spectral loss model')\n888         else:\n889             self._spectral_model = partial(model, self)\n890 \n891     def infer_spectral_model(self):\n892         \"\"\"Infer spectral model from system attributes.\"\"\"\n893         params = _common_keys(self.system.module_parameters)\n894         if {'A4', 'A3', 'A2', 'A1', 'A0'} <= params:\n895             return self.sapm_spectral_loss\n896         elif ((('Technology' in params or\n897                 'Material' in params) and\n898                (self.system._infer_cell_type() is not None)) or\n899               'first_solar_spectral_coefficients' in params):\n900             return self.first_solar_spectral_loss\n901         else:\n902             raise ValueError('could not infer spectral model from '\n903                              'system.module_parameters. Check that the '\n904                              'module_parameters for all Arrays in '\n905                              'system.arrays contain valid '\n906                              'first_solar_spectral_coefficients, a valid '\n907                              'Material or Technology value, or set '\n908                              'spectral_model=\"no_loss\".')\n909 \n910     def first_solar_spectral_loss(self):\n911         self.results.spectral_modifier = self.system.first_solar_spectral_loss(\n912             _tuple_from_dfs(self.results.weather, 'precipitable_water'),\n913             self.results.airmass['airmass_absolute']\n914         )\n915         return self\n916 \n917     def sapm_spectral_loss(self):\n918         self.results.spectral_modifier = self.system.sapm_spectral_loss(\n919             self.results.airmass['airmass_absolute']\n920         )\n921         return self\n922 \n923     def no_spectral_loss(self):\n924         if self.system.num_arrays == 1:\n925             self.results.spectral_modifier = 1\n926         else:\n927             self.results.spectral_modifier = (1,) * self.system.num_arrays\n928         return self\n929 \n930     @property\n931     def temperature_model(self):\n932         return self._temperature_model\n933 \n934     @temperature_model.setter\n935     def temperature_model(self, model):\n936         if model is None:\n937             self._temperature_model = self.infer_temperature_model()\n938         elif isinstance(model, str):\n939             model = model.lower()\n940             if model == 'sapm':\n941                 self._temperature_model = self.sapm_temp\n942             elif model == 'pvsyst':\n943                 self._temperature_model = self.pvsyst_temp\n944             elif model == 'faiman':\n945                 self._temperature_model = self.faiman_temp\n946             elif model == 'fuentes':\n947                 self._temperature_model = self.fuentes_temp\n948             elif model == 'noct_sam':\n949                 self._temperature_model = self.noct_sam_temp\n950             else:\n951                 raise ValueError(model + ' is not a valid temperature model')\n952             # check system.temperature_model_parameters for consistency\n953             name_from_params = self.infer_temperature_model().__name__\n954             if self._temperature_model.__name__ != name_from_params:\n955                 raise ValueError(\n956                     f'Temperature model {self._temperature_model.__name__} is '\n957                     f'inconsistent with PVSystem temperature model '\n958                     f'parameters. All Arrays in system.arrays must have '\n959                     f'consistent parameters. Common temperature model '\n960                     f'parameters: '\n961                     f'{_common_keys(self.system.temperature_model_parameters)}'\n962                 )\n963         else:\n964             self._temperature_model = partial(model, self)\n965 \n966     def infer_temperature_model(self):\n967         \"\"\"Infer temperature model from system attributes.\"\"\"\n968         params = _common_keys(self.system.temperature_model_parameters)\n969         # remove or statement in v0.9\n970         if {'a', 'b', 'deltaT'} <= params or (\n971                 not params and self.system.racking_model is None\n972                 and self.system.module_type is None):\n973             return self.sapm_temp\n974         elif {'u_c', 'u_v'} <= params:\n975             return self.pvsyst_temp\n976         elif {'u0', 'u1'} <= params:\n977             return self.faiman_temp\n978         elif {'noct_installed'} <= params:\n979             return self.fuentes_temp\n980         elif {'noct', 'eta_m_ref'} <= params:\n981             return self.noct_sam_temp\n982         else:\n983             raise ValueError(f'could not infer temperature model from '\n984                              f'system.temperature_model_parameters. Check '\n985                              f'that all Arrays in system.arrays have '\n986                              f'parameters for the same temperature model. '\n987                              f'Common temperature model parameters: {params}.')\n988 \n989     def _set_celltemp(self, model):\n990         \"\"\"Set self.results.cell_temperature using the given cell\n991         temperature model.\n992 \n993         Parameters\n994         ----------\n995         model : function\n996             A function that takes POA irradiance, air temperature, and\n997             wind speed and returns cell temperature. `model` must accept\n998             tuples or single values for each parameter where each element of\n999             the tuple is the value for a different array in the system\n1000             (see :py:class:`pvlib.pvsystem.PVSystem` for more information).\n1001 \n1002         Returns\n1003         -------\n1004         self\n1005         \"\"\"\n1006 \n1007         poa = _irrad_for_celltemp(self.results.total_irrad,\n1008                                   self.results.effective_irradiance)\n1009         temp_air = _tuple_from_dfs(self.results.weather, 'temp_air')\n1010         wind_speed = _tuple_from_dfs(self.results.weather, 'wind_speed')\n1011         kwargs = {}\n1012         if model == self.system.noct_sam_celltemp:\n1013             kwargs['effective_irradiance'] = self.results.effective_irradiance\n1014         self.results.cell_temperature = model(poa, temp_air, wind_speed,\n1015                                               **kwargs)\n1016         return self\n1017 \n1018     def sapm_temp(self):\n1019         return self._set_celltemp(self.system.sapm_celltemp)\n1020 \n1021     def pvsyst_temp(self):\n1022         return self._set_celltemp(self.system.pvsyst_celltemp)\n1023 \n1024     def faiman_temp(self):\n1025         return self._set_celltemp(self.system.faiman_celltemp)\n1026 \n1027     def fuentes_temp(self):\n1028         return self._set_celltemp(self.system.fuentes_celltemp)\n1029 \n1030     def noct_sam_temp(self):\n1031         return self._set_celltemp(self.system.noct_sam_celltemp)\n1032 \n1033     @property\n1034     def dc_ohmic_model(self):\n1035         return self._dc_ohmic_model\n1036 \n1037     @dc_ohmic_model.setter\n1038     def dc_ohmic_model(self, model):\n1039         if isinstance(model, str):\n1040             model = model.lower()\n1041             if model == 'dc_ohms_from_percent':\n1042                 self._dc_ohmic_model = self.dc_ohms_from_percent\n1043             elif model == 'no_loss':\n1044                 self._dc_ohmic_model = self.no_dc_ohmic_loss\n1045             else:\n1046                 raise ValueError(model + ' is not a valid losses model')\n1047         else:\n1048             self._dc_ohmic_model = partial(model, self)\n1049 \n1050     def dc_ohms_from_percent(self):\n1051         \"\"\"\n1052         Calculate time series of ohmic losses and apply those to the mpp power\n1053         output of the `dc_model` based on the pvsyst equivalent resistance\n1054         method. Uses a `dc_ohmic_percent` parameter in the `losses_parameters`\n1055         of the PVsystem.\n1056         \"\"\"\n1057         Rw = self.system.dc_ohms_from_percent()\n1058         if isinstance(self.results.dc, tuple):\n1059             self.results.dc_ohmic_losses = tuple(\n1060                 pvsystem.dc_ohmic_losses(Rw, df['i_mp'])\n1061                 for Rw, df in zip(Rw, self.results.dc)\n1062             )\n1063             for df, loss in zip(self.results.dc, self.results.dc_ohmic_losses):\n1064                 df['p_mp'] = df['p_mp'] - loss\n1065         else:\n1066             self.results.dc_ohmic_losses = pvsystem.dc_ohmic_losses(\n1067                 Rw, self.results.dc['i_mp']\n1068             )\n1069             self.results.dc['p_mp'] = (self.results.dc['p_mp']\n1070                                        - self.results.dc_ohmic_losses)\n1071         return self\n1072 \n1073     def no_dc_ohmic_loss(self):\n1074         return self\n1075 \n1076     @property\n1077     def losses_model(self):\n1078         return self._losses_model\n1079 \n1080     @losses_model.setter\n1081     def losses_model(self, model):\n1082         if model is None:\n1083             self._losses_model = self.infer_losses_model()\n1084         elif isinstance(model, str):\n1085             model = model.lower()\n1086             if model == 'pvwatts':\n1087                 self._losses_model = self.pvwatts_losses\n1088             elif model == 'no_loss':\n1089                 self._losses_model = self.no_extra_losses\n1090             else:\n1091                 raise ValueError(model + ' is not a valid losses model')\n1092         else:\n1093             self._losses_model = partial(model, self)\n1094 \n1095     def infer_losses_model(self):\n1096         raise NotImplementedError\n1097 \n1098     def pvwatts_losses(self):\n1099         self.losses = (100 - self.system.pvwatts_losses()) / 100.\n1100         if isinstance(self.results.dc, tuple):\n1101             for dc in self.results.dc:\n1102                 dc *= self.losses\n1103         else:\n1104             self.results.dc *= self.losses\n1105         return self\n1106 \n1107     def no_extra_losses(self):\n1108         self.losses = 1\n1109         return self\n1110 \n1111     def effective_irradiance_model(self):\n1112         def _eff_irrad(module_parameters, total_irrad, spect_mod, aoi_mod):\n1113             fd = module_parameters.get('FD', 1.)\n1114             return spect_mod * (total_irrad['poa_direct'] * aoi_mod +\n1115                                 fd * total_irrad['poa_diffuse'])\n1116         if isinstance(self.results.total_irrad, tuple):\n1117             self.results.effective_irradiance = tuple(\n1118                 _eff_irrad(array.module_parameters, ti, sm, am) for\n1119                 array, ti, sm, am in zip(\n1120                     self.system.arrays, self.results.total_irrad,\n1121                     self.results.spectral_modifier, self.results.aoi_modifier))\n1122         else:\n1123             self.results.effective_irradiance = _eff_irrad(\n1124                 self.system.module_parameters,\n1125                 self.results.total_irrad,\n1126                 self.results.spectral_modifier,\n1127                 self.results.aoi_modifier\n1128             )\n1129         return self\n1130 \n1131     def complete_irradiance(self, weather):\n1132         \"\"\"\n1133         Determine the missing irradiation columns. Only two of the\n1134         following data columns (dni, ghi, dhi) are needed to calculate\n1135         the missing data.\n1136 \n1137         This function is not safe at the moment. Results can be too high\n1138         or negative. Please contribute and help to improve this function\n1139         on https://github.com/pvlib/pvlib-python\n1140 \n1141         Parameters\n1142         ----------\n1143         weather : DataFrame, or tuple or list of DataFrame\n1144             Column names must be ``'dni'``, ``'ghi'``, ``'dhi'``,\n1145             ``'wind_speed'``, ``'temp_air'``. All irradiance components\n1146             are required. Air temperature of 20 C and wind speed\n1147             of 0 m/s will be added to the DataFrame if not provided.\n1148             If `weather` is a tuple it must be the same length as the number\n1149             of Arrays in the system and the indices for each DataFrame must\n1150             be the same.\n1151 \n1152         Returns\n1153         -------\n1154         self\n1155 \n1156         Raises\n1157         ------\n1158         ValueError\n1159             if the number of dataframes in `weather` is not the same as the\n1160             number of Arrays in the system or if the indices of all elements\n1161             of `weather` are not the same.\n1162 \n1163         Notes\n1164         -----\n1165         Assigns attributes to ``results``: ``times``, ``weather``\n1166 \n1167         Examples\n1168         --------\n1169         This example does not work until the parameters `my_system`,\n1170         `my_location`, and `my_weather` are defined but shows the basic idea\n1171         how this method can be used.\n1172 \n1173         >>> from pvlib.modelchain import ModelChain\n1174 \n1175         >>> # my_weather containing 'dhi' and 'ghi'.\n1176         >>> mc = ModelChain(my_system, my_location)  # doctest: +SKIP\n1177         >>> mc.complete_irradiance(my_weather)  # doctest: +SKIP\n1178         >>> mc.run_model(mc.results.weather)  # doctest: +SKIP\n1179 \n1180         >>> # my_weather containing 'dhi', 'ghi' and 'dni'.\n1181         >>> mc = ModelChain(my_system, my_location)  # doctest: +SKIP\n1182         >>> mc.run_model(my_weather)  # doctest: +SKIP\n1183         \"\"\"\n1184         weather = _to_tuple(weather)\n1185         self._check_multiple_input(weather)\n1186         # Don't use ModelChain._assign_weather() here because it adds\n1187         # temperature and wind-speed columns which we do not need here.\n1188         self.results.weather = _copy(weather)\n1189         self._assign_times()\n1190         self.results.solar_position = self.location.get_solarposition(\n1191             self.results.times, method=self.solar_position_method)\n1192 \n1193         if isinstance(weather, tuple):\n1194             for w in self.results.weather:\n1195                 self._complete_irradiance(w)\n1196         else:\n1197             self._complete_irradiance(self.results.weather)\n1198 \n1199         return self\n1200 \n1201     def _complete_irradiance(self, weather):\n1202         icolumns = set(weather.columns)\n1203         wrn_txt = (\"This function is not safe at the moment.\\n\" +\n1204                    \"Results can be too high or negative.\\n\" +\n1205                    \"Help to improve this function on github:\\n\" +\n1206                    \"https://github.com/pvlib/pvlib-python \\n\")\n1207 \n1208         if {'ghi', 'dhi'} <= icolumns and 'dni' not in icolumns:\n1209             clearsky = self.location.get_clearsky(\n1210                 weather.index, solar_position=self.results.solar_position)\n1211             weather.loc[:, 'dni'] = pvlib.irradiance.dni(\n1212                 weather.loc[:, 'ghi'], weather.loc[:, 'dhi'],\n1213                 self.results.solar_position.zenith,\n1214                 clearsky_dni=clearsky['dni'],\n1215                 clearsky_tolerance=1.1)\n1216         elif {'dni', 'dhi'} <= icolumns and 'ghi' not in icolumns:\n1217             warnings.warn(wrn_txt, UserWarning)\n1218             weather.loc[:, 'ghi'] = (\n1219                 weather.dhi + weather.dni *\n1220                 tools.cosd(self.results.solar_position.zenith)\n1221             )\n1222         elif {'dni', 'ghi'} <= icolumns and 'dhi' not in icolumns:\n1223             warnings.warn(wrn_txt, UserWarning)\n1224             weather.loc[:, 'dhi'] = (\n1225                 weather.ghi - weather.dni *\n1226                 tools.cosd(self.results.solar_position.zenith))\n1227 \n1228     def _prep_inputs_solar_pos(self, weather):\n1229         \"\"\"\n1230         Assign solar position\n1231         \"\"\"\n1232         # build weather kwargs for solar position calculation\n1233         kwargs = _build_kwargs(['pressure', 'temp_air'],\n1234                                weather[0] if isinstance(weather, tuple)\n1235                                else weather)\n1236         try:\n1237             kwargs['temperature'] = kwargs.pop('temp_air')\n1238         except KeyError:\n1239             pass\n1240 \n1241         self.results.solar_position = self.location.get_solarposition(\n1242             self.results.times, method=self.solar_position_method,\n1243             **kwargs)\n1244         return self\n1245 \n1246     def _prep_inputs_airmass(self):\n1247         \"\"\"\n1248         Assign airmass\n1249         \"\"\"\n1250         self.results.airmass = self.location.get_airmass(\n1251             solar_position=self.results.solar_position,\n1252             model=self.airmass_model)\n1253         return self\n1254 \n1255     def _prep_inputs_tracking(self):\n1256         \"\"\"\n1257         Calculate tracker position and AOI\n1258         \"\"\"\n1259         self.results.tracking = self.system.singleaxis(\n1260             self.results.solar_position['apparent_zenith'],\n1261             self.results.solar_position['azimuth'])\n1262         self.results.tracking['surface_tilt'] = (\n1263             self.results.tracking['surface_tilt']\n1264                 .fillna(self.system.axis_tilt))\n1265         self.results.tracking['surface_azimuth'] = (\n1266             self.results.tracking['surface_azimuth']\n1267                 .fillna(self.system.axis_azimuth))\n1268         self.results.aoi = self.results.tracking['aoi']\n1269         return self\n1270 \n1271     def _prep_inputs_fixed(self):\n1272         \"\"\"\n1273         Calculate AOI for fixed tilt system\n1274         \"\"\"\n1275         self.results.aoi = self.system.get_aoi(\n1276             self.results.solar_position['apparent_zenith'],\n1277             self.results.solar_position['azimuth'])\n1278         return self\n1279 \n1280     def _verify_df(self, data, required):\n1281         \"\"\" Checks data for column names in required\n1282 \n1283         Parameters\n1284         ----------\n1285         data : Dataframe\n1286         required : List of str\n1287 \n1288         Raises\n1289         ------\n1290         ValueError if any of required are not in data.columns.\n1291         \"\"\"\n1292         def _verify(data, index=None):\n1293             if not set(required) <= set(data.columns):\n1294                 tuple_txt = \"\" if index is None else f\"in element {index} \"\n1295                 raise ValueError(\n1296                     \"Incomplete input data. Data needs to contain \"\n1297                     f\"{required}. Detected data {tuple_txt}contains: \"\n1298                     f\"{list(data.columns)}\")\n1299         if not isinstance(data, tuple):\n1300             _verify(data)\n1301         else:\n1302             for (i, array_data) in enumerate(data):\n1303                 _verify(array_data, i)\n1304 \n1305     def _configure_results(self, per_array_data):\n1306         \"\"\"Configure the type used for per-array fields in\n1307         ModelChainResult.\n1308 \n1309         If ``per_array_data`` is True and the number of arrays in the\n1310         system is 1, then per-array results are stored as length-1\n1311         tuples. This overrides the PVSystem defaults of unpacking a 1\n1312         length tuple into a singleton.\n1313 \n1314         Parameters\n1315         ----------\n1316         per_array_data : bool\n1317             If input data is provided for each array, pass True. If a\n1318             single input data is provided for all arrays, pass False.\n1319         \"\"\"\n1320         self.results._singleton_tuples = (\n1321             self.system.num_arrays == 1 and per_array_data\n1322         )\n1323 \n1324     def _assign_weather(self, data):\n1325         def _build_weather(data):\n1326             key_list = [k for k in WEATHER_KEYS if k in data]\n1327             weather = data[key_list].copy()\n1328             if weather.get('wind_speed') is None:\n1329                 weather['wind_speed'] = 0\n1330             if weather.get('temp_air') is None:\n1331                 weather['temp_air'] = 20\n1332             return weather\n1333         if isinstance(data, tuple):\n1334             weather = tuple(_build_weather(wx) for wx in data)\n1335             self._configure_results(per_array_data=True)\n1336         else:\n1337             weather = _build_weather(data)\n1338             self._configure_results(per_array_data=False)\n1339         self.results.weather = weather\n1340         self._assign_times()\n1341         return self\n1342 \n1343     def _assign_total_irrad(self, data):\n1344         def _build_irrad(data):\n1345             key_list = [k for k in POA_KEYS if k in data]\n1346             return data[key_list].copy()\n1347         if isinstance(data, tuple):\n1348             self.results.total_irrad = tuple(\n1349                 _build_irrad(irrad_data) for irrad_data in data\n1350             )\n1351             return self\n1352         self.results.total_irrad = _build_irrad(data)\n1353         return self\n1354 \n1355     def _assign_times(self):\n1356         \"\"\"Assign self.results.times according the the index of\n1357         self.results.weather.\n1358 \n1359         If there are multiple DataFrames in self.results.weather then\n1360         the index of the first one is assigned. It is assumed that the\n1361         indices of each DataFrame in self.results.weather are the same.\n1362         This can be verified by calling :py:func:`_all_same_index` or\n1363         :py:meth:`self._check_multiple_weather` before calling this\n1364         method.\n1365         \"\"\"\n1366         if isinstance(self.results.weather, tuple):\n1367             self.results.times = self.results.weather[0].index\n1368         else:\n1369             self.results.times = self.results.weather.index\n1370 \n1371     def prepare_inputs(self, weather):\n1372         \"\"\"\n1373         Prepare the solar position, irradiance, and weather inputs to\n1374         the model, starting with GHI, DNI and DHI.\n1375 \n1376         Parameters\n1377         ----------\n1378         weather : DataFrame, or tuple or list of DataFrame\n1379             Required column names include ``'dni'``, ``'ghi'``, ``'dhi'``.\n1380             Optional column names are ``'wind_speed'``, ``'temp_air'``; if not\n1381             provided, air temperature of 20 C and wind speed\n1382             of 0 m/s will be added to the DataFrame.\n1383 \n1384             If `weather` is a tuple or list, it must be of the same length and\n1385             order as the Arrays of the ModelChain's PVSystem.\n1386 \n1387         Raises\n1388         ------\n1389         ValueError\n1390             If any `weather` DataFrame(s) is missing an irradiance component.\n1391         ValueError\n1392             If `weather` is a tuple or list and the DataFrames it contains have\n1393             different indices.\n1394         ValueError\n1395             If `weather` is a tuple or list with a different length than the\n1396             number of Arrays in the system.\n1397 \n1398         Notes\n1399         -----\n1400         Assigns attributes to ``results``: ``times``, ``weather``,\n1401         ``solar_position``, ``airmass``, ``total_irrad``, ``aoi``\n1402 \n1403         See also\n1404         --------\n1405         ModelChain.complete_irradiance\n1406         \"\"\"\n1407         weather = _to_tuple(weather)\n1408         self._check_multiple_input(weather, strict=False)\n1409         self._verify_df(weather, required=['ghi', 'dni', 'dhi'])\n1410         self._assign_weather(weather)\n1411 \n1412         self._prep_inputs_solar_pos(weather)\n1413         self._prep_inputs_airmass()\n1414 \n1415         # PVSystem.get_irradiance and SingleAxisTracker.get_irradiance\n1416         # and PVSystem.get_aoi and SingleAxisTracker.get_aoi\n1417         # have different method signatures. Use partial to handle\n1418         # the differences.\n1419         if isinstance(self.system, SingleAxisTracker):\n1420             self._prep_inputs_tracking()\n1421             get_irradiance = partial(\n1422                 self.system.get_irradiance,\n1423                 self.results.tracking['surface_tilt'],\n1424                 self.results.tracking['surface_azimuth'],\n1425                 self.results.solar_position['apparent_zenith'],\n1426                 self.results.solar_position['azimuth'])\n1427         else:\n1428             self._prep_inputs_fixed()\n1429             get_irradiance = partial(\n1430                 self.system.get_irradiance,\n1431                 self.results.solar_position['apparent_zenith'],\n1432                 self.results.solar_position['azimuth'])\n1433 \n1434         self.results.total_irrad = get_irradiance(\n1435             _tuple_from_dfs(self.results.weather, 'dni'),\n1436             _tuple_from_dfs(self.results.weather, 'ghi'),\n1437             _tuple_from_dfs(self.results.weather, 'dhi'),\n1438             airmass=self.results.airmass['airmass_relative'],\n1439             model=self.transposition_model\n1440         )\n1441 \n1442         return self\n1443 \n1444     def _check_multiple_input(self, data, strict=True):\n1445         \"\"\"Check that the number of elements in `data` is the same as\n1446         the number of Arrays in `self.system`.\n1447 \n1448         In most cases if ``self.system.num_arrays`` is greater than 1 we\n1449         want to raise an error when `data` is not a tuple; however, that\n1450         behavior can be suppressed by setting ``strict=False``. This is\n1451         useful for validating inputs such as GHI, DHI, DNI, wind speed, or\n1452         air temperature that can be applied a ``PVSystem`` as a system-wide\n1453         input. In this case we want to ensure that when a tuple is provided\n1454         it has the same length as the number of Arrays, but we do not want\n1455         to fail if the input is not a tuple.\n1456         \"\"\"\n1457         if (not strict or self.system.num_arrays == 1) \\\n1458                 and not isinstance(data, tuple):\n1459             return\n1460         if strict and not isinstance(data, tuple):\n1461             raise TypeError(\"Input must be a tuple of length \"\n1462                             f\"{self.system.num_arrays}, \"\n1463                             f\"got {type(data).__name__}.\")\n1464         if len(data) != self.system.num_arrays:\n1465             raise ValueError(\"Input must be same length as number of Arrays \"\n1466                              f\"in system. Expected {self.system.num_arrays}, \"\n1467                              f\"got {len(data)}.\")\n1468         _all_same_index(data)\n1469 \n1470     def prepare_inputs_from_poa(self, data):\n1471         \"\"\"\n1472         Prepare the solar position, irradiance and weather inputs to\n1473         the model, starting with plane-of-array irradiance.\n1474 \n1475         Parameters\n1476         ----------\n1477         data : DataFrame, or tuple or list of DataFrame\n1478             Contains plane-of-array irradiance data. Required column names\n1479             include ``'poa_global'``, ``'poa_direct'`` and ``'poa_diffuse'``.\n1480             Columns with weather-related data are ssigned to the\n1481             ``weather`` attribute.  If columns for ``'temp_air'`` and\n1482             ``'wind_speed'`` are not provided, air temperature of 20 C and wind\n1483             speed of 0 m/s are assumed.\n1484 \n1485             If list or tuple, must be of the same length and order as the\n1486             Arrays of the ModelChain's PVSystem.\n1487 \n1488         Raises\n1489         ------\n1490         ValueError\n1491              If the number of DataFrames passed in `data` is not the same\n1492              as the number of Arrays in the system.\n1493 \n1494         Notes\n1495         -----\n1496         Assigns attributes to ``results``: ``times``, ``weather``,\n1497         ``total_irrad``, ``solar_position``, ``airmass``, ``aoi``.\n1498 \n1499         See also\n1500         --------\n1501         pvlib.modelchain.ModelChain.prepare_inputs\n1502         \"\"\"\n1503         data = _to_tuple(data)\n1504         self._check_multiple_input(data)\n1505         self._assign_weather(data)\n1506 \n1507         self._verify_df(data, required=['poa_global', 'poa_direct',\n1508                                         'poa_diffuse'])\n1509         self._assign_total_irrad(data)\n1510 \n1511         self._prep_inputs_solar_pos(data)\n1512         self._prep_inputs_airmass()\n1513 \n1514         if isinstance(self.system, SingleAxisTracker):\n1515             self._prep_inputs_tracking()\n1516         else:\n1517             self._prep_inputs_fixed()\n1518 \n1519         return self\n1520 \n1521     def _get_cell_temperature(self, data,\n1522                               poa, temperature_model_parameters):\n1523         \"\"\"Extract the cell temperature data from a DataFrame.\n1524 \n1525         If 'cell_temperature' column exists in data then it is returned. If\n1526         'module_temperature' column exists in data, then it is used with poa to\n1527         calculate the cell temperature. If neither column exists then None is\n1528         returned.\n1529 \n1530         Parameters\n1531         ----------\n1532         data : DataFrame (not a tuple of DataFrame)\n1533         poa : Series (not a tuple of Series)\n1534 \n1535         Returns\n1536         -------\n1537         Series\n1538         \"\"\"\n1539         if 'cell_temperature' in data:\n1540             return data['cell_temperature']\n1541         # cell_temperature is not in input. Calculate cell_temperature using\n1542         # a temperature_model.\n1543         # If module_temperature is in input data we can use the SAPM cell\n1544         # temperature model.\n1545         if (('module_temperature' in data) and\n1546                 (self.temperature_model == self.sapm_temp)):\n1547             # use SAPM cell temperature model only\n1548             return pvlib.temperature.sapm_cell_from_module(\n1549                 module_temperature=data['module_temperature'],\n1550                 poa_global=poa,\n1551                 deltaT=temperature_model_parameters['deltaT'])\n1552 \n1553     def _prepare_temperature_single_array(self, data, poa):\n1554         \"\"\"Set cell_temperature using a single data frame.\"\"\"\n1555         self.results.cell_temperature = self._get_cell_temperature(\n1556             data,\n1557             poa,\n1558             self.system.temperature_model_parameters\n1559         )\n1560         if self.results.cell_temperature is None:\n1561             self.temperature_model()\n1562         return self\n1563 \n1564     def _prepare_temperature(self, data=None):\n1565         \"\"\"\n1566         Sets cell_temperature using inputs in data and the specified\n1567         temperature model.\n1568 \n1569         If 'data' contains 'cell_temperature', these values are assigned to\n1570         attribute ``cell_temperature``. If 'data' contains 'module_temperature`\n1571         and `temperature_model' is 'sapm', cell temperature is calculated using\n1572         :py:func:`pvlib.temperature.sapm_cell_from_module`. Otherwise, cell\n1573         temperature is calculated by 'temperature_model'.\n1574 \n1575         Parameters\n1576         ----------\n1577         data : DataFrame, default None\n1578             May contain columns ``'cell_temperature'`` or\n1579             ``'module_temperaure'``.\n1580 \n1581         Returns\n1582         -------\n1583         self\n1584 \n1585         Assigns attribute ``results.cell_temperature``.\n1586 \n1587         \"\"\"\n1588         poa = _irrad_for_celltemp(self.results.total_irrad,\n1589                                   self.results.effective_irradiance)\n1590         # handle simple case first, single array, data not iterable\n1591         if not isinstance(data, tuple) and self.system.num_arrays == 1:\n1592             return self._prepare_temperature_single_array(data, poa)\n1593         if not isinstance(data, tuple):\n1594             # broadcast data to all arrays\n1595             data = (data,) * self.system.num_arrays\n1596         # data is tuple, so temperature_model_parameters must also be\n1597         # tuple. system.temperature_model_parameters is reduced to a dict\n1598         # if system.num_arrays == 1, so manually access parameters. GH 1192\n1599         t_mod_params = tuple(array.temperature_model_parameters\n1600                              for array in self.system.arrays)\n1601         # find where cell or module temperature is specified in input data\n1602         given_cell_temperature = tuple(itertools.starmap(\n1603             self._get_cell_temperature, zip(data, poa, t_mod_params)\n1604         ))\n1605         # If cell temperature has been specified for all arrays return\n1606         # immediately and do not try to compute it.\n1607         if all(cell_temp is not None for cell_temp in given_cell_temperature):\n1608             self.results.cell_temperature = given_cell_temperature\n1609             return self\n1610         # Calculate cell temperature from weather data. If cell_temperature\n1611         # has not been provided for some arrays then it is computed.\n1612         self.temperature_model()\n1613         # replace calculated cell temperature with temperature given in `data`\n1614         # where available.\n1615         self.results.cell_temperature = tuple(\n1616             itertools.starmap(\n1617                 lambda given, modeled: modeled if given is None else given,\n1618                 zip(given_cell_temperature, self.results.cell_temperature)\n1619             )\n1620         )\n1621         return self\n1622 \n1623     def run_model(self, weather):\n1624         \"\"\"\n1625         Run the model chain starting with broadband global, diffuse and/or\n1626         direct irradiance.\n1627 \n1628         Parameters\n1629         ----------\n1630         weather : DataFrame, or tuple or list of DataFrame\n1631             Irradiance column names must include ``'dni'``, ``'ghi'``, and\n1632             ``'dhi'``. If optional columns ``'temp_air'`` and ``'wind_speed'``\n1633             are not provided, air temperature of 20 C and wind speed of 0 m/s\n1634             are added to the DataFrame. If optional column\n1635             ``'cell_temperature'`` is provided, these values are used instead\n1636             of `temperature_model`. If optional column `module_temperature`\n1637             is provided, `temperature_model` must be ``'sapm'``.\n1638 \n1639             If list or tuple, must be of the same length and order as the\n1640             Arrays of the ModelChain's PVSystem.\n1641 \n1642         Returns\n1643         -------\n1644         self\n1645 \n1646         Raises\n1647         ------\n1648         ValueError\n1649             If the number of DataFrames in `data` is different than the number\n1650             of Arrays in the PVSystem.\n1651         ValueError\n1652             If the DataFrames in `data` have different indexes.\n1653 \n1654         Notes\n1655         -----\n1656         Assigns attributes to ``results``: ``times``, ``weather``,\n1657         ``solar_position``, ``airmass``, ``total_irrad``, ``aoi``,\n1658         ``aoi_modifier``, ``spectral_modifier``, and\n1659         ``effective_irradiance``, ``cell_temperature``, ``dc``, ``ac``,\n1660         ``losses``, ``diode_params`` (if dc_model is a single diode\n1661         model).\n1662 \n1663         See also\n1664         --------\n1665         pvlib.modelchain.ModelChain.run_model_from_poa\n1666         pvlib.modelchain.ModelChain.run_model_from_effective_irradiance\n1667         \"\"\"\n1668         weather = _to_tuple(weather)\n1669         self.prepare_inputs(weather)\n1670         self.aoi_model()\n1671         self.spectral_model()\n1672         self.effective_irradiance_model()\n1673 \n1674         self._run_from_effective_irrad(weather)\n1675 \n1676         return self\n1677 \n1678     def run_model_from_poa(self, data):\n1679         \"\"\"\n1680         Run the model starting with broadband irradiance in the plane of array.\n1681 \n1682         Data must include direct, diffuse and total irradiance (W/m2) in the\n1683         plane of array. Reflections and spectral adjustments are made to\n1684         calculate effective irradiance (W/m2).\n1685 \n1686         Parameters\n1687         ----------\n1688         data : DataFrame, or tuple or list of DataFrame\n1689             Required column names include ``'poa_global'``,\n1690             ``'poa_direct'`` and ``'poa_diffuse'``. If optional columns\n1691             ``'temp_air'`` and ``'wind_speed'`` are not provided, air\n1692             temperature of 20 C and wind speed of 0 m/s are assumed.\n1693             If optional column ``'cell_temperature'`` is provided, these values\n1694             are used instead of `temperature_model`. If optional column\n1695             ``'module_temperature'`` is provided, `temperature_model` must be\n1696             ``'sapm'``.\n1697 \n1698             If the ModelChain's PVSystem has multiple arrays, `data` must be a\n1699             list or tuple with the same length and order as the PVsystem's\n1700             Arrays. Each element of `data` provides the irradiance and weather\n1701             for the corresponding array.\n1702 \n1703         Returns\n1704         -------\n1705         self\n1706 \n1707         Raises\n1708         ------\n1709         ValueError\n1710             If the number of DataFrames in `data` is different than the number\n1711             of Arrays in the PVSystem.\n1712         ValueError\n1713             If the DataFrames in `data` have different indexes.\n1714 \n1715         Notes\n1716         -----\n1717         Assigns attributes to results: ``times``, ``weather``,\n1718         ``solar_position``, ``airmass``, ``total_irrad``, ``aoi``,\n1719         ``aoi_modifier``, ``spectral_modifier``, and\n1720         ``effective_irradiance``, ``cell_temperature``, ``dc``, ``ac``,\n1721         ``losses``, ``diode_params`` (if dc_model is a single diode\n1722         model).\n1723 \n1724         See also\n1725         --------\n1726         pvlib.modelchain.ModelChain.run_model\n1727         pvlib.modelchain.ModelChain.run_model_from_effective_irradiance\n1728         \"\"\"\n1729         data = _to_tuple(data)\n1730         self.prepare_inputs_from_poa(data)\n1731 \n1732         self.aoi_model()\n1733         self.spectral_model()\n1734         self.effective_irradiance_model()\n1735 \n1736         self._run_from_effective_irrad(data)\n1737 \n1738         return self\n1739 \n1740     def _run_from_effective_irrad(self, data=None):\n1741         \"\"\"\n1742         Executes the temperature, DC, losses and AC models.\n1743 \n1744         Parameters\n1745         ----------\n1746         data : DataFrame, or tuple of DataFrame, default None\n1747             If optional column ``'cell_temperature'`` is provided, these values\n1748             are used instead of `temperature_model`. If optional column\n1749             `module_temperature` is provided, `temperature_model` must be\n1750             ``'sapm'``.\n1751 \n1752         Returns\n1753         -------\n1754         self\n1755 \n1756         Notes\n1757         -----\n1758         Assigns attributes:``cell_temperature``, ``dc``, ``ac``, ``losses``,\n1759         ``diode_params`` (if dc_model is a single diode model).\n1760         \"\"\"\n1761         self._prepare_temperature(data)\n1762         self.dc_model()\n1763         self.dc_ohmic_model()\n1764         self.losses_model()\n1765         self.ac_model()\n1766 \n1767         return self\n1768 \n1769     def run_model_from_effective_irradiance(self, data=None):\n1770         \"\"\"\n1771         Run the model starting with effective irradiance in the plane of array.\n1772 \n1773         Effective irradiance is irradiance in the plane-of-array after any\n1774         adjustments for soiling, reflections and spectrum.\n1775 \n1776         Parameters\n1777         ----------\n1778         data : DataFrame, or list or tuple of DataFrame\n1779             Required column is ``'effective_irradiance'``.\n1780             Optional columns include ``'cell_temperature'``,\n1781             ``'module_temperature'`` and ``'poa_global'``.\n1782 \n1783             If the ModelChain's PVSystem has multiple arrays, `data` must be a\n1784             list or tuple with the same length and order as the PVsystem's\n1785             Arrays. Each element of `data` provides the irradiance and weather\n1786             for the corresponding array.\n1787 \n1788         Returns\n1789         -------\n1790         self\n1791 \n1792         Raises\n1793         ------\n1794         ValueError\n1795             If the number of DataFrames in `data` is different than the number\n1796             of Arrays in the PVSystem.\n1797         ValueError\n1798             If the DataFrames in `data` have different indexes.\n1799 \n1800         Notes\n1801         -----\n1802         Optional ``data`` columns ``'cell_temperature'``,\n1803         ``'module_temperature'`` and ``'poa_global'`` are used for determining\n1804         cell temperature.\n1805 \n1806         * If optional column ``'cell_temperature'`` is present, these values\n1807           are used and `temperature_model` is ignored.\n1808         * If optional column ``'module_temperature'`` is preset,\n1809           `temperature_model` must be ``'sapm'``.\n1810         * Otherwise, cell temperature is calculated using `temperature_model`.\n1811 \n1812         The cell temperature models require plane-of-array irradiance as input.\n1813         If optional column ``'poa_global'`` is present, these data are used.\n1814         If ``'poa_global'`` is not present, ``'effective_irradiance'`` is used.\n1815 \n1816         Assigns attributes to results: ``times``, ``weather``, ``total_irrad``,\n1817         ``effective_irradiance``, ``cell_temperature``, ``dc``, ``ac``,\n1818         ``losses``, ``diode_params`` (if dc_model is a single diode model).\n1819 \n1820         See also\n1821         --------\n1822         pvlib.modelchain.ModelChain.run_model\n1823         pvlib.modelchain.ModelChain.run_model_from_poa\n1824         \"\"\"\n1825         data = _to_tuple(data)\n1826         self._check_multiple_input(data)\n1827         self._verify_df(data, required=['effective_irradiance'])\n1828         self._assign_weather(data)\n1829         self._assign_total_irrad(data)\n1830         self.results.effective_irradiance = _tuple_from_dfs(\n1831             data, 'effective_irradiance')\n1832         self._run_from_effective_irrad(data)\n1833 \n1834         return self\n1835 \n1836 \n1837 def _irrad_for_celltemp(total_irrad, effective_irradiance):\n1838     \"\"\"\n1839     Determine irradiance to use for cell temperature models, in order\n1840     of preference 'poa_global' then 'effective_irradiance'\n1841 \n1842     Returns\n1843     -------\n1844     Series or tuple of Series\n1845         tuple if total_irrad is a tuple of DataFrame\n1846 \n1847     \"\"\"\n1848     if isinstance(total_irrad, tuple):\n1849         if all(['poa_global' in df for df in total_irrad]):\n1850             return _tuple_from_dfs(total_irrad, 'poa_global')\n1851         else:\n1852             return effective_irradiance\n1853     else:\n1854         if 'poa_global' in total_irrad:\n1855             return total_irrad['poa_global']\n1856         else:\n1857             return effective_irradiance\n1858 \n1859 \n1860 def _snl_params(inverter_params):\n1861     \"\"\"Return True if `inverter_params` includes parameters for the\n1862     Sandia inverter model.\"\"\"\n1863     return {'C0', 'C1', 'C2'} <= inverter_params\n1864 \n1865 \n1866 def _adr_params(inverter_params):\n1867     \"\"\"Return True if `inverter_params` includes parameters for the ADR\n1868     inverter model.\"\"\"\n1869     return {'ADRCoefficients'} <= inverter_params\n1870 \n1871 \n1872 def _pvwatts_params(inverter_params):\n1873     \"\"\"Return True if `inverter_params` includes parameters for the\n1874     PVWatts inverter model.\"\"\"\n1875     return {'pdc0'} <= inverter_params\n1876 \n1877 \n1878 def _copy(data):\n1879     \"\"\"Return a copy of each DataFrame in `data` if it is a tuple,\n1880     otherwise return a copy of `data`.\"\"\"\n1881     if not isinstance(data, tuple):\n1882         return data.copy()\n1883     return tuple(df.copy() for df in data)\n1884 \n1885 \n1886 def _all_same_index(data):\n1887     \"\"\"Raise a ValueError if all DataFrames in `data` do not have the\n1888     same index.\"\"\"\n1889     indexes = map(lambda df: df.index, data)\n1890     next(indexes, None)\n1891     for index in indexes:\n1892         if not index.equals(data[0].index):\n1893             raise ValueError(\"Input DataFrames must have same index.\")\n1894 \n1895 \n1896 def _common_keys(dicts):\n1897     \"\"\"Return the intersection of the set of keys for each dictionary\n1898     in `dicts`\"\"\"\n1899     def _keys(x):\n1900         return set(x.keys())\n1901     if isinstance(dicts, tuple):\n1902         return set.intersection(*map(_keys, dicts))\n1903     return _keys(dicts)\n1904 \n1905 \n1906 def _tuple_from_dfs(dfs, name):\n1907     \"\"\"Extract a column from each DataFrame in `dfs` if `dfs` is a tuple.\n1908 \n1909     Returns a tuple of Series if `dfs` is a tuple or a Series if `dfs` is\n1910     a DataFrame.\n1911     \"\"\"\n1912     if isinstance(dfs, tuple):\n1913         return tuple(df[name] for df in dfs)\n1914     else:\n1915         return dfs[name]\n1916 \n1917 \n1918 def _to_tuple(x):\n1919     if not isinstance(x, (tuple, list)):\n1920         return x\n1921     return tuple(x)\n1922 \n[end of pvlib/modelchain.py]\n[start of pvlib/pvsystem.py]\n1 \"\"\"\n2 The ``pvsystem`` module contains functions for modeling the output and\n3 performance of PV modules and inverters.\n4 \"\"\"\n5 \n6 from collections import OrderedDict\n7 import functools\n8 import io\n9 import itertools\n10 import os\n11 from urllib.request import urlopen\n12 import numpy as np\n13 import pandas as pd\n14 \n15 from pvlib._deprecation import deprecated\n16 \n17 from pvlib import (atmosphere, iam, inverter, irradiance,\n18                    singlediode as _singlediode, temperature)\n19 from pvlib.tools import _build_kwargs\n20 \n21 \n22 # a dict of required parameter names for each DC power model\n23 _DC_MODEL_PARAMS = {\n24     'sapm': {\n25         'A0', 'A1', 'A2', 'A3', 'A4', 'B0', 'B1', 'B2', 'B3',\n26         'B4', 'B5', 'C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6',\n27         'C7', 'Isco', 'Impo', 'Voco', 'Vmpo', 'Aisc', 'Aimp', 'Bvoco',\n28         'Mbvoc', 'Bvmpo', 'Mbvmp', 'N', 'Cells_in_Series',\n29         'IXO', 'IXXO', 'FD'},\n30     'desoto': {\n31         'alpha_sc', 'a_ref', 'I_L_ref', 'I_o_ref',\n32         'R_sh_ref', 'R_s'},\n33     'cec': {\n34         'alpha_sc', 'a_ref', 'I_L_ref', 'I_o_ref',\n35         'R_sh_ref', 'R_s', 'Adjust'},\n36     'pvsyst': {\n37         'gamma_ref', 'mu_gamma', 'I_L_ref', 'I_o_ref',\n38         'R_sh_ref', 'R_sh_0', 'R_s', 'alpha_sc', 'EgRef',\n39         'cells_in_series'},\n40     'singlediode': {\n41         'alpha_sc', 'a_ref', 'I_L_ref', 'I_o_ref',\n42         'R_sh_ref', 'R_s'},\n43     'pvwatts': {'pdc0', 'gamma_pdc'}\n44 }\n45 \n46 \n47 def _unwrap_single_value(func):\n48     \"\"\"Decorator for functions that return iterables.\n49 \n50     If the length of the iterable returned by `func` is 1, then\n51     the single member of the iterable is returned. If the length is\n52     greater than 1, then entire iterable is returned.\n53 \n54     Adds 'unwrap' as a keyword argument that can be set to False\n55     to force the return value to be a tuple, regardless of its length.\n56     \"\"\"\n57     @functools.wraps(func)\n58     def f(*args, **kwargs):\n59         unwrap = kwargs.pop('unwrap', True)\n60         x = func(*args, **kwargs)\n61         if unwrap and len(x) == 1:\n62             return x[0]\n63         return x\n64     return f\n65 \n66 \n67 # not sure if this belongs in the pvsystem module.\n68 # maybe something more like core.py? It may eventually grow to\n69 # import a lot more functionality from other modules.\n70 class PVSystem:\n71     \"\"\"\n72     The PVSystem class defines a standard set of PV system attributes\n73     and modeling functions. This class describes the collection and\n74     interactions of PV system components rather than an installed system\n75     on the ground. It is typically used in combination with\n76     :py:class:`~pvlib.location.Location` and\n77     :py:class:`~pvlib.modelchain.ModelChain`\n78     objects.\n79 \n80     The class supports basic system topologies consisting of:\n81 \n82         * `N` total modules arranged in series\n83           (`modules_per_string=N`, `strings_per_inverter=1`).\n84         * `M` total modules arranged in parallel\n85           (`modules_per_string=1`, `strings_per_inverter=M`).\n86         * `NxM` total modules arranged in `M` strings of `N` modules each\n87           (`modules_per_string=N`, `strings_per_inverter=M`).\n88 \n89     The class is complementary to the module-level functions.\n90 \n91     The attributes should generally be things that don't change about\n92     the system, such the type of module and the inverter. The instance\n93     methods accept arguments for things that do change, such as\n94     irradiance and temperature.\n95 \n96     Parameters\n97     ----------\n98     arrays : iterable of Array, optional\n99         List of arrays that are part of the system. If not specified\n100         a single array is created from the other parameters (e.g.\n101         `surface_tilt`, `surface_azimuth`). If `arrays` is specified\n102         the following parameters are ignored:\n103 \n104         - `surface_tilt`\n105         - `surface_azimuth`\n106         - `albedo`\n107         - `surface_type`\n108         - `module`\n109         - `module_type`\n110         - `module_parameters`\n111         - `temperature_model_parameters`\n112         - `modules_per_string`\n113         - `strings_per_inverter`\n114 \n115     surface_tilt: float or array-like, default 0\n116         Surface tilt angles in decimal degrees.\n117         The tilt angle is defined as degrees from horizontal\n118         (e.g. surface facing up = 0, surface facing horizon = 90)\n119 \n120     surface_azimuth: float or array-like, default 180\n121         Azimuth angle of the module surface.\n122         North=0, East=90, South=180, West=270.\n123 \n124     albedo : None or float, default None\n125         The ground albedo. If ``None``, will attempt to use\n126         ``surface_type`` and ``irradiance.SURFACE_ALBEDOS``\n127         to lookup albedo.\n128 \n129     surface_type : None or string, default None\n130         The ground surface type. See ``irradiance.SURFACE_ALBEDOS``\n131         for valid values.\n132 \n133     module : None or string, default None\n134         The model name of the modules.\n135         May be used to look up the module_parameters dictionary\n136         via some other method.\n137 \n138     module_type : None or string, default 'glass_polymer'\n139          Describes the module's construction. Valid strings are 'glass_polymer'\n140          and 'glass_glass'. Used for cell and module temperature calculations.\n141 \n142     module_parameters : None, dict or Series, default None\n143         Module parameters as defined by the SAPM, CEC, or other.\n144 \n145     temperature_model_parameters : None, dict or Series, default None.\n146         Temperature model parameters as required by one of the models in\n147         pvlib.temperature (excluding poa_global, temp_air and wind_speed).\n148 \n149     modules_per_string: int or float, default 1\n150         See system topology discussion above.\n151 \n152     strings_per_inverter: int or float, default 1\n153         See system topology discussion above.\n154 \n155     inverter : None or string, default None\n156         The model name of the inverters.\n157         May be used to look up the inverter_parameters dictionary\n158         via some other method.\n159 \n160     inverter_parameters : None, dict or Series, default None\n161         Inverter parameters as defined by the SAPM, CEC, or other.\n162 \n163     racking_model : None or string, default 'open_rack'\n164         Valid strings are 'open_rack', 'close_mount', and 'insulated_back'.\n165         Used to identify a parameter set for the SAPM cell temperature model.\n166 \n167     losses_parameters : None, dict or Series, default None\n168         Losses parameters as defined by PVWatts or other.\n169 \n170     name : None or string, default None\n171 \n172     **kwargs\n173         Arbitrary keyword arguments.\n174         Included for compatibility, but not used.\n175 \n176     See also\n177     --------\n178     pvlib.location.Location\n179     pvlib.tracking.SingleAxisTracker\n180     \"\"\"\n181 \n182     def __init__(self,\n183                  arrays=None,\n184                  surface_tilt=0, surface_azimuth=180,\n185                  albedo=None, surface_type=None,\n186                  module=None, module_type=None,\n187                  module_parameters=None,\n188                  temperature_model_parameters=None,\n189                  modules_per_string=1, strings_per_inverter=1,\n190                  inverter=None, inverter_parameters=None,\n191                  racking_model=None, losses_parameters=None, name=None):\n192 \n193         if arrays is None:\n194             if losses_parameters is None:\n195                 array_losses_parameters = {}\n196             else:\n197                 array_losses_parameters = _build_kwargs(['dc_ohmic_percent'],\n198                                                         losses_parameters)\n199             self.arrays = (Array(\n200                 surface_tilt,\n201                 surface_azimuth,\n202                 albedo,\n203                 surface_type,\n204                 module,\n205                 module_type,\n206                 module_parameters,\n207                 temperature_model_parameters,\n208                 modules_per_string,\n209                 strings_per_inverter,\n210                 racking_model,\n211                 array_losses_parameters,\n212             ),)\n213         else:\n214             self.arrays = tuple(arrays)\n215 \n216         self.inverter = inverter\n217         if inverter_parameters is None:\n218             self.inverter_parameters = {}\n219         else:\n220             self.inverter_parameters = inverter_parameters\n221 \n222         if losses_parameters is None:\n223             self.losses_parameters = {}\n224         else:\n225             self.losses_parameters = losses_parameters\n226 \n227         self.name = name\n228 \n229     def __repr__(self):\n230         repr = f'PVSystem:\\n  name: {self.name}\\n  '\n231         for array in self.arrays:\n232             repr += '\\n  '.join(array.__repr__().split('\\n'))\n233             repr += '\\n  '\n234         repr += f'inverter: {self.inverter}'\n235         return repr\n236 \n237     def _validate_per_array(self, values, system_wide=False):\n238         \"\"\"Check that `values` is a tuple of the same length as\n239         `self.arrays`.\n240 \n241         If `values` is not a tuple it is packed in to a length-1 tuple before\n242         the check. If the lengths are not the same a ValueError is raised,\n243         otherwise the tuple `values` is returned.\n244 \n245         When `system_wide` is True and `values` is not a tuple, `values`\n246         is replicated to a tuple of the same length as `self.arrays` and that\n247         tuple is returned.\n248         \"\"\"\n249         if system_wide and not isinstance(values, tuple):\n250             return (values,) * self.num_arrays\n251         if not isinstance(values, tuple):\n252             values = (values,)\n253         if len(values) != len(self.arrays):\n254             raise ValueError(\"Length mismatch for per-array parameter\")\n255         return values\n256 \n257     @_unwrap_single_value\n258     def _infer_cell_type(self):\n259 \n260         \"\"\"\n261         Examines module_parameters and maps the Technology key for the CEC\n262         database and the Material key for the Sandia database to a common\n263         list of strings for cell type.\n264 \n265         Returns\n266         -------\n267         cell_type: str\n268         \"\"\"\n269         return tuple(array._infer_cell_type() for array in self.arrays)\n270 \n271     @_unwrap_single_value\n272     def get_aoi(self, solar_zenith, solar_azimuth):\n273         \"\"\"Get the angle of incidence on the Array(s) in the system.\n274 \n275         Parameters\n276         ----------\n277         solar_zenith : float or Series.\n278             Solar zenith angle.\n279         solar_azimuth : float or Series.\n280             Solar azimuth angle.\n281 \n282         Returns\n283         -------\n284         aoi : Series or tuple of Series\n285             The angle of incidence\n286         \"\"\"\n287 \n288         return tuple(array.get_aoi(solar_zenith, solar_azimuth)\n289                      for array in self.arrays)\n290 \n291     @_unwrap_single_value\n292     def get_irradiance(self, solar_zenith, solar_azimuth, dni, ghi, dhi,\n293                        dni_extra=None, airmass=None, model='haydavies',\n294                        **kwargs):\n295         \"\"\"\n296         Uses the :py:func:`irradiance.get_total_irradiance` function to\n297         calculate the plane of array irradiance components on a tilted\n298         surface defined by ``self.surface_tilt``,\n299         ``self.surface_azimuth``, and ``self.albedo``.\n300 \n301         Parameters\n302         ----------\n303         solar_zenith : float or Series.\n304             Solar zenith angle.\n305         solar_azimuth : float or Series.\n306             Solar azimuth angle.\n307         dni : float or Series or tuple of float or Series\n308             Direct Normal Irradiance\n309         ghi : float or Series or tuple of float or Series\n310             Global horizontal irradiance\n311         dhi : float or Series or tuple of float or Series\n312             Diffuse horizontal irradiance\n313         dni_extra : None, float or Series, default None\n314             Extraterrestrial direct normal irradiance\n315         airmass : None, float or Series, default None\n316             Airmass\n317         model : String, default 'haydavies'\n318             Irradiance model.\n319 \n320         kwargs\n321             Extra parameters passed to :func:`irradiance.get_total_irradiance`.\n322 \n323         Notes\n324         -----\n325         Each of `dni`, `ghi`, and `dni` parameters may be passed as a tuple\n326         to provide different irradiance for each array in the system. If not\n327         passed as a tuple then the same value is used for input to each Array.\n328         If passed as a tuple the length must be the same as the number of\n329         Arrays.\n330 \n331         Returns\n332         -------\n333         poa_irradiance : DataFrame or tuple of DataFrame\n334             Column names are: ``total, beam, sky, ground``.\n335         \"\"\"\n336         dni = self._validate_per_array(dni, system_wide=True)\n337         ghi = self._validate_per_array(ghi, system_wide=True)\n338         dhi = self._validate_per_array(dhi, system_wide=True)\n339         return tuple(\n340             array.get_irradiance(solar_zenith, solar_azimuth,\n341                                  dni, ghi, dhi,\n342                                  dni_extra, airmass, model,\n343                                  **kwargs)\n344             for array, dni, ghi, dhi in zip(\n345                 self.arrays, dni, ghi, dhi\n346             )\n347         )\n348 \n349     @_unwrap_single_value\n350     def get_iam(self, aoi, iam_model='physical'):\n351         \"\"\"\n352         Determine the incidence angle modifier using the method specified by\n353         ``iam_model``.\n354 \n355         Parameters for the selected IAM model are expected to be in\n356         ``PVSystem.module_parameters``. Default parameters are available for\n357         the 'physical', 'ashrae' and 'martin_ruiz' models.\n358 \n359         Parameters\n360         ----------\n361         aoi : numeric or tuple of numeric\n362             The angle of incidence in degrees.\n363 \n364         aoi_model : string, default 'physical'\n365             The IAM model to be used. Valid strings are 'physical', 'ashrae',\n366             'martin_ruiz' and 'sapm'.\n367         Returns\n368         -------\n369         iam : numeric or tuple of numeric\n370             The AOI modifier.\n371 \n372         Raises\n373         ------\n374         ValueError\n375             if `iam_model` is not a valid model name.\n376         \"\"\"\n377         aoi = self._validate_per_array(aoi)\n378         return tuple(array.get_iam(aoi, iam_model)\n379                      for array, aoi in zip(self.arrays, aoi))\n380 \n381     @_unwrap_single_value\n382     def calcparams_desoto(self, effective_irradiance, temp_cell, **kwargs):\n383         \"\"\"\n384         Use the :py:func:`calcparams_desoto` function, the input\n385         parameters and ``self.module_parameters`` to calculate the\n386         module currents and resistances.\n387 \n388         Parameters\n389         ----------\n390         effective_irradiance : numeric or tuple of numeric\n391             The irradiance (W/m2) that is converted to photocurrent.\n392 \n393         temp_cell : float or Series or tuple of float or Series\n394             The average cell temperature of cells within a module in C.\n395 \n396         **kwargs\n397             See pvsystem.calcparams_desoto for details\n398 \n399         Returns\n400         -------\n401         See pvsystem.calcparams_desoto for details\n402         \"\"\"\n403         effective_irradiance = self._validate_per_array(effective_irradiance)\n404         temp_cell = self._validate_per_array(temp_cell)\n405 \n406         build_kwargs = functools.partial(\n407             _build_kwargs,\n408             ['a_ref', 'I_L_ref', 'I_o_ref', 'R_sh_ref',\n409              'R_s', 'alpha_sc', 'EgRef', 'dEgdT',\n410              'irrad_ref', 'temp_ref']\n411         )\n412 \n413         return tuple(\n414             calcparams_desoto(\n415                 effective_irradiance, temp_cell,\n416                 **build_kwargs(array.module_parameters)\n417             )\n418             for array, effective_irradiance, temp_cell\n419             in zip(self.arrays, effective_irradiance, temp_cell)\n420         )\n421 \n422     @_unwrap_single_value\n423     def calcparams_cec(self, effective_irradiance, temp_cell, **kwargs):\n424         \"\"\"\n425         Use the :py:func:`calcparams_cec` function, the input\n426         parameters and ``self.module_parameters`` to calculate the\n427         module currents and resistances.\n428 \n429         Parameters\n430         ----------\n431         effective_irradiance : numeric or tuple of numeric\n432             The irradiance (W/m2) that is converted to photocurrent.\n433 \n434         temp_cell : float or Series or tuple of float or Series\n435             The average cell temperature of cells within a module in C.\n436 \n437         **kwargs\n438             See pvsystem.calcparams_cec for details\n439 \n440         Returns\n441         -------\n442         See pvsystem.calcparams_cec for details\n443         \"\"\"\n444         effective_irradiance = self._validate_per_array(effective_irradiance)\n445         temp_cell = self._validate_per_array(temp_cell)\n446 \n447         build_kwargs = functools.partial(\n448             _build_kwargs,\n449             ['a_ref', 'I_L_ref', 'I_o_ref', 'R_sh_ref',\n450              'R_s', 'alpha_sc', 'Adjust', 'EgRef', 'dEgdT',\n451              'irrad_ref', 'temp_ref']\n452         )\n453 \n454         return tuple(\n455             calcparams_cec(\n456                 effective_irradiance, temp_cell,\n457                 **build_kwargs(array.module_parameters)\n458             )\n459             for array, effective_irradiance, temp_cell\n460             in zip(self.arrays, effective_irradiance, temp_cell)\n461         )\n462 \n463     @_unwrap_single_value\n464     def calcparams_pvsyst(self, effective_irradiance, temp_cell):\n465         \"\"\"\n466         Use the :py:func:`calcparams_pvsyst` function, the input\n467         parameters and ``self.module_parameters`` to calculate the\n468         module currents and resistances.\n469 \n470         Parameters\n471         ----------\n472         effective_irradiance : numeric or tuple of numeric\n473             The irradiance (W/m2) that is converted to photocurrent.\n474 \n475         temp_cell : float or Series or tuple of float or Series\n476             The average cell temperature of cells within a module in C.\n477 \n478         Returns\n479         -------\n480         See pvsystem.calcparams_pvsyst for details\n481         \"\"\"\n482         effective_irradiance = self._validate_per_array(effective_irradiance)\n483         temp_cell = self._validate_per_array(temp_cell)\n484 \n485         build_kwargs = functools.partial(\n486             _build_kwargs,\n487             ['gamma_ref', 'mu_gamma', 'I_L_ref', 'I_o_ref',\n488              'R_sh_ref', 'R_sh_0', 'R_sh_exp',\n489              'R_s', 'alpha_sc', 'EgRef',\n490              'irrad_ref', 'temp_ref',\n491              'cells_in_series']\n492         )\n493 \n494         return tuple(\n495             calcparams_pvsyst(\n496                 effective_irradiance, temp_cell,\n497                 **build_kwargs(array.module_parameters)\n498             )\n499             for array, effective_irradiance, temp_cell\n500             in zip(self.arrays, effective_irradiance, temp_cell)\n501         )\n502 \n503     @_unwrap_single_value\n504     def sapm(self, effective_irradiance, temp_cell, **kwargs):\n505         \"\"\"\n506         Use the :py:func:`sapm` function, the input parameters,\n507         and ``self.module_parameters`` to calculate\n508         Voc, Isc, Ix, Ixx, Vmp, and Imp.\n509 \n510         Parameters\n511         ----------\n512         effective_irradiance : numeric or tuple of numeric\n513             The irradiance (W/m2) that is converted to photocurrent.\n514 \n515         temp_cell : float or Series or tuple of float or Series\n516             The average cell temperature of cells within a module in C.\n517 \n518         kwargs\n519             See pvsystem.sapm for details\n520 \n521         Returns\n522         -------\n523         See pvsystem.sapm for details\n524         \"\"\"\n525         effective_irradiance = self._validate_per_array(effective_irradiance)\n526         temp_cell = self._validate_per_array(temp_cell)\n527 \n528         return tuple(\n529             sapm(effective_irradiance, temp_cell, array.module_parameters)\n530             for array, effective_irradiance, temp_cell\n531             in zip(self.arrays, effective_irradiance, temp_cell)\n532         )\n533 \n534     @_unwrap_single_value\n535     def sapm_celltemp(self, poa_global, temp_air, wind_speed):\n536         \"\"\"Uses :py:func:`temperature.sapm_cell` to calculate cell\n537         temperatures.\n538 \n539         Parameters\n540         ----------\n541         poa_global : numeric or tuple of numeric\n542             Total incident irradiance in W/m^2.\n543 \n544         temp_air : numeric or tuple of numeric\n545             Ambient dry bulb temperature in degrees C.\n546 \n547         wind_speed : numeric or tuple of numeric\n548             Wind speed in m/s at a height of 10 meters.\n549 \n550         Returns\n551         -------\n552         numeric or tuple of numeric\n553             values in degrees C.\n554 \n555         Notes\n556         -----\n557         The `temp_air` and `wind_speed` parameters may be passed as tuples\n558         to provide different values for each Array in the system. If not\n559         passed as a tuple then the same value is used for input to each Array.\n560         If passed as a tuple the length must be the same as the number of\n561         Arrays.\n562         \"\"\"\n563         poa_global = self._validate_per_array(poa_global)\n564         temp_air = self._validate_per_array(temp_air, system_wide=True)\n565         wind_speed = self._validate_per_array(wind_speed, system_wide=True)\n566 \n567         build_kwargs = functools.partial(_build_kwargs, ['a', 'b', 'deltaT'])\n568         return tuple(\n569             temperature.sapm_cell(\n570                 poa_global, temp_air, wind_speed,\n571                 **build_kwargs(array.temperature_model_parameters)\n572             )\n573             for array, poa_global, temp_air, wind_speed in zip(\n574                 self.arrays, poa_global, temp_air, wind_speed\n575             )\n576         )\n577 \n578     @_unwrap_single_value\n579     def sapm_spectral_loss(self, airmass_absolute):\n580         \"\"\"\n581         Use the :py:func:`sapm_spectral_loss` function, the input\n582         parameters, and ``self.module_parameters`` to calculate F1.\n583 \n584         Parameters\n585         ----------\n586         airmass_absolute : numeric\n587             Absolute airmass.\n588 \n589         Returns\n590         -------\n591         F1 : numeric or tuple of numeric\n592             The SAPM spectral loss coefficient.\n593         \"\"\"\n594         return tuple(\n595             sapm_spectral_loss(airmass_absolute, array.module_parameters)\n596             for array in self.arrays\n597         )\n598 \n599     @_unwrap_single_value\n600     def sapm_effective_irradiance(self, poa_direct, poa_diffuse,\n601                                   airmass_absolute, aoi,\n602                                   reference_irradiance=1000):\n603         \"\"\"\n604         Use the :py:func:`sapm_effective_irradiance` function, the input\n605         parameters, and ``self.module_parameters`` to calculate\n606         effective irradiance.\n607 \n608         Parameters\n609         ----------\n610         poa_direct : numeric or tuple of numeric\n611             The direct irradiance incident upon the module.  [W/m2]\n612 \n613         poa_diffuse : numeric or tuple of numeric\n614             The diffuse irradiance incident on module.  [W/m2]\n615 \n616         airmass_absolute : numeric\n617             Absolute airmass. [unitless]\n618 \n619         aoi : numeric or tuple of numeric\n620             Angle of incidence. [degrees]\n621 \n622         Returns\n623         -------\n624         effective_irradiance : numeric or tuple of numeric\n625             The SAPM effective irradiance. [W/m2]\n626         \"\"\"\n627         poa_direct = self._validate_per_array(poa_direct)\n628         poa_diffuse = self._validate_per_array(poa_diffuse)\n629         aoi = self._validate_per_array(aoi)\n630         return tuple(\n631             sapm_effective_irradiance(\n632                 poa_direct, poa_diffuse, airmass_absolute, aoi,\n633                 array.module_parameters)\n634             for array, poa_direct, poa_diffuse, aoi\n635             in zip(self.arrays, poa_direct, poa_diffuse, aoi)\n636         )\n637 \n638     @_unwrap_single_value\n639     def pvsyst_celltemp(self, poa_global, temp_air, wind_speed=1.0):\n640         \"\"\"Uses :py:func:`temperature.pvsyst_cell` to calculate cell\n641         temperature.\n642 \n643         Parameters\n644         ----------\n645         poa_global : numeric or tuple of numeric\n646             Total incident irradiance in W/m^2.\n647 \n648         temp_air : numeric or tuple of numeric\n649             Ambient dry bulb temperature in degrees C.\n650 \n651         wind_speed : numeric or tuple of numeric, default 1.0\n652             Wind speed in m/s measured at the same height for which the wind\n653             loss factor was determined.  The default value is 1.0, which is\n654             the wind speed at module height used to determine NOCT.\n655 \n656         Returns\n657         -------\n658         numeric or tuple of numeric\n659             values in degrees C.\n660 \n661         Notes\n662         -----\n663         The `temp_air` and `wind_speed` parameters may be passed as tuples\n664         to provide different values for each Array in the system. If not\n665         passed as a tuple then the same value is used for input to each Array.\n666         If passed as a tuple the length must be the same as the number of\n667         Arrays.\n668         \"\"\"\n669         poa_global = self._validate_per_array(poa_global)\n670         temp_air = self._validate_per_array(temp_air, system_wide=True)\n671         wind_speed = self._validate_per_array(wind_speed, system_wide=True)\n672 \n673         def build_celltemp_kwargs(array):\n674             return {**_build_kwargs(['eta_m', 'alpha_absorption'],\n675                                     array.module_parameters),\n676                     **_build_kwargs(['u_c', 'u_v'],\n677                                     array.temperature_model_parameters)}\n678         return tuple(\n679             temperature.pvsyst_cell(poa_global, temp_air, wind_speed,\n680                                     **build_celltemp_kwargs(array))\n681             for array, poa_global, temp_air, wind_speed in zip(\n682                 self.arrays, poa_global, temp_air, wind_speed\n683             )\n684         )\n685 \n686     @_unwrap_single_value\n687     def faiman_celltemp(self, poa_global, temp_air, wind_speed=1.0):\n688         \"\"\"\n689         Use :py:func:`temperature.faiman` to calculate cell temperature.\n690 \n691         Parameters\n692         ----------\n693         poa_global : numeric or tuple of numeric\n694             Total incident irradiance [W/m^2].\n695 \n696         temp_air : numeric or tuple of numeric\n697             Ambient dry bulb temperature [C].\n698 \n699         wind_speed : numeric or tuple of numeric, default 1.0\n700             Wind speed in m/s measured at the same height for which the wind\n701             loss factor was determined.  The default value 1.0 m/s is the wind\n702             speed at module height used to determine NOCT. [m/s]\n703 \n704         Returns\n705         -------\n706         numeric or tuple of numeric\n707             values in degrees C.\n708 \n709         Notes\n710         -----\n711         The `temp_air` and `wind_speed` parameters may be passed as tuples\n712         to provide different values for each Array in the system. If not\n713         passed as a tuple then the same value is used for input to each Array.\n714         If passed as a tuple the length must be the same as the number of\n715         Arrays.\n716         \"\"\"\n717         poa_global = self._validate_per_array(poa_global)\n718         temp_air = self._validate_per_array(temp_air, system_wide=True)\n719         wind_speed = self._validate_per_array(wind_speed, system_wide=True)\n720         return tuple(\n721             temperature.faiman(\n722                 poa_global, temp_air, wind_speed,\n723                 **_build_kwargs(\n724                     ['u0', 'u1'], array.temperature_model_parameters))\n725             for array, poa_global, temp_air, wind_speed in zip(\n726                 self.arrays, poa_global, temp_air, wind_speed\n727             )\n728         )\n729 \n730     @_unwrap_single_value\n731     def fuentes_celltemp(self, poa_global, temp_air, wind_speed):\n732         \"\"\"\n733         Use :py:func:`temperature.fuentes` to calculate cell temperature.\n734 \n735         Parameters\n736         ----------\n737         poa_global : pandas Series or tuple of Series\n738             Total incident irradiance [W/m^2]\n739 \n740         temp_air : pandas Series or tuple of Series\n741             Ambient dry bulb temperature [C]\n742 \n743         wind_speed : pandas Series or tuple of Series\n744             Wind speed [m/s]\n745 \n746         Returns\n747         -------\n748         temperature_cell : Series or tuple of Series\n749             The modeled cell temperature [C]\n750 \n751         Notes\n752         -----\n753         The Fuentes thermal model uses the module surface tilt for convection\n754         modeling. The SAM implementation of PVWatts hardcodes the surface tilt\n755         value at 30 degrees, ignoring whatever value is used for irradiance\n756         transposition. This method defaults to using ``self.surface_tilt``, but\n757         if you want to match the PVWatts behavior, you can override it by\n758         including a ``surface_tilt`` value in ``temperature_model_parameters``.\n759 \n760         The `temp_air` and `wind_speed` parameters may be passed as tuples\n761         to provide different values for each Array in the system. If not\n762         passed as a tuple then the same value is used for input to each Array.\n763         If passed as a tuple the length must be the same as the number of\n764         Arrays.\n765         \"\"\"\n766         # default to using the Array attribute, but allow user to\n767         # override with a custom surface_tilt value\n768         poa_global = self._validate_per_array(poa_global)\n769         temp_air = self._validate_per_array(temp_air, system_wide=True)\n770         wind_speed = self._validate_per_array(wind_speed, system_wide=True)\n771 \n772         def _build_kwargs_fuentes(array):\n773             kwargs = {'surface_tilt': array.surface_tilt}\n774             temp_model_kwargs = _build_kwargs([\n775                 'noct_installed', 'module_height', 'wind_height', 'emissivity',\n776                 'absorption', 'surface_tilt', 'module_width', 'module_length'],\n777                 array.temperature_model_parameters)\n778             kwargs.update(temp_model_kwargs)\n779             return kwargs\n780         return tuple(\n781             temperature.fuentes(\n782                 poa_global, temp_air, wind_speed,\n783                 **_build_kwargs_fuentes(array))\n784             for array, poa_global, temp_air, wind_speed in zip(\n785                 self.arrays, poa_global, temp_air, wind_speed\n786             )\n787         )\n788 \n789     @_unwrap_single_value\n790     def noct_sam_celltemp(self, poa_global, temp_air, wind_speed,\n791                           effective_irradiance=None):\n792         \"\"\"\n793         Use :py:func:`temperature.noct_sam` to calculate cell temperature.\n794 \n795         Parameters\n796         ----------\n797         poa_global : numeric or tuple of numeric\n798             Total incident irradiance in W/m^2.\n799 \n800         temp_air : numeric or tuple of numeric\n801             Ambient dry bulb temperature in degrees C.\n802 \n803         wind_speed : numeric or tuple of numeric\n804             Wind speed in m/s at a height of 10 meters.\n805 \n806         effective_irradiance : numeric, tuple of numeric, or None.\n807             The irradiance that is converted to photocurrent. If None,\n808             assumed equal to ``poa_global``. [W/m^2]\n809 \n810         Returns\n811         -------\n812         temperature_cell : numeric or tuple of numeric\n813             The modeled cell temperature [C]\n814 \n815         Notes\n816         -----\n817         The `temp_air` and `wind_speed` parameters may be passed as tuples\n818         to provide different values for each Array in the system. If not\n819         passed as a tuple then the same value is used for input to each Array.\n820         If passed as a tuple the length must be the same as the number of\n821         Arrays.\n822         \"\"\"\n823         # default to using the Array attribute, but allow user to\n824         # override with a custom surface_tilt value\n825         poa_global = self._validate_per_array(poa_global)\n826         temp_air = self._validate_per_array(temp_air, system_wide=True)\n827         wind_speed = self._validate_per_array(wind_speed, system_wide=True)\n828 \n829         # need effective_irradiance to be an iterable\n830         if effective_irradiance is None:\n831             effective_irradiance = tuple([None] * self.num_arrays)\n832         else:\n833             effective_irradiance = self._validate_per_array(\n834                 effective_irradiance)\n835 \n836         def _build_kwargs_noct_sam(array):\n837             temp_model_kwargs = _build_kwargs([\n838                 'transmittance_absorptance',\n839                 'array_height', 'mount_standoff'],\n840                 array.temperature_model_parameters)\n841             try:\n842                 # noct_sam required args\n843                 # bundled with kwargs for simplicity\n844                 temp_model_kwargs['noct'] = \\\n845                     array.temperature_model_parameters['noct']\n846                 temp_model_kwargs['eta_m_ref'] = \\\n847                     array.temperature_model_parameters['eta_m_ref']\n848             except KeyError:\n849                 msg = ('Parameters noct and eta_m_ref are required.'\n850                        ' Found {} in temperature_model_parameters.'\n851                        .format(array.temperature_model_parameters))\n852                 raise KeyError(msg)\n853             return temp_model_kwargs\n854         return tuple(\n855             temperature.noct_sam(\n856                 poa_global, temp_air, wind_speed,\n857                 effective_irradiance=eff_irrad,\n858                 **_build_kwargs_noct_sam(array))\n859             for array, poa_global, temp_air, wind_speed, eff_irrad in zip(\n860                 self.arrays, poa_global, temp_air, wind_speed,\n861                 effective_irradiance\n862             )\n863         )\n864 \n865     @_unwrap_single_value\n866     def first_solar_spectral_loss(self, pw, airmass_absolute):\n867 \n868         \"\"\"\n869         Use the :py:func:`first_solar_spectral_correction` function to\n870         calculate the spectral loss modifier. The model coefficients are\n871         specific to the module's cell type, and are determined by searching\n872         for one of the following keys in self.module_parameters (in order):\n873 \n874         - 'first_solar_spectral_coefficients' (user-supplied coefficients)\n875         - 'Technology' - a string describing the cell type, can be read from\n876           the CEC module parameter database\n877         - 'Material' - a string describing the cell type, can be read from\n878           the Sandia module database.\n879 \n880         Parameters\n881         ----------\n882         pw : array-like\n883             atmospheric precipitable water (cm).\n884 \n885         airmass_absolute : array-like\n886             absolute (pressure corrected) airmass.\n887 \n888         Returns\n889         -------\n890         modifier: array-like or tuple of array-like\n891             spectral mismatch factor (unitless) which can be multiplied\n892             with broadband irradiance reaching a module's cells to estimate\n893             effective irradiance, i.e., the irradiance that is converted to\n894             electrical current.\n895         \"\"\"\n896         pw = self._validate_per_array(pw, system_wide=True)\n897 \n898         def _spectral_correction(array, pw):\n899             if 'first_solar_spectral_coefficients' in \\\n900                     array.module_parameters.keys():\n901                 coefficients = \\\n902                     array.module_parameters[\n903                         'first_solar_spectral_coefficients'\n904                     ]\n905                 module_type = None\n906             else:\n907                 module_type = array._infer_cell_type()\n908                 coefficients = None\n909 \n910             return atmosphere.first_solar_spectral_correction(\n911                 pw, airmass_absolute,\n912                 module_type, coefficients\n913             )\n914         return tuple(\n915             itertools.starmap(_spectral_correction, zip(self.arrays, pw))\n916         )\n917 \n918     def singlediode(self, photocurrent, saturation_current,\n919                     resistance_series, resistance_shunt, nNsVth,\n920                     ivcurve_pnts=None):\n921         \"\"\"Wrapper around the :py:func:`pvlib.pvsystem.singlediode` function.\n922 \n923         See :py:func:`pvsystem.singlediode` for details\n924         \"\"\"\n925         return singlediode(photocurrent, saturation_current,\n926                            resistance_series, resistance_shunt, nNsVth,\n927                            ivcurve_pnts=ivcurve_pnts)\n928 \n929     def i_from_v(self, resistance_shunt, resistance_series, nNsVth, voltage,\n930                  saturation_current, photocurrent):\n931         \"\"\"Wrapper around the :py:func:`pvlib.pvsystem.i_from_v` function.\n932 \n933         See :py:func:`pvsystem.i_from_v` for details\n934         \"\"\"\n935         return i_from_v(resistance_shunt, resistance_series, nNsVth, voltage,\n936                         saturation_current, photocurrent)\n937 \n938     def get_ac(self, model, p_dc, v_dc=None):\n939         r\"\"\"Calculates AC power from p_dc using the inverter model indicated\n940         by model and self.inverter_parameters.\n941 \n942         Parameters\n943         ----------\n944         model : str\n945             Must be one of 'sandia', 'adr', or 'pvwatts'.\n946         p_dc : numeric, or tuple, list or array of numeric\n947             DC power on each MPPT input of the inverter. Use tuple, list or\n948             array for inverters with multiple MPPT inputs. If type is array,\n949             p_dc must be 2d with axis 0 being the MPPT inputs. [W]\n950         v_dc : numeric, or tuple, list or array of numeric\n951             DC voltage on each MPPT input of the inverter. Required when\n952             model='sandia' or model='adr'. Use tuple, list or\n953             array for inverters with multiple MPPT inputs. If type is array,\n954             v_dc must be 2d with axis 0 being the MPPT inputs. [V]\n955 \n956         Returns\n957         -------\n958         power_ac : numeric\n959             AC power output for the inverter. [W]\n960 \n961         Raises\n962         ------\n963         ValueError\n964             If model is not one of 'sandia', 'adr' or 'pvwatts'.\n965         ValueError\n966             If model='adr' and the PVSystem has more than one array.\n967 \n968         See also\n969         --------\n970         pvlib.inverter.sandia\n971         pvlib.inverter.sandia_multi\n972         pvlib.inverter.adr\n973         pvlib.inverter.pvwatts\n974         pvlib.inverter.pvwatts_multi\n975         \"\"\"\n976         model = model.lower()\n977         multiple_arrays = self.num_arrays > 1\n978         if model == 'sandia':\n979             p_dc = self._validate_per_array(p_dc)\n980             v_dc = self._validate_per_array(v_dc)\n981             if multiple_arrays:\n982                 return inverter.sandia_multi(\n983                     v_dc, p_dc, self.inverter_parameters)\n984             return inverter.sandia(v_dc[0], p_dc[0], self.inverter_parameters)\n985         elif model == 'pvwatts':\n986             kwargs = _build_kwargs(['eta_inv_nom', 'eta_inv_ref'],\n987                                    self.inverter_parameters)\n988             p_dc = self._validate_per_array(p_dc)\n989             if multiple_arrays:\n990                 return inverter.pvwatts_multi(\n991                     p_dc, self.inverter_parameters['pdc0'], **kwargs)\n992             return inverter.pvwatts(\n993                 p_dc[0], self.inverter_parameters['pdc0'], **kwargs)\n994         elif model == 'adr':\n995             if multiple_arrays:\n996                 raise ValueError(\n997                     'The adr inverter function cannot be used for an inverter',\n998                     ' with multiple MPPT inputs')\n999             # While this is only used for single-array systems, calling\n1000             # _validate_per_arry lets us pass in singleton tuples.\n1001             p_dc = self._validate_per_array(p_dc)\n1002             v_dc = self._validate_per_array(v_dc)\n1003             return inverter.adr(v_dc[0], p_dc[0], self.inverter_parameters)\n1004         else:\n1005             raise ValueError(\n1006                 model + ' is not a valid AC power model.',\n1007                 ' model must be one of \"sandia\", \"adr\" or \"pvwatts\"')\n1008 \n1009     @deprecated('0.9', alternative='PVSystem.get_ac', removal='0.10')\n1010     def snlinverter(self, v_dc, p_dc):\n1011         \"\"\"Uses :py:func:`pvlib.inverter.sandia` to calculate AC power based on\n1012         ``self.inverter_parameters`` and the input voltage and power.\n1013 \n1014         See :py:func:`pvlib.inverter.sandia` for details\n1015         \"\"\"\n1016         return inverter.sandia(v_dc, p_dc, self.inverter_parameters)\n1017 \n1018     @deprecated('0.9', alternative='PVSystem.get_ac', removal='0.10')\n1019     def adrinverter(self, v_dc, p_dc):\n1020         \"\"\"Uses :py:func:`pvlib.inverter.adr` to calculate AC power based on\n1021         ``self.inverter_parameters`` and the input voltage and power.\n1022 \n1023         See :py:func:`pvlib.inverter.adr` for details\n1024         \"\"\"\n1025         return inverter.adr(v_dc, p_dc, self.inverter_parameters)\n1026 \n1027     @_unwrap_single_value\n1028     def scale_voltage_current_power(self, data):\n1029         \"\"\"\n1030         Scales the voltage, current, and power of the `data` DataFrame\n1031         by `self.modules_per_string` and `self.strings_per_inverter`.\n1032 \n1033         Parameters\n1034         ----------\n1035         data: DataFrame or tuple of DataFrame\n1036             May contain columns `'v_mp', 'v_oc', 'i_mp' ,'i_x', 'i_xx',\n1037             'i_sc', 'p_mp'`.\n1038 \n1039         Returns\n1040         -------\n1041         scaled_data: DataFrame or tuple of DataFrame\n1042             A scaled copy of the input data.\n1043         \"\"\"\n1044         data = self._validate_per_array(data)\n1045         return tuple(\n1046             scale_voltage_current_power(data,\n1047                                         voltage=array.modules_per_string,\n1048                                         current=array.strings)\n1049             for array, data in zip(self.arrays, data)\n1050         )\n1051 \n1052     @_unwrap_single_value\n1053     def pvwatts_dc(self, g_poa_effective, temp_cell):\n1054         \"\"\"\n1055         Calcuates DC power according to the PVWatts model using\n1056         :py:func:`pvlib.pvsystem.pvwatts_dc`, `self.module_parameters['pdc0']`,\n1057         and `self.module_parameters['gamma_pdc']`.\n1058 \n1059         See :py:func:`pvlib.pvsystem.pvwatts_dc` for details.\n1060         \"\"\"\n1061         g_poa_effective = self._validate_per_array(g_poa_effective)\n1062         temp_cell = self._validate_per_array(temp_cell)\n1063         return tuple(\n1064             pvwatts_dc(g_poa_effective, temp_cell,\n1065                        array.module_parameters['pdc0'],\n1066                        array.module_parameters['gamma_pdc'],\n1067                        **_build_kwargs(['temp_ref'], array.module_parameters))\n1068             for array, g_poa_effective, temp_cell\n1069             in zip(self.arrays, g_poa_effective, temp_cell)\n1070         )\n1071 \n1072     def pvwatts_losses(self):\n1073         \"\"\"\n1074         Calculates DC power losses according the PVwatts model using\n1075         :py:func:`pvlib.pvsystem.pvwatts_losses` and\n1076         ``self.losses_parameters``.\n1077 \n1078         See :py:func:`pvlib.pvsystem.pvwatts_losses` for details.\n1079         \"\"\"\n1080         kwargs = _build_kwargs(['soiling', 'shading', 'snow', 'mismatch',\n1081                                 'wiring', 'connections', 'lid',\n1082                                 'nameplate_rating', 'age', 'availability'],\n1083                                self.losses_parameters)\n1084         return pvwatts_losses(**kwargs)\n1085 \n1086     @deprecated('0.9', alternative='PVSystem.get_ac', removal='0.10')\n1087     def pvwatts_ac(self, pdc):\n1088         \"\"\"\n1089         Calculates AC power according to the PVWatts model using\n1090         :py:func:`pvlib.inverter.pvwatts`, `self.module_parameters[\"pdc0\"]`,\n1091         and `eta_inv_nom=self.inverter_parameters[\"eta_inv_nom\"]`.\n1092 \n1093         See :py:func:`pvlib.inverter.pvwatts` for details.\n1094         \"\"\"\n1095         kwargs = _build_kwargs(['eta_inv_nom', 'eta_inv_ref'],\n1096                                self.inverter_parameters)\n1097 \n1098         return inverter.pvwatts(pdc, self.inverter_parameters['pdc0'],\n1099                                 **kwargs)\n1100 \n1101     @_unwrap_single_value\n1102     def dc_ohms_from_percent(self):\n1103         \"\"\"\n1104         Calculates the equivalent resistance of the wires for each array using\n1105         :py:func:`pvlib.pvsystem.dc_ohms_from_percent`\n1106 \n1107         See :py:func:`pvlib.pvsystem.dc_ohms_from_percent` for details.\n1108         \"\"\"\n1109 \n1110         return tuple(array.dc_ohms_from_percent() for array in self.arrays)\n1111 \n1112     @property\n1113     @_unwrap_single_value\n1114     def module_parameters(self):\n1115         return tuple(array.module_parameters for array in self.arrays)\n1116 \n1117     @property\n1118     @_unwrap_single_value\n1119     def module(self):\n1120         return tuple(array.module for array in self.arrays)\n1121 \n1122     @property\n1123     @_unwrap_single_value\n1124     def module_type(self):\n1125         return tuple(array.module_type for array in self.arrays)\n1126 \n1127     @property\n1128     @_unwrap_single_value\n1129     def temperature_model_parameters(self):\n1130         return tuple(array.temperature_model_parameters\n1131                      for array in self.arrays)\n1132 \n1133     @temperature_model_parameters.setter\n1134     def temperature_model_parameters(self, value):\n1135         for array in self.arrays:\n1136             array.temperature_model_parameters = value\n1137 \n1138     @property\n1139     @_unwrap_single_value\n1140     def surface_tilt(self):\n1141         return tuple(array.surface_tilt for array in self.arrays)\n1142 \n1143     @surface_tilt.setter\n1144     def surface_tilt(self, value):\n1145         for array in self.arrays:\n1146             array.surface_tilt = value\n1147 \n1148     @property\n1149     @_unwrap_single_value\n1150     def surface_azimuth(self):\n1151         return tuple(array.surface_azimuth for array in self.arrays)\n1152 \n1153     @surface_azimuth.setter\n1154     def surface_azimuth(self, value):\n1155         for array in self.arrays:\n1156             array.surface_azimuth = value\n1157 \n1158     @property\n1159     @_unwrap_single_value\n1160     def albedo(self):\n1161         return tuple(array.albedo for array in self.arrays)\n1162 \n1163     @property\n1164     @_unwrap_single_value\n1165     def racking_model(self):\n1166         return tuple(array.racking_model for array in self.arrays)\n1167 \n1168     @racking_model.setter\n1169     def racking_model(self, value):\n1170         for array in self.arrays:\n1171             array.racking_model = value\n1172 \n1173     @property\n1174     @_unwrap_single_value\n1175     def modules_per_string(self):\n1176         return tuple(array.modules_per_string for array in self.arrays)\n1177 \n1178     @property\n1179     @_unwrap_single_value\n1180     def strings_per_inverter(self):\n1181         return tuple(array.strings for array in self.arrays)\n1182 \n1183     @property\n1184     def num_arrays(self):\n1185         \"\"\"The number of Arrays in the system.\"\"\"\n1186         return len(self.arrays)\n1187 \n1188 \n1189 class Array:\n1190     \"\"\"\n1191     An Array is a set of of modules at the same orientation.\n1192 \n1193     Specifically, an array is defined by tilt, azimuth, the\n1194     module parameters, the number of parallel strings of modules\n1195     and the number of modules on each string.\n1196 \n1197     Parameters\n1198     ----------\n1199     surface_tilt: float or array-like, default 0\n1200         Surface tilt angles in decimal degrees.\n1201         The tilt angle is defined as degrees from horizontal\n1202         (e.g. surface facing up = 0, surface facing horizon = 90)\n1203 \n1204     surface_azimuth: float or array-like, default 180\n1205         Azimuth angle of the module surface.\n1206         North=0, East=90, South=180, West=270.\n1207 \n1208     albedo : None or float, default None\n1209         The ground albedo. If ``None``, will attempt to use\n1210         ``surface_type`` to look up an albedo value in\n1211         ``irradiance.SURFACE_ALBEDOS``. If a surface albedo\n1212         cannot be found then 0.25 is used.\n1213 \n1214     surface_type : None or string, default None\n1215         The ground surface type. See ``irradiance.SURFACE_ALBEDOS``\n1216         for valid values.\n1217 \n1218     module : None or string, default None\n1219         The model name of the modules.\n1220         May be used to look up the module_parameters dictionary\n1221         via some other method.\n1222 \n1223     module_type : None or string, default None\n1224          Describes the module's construction. Valid strings are 'glass_polymer'\n1225          and 'glass_glass'. Used for cell and module temperature calculations.\n1226 \n1227     module_parameters : None, dict or Series, default None\n1228         Parameters for the module model, e.g., SAPM, CEC, or other.\n1229 \n1230     temperature_model_parameters : None, dict or Series, default None.\n1231         Parameters for the module temperature model, e.g., SAPM, Pvsyst, or\n1232         other.\n1233 \n1234     modules_per_string: int, default 1\n1235         Number of modules per string in the array.\n1236 \n1237     strings: int, default 1\n1238         Number of parallel strings in the array.\n1239 \n1240     racking_model : None or string, default None\n1241         Valid strings are 'open_rack', 'close_mount', and 'insulated_back'.\n1242         Used to identify a parameter set for the SAPM cell temperature model.\n1243 \n1244     array_losses_parameters: None, dict or Series, default None.\n1245         Supported keys are 'dc_ohmic_percent'.\n1246 \n1247     \"\"\"\n1248 \n1249     def __init__(self,\n1250                  surface_tilt=0, surface_azimuth=180,\n1251                  albedo=None, surface_type=None,\n1252                  module=None, module_type=None,\n1253                  module_parameters=None,\n1254                  temperature_model_parameters=None,\n1255                  modules_per_string=1, strings=1,\n1256                  racking_model=None, array_losses_parameters=None,\n1257                  name=None):\n1258         self.surface_tilt = surface_tilt\n1259         self.surface_azimuth = surface_azimuth\n1260 \n1261         self.surface_type = surface_type\n1262         if albedo is None:\n1263             self.albedo = irradiance.SURFACE_ALBEDOS.get(surface_type, 0.25)\n1264         else:\n1265             self.albedo = albedo\n1266 \n1267         self.module = module\n1268         if module_parameters is None:\n1269             self.module_parameters = {}\n1270         else:\n1271             self.module_parameters = module_parameters\n1272 \n1273         self.module_type = module_type\n1274         self.racking_model = racking_model\n1275 \n1276         self.strings = strings\n1277         self.modules_per_string = modules_per_string\n1278 \n1279         if temperature_model_parameters is None:\n1280             self.temperature_model_parameters = \\\n1281                 self._infer_temperature_model_params()\n1282         else:\n1283             self.temperature_model_parameters = temperature_model_parameters\n1284 \n1285         if array_losses_parameters is None:\n1286             self.array_losses_parameters = {}\n1287         else:\n1288             self.array_losses_parameters = array_losses_parameters\n1289 \n1290         self.name = name\n1291 \n1292     def __repr__(self):\n1293         attrs = ['name', 'surface_tilt', 'surface_azimuth', 'module',\n1294                  'albedo', 'racking_model', 'module_type',\n1295                  'temperature_model_parameters',\n1296                  'strings', 'modules_per_string']\n1297         return 'Array:\\n  ' + '\\n  '.join(\n1298             f'{attr}: {getattr(self, attr)}' for attr in attrs\n1299         )\n1300 \n1301     def _infer_temperature_model_params(self):\n1302         # try to infer temperature model parameters from from racking_model\n1303         # and module_type\n1304         param_set = f'{self.racking_model}_{self.module_type}'\n1305         if param_set in temperature.TEMPERATURE_MODEL_PARAMETERS['sapm']:\n1306             return temperature._temperature_model_params('sapm', param_set)\n1307         elif 'freestanding' in param_set:\n1308             return temperature._temperature_model_params('pvsyst',\n1309                                                          'freestanding')\n1310         elif 'insulated' in param_set:  # after SAPM to avoid confusing keys\n1311             return temperature._temperature_model_params('pvsyst',\n1312                                                          'insulated')\n1313         else:\n1314             return {}\n1315 \n1316     def _infer_cell_type(self):\n1317 \n1318         \"\"\"\n1319         Examines module_parameters and maps the Technology key for the CEC\n1320         database and the Material key for the Sandia database to a common\n1321         list of strings for cell type.\n1322 \n1323         Returns\n1324         -------\n1325         cell_type: str\n1326 \n1327         \"\"\"\n1328 \n1329         _cell_type_dict = {'Multi-c-Si': 'multisi',\n1330                            'Mono-c-Si': 'monosi',\n1331                            'Thin Film': 'cigs',\n1332                            'a-Si/nc': 'asi',\n1333                            'CIS': 'cigs',\n1334                            'CIGS': 'cigs',\n1335                            '1-a-Si': 'asi',\n1336                            'CdTe': 'cdte',\n1337                            'a-Si': 'asi',\n1338                            '2-a-Si': None,\n1339                            '3-a-Si': None,\n1340                            'HIT-Si': 'monosi',\n1341                            'mc-Si': 'multisi',\n1342                            'c-Si': 'multisi',\n1343                            'Si-Film': 'asi',\n1344                            'EFG mc-Si': 'multisi',\n1345                            'GaAs': None,\n1346                            'a-Si / mono-Si': 'monosi'}\n1347 \n1348         if 'Technology' in self.module_parameters.keys():\n1349             # CEC module parameter set\n1350             cell_type = _cell_type_dict[self.module_parameters['Technology']]\n1351         elif 'Material' in self.module_parameters.keys():\n1352             # Sandia module parameter set\n1353             cell_type = _cell_type_dict[self.module_parameters['Material']]\n1354         else:\n1355             cell_type = None\n1356 \n1357         return cell_type\n1358 \n1359     def get_aoi(self, solar_zenith, solar_azimuth):\n1360         \"\"\"\n1361         Get the angle of incidence on the array.\n1362 \n1363         Parameters\n1364         ----------\n1365         solar_zenith : float or Series\n1366             Solar zenith angle.\n1367         solar_azimuth : float or Series\n1368             Solar azimuth angle\n1369 \n1370         Returns\n1371         -------\n1372         aoi : Series\n1373             Then angle of incidence.\n1374         \"\"\"\n1375         return irradiance.aoi(self.surface_tilt, self.surface_azimuth,\n1376                               solar_zenith, solar_azimuth)\n1377 \n1378     def get_irradiance(self, solar_zenith, solar_azimuth, dni, ghi, dhi,\n1379                        dni_extra=None, airmass=None, model='haydavies',\n1380                        **kwargs):\n1381         \"\"\"\n1382         Get plane of array irradiance components.\n1383 \n1384         Uses the :py:func:`pvlib.irradiance.get_total_irradiance` function to\n1385         calculate the plane of array irradiance components for a surface\n1386         defined by ``self.surface_tilt`` and ``self.surface_azimuth`` with\n1387         albedo ``self.albedo``.\n1388 \n1389         Parameters\n1390         ----------\n1391         solar_zenith : float or Series.\n1392             Solar zenith angle.\n1393         solar_azimuth : float or Series.\n1394             Solar azimuth angle.\n1395         dni : float or Series\n1396             Direct Normal Irradiance\n1397         ghi : float or Series\n1398             Global horizontal irradiance\n1399         dhi : float or Series\n1400             Diffuse horizontal irradiance\n1401         dni_extra : None, float or Series, default None\n1402             Extraterrestrial direct normal irradiance\n1403         airmass : None, float or Series, default None\n1404             Airmass\n1405         model : String, default 'haydavies'\n1406             Irradiance model.\n1407 \n1408         kwargs\n1409             Extra parameters passed to\n1410             :py:func:`pvlib.irradiance.get_total_irradiance`.\n1411 \n1412         Returns\n1413         -------\n1414         poa_irradiance : DataFrame\n1415             Column names are: ``total, beam, sky, ground``.\n1416         \"\"\"\n1417         # not needed for all models, but this is easier\n1418         if dni_extra is None:\n1419             dni_extra = irradiance.get_extra_radiation(solar_zenith.index)\n1420 \n1421         if airmass is None:\n1422             airmass = atmosphere.get_relative_airmass(solar_zenith)\n1423 \n1424         return irradiance.get_total_irradiance(self.surface_tilt,\n1425                                                self.surface_azimuth,\n1426                                                solar_zenith, solar_azimuth,\n1427                                                dni, ghi, dhi,\n1428                                                dni_extra=dni_extra,\n1429                                                airmass=airmass,\n1430                                                model=model,\n1431                                                albedo=self.albedo,\n1432                                                **kwargs)\n1433 \n1434     def get_iam(self, aoi, iam_model='physical'):\n1435         \"\"\"\n1436         Determine the incidence angle modifier using the method specified by\n1437         ``iam_model``.\n1438 \n1439         Parameters for the selected IAM model are expected to be in\n1440         ``Array.module_parameters``. Default parameters are available for\n1441         the 'physical', 'ashrae' and 'martin_ruiz' models.\n1442 \n1443         Parameters\n1444         ----------\n1445         aoi : numeric\n1446             The angle of incidence in degrees.\n1447 \n1448         aoi_model : string, default 'physical'\n1449             The IAM model to be used. Valid strings are 'physical', 'ashrae',\n1450             'martin_ruiz' and 'sapm'.\n1451 \n1452         Returns\n1453         -------\n1454         iam : numeric\n1455             The AOI modifier.\n1456 \n1457         Raises\n1458         ------\n1459         ValueError\n1460             if `iam_model` is not a valid model name.\n1461         \"\"\"\n1462         model = iam_model.lower()\n1463         if model in ['ashrae', 'physical', 'martin_ruiz']:\n1464             param_names = iam._IAM_MODEL_PARAMS[model]\n1465             kwargs = _build_kwargs(param_names, self.module_parameters)\n1466             func = getattr(iam, model)\n1467             return func(aoi, **kwargs)\n1468         elif model == 'sapm':\n1469             return iam.sapm(aoi, self.module_parameters)\n1470         elif model == 'interp':\n1471             raise ValueError(model + ' is not implemented as an IAM model '\n1472                              'option for Array')\n1473         else:\n1474             raise ValueError(model + ' is not a valid IAM model')\n1475 \n1476     def dc_ohms_from_percent(self):\n1477         \"\"\"\n1478         Calculates the equivalent resistance of the wires using\n1479         :py:func:`pvlib.pvsystem.dc_ohms_from_percent`\n1480 \n1481         Makes use of array module parameters according to the\n1482         following DC models:\n1483 \n1484         CEC:\n1485 \n1486             * `self.module_parameters[\"V_mp_ref\"]`\n1487             * `self.module_parameters[\"I_mp_ref\"]`\n1488 \n1489         SAPM:\n1490 \n1491             * `self.module_parameters[\"Vmpo\"]`\n1492             * `self.module_parameters[\"Impo\"]`\n1493 \n1494         PVsyst-like or other:\n1495 \n1496             * `self.module_parameters[\"Vmpp\"]`\n1497             * `self.module_parameters[\"Impp\"]`\n1498 \n1499         Other array parameters that are used are:\n1500         `self.losses_parameters[\"dc_ohmic_percent\"]`,\n1501         `self.modules_per_string`, and\n1502         `self.strings`.\n1503 \n1504         See :py:func:`pvlib.pvsystem.dc_ohms_from_percent` for more details.\n1505         \"\"\"\n1506 \n1507         # get relevent Vmp and Imp parameters from CEC parameters\n1508         if all([elem in self.module_parameters\n1509                 for elem in ['V_mp_ref', 'I_mp_ref']]):\n1510             vmp_ref = self.module_parameters['V_mp_ref']\n1511             imp_ref = self.module_parameters['I_mp_ref']\n1512 \n1513         # get relevant Vmp and Imp parameters from SAPM parameters\n1514         elif all([elem in self.module_parameters\n1515                   for elem in ['Vmpo', 'Impo']]):\n1516             vmp_ref = self.module_parameters['Vmpo']\n1517             imp_ref = self.module_parameters['Impo']\n1518 \n1519         # get relevant Vmp and Imp parameters if they are PVsyst-like\n1520         elif all([elem in self.module_parameters\n1521                   for elem in ['Vmpp', 'Impp']]):\n1522             vmp_ref = self.module_parameters['Vmpp']\n1523             imp_ref = self.module_parameters['Impp']\n1524 \n1525         # raise error if relevant Vmp and Imp parameters are not found\n1526         else:\n1527             raise ValueError('Parameters for Vmp and Imp could not be found '\n1528                              'in the array module parameters. Module '\n1529                              'parameters must include one set of '\n1530                              '{\"V_mp_ref\", \"I_mp_Ref\"}, '\n1531                              '{\"Vmpo\", \"Impo\"}, or '\n1532                              '{\"Vmpp\", \"Impp\"}.'\n1533                              )\n1534 \n1535         return dc_ohms_from_percent(\n1536             vmp_ref,\n1537             imp_ref,\n1538             self.array_losses_parameters['dc_ohmic_percent'],\n1539             self.modules_per_string,\n1540             self.strings)\n1541 \n1542 \n1543 def calcparams_desoto(effective_irradiance, temp_cell,\n1544                       alpha_sc, a_ref, I_L_ref, I_o_ref, R_sh_ref, R_s,\n1545                       EgRef=1.121, dEgdT=-0.0002677,\n1546                       irrad_ref=1000, temp_ref=25):\n1547     '''\n1548     Calculates five parameter values for the single diode equation at\n1549     effective irradiance and cell temperature using the De Soto et al.\n1550     model described in [1]_. The five values returned by calcparams_desoto\n1551     can be used by singlediode to calculate an IV curve.\n1552 \n1553     Parameters\n1554     ----------\n1555     effective_irradiance : numeric\n1556         The irradiance (W/m2) that is converted to photocurrent.\n1557 \n1558     temp_cell : numeric\n1559         The average cell temperature of cells within a module in C.\n1560 \n1561     alpha_sc : float\n1562         The short-circuit current temperature coefficient of the\n1563         module in units of A/C.\n1564 \n1565     a_ref : float\n1566         The product of the usual diode ideality factor (n, unitless),\n1567         number of cells in series (Ns), and cell thermal voltage at reference\n1568         conditions, in units of V.\n1569 \n1570     I_L_ref : float\n1571         The light-generated current (or photocurrent) at reference conditions,\n1572         in amperes.\n1573 \n1574     I_o_ref : float\n1575         The dark or diode reverse saturation current at reference conditions,\n1576         in amperes.\n1577 \n1578     R_sh_ref : float\n1579         The shunt resistance at reference conditions, in ohms.\n1580 \n1581     R_s : float\n1582         The series resistance at reference conditions, in ohms.\n1583 \n1584     EgRef : float\n1585         The energy bandgap at reference temperature in units of eV.\n1586         1.121 eV for crystalline silicon. EgRef must be >0.  For parameters\n1587         from the SAM CEC module database, EgRef=1.121 is implicit for all\n1588         cell types in the parameter estimation algorithm used by NREL.\n1589 \n1590     dEgdT : float\n1591         The temperature dependence of the energy bandgap at reference\n1592         conditions in units of 1/K. May be either a scalar value\n1593         (e.g. -0.0002677 as in [1]_) or a DataFrame (this may be useful if\n1594         dEgdT is a modeled as a function of temperature). For parameters from\n1595         the SAM CEC module database, dEgdT=-0.0002677 is implicit for all cell\n1596         types in the parameter estimation algorithm used by NREL.\n1597 \n1598     irrad_ref : float (optional, default=1000)\n1599         Reference irradiance in W/m^2.\n1600 \n1601     temp_ref : float (optional, default=25)\n1602         Reference cell temperature in C.\n1603 \n1604     Returns\n1605     -------\n1606     Tuple of the following results:\n1607 \n1608     photocurrent : numeric\n1609         Light-generated current in amperes\n1610 \n1611     saturation_current : numeric\n1612         Diode saturation curent in amperes\n1613 \n1614     resistance_series : float\n1615         Series resistance in ohms\n1616 \n1617     resistance_shunt : numeric\n1618         Shunt resistance in ohms\n1619 \n1620     nNsVth : numeric\n1621         The product of the usual diode ideality factor (n, unitless),\n1622         number of cells in series (Ns), and cell thermal voltage at\n1623         specified effective irradiance and cell temperature.\n1624 \n1625     References\n1626     ----------\n1627     .. [1] W. De Soto et al., \"Improvement and validation of a model for\n1628        photovoltaic array performance\", Solar Energy, vol 80, pp. 78-88,\n1629        2006.\n1630 \n1631     .. [2] System Advisor Model web page. https://sam.nrel.gov.\n1632 \n1633     .. [3] A. Dobos, \"An Improved Coefficient Calculator for the California\n1634        Energy Commission 6 Parameter Photovoltaic Module Model\", Journal of\n1635        Solar Energy Engineering, vol 134, 2012.\n1636 \n1637     .. [4] O. Madelung, \"Semiconductors: Data Handbook, 3rd ed.\" ISBN\n1638        3-540-40488-0\n1639 \n1640     See Also\n1641     --------\n1642     singlediode\n1643     retrieve_sam\n1644 \n1645     Notes\n1646     -----\n1647     If the reference parameters in the ModuleParameters struct are read\n1648     from a database or library of parameters (e.g. System Advisor\n1649     Model), it is important to use the same EgRef and dEgdT values that\n1650     were used to generate the reference parameters, regardless of the\n1651     actual bandgap characteristics of the semiconductor. For example, in\n1652     the case of the System Advisor Model library, created as described\n1653     in [3], EgRef and dEgdT for all modules were 1.121 and -0.0002677,\n1654     respectively.\n1655 \n1656     This table of reference bandgap energies (EgRef), bandgap energy\n1657     temperature dependence (dEgdT), and \"typical\" airmass response (M)\n1658     is provided purely as reference to those who may generate their own\n1659     reference module parameters (a_ref, IL_ref, I0_ref, etc.) based upon\n1660     the various PV semiconductors. Again, we stress the importance of\n1661     using identical EgRef and dEgdT when generation reference parameters\n1662     and modifying the reference parameters (for irradiance, temperature,\n1663     and airmass) per DeSoto's equations.\n1664 \n1665      Crystalline Silicon (Si):\n1666          * EgRef = 1.121\n1667          * dEgdT = -0.0002677\n1668 \n1669          >>> M = np.polyval([-1.26E-4, 2.816E-3, -0.024459, 0.086257, 0.9181],\n1670          ...                AMa) # doctest: +SKIP\n1671 \n1672          Source: [1]\n1673 \n1674      Cadmium Telluride (CdTe):\n1675          * EgRef = 1.475\n1676          * dEgdT = -0.0003\n1677 \n1678          >>> M = np.polyval([-2.46E-5, 9.607E-4, -0.0134, 0.0716, 0.9196],\n1679          ...                AMa) # doctest: +SKIP\n1680 \n1681          Source: [4]\n1682 \n1683      Copper Indium diSelenide (CIS):\n1684          * EgRef = 1.010\n1685          * dEgdT = -0.00011\n1686 \n1687          >>> M = np.polyval([-3.74E-5, 0.00125, -0.01462, 0.0718, 0.9210],\n1688          ...                AMa) # doctest: +SKIP\n1689 \n1690          Source: [4]\n1691 \n1692      Copper Indium Gallium diSelenide (CIGS):\n1693          * EgRef = 1.15\n1694          * dEgdT = ????\n1695 \n1696          >>> M = np.polyval([-9.07E-5, 0.0022, -0.0202, 0.0652, 0.9417],\n1697          ...                AMa) # doctest: +SKIP\n1698 \n1699          Source: Wikipedia\n1700 \n1701      Gallium Arsenide (GaAs):\n1702          * EgRef = 1.424\n1703          * dEgdT = -0.000433\n1704          * M = unknown\n1705 \n1706          Source: [4]\n1707     '''\n1708 \n1709     # Boltzmann constant in eV/K\n1710     k = 8.617332478e-05\n1711 \n1712     # reference temperature\n1713     Tref_K = temp_ref + 273.15\n1714     Tcell_K = temp_cell + 273.15\n1715 \n1716     E_g = EgRef * (1 + dEgdT*(Tcell_K - Tref_K))\n1717 \n1718     nNsVth = a_ref * (Tcell_K / Tref_K)\n1719 \n1720     # In the equation for IL, the single factor effective_irradiance is\n1721     # used, in place of the product S*M in [1]. effective_irradiance is\n1722     # equivalent to the product of S (irradiance reaching a module's cells) *\n1723     # M (spectral adjustment factor) as described in [1].\n1724     IL = effective_irradiance / irrad_ref * \\\n1725         (I_L_ref + alpha_sc * (Tcell_K - Tref_K))\n1726     I0 = (I_o_ref * ((Tcell_K / Tref_K) ** 3) *\n1727           (np.exp(EgRef / (k*(Tref_K)) - (E_g / (k*(Tcell_K))))))\n1728     # Note that the equation for Rsh differs from [1]. In [1] Rsh is given as\n1729     # Rsh = Rsh_ref * (S_ref / S) where S is broadband irradiance reaching\n1730     # the module's cells. If desired this model behavior can be duplicated\n1731     # by applying reflection and soiling losses to broadband plane of array\n1732     # irradiance and not applying a spectral loss modifier, i.e.,\n1733     # spectral_modifier = 1.0.\n1734     # use errstate to silence divide by warning\n1735     with np.errstate(divide='ignore'):\n1736         Rsh = R_sh_ref * (irrad_ref / effective_irradiance)\n1737     Rs = R_s\n1738 \n1739     return IL, I0, Rs, Rsh, nNsVth\n1740 \n1741 \n1742 def calcparams_cec(effective_irradiance, temp_cell,\n1743                    alpha_sc, a_ref, I_L_ref, I_o_ref, R_sh_ref, R_s,\n1744                    Adjust, EgRef=1.121, dEgdT=-0.0002677,\n1745                    irrad_ref=1000, temp_ref=25):\n1746     '''\n1747     Calculates five parameter values for the single diode equation at\n1748     effective irradiance and cell temperature using the CEC\n1749     model. The CEC model [1]_ differs from the De soto et al.\n1750     model [3]_ by the parameter Adjust. The five values returned by\n1751     calcparams_cec can be used by singlediode to calculate an IV curve.\n1752 \n1753     Parameters\n1754     ----------\n1755     effective_irradiance : numeric\n1756         The irradiance (W/m2) that is converted to photocurrent.\n1757 \n1758     temp_cell : numeric\n1759         The average cell temperature of cells within a module in C.\n1760 \n1761     alpha_sc : float\n1762         The short-circuit current temperature coefficient of the\n1763         module in units of A/C.\n1764 \n1765     a_ref : float\n1766         The product of the usual diode ideality factor (n, unitless),\n1767         number of cells in series (Ns), and cell thermal voltage at reference\n1768         conditions, in units of V.\n1769 \n1770     I_L_ref : float\n1771         The light-generated current (or photocurrent) at reference conditions,\n1772         in amperes.\n1773 \n1774     I_o_ref : float\n1775         The dark or diode reverse saturation current at reference conditions,\n1776         in amperes.\n1777 \n1778     R_sh_ref : float\n1779         The shunt resistance at reference conditions, in ohms.\n1780 \n1781     R_s : float\n1782         The series resistance at reference conditions, in ohms.\n1783 \n1784     Adjust : float\n1785         The adjustment to the temperature coefficient for short circuit\n1786         current, in percent\n1787 \n1788     EgRef : float\n1789         The energy bandgap at reference temperature in units of eV.\n1790         1.121 eV for crystalline silicon. EgRef must be >0.  For parameters\n1791         from the SAM CEC module database, EgRef=1.121 is implicit for all\n1792         cell types in the parameter estimation algorithm used by NREL.\n1793 \n1794     dEgdT : float\n1795         The temperature dependence of the energy bandgap at reference\n1796         conditions in units of 1/K. May be either a scalar value\n1797         (e.g. -0.0002677 as in [3]) or a DataFrame (this may be useful if\n1798         dEgdT is a modeled as a function of temperature). For parameters from\n1799         the SAM CEC module database, dEgdT=-0.0002677 is implicit for all cell\n1800         types in the parameter estimation algorithm used by NREL.\n1801 \n1802     irrad_ref : float (optional, default=1000)\n1803         Reference irradiance in W/m^2.\n1804 \n1805     temp_ref : float (optional, default=25)\n1806         Reference cell temperature in C.\n1807 \n1808     Returns\n1809     -------\n1810     Tuple of the following results:\n1811 \n1812     photocurrent : numeric\n1813         Light-generated current in amperes\n1814 \n1815     saturation_current : numeric\n1816         Diode saturation curent in amperes\n1817 \n1818     resistance_series : float\n1819         Series resistance in ohms\n1820 \n1821     resistance_shunt : numeric\n1822         Shunt resistance in ohms\n1823 \n1824     nNsVth : numeric\n1825         The product of the usual diode ideality factor (n, unitless),\n1826         number of cells in series (Ns), and cell thermal voltage at\n1827         specified effective irradiance and cell temperature.\n1828 \n1829     References\n1830     ----------\n1831     .. [1] A. Dobos, \"An Improved Coefficient Calculator for the California\n1832        Energy Commission 6 Parameter Photovoltaic Module Model\", Journal of\n1833        Solar Energy Engineering, vol 134, 2012.\n1834 \n1835     .. [2] System Advisor Model web page. https://sam.nrel.gov.\n1836 \n1837     .. [3] W. De Soto et al., \"Improvement and validation of a model for\n1838        photovoltaic array performance\", Solar Energy, vol 80, pp. 78-88,\n1839        2006.\n1840 \n1841     See Also\n1842     --------\n1843     calcparams_desoto\n1844     singlediode\n1845     retrieve_sam\n1846 \n1847     '''\n1848 \n1849     # pass adjusted temperature coefficient to desoto\n1850     return calcparams_desoto(effective_irradiance, temp_cell,\n1851                              alpha_sc*(1.0 - Adjust/100),\n1852                              a_ref, I_L_ref, I_o_ref,\n1853                              R_sh_ref, R_s,\n1854                              EgRef=1.121, dEgdT=-0.0002677,\n1855                              irrad_ref=1000, temp_ref=25)\n1856 \n1857 \n1858 def calcparams_pvsyst(effective_irradiance, temp_cell,\n1859                       alpha_sc, gamma_ref, mu_gamma,\n1860                       I_L_ref, I_o_ref,\n1861                       R_sh_ref, R_sh_0, R_s,\n1862                       cells_in_series,\n1863                       R_sh_exp=5.5,\n1864                       EgRef=1.121,\n1865                       irrad_ref=1000, temp_ref=25):\n1866     '''\n1867     Calculates five parameter values for the single diode equation at\n1868     effective irradiance and cell temperature using the PVsyst v6\n1869     model.  The PVsyst v6 model is described in [1]_, [2]_, [3]_.\n1870     The five values returned by calcparams_pvsyst can be used by singlediode\n1871     to calculate an IV curve.\n1872 \n1873     Parameters\n1874     ----------\n1875     effective_irradiance : numeric\n1876         The irradiance (W/m2) that is converted to photocurrent.\n1877 \n1878     temp_cell : numeric\n1879         The average cell temperature of cells within a module in C.\n1880 \n1881     alpha_sc : float\n1882         The short-circuit current temperature coefficient of the\n1883         module in units of A/C.\n1884 \n1885     gamma_ref : float\n1886         The diode ideality factor\n1887 \n1888     mu_gamma : float\n1889         The temperature coefficient for the diode ideality factor, 1/K\n1890 \n1891     I_L_ref : float\n1892         The light-generated current (or photocurrent) at reference conditions,\n1893         in amperes.\n1894 \n1895     I_o_ref : float\n1896         The dark or diode reverse saturation current at reference conditions,\n1897         in amperes.\n1898 \n1899     R_sh_ref : float\n1900         The shunt resistance at reference conditions, in ohms.\n1901 \n1902     R_sh_0 : float\n1903         The shunt resistance at zero irradiance conditions, in ohms.\n1904 \n1905     R_s : float\n1906         The series resistance at reference conditions, in ohms.\n1907 \n1908     cells_in_series : integer\n1909         The number of cells connected in series.\n1910 \n1911     R_sh_exp : float\n1912         The exponent in the equation for shunt resistance, unitless. Defaults\n1913         to 5.5.\n1914 \n1915     EgRef : float\n1916         The energy bandgap at reference temperature in units of eV.\n1917         1.121 eV for crystalline silicon. EgRef must be >0.\n1918 \n1919     irrad_ref : float (optional, default=1000)\n1920         Reference irradiance in W/m^2.\n1921 \n1922     temp_ref : float (optional, default=25)\n1923         Reference cell temperature in C.\n1924 \n1925     Returns\n1926     -------\n1927     Tuple of the following results:\n1928 \n1929     photocurrent : numeric\n1930         Light-generated current in amperes\n1931 \n1932     saturation_current : numeric\n1933         Diode saturation current in amperes\n1934 \n1935     resistance_series : float\n1936         Series resistance in ohms\n1937 \n1938     resistance_shunt : numeric\n1939         Shunt resistance in ohms\n1940 \n1941     nNsVth : numeric\n1942         The product of the usual diode ideality factor (n, unitless),\n1943         number of cells in series (Ns), and cell thermal voltage at\n1944         specified effective irradiance and cell temperature.\n1945 \n1946     References\n1947     ----------\n1948     .. [1] K. Sauer, T. Roessler, C. W. Hansen, Modeling the Irradiance and\n1949        Temperature Dependence of Photovoltaic Modules in PVsyst,\n1950        IEEE Journal of Photovoltaics v5(1), January 2015.\n1951 \n1952     .. [2] A. Mermoud, PV modules modelling, Presentation at the 2nd PV\n1953        Performance Modeling Workshop, Santa Clara, CA, May 2013\n1954 \n1955     .. [3] A. Mermoud, T. Lejeune, Performance Assessment of a Simulation Model\n1956        for PV modules of any available technology, 25th European Photovoltaic\n1957        Solar Energy Conference, Valencia, Spain, Sept. 2010\n1958 \n1959     See Also\n1960     --------\n1961     calcparams_desoto\n1962     singlediode\n1963 \n1964     '''\n1965 \n1966     # Boltzmann constant in J/K\n1967     k = 1.38064852e-23\n1968 \n1969     # elementary charge in coulomb\n1970     q = 1.6021766e-19\n1971 \n1972     # reference temperature\n1973     Tref_K = temp_ref + 273.15\n1974     Tcell_K = temp_cell + 273.15\n1975 \n1976     gamma = gamma_ref + mu_gamma * (Tcell_K - Tref_K)\n1977     nNsVth = gamma * k / q * cells_in_series * Tcell_K\n1978 \n1979     IL = effective_irradiance / irrad_ref * \\\n1980         (I_L_ref + alpha_sc * (Tcell_K - Tref_K))\n1981 \n1982     I0 = I_o_ref * ((Tcell_K / Tref_K) ** 3) * \\\n1983         (np.exp((q * EgRef) / (k * gamma) * (1 / Tref_K - 1 / Tcell_K)))\n1984 \n1985     Rsh_tmp = \\\n1986         (R_sh_ref - R_sh_0 * np.exp(-R_sh_exp)) / (1.0 - np.exp(-R_sh_exp))\n1987     Rsh_base = np.maximum(0.0, Rsh_tmp)\n1988 \n1989     Rsh = Rsh_base + (R_sh_0 - Rsh_base) * \\\n1990         np.exp(-R_sh_exp * effective_irradiance / irrad_ref)\n1991 \n1992     Rs = R_s\n1993 \n1994     return IL, I0, Rs, Rsh, nNsVth\n1995 \n1996 \n1997 def retrieve_sam(name=None, path=None):\n1998     '''\n1999     Retrieve latest module and inverter info from a local file or the\n2000     SAM website.\n2001 \n2002     This function will retrieve either:\n2003 \n2004         * CEC module database\n2005         * Sandia Module database\n2006         * CEC Inverter database\n2007         * Anton Driesse Inverter database\n2008 \n2009     and return it as a pandas DataFrame.\n2010 \n2011     Parameters\n2012     ----------\n2013     name : None or string, default None\n2014         Name can be one of:\n2015 \n2016         * 'CECMod' - returns the CEC module database\n2017         * 'CECInverter' - returns the CEC Inverter database\n2018         * 'SandiaInverter' - returns the CEC Inverter database\n2019           (CEC is only current inverter db available; tag kept for\n2020           backwards compatibility)\n2021         * 'SandiaMod' - returns the Sandia Module database\n2022         * 'ADRInverter' - returns the ADR Inverter database\n2023 \n2024     path : None or string, default None\n2025         Path to the SAM file. May also be a URL.\n2026 \n2027     Returns\n2028     -------\n2029     samfile : DataFrame\n2030         A DataFrame containing all the elements of the desired database.\n2031         Each column represents a module or inverter, and a specific\n2032         dataset can be retrieved by the command\n2033 \n2034     Raises\n2035     ------\n2036     ValueError\n2037         If no name or path is provided.\n2038 \n2039     Notes\n2040     -----\n2041     Files available at\n2042         https://github.com/NREL/SAM/tree/develop/deploy/libraries\n2043     Documentation for module and inverter data sets:\n2044         https://sam.nrel.gov/photovoltaic/pv-sub-page-2.html\n2045 \n2046     Examples\n2047     --------\n2048 \n2049     >>> from pvlib import pvsystem\n2050     >>> invdb = pvsystem.retrieve_sam('CECInverter')\n2051     >>> inverter = invdb.AE_Solar_Energy__AE6_0__277V__277V__CEC_2012_\n2052     >>> inverter\n2053     Vac           277.000000\n2054     Paco         6000.000000\n2055     Pdco         6165.670000\n2056     Vdco          361.123000\n2057     Pso            36.792300\n2058     C0             -0.000002\n2059     C1             -0.000047\n2060     C2             -0.001861\n2061     C3              0.000721\n2062     Pnt             0.070000\n2063     Vdcmax        600.000000\n2064     Idcmax         32.000000\n2065     Mppt_low      200.000000\n2066     Mppt_high     500.000000\n2067     Name: AE_Solar_Energy__AE6_0__277V__277V__CEC_2012_, dtype: float64\n2068     '''\n2069 \n2070     if name is not None:\n2071         name = name.lower()\n2072         data_path = os.path.join(\n2073             os.path.dirname(os.path.abspath(__file__)), 'data')\n2074         if name == 'cecmod':\n2075             csvdata = os.path.join(\n2076                 data_path, 'sam-library-cec-modules-2019-03-05.csv')\n2077         elif name == 'sandiamod':\n2078             csvdata = os.path.join(\n2079                 data_path, 'sam-library-sandia-modules-2015-6-30.csv')\n2080         elif name == 'adrinverter':\n2081             csvdata = os.path.join(data_path, 'adr-library-2013-10-01.csv')\n2082         elif name in ['cecinverter', 'sandiainverter']:\n2083             # Allowing either, to provide for old code,\n2084             # while aligning with current expectations\n2085             csvdata = os.path.join(\n2086                 data_path, 'sam-library-cec-inverters-2019-03-05.csv')\n2087         else:\n2088             raise ValueError(f'invalid name {name}')\n2089     elif path is not None:\n2090         if path.startswith('http'):\n2091             response = urlopen(path)\n2092             csvdata = io.StringIO(response.read().decode(errors='ignore'))\n2093         else:\n2094             csvdata = path\n2095     elif name is None and path is None:\n2096         raise ValueError(\"A name or path must be provided!\")\n2097 \n2098     return _parse_raw_sam_df(csvdata)\n2099 \n2100 \n2101 def _normalize_sam_product_names(names):\n2102     '''\n2103     Replace special characters within the product names to make them more\n2104     suitable for use as Dataframe column names.\n2105     '''\n2106     # Contributed by Anton Driesse (@adriesse), PV Performance Labs. July, 2019\n2107 \n2108     import warnings\n2109 \n2110     BAD_CHARS = ' -.()[]:+/\",'\n2111     GOOD_CHARS = '____________'\n2112 \n2113     mapping = str.maketrans(BAD_CHARS, GOOD_CHARS)\n2114     names = pd.Series(data=names)\n2115     norm_names = names.str.translate(mapping)\n2116 \n2117     n_duplicates = names.duplicated().sum()\n2118     if n_duplicates > 0:\n2119         warnings.warn('Original names contain %d duplicate(s).' % n_duplicates)\n2120 \n2121     n_duplicates = norm_names.duplicated().sum()\n2122     if n_duplicates > 0:\n2123         warnings.warn(\n2124             'Normalized names contain %d duplicate(s).' % n_duplicates)\n2125 \n2126     return norm_names.values\n2127 \n2128 \n2129 def _parse_raw_sam_df(csvdata):\n2130 \n2131     df = pd.read_csv(csvdata, index_col=0, skiprows=[1, 2])\n2132 \n2133     df.columns = df.columns.str.replace(' ', '_')\n2134     df.index = _normalize_sam_product_names(df.index)\n2135     df = df.transpose()\n2136 \n2137     if 'ADRCoefficients' in df.index:\n2138         ad_ce = 'ADRCoefficients'\n2139         # for each inverter, parses a string of coefficients like\n2140         # ' 1.33, 2.11, 3.12' into a list containing floats:\n2141         # [1.33, 2.11, 3.12]\n2142         df.loc[ad_ce] = df.loc[ad_ce].map(lambda x: list(\n2143             map(float, x.strip(' []').split())))\n2144 \n2145     return df\n2146 \n2147 \n2148 def sapm(effective_irradiance, temp_cell, module):\n2149     '''\n2150     The Sandia PV Array Performance Model (SAPM) generates 5 points on a\n2151     PV module's I-V curve (Voc, Isc, Ix, Ixx, Vmp/Imp) according to\n2152     SAND2004-3535. Assumes a reference cell temperature of 25 C.\n2153 \n2154     Parameters\n2155     ----------\n2156     effective_irradiance : numeric\n2157         Irradiance reaching the module's cells, after reflections and\n2158         adjustment for spectrum. [W/m2]\n2159 \n2160     temp_cell : numeric\n2161         Cell temperature [C].\n2162 \n2163     module : dict-like\n2164         A dict or Series defining the SAPM parameters. See the notes section\n2165         for more details.\n2166 \n2167     Returns\n2168     -------\n2169     A DataFrame with the columns:\n2170 \n2171         * i_sc : Short-circuit current (A)\n2172         * i_mp : Current at the maximum-power point (A)\n2173         * v_oc : Open-circuit voltage (V)\n2174         * v_mp : Voltage at maximum-power point (V)\n2175         * p_mp : Power at maximum-power point (W)\n2176         * i_x : Current at module V = 0.5Voc, defines 4th point on I-V\n2177           curve for modeling curve shape\n2178         * i_xx : Current at module V = 0.5(Voc+Vmp), defines 5th point on\n2179           I-V curve for modeling curve shape\n2180 \n2181     Notes\n2182     -----\n2183     The SAPM parameters which are required in ``module`` are\n2184     listed in the following table.\n2185 \n2186     The Sandia module database contains parameter values for a limited set\n2187     of modules. The CEC module database does not contain these parameters.\n2188     Both databases can be accessed using :py:func:`retrieve_sam`.\n2189 \n2190     ================   ========================================================\n2191     Key                Description\n2192     ================   ========================================================\n2193     A0-A4              The airmass coefficients used in calculating\n2194                        effective irradiance\n2195     B0-B5              The angle of incidence coefficients used in calculating\n2196                        effective irradiance\n2197     C0-C7              The empirically determined coefficients relating\n2198                        Imp, Vmp, Ix, and Ixx to effective irradiance\n2199     Isco               Short circuit current at reference condition (amps)\n2200     Impo               Maximum power current at reference condition (amps)\n2201     Voco               Open circuit voltage at reference condition (amps)\n2202     Vmpo               Maximum power voltage at reference condition (amps)\n2203     Aisc               Short circuit current temperature coefficient at\n2204                        reference condition (1/C)\n2205     Aimp               Maximum power current temperature coefficient at\n2206                        reference condition (1/C)\n2207     Bvoco              Open circuit voltage temperature coefficient at\n2208                        reference condition (V/C)\n2209     Mbvoc              Coefficient providing the irradiance dependence for the\n2210                        BetaVoc temperature coefficient at reference irradiance\n2211                        (V/C)\n2212     Bvmpo              Maximum power voltage temperature coefficient at\n2213                        reference condition\n2214     Mbvmp              Coefficient providing the irradiance dependence for the\n2215                        BetaVmp temperature coefficient at reference irradiance\n2216                        (V/C)\n2217     N                  Empirically determined \"diode factor\" (dimensionless)\n2218     Cells_in_Series    Number of cells in series in a module's cell string(s)\n2219     IXO                Ix at reference conditions\n2220     IXXO               Ixx at reference conditions\n2221     FD                 Fraction of diffuse irradiance used by module\n2222     ================   ========================================================\n2223 \n2224     References\n2225     ----------\n2226     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n2227        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n2228        NM.\n2229 \n2230     See Also\n2231     --------\n2232     retrieve_sam\n2233     pvlib.temperature.sapm_cell\n2234     pvlib.temperature.sapm_module\n2235     '''\n2236 \n2237     # TODO: someday, change temp_ref and irrad_ref to reference_temperature and\n2238     # reference_irradiance and expose\n2239     temp_ref = 25\n2240     irrad_ref = 1000\n2241 \n2242     q = 1.60218e-19  # Elementary charge in units of coulombs\n2243     kb = 1.38066e-23  # Boltzmann's constant in units of J/K\n2244 \n2245     # avoid problem with integer input\n2246     Ee = np.array(effective_irradiance, dtype='float64') / irrad_ref\n2247 \n2248     # set up masking for 0, positive, and nan inputs\n2249     Ee_gt_0 = np.full_like(Ee, False, dtype='bool')\n2250     Ee_eq_0 = np.full_like(Ee, False, dtype='bool')\n2251     notnan = ~np.isnan(Ee)\n2252     np.greater(Ee, 0, where=notnan, out=Ee_gt_0)\n2253     np.equal(Ee, 0, where=notnan, out=Ee_eq_0)\n2254 \n2255     Bvmpo = module['Bvmpo'] + module['Mbvmp']*(1 - Ee)\n2256     Bvoco = module['Bvoco'] + module['Mbvoc']*(1 - Ee)\n2257     delta = module['N'] * kb * (temp_cell + 273.15) / q\n2258 \n2259     # avoid repeated computation\n2260     logEe = np.full_like(Ee, np.nan)\n2261     np.log(Ee, where=Ee_gt_0, out=logEe)\n2262     logEe = np.where(Ee_eq_0, -np.inf, logEe)\n2263     # avoid repeated __getitem__\n2264     cells_in_series = module['Cells_in_Series']\n2265 \n2266     out = OrderedDict()\n2267 \n2268     out['i_sc'] = (\n2269         module['Isco'] * Ee * (1 + module['Aisc']*(temp_cell - temp_ref)))\n2270 \n2271     out['i_mp'] = (\n2272         module['Impo'] * (module['C0']*Ee + module['C1']*(Ee**2)) *\n2273         (1 + module['Aimp']*(temp_cell - temp_ref)))\n2274 \n2275     out['v_oc'] = np.maximum(0, (\n2276         module['Voco'] + cells_in_series * delta * logEe +\n2277         Bvoco*(temp_cell - temp_ref)))\n2278 \n2279     out['v_mp'] = np.maximum(0, (\n2280         module['Vmpo'] +\n2281         module['C2'] * cells_in_series * delta * logEe +\n2282         module['C3'] * cells_in_series * ((delta * logEe) ** 2) +\n2283         Bvmpo*(temp_cell - temp_ref)))\n2284 \n2285     out['p_mp'] = out['i_mp'] * out['v_mp']\n2286 \n2287     out['i_x'] = (\n2288         module['IXO'] * (module['C4']*Ee + module['C5']*(Ee**2)) *\n2289         (1 + module['Aisc']*(temp_cell - temp_ref)))\n2290 \n2291     # the Ixx calculation in King 2004 has a typo (mixes up Aisc and Aimp)\n2292     out['i_xx'] = (\n2293         module['IXXO'] * (module['C6']*Ee + module['C7']*(Ee**2)) *\n2294         (1 + module['Aisc']*(temp_cell - temp_ref)))\n2295 \n2296     if isinstance(out['i_sc'], pd.Series):\n2297         out = pd.DataFrame(out)\n2298 \n2299     return out\n2300 \n2301 \n2302 def sapm_spectral_loss(airmass_absolute, module):\n2303     \"\"\"\n2304     Calculates the SAPM spectral loss coefficient, F1.\n2305 \n2306     Parameters\n2307     ----------\n2308     airmass_absolute : numeric\n2309         Absolute airmass\n2310 \n2311     module : dict-like\n2312         A dict, Series, or DataFrame defining the SAPM performance\n2313         parameters. See the :py:func:`sapm` notes section for more\n2314         details.\n2315 \n2316     Returns\n2317     -------\n2318     F1 : numeric\n2319         The SAPM spectral loss coefficient.\n2320 \n2321     Notes\n2322     -----\n2323     nan airmass values will result in 0 output.\n2324     \"\"\"\n2325 \n2326     am_coeff = [module['A4'], module['A3'], module['A2'], module['A1'],\n2327                 module['A0']]\n2328 \n2329     spectral_loss = np.polyval(am_coeff, airmass_absolute)\n2330 \n2331     spectral_loss = np.where(np.isnan(spectral_loss), 0, spectral_loss)\n2332 \n2333     spectral_loss = np.maximum(0, spectral_loss)\n2334 \n2335     if isinstance(airmass_absolute, pd.Series):\n2336         spectral_loss = pd.Series(spectral_loss, airmass_absolute.index)\n2337 \n2338     return spectral_loss\n2339 \n2340 \n2341 def sapm_effective_irradiance(poa_direct, poa_diffuse, airmass_absolute, aoi,\n2342                               module):\n2343     r\"\"\"\n2344     Calculates the SAPM effective irradiance using the SAPM spectral\n2345     loss and SAPM angle of incidence loss functions.\n2346 \n2347     Parameters\n2348     ----------\n2349     poa_direct : numeric\n2350         The direct irradiance incident upon the module. [W/m2]\n2351 \n2352     poa_diffuse : numeric\n2353         The diffuse irradiance incident on module.  [W/m2]\n2354 \n2355     airmass_absolute : numeric\n2356         Absolute airmass. [unitless]\n2357 \n2358     aoi : numeric\n2359         Angle of incidence. [degrees]\n2360 \n2361     module : dict-like\n2362         A dict, Series, or DataFrame defining the SAPM performance\n2363         parameters. See the :py:func:`sapm` notes section for more\n2364         details.\n2365 \n2366     Returns\n2367     -------\n2368     effective_irradiance : numeric\n2369         Effective irradiance accounting for reflections and spectral content.\n2370         [W/m2]\n2371 \n2372     Notes\n2373     -----\n2374     The SAPM model for effective irradiance [1]_ translates broadband direct\n2375     and diffuse irradiance on the plane of array to the irradiance absorbed by\n2376     a module's cells.\n2377 \n2378     The model is\n2379     .. math::\n2380 \n2381         `Ee = f_1(AM_a) (E_b f_2(AOI) + f_d E_d)`\n2382 \n2383     where :math:`Ee` is effective irradiance (W/m2), :math:`f_1` is a fourth\n2384     degree polynomial in air mass :math:`AM_a`, :math:`E_b` is beam (direct)\n2385     irradiance on the plane of array, :math:`E_d` is diffuse irradiance on the\n2386     plane of array, :math:`f_2` is a fifth degree polynomial in the angle of\n2387     incidence :math:`AOI`, and :math:`f_d` is the fraction of diffuse\n2388     irradiance on the plane of array that is not reflected away.\n2389 \n2390     References\n2391     ----------\n2392     .. [1] D. King et al, \"Sandia Photovoltaic Array Performance Model\",\n2393        SAND2004-3535, Sandia National Laboratories, Albuquerque, NM\n2394 \n2395     See also\n2396     --------\n2397     pvlib.iam.sapm\n2398     pvlib.pvsystem.sapm_spectral_loss\n2399     pvlib.pvsystem.sapm\n2400     \"\"\"\n2401 \n2402     F1 = sapm_spectral_loss(airmass_absolute, module)\n2403     F2 = iam.sapm(aoi, module)\n2404 \n2405     Ee = F1 * (poa_direct * F2 + module['FD'] * poa_diffuse)\n2406 \n2407     return Ee\n2408 \n2409 \n2410 def singlediode(photocurrent, saturation_current, resistance_series,\n2411                 resistance_shunt, nNsVth, ivcurve_pnts=None,\n2412                 method='lambertw'):\n2413     r\"\"\"\n2414     Solve the single-diode equation to obtain a photovoltaic IV curve.\n2415 \n2416     Solves the single diode equation [1]_\n2417 \n2418     .. math::\n2419 \n2420         I = I_L -\n2421             I_0 \\left[\n2422                 \\exp \\left(\\frac{V+I R_s}{n N_s V_{th}} \\right)-1\n2423             \\right] -\n2424             \\frac{V + I R_s}{R_{sh}}\n2425 \n2426     for :math:`I` and :math:`V` when given :math:`I_L, I_0, R_s, R_{sh},` and\n2427     :math:`n N_s V_{th}` which are described later. Returns a DataFrame\n2428     which contains the 5 points on the I-V curve specified in\n2429     [3]_. If all :math:`I_L, I_0, R_s, R_{sh},` and\n2430     :math:`n N_s V_{th}` are scalar, a single curve is returned, if any\n2431     are Series (of the same length), multiple IV curves are calculated.\n2432 \n2433     The input parameters can be calculated from meteorological data using a\n2434     function for a single diode model, e.g.,\n2435     :py:func:`~pvlib.pvsystem.calcparams_desoto`.\n2436 \n2437     Parameters\n2438     ----------\n2439     photocurrent : numeric\n2440         Light-generated current :math:`I_L` (photocurrent)\n2441         ``0 <= photocurrent``. [A]\n2442 \n2443     saturation_current : numeric\n2444         Diode saturation :math:`I_0` current under desired IV curve\n2445         conditions. ``0 < saturation_current``. [A]\n2446 \n2447     resistance_series : numeric\n2448         Series resistance :math:`R_s` under desired IV curve conditions.\n2449         ``0 <= resistance_series < numpy.inf``.  [ohm]\n2450 \n2451     resistance_shunt : numeric\n2452         Shunt resistance :math:`R_{sh}` under desired IV curve conditions.\n2453         ``0 < resistance_shunt <= numpy.inf``.  [ohm]\n2454 \n2455     nNsVth : numeric\n2456         The product of three components: 1) the usual diode ideality factor\n2457         :math:`n`, 2) the number of cells in series :math:`N_s`, and 3)\n2458         the cell thermal voltage\n2459         :math:`V_{th}`. The thermal voltage of the cell (in volts) may be\n2460         calculated as :math:`k_B T_c / q`, where :math:`k_B` is\n2461         Boltzmann's constant (J/K), :math:`T_c` is the temperature of the p-n\n2462         junction in Kelvin, and :math:`q` is the charge of an electron\n2463         (coulombs). ``0 < nNsVth``.  [V]\n2464 \n2465     ivcurve_pnts : None or int, default None\n2466         Number of points in the desired IV curve. If None or 0, no points on\n2467         the IV curves will be produced.\n2468 \n2469     method : str, default 'lambertw'\n2470         Determines the method used to calculate points on the IV curve. The\n2471         options are ``'lambertw'``, ``'newton'``, or ``'brentq'``.\n2472 \n2473     Returns\n2474     -------\n2475     OrderedDict or DataFrame\n2476 \n2477     The returned dict-like object always contains the keys/columns:\n2478 \n2479         * i_sc - short circuit current in amperes.\n2480         * v_oc - open circuit voltage in volts.\n2481         * i_mp - current at maximum power point in amperes.\n2482         * v_mp - voltage at maximum power point in volts.\n2483         * p_mp - power at maximum power point in watts.\n2484         * i_x - current, in amperes, at ``v = 0.5*v_oc``.\n2485         * i_xx - current, in amperes, at ``V = 0.5*(v_oc+v_mp)``.\n2486 \n2487     If ivcurve_pnts is greater than 0, the output dictionary will also\n2488     include the keys:\n2489 \n2490         * i - IV curve current in amperes.\n2491         * v - IV curve voltage in volts.\n2492 \n2493     The output will be an OrderedDict if photocurrent is a scalar,\n2494     array, or ivcurve_pnts is not None.\n2495 \n2496     The output will be a DataFrame if photocurrent is a Series and\n2497     ivcurve_pnts is None.\n2498 \n2499     See also\n2500     --------\n2501     calcparams_desoto\n2502     calcparams_cec\n2503     calcparams_pvsyst\n2504     sapm\n2505     pvlib.singlediode.bishop88\n2506 \n2507     Notes\n2508     -----\n2509     If the method is ``'lambertw'`` then the solution employed to solve the\n2510     implicit diode equation utilizes the Lambert W function to obtain an\n2511     explicit function of :math:`V=f(I)` and :math:`I=f(V)` as shown in [2]_.\n2512 \n2513     If the method is ``'newton'`` then the root-finding Newton-Raphson method\n2514     is used. It should be safe for well behaved IV-curves, but the ``'brentq'``\n2515     method is recommended for reliability.\n2516 \n2517     If the method is ``'brentq'`` then Brent's bisection search method is used\n2518     that guarantees convergence by bounding the voltage between zero and\n2519     open-circuit.\n2520 \n2521     If the method is either ``'newton'`` or ``'brentq'`` and ``ivcurve_pnts``\n2522     are indicated, then :func:`pvlib.singlediode.bishop88` [4]_ is used to\n2523     calculate the points on the IV curve points at diode voltages from zero to\n2524     open-circuit voltage with a log spacing that gets closer as voltage\n2525     increases. If the method is ``'lambertw'`` then the calculated points on\n2526     the IV curve are linearly spaced.\n2527 \n2528     References\n2529     ----------\n2530     .. [1] S.R. Wenham, M.A. Green, M.E. Watt, \"Applied Photovoltaics\" ISBN\n2531        0 86758 909 4\n2532 \n2533     .. [2] A. Jain, A. Kapoor, \"Exact analytical solutions of the\n2534        parameters of real solar cells using Lambert W-function\", Solar\n2535        Energy Materials and Solar Cells, 81 (2004) 269-277.\n2536 \n2537     .. [3] D. King et al, \"Sandia Photovoltaic Array Performance Model\",\n2538        SAND2004-3535, Sandia National Laboratories, Albuquerque, NM\n2539 \n2540     .. [4] \"Computer simulation of the effects of electrical mismatches in\n2541        photovoltaic cell interconnection circuits\" JW Bishop, Solar Cell (1988)\n2542        https://doi.org/10.1016/0379-6787(88)90059-2\n2543     \"\"\"\n2544     # Calculate points on the IV curve using the LambertW solution to the\n2545     # single diode equation\n2546     if method.lower() == 'lambertw':\n2547         out = _singlediode._lambertw(\n2548             photocurrent, saturation_current, resistance_series,\n2549             resistance_shunt, nNsVth, ivcurve_pnts\n2550         )\n2551         i_sc, v_oc, i_mp, v_mp, p_mp, i_x, i_xx = out[:7]\n2552         if ivcurve_pnts:\n2553             ivcurve_i, ivcurve_v = out[7:]\n2554     else:\n2555         # Calculate points on the IV curve using either 'newton' or 'brentq'\n2556         # methods. Voltages are determined by first solving the single diode\n2557         # equation for the diode voltage V_d then backing out voltage\n2558         args = (photocurrent, saturation_current, resistance_series,\n2559                 resistance_shunt, nNsVth)  # collect args\n2560         v_oc = _singlediode.bishop88_v_from_i(\n2561             0.0, *args, method=method.lower()\n2562         )\n2563         i_mp, v_mp, p_mp = _singlediode.bishop88_mpp(\n2564             *args, method=method.lower()\n2565         )\n2566         i_sc = _singlediode.bishop88_i_from_v(\n2567             0.0, *args, method=method.lower()\n2568         )\n2569         i_x = _singlediode.bishop88_i_from_v(\n2570             v_oc / 2.0, *args, method=method.lower()\n2571         )\n2572         i_xx = _singlediode.bishop88_i_from_v(\n2573             (v_oc + v_mp) / 2.0, *args, method=method.lower()\n2574         )\n2575 \n2576         # calculate the IV curve if requested using bishop88\n2577         if ivcurve_pnts:\n2578             vd = v_oc * (\n2579                 (11.0 - np.logspace(np.log10(11.0), 0.0, ivcurve_pnts)) / 10.0\n2580             )\n2581             ivcurve_i, ivcurve_v, _ = _singlediode.bishop88(vd, *args)\n2582 \n2583     out = OrderedDict()\n2584     out['i_sc'] = i_sc\n2585     out['v_oc'] = v_oc\n2586     out['i_mp'] = i_mp\n2587     out['v_mp'] = v_mp\n2588     out['p_mp'] = p_mp\n2589     out['i_x'] = i_x\n2590     out['i_xx'] = i_xx\n2591 \n2592     if ivcurve_pnts:\n2593 \n2594         out['v'] = ivcurve_v\n2595         out['i'] = ivcurve_i\n2596 \n2597     if isinstance(photocurrent, pd.Series) and not ivcurve_pnts:\n2598         out = pd.DataFrame(out, index=photocurrent.index)\n2599 \n2600     return out\n2601 \n2602 \n2603 def max_power_point(photocurrent, saturation_current, resistance_series,\n2604                     resistance_shunt, nNsVth, d2mutau=0, NsVbi=np.Inf,\n2605                     method='brentq'):\n2606     \"\"\"\n2607     Given the single diode equation coefficients, calculates the maximum power\n2608     point (MPP).\n2609 \n2610     Parameters\n2611     ----------\n2612     photocurrent : numeric\n2613         photo-generated current [A]\n2614     saturation_current : numeric\n2615         diode reverse saturation current [A]\n2616     resistance_series : numeric\n2617         series resitance [ohms]\n2618     resistance_shunt : numeric\n2619         shunt resitance [ohms]\n2620     nNsVth : numeric\n2621         product of thermal voltage ``Vth`` [V], diode ideality factor ``n``,\n2622         and number of serices cells ``Ns``\n2623     d2mutau : numeric, default 0\n2624         PVsyst parameter for cadmium-telluride (CdTe) and amorphous-silicon\n2625         (a-Si) modules that accounts for recombination current in the\n2626         intrinsic layer. The value is the ratio of intrinsic layer thickness\n2627         squared :math:`d^2` to the diffusion length of charge carriers\n2628         :math:`\\\\mu \\\\tau`. [V]\n2629     NsVbi : numeric, default np.inf\n2630         PVsyst parameter for cadmium-telluride (CdTe) and amorphous-silicon\n2631         (a-Si) modules that is the product of the PV module number of series\n2632         cells ``Ns`` and the builtin voltage ``Vbi`` of the intrinsic layer.\n2633         [V].\n2634     method : str\n2635         either ``'newton'`` or ``'brentq'``\n2636 \n2637     Returns\n2638     -------\n2639     OrderedDict or pandas.Datafrane\n2640         ``(i_mp, v_mp, p_mp)``\n2641 \n2642     Notes\n2643     -----\n2644     Use this function when you only want to find the maximum power point. Use\n2645     :func:`singlediode` when you need to find additional points on the IV\n2646     curve. This function uses Brent's method by default because it is\n2647     guaranteed to converge.\n2648     \"\"\"\n2649     i_mp, v_mp, p_mp = _singlediode.bishop88_mpp(\n2650         photocurrent, saturation_current, resistance_series,\n2651         resistance_shunt, nNsVth, d2mutau=0, NsVbi=np.Inf,\n2652         method=method.lower()\n2653     )\n2654     if isinstance(photocurrent, pd.Series):\n2655         ivp = {'i_mp': i_mp, 'v_mp': v_mp, 'p_mp': p_mp}\n2656         out = pd.DataFrame(ivp, index=photocurrent.index)\n2657     else:\n2658         out = OrderedDict()\n2659         out['i_mp'] = i_mp\n2660         out['v_mp'] = v_mp\n2661         out['p_mp'] = p_mp\n2662     return out\n2663 \n2664 \n2665 def v_from_i(resistance_shunt, resistance_series, nNsVth, current,\n2666              saturation_current, photocurrent, method='lambertw'):\n2667     '''\n2668     Device voltage at the given device current for the single diode model.\n2669 \n2670     Uses the single diode model (SDM) as described in, e.g.,\n2671     Jain and Kapoor 2004 [1]_.\n2672     The solution is per Eq 3 of [1]_ except when resistance_shunt=numpy.inf,\n2673     in which case the explict solution for voltage is used.\n2674     Ideal device parameters are specified by resistance_shunt=np.inf and\n2675     resistance_series=0.\n2676     Inputs to this function can include scalars and pandas.Series, but it is\n2677     the caller's responsibility to ensure that the arguments are all float64\n2678     and within the proper ranges.\n2679 \n2680     Parameters\n2681     ----------\n2682     resistance_shunt : numeric\n2683         Shunt resistance in ohms under desired IV curve conditions.\n2684         Often abbreviated ``Rsh``.\n2685         0 < resistance_shunt <= numpy.inf\n2686 \n2687     resistance_series : numeric\n2688         Series resistance in ohms under desired IV curve conditions.\n2689         Often abbreviated ``Rs``.\n2690         0 <= resistance_series < numpy.inf\n2691 \n2692     nNsVth : numeric\n2693         The product of three components. 1) The usual diode ideal factor\n2694         (n), 2) the number of cells in series (Ns), and 3) the cell\n2695         thermal voltage under the desired IV curve conditions (Vth). The\n2696         thermal voltage of the cell (in volts) may be calculated as\n2697         ``k*temp_cell/q``, where k is Boltzmann's constant (J/K),\n2698         temp_cell is the temperature of the p-n junction in Kelvin, and\n2699         q is the charge of an electron (coulombs).\n2700         0 < nNsVth\n2701 \n2702     current : numeric\n2703         The current in amperes under desired IV curve conditions.\n2704 \n2705     saturation_current : numeric\n2706         Diode saturation current in amperes under desired IV curve\n2707         conditions. Often abbreviated ``I_0``.\n2708         0 < saturation_current\n2709 \n2710     photocurrent : numeric\n2711         Light-generated current (photocurrent) in amperes under desired\n2712         IV curve conditions. Often abbreviated ``I_L``.\n2713         0 <= photocurrent\n2714 \n2715     method : str\n2716         Method to use: ``'lambertw'``, ``'newton'``, or ``'brentq'``. *Note*:\n2717         ``'brentq'`` is limited to 1st quadrant only.\n2718 \n2719     Returns\n2720     -------\n2721     current : np.ndarray or scalar\n2722 \n2723     References\n2724     ----------\n2725     .. [1] A. Jain, A. Kapoor, \"Exact analytical solutions of the\n2726        parameters of real solar cells using Lambert W-function\", Solar\n2727        Energy Materials and Solar Cells, 81 (2004) 269-277.\n2728     '''\n2729     if method.lower() == 'lambertw':\n2730         return _singlediode._lambertw_v_from_i(\n2731             resistance_shunt, resistance_series, nNsVth, current,\n2732             saturation_current, photocurrent\n2733         )\n2734     else:\n2735         # Calculate points on the IV curve using either 'newton' or 'brentq'\n2736         # methods. Voltages are determined by first solving the single diode\n2737         # equation for the diode voltage V_d then backing out voltage\n2738         args = (current, photocurrent, saturation_current,\n2739                 resistance_series, resistance_shunt, nNsVth)\n2740         V = _singlediode.bishop88_v_from_i(*args, method=method.lower())\n2741         # find the right size and shape for returns\n2742         size, shape = _singlediode._get_size_and_shape(args)\n2743         if size <= 1:\n2744             if shape is not None:\n2745                 V = np.tile(V, shape)\n2746         if np.isnan(V).any() and size <= 1:\n2747             V = np.repeat(V, size)\n2748             if shape is not None:\n2749                 V = V.reshape(shape)\n2750         return V\n2751 \n2752 \n2753 def i_from_v(resistance_shunt, resistance_series, nNsVth, voltage,\n2754              saturation_current, photocurrent, method='lambertw'):\n2755     '''\n2756     Device current at the given device voltage for the single diode model.\n2757 \n2758     Uses the single diode model (SDM) as described in, e.g.,\n2759      Jain and Kapoor 2004 [1]_.\n2760     The solution is per Eq 2 of [1] except when resistance_series=0,\n2761      in which case the explict solution for current is used.\n2762     Ideal device parameters are specified by resistance_shunt=np.inf and\n2763      resistance_series=0.\n2764     Inputs to this function can include scalars and pandas.Series, but it is\n2765      the caller's responsibility to ensure that the arguments are all float64\n2766      and within the proper ranges.\n2767 \n2768     Parameters\n2769     ----------\n2770     resistance_shunt : numeric\n2771         Shunt resistance in ohms under desired IV curve conditions.\n2772         Often abbreviated ``Rsh``.\n2773         0 < resistance_shunt <= numpy.inf\n2774 \n2775     resistance_series : numeric\n2776         Series resistance in ohms under desired IV curve conditions.\n2777         Often abbreviated ``Rs``.\n2778         0 <= resistance_series < numpy.inf\n2779 \n2780     nNsVth : numeric\n2781         The product of three components. 1) The usual diode ideal factor\n2782         (n), 2) the number of cells in series (Ns), and 3) the cell\n2783         thermal voltage under the desired IV curve conditions (Vth). The\n2784         thermal voltage of the cell (in volts) may be calculated as\n2785         ``k*temp_cell/q``, where k is Boltzmann's constant (J/K),\n2786         temp_cell is the temperature of the p-n junction in Kelvin, and\n2787         q is the charge of an electron (coulombs).\n2788         0 < nNsVth\n2789 \n2790     voltage : numeric\n2791         The voltage in Volts under desired IV curve conditions.\n2792 \n2793     saturation_current : numeric\n2794         Diode saturation current in amperes under desired IV curve\n2795         conditions. Often abbreviated ``I_0``.\n2796         0 < saturation_current\n2797 \n2798     photocurrent : numeric\n2799         Light-generated current (photocurrent) in amperes under desired\n2800         IV curve conditions. Often abbreviated ``I_L``.\n2801         0 <= photocurrent\n2802 \n2803     method : str\n2804         Method to use: ``'lambertw'``, ``'newton'``, or ``'brentq'``. *Note*:\n2805         ``'brentq'`` is limited to 1st quadrant only.\n2806 \n2807     Returns\n2808     -------\n2809     current : np.ndarray or scalar\n2810 \n2811     References\n2812     ----------\n2813     .. [1] A. Jain, A. Kapoor, \"Exact analytical solutions of the\n2814        parameters of real solar cells using Lambert W-function\", Solar\n2815        Energy Materials and Solar Cells, 81 (2004) 269-277.\n2816     '''\n2817     if method.lower() == 'lambertw':\n2818         return _singlediode._lambertw_i_from_v(\n2819             resistance_shunt, resistance_series, nNsVth, voltage,\n2820             saturation_current, photocurrent\n2821         )\n2822     else:\n2823         # Calculate points on the IV curve using either 'newton' or 'brentq'\n2824         # methods. Voltages are determined by first solving the single diode\n2825         # equation for the diode voltage V_d then backing out voltage\n2826         args = (voltage, photocurrent, saturation_current, resistance_series,\n2827                 resistance_shunt, nNsVth)\n2828         current = _singlediode.bishop88_i_from_v(*args, method=method.lower())\n2829         # find the right size and shape for returns\n2830         size, shape = _singlediode._get_size_and_shape(args)\n2831         if size <= 1:\n2832             if shape is not None:\n2833                 current = np.tile(current, shape)\n2834         if np.isnan(current).any() and size <= 1:\n2835             current = np.repeat(current, size)\n2836             if shape is not None:\n2837                 current = current.reshape(shape)\n2838         return current\n2839 \n2840 \n2841 def scale_voltage_current_power(data, voltage=1, current=1):\n2842     \"\"\"\n2843     Scales the voltage, current, and power in data by the voltage\n2844     and current factors.\n2845 \n2846     Parameters\n2847     ----------\n2848     data: DataFrame\n2849         May contain columns `'v_mp', 'v_oc', 'i_mp' ,'i_x', 'i_xx',\n2850         'i_sc', 'p_mp'`.\n2851     voltage: numeric, default 1\n2852         The amount by which to multiply the voltages.\n2853     current: numeric, default 1\n2854         The amount by which to multiply the currents.\n2855 \n2856     Returns\n2857     -------\n2858     scaled_data: DataFrame\n2859         A scaled copy of the input data.\n2860         `'p_mp'` is scaled by `voltage * current`.\n2861     \"\"\"\n2862 \n2863     # as written, only works with a DataFrame\n2864     # could make it work with a dict, but it would be more verbose\n2865     voltage_keys = ['v_mp', 'v_oc']\n2866     current_keys = ['i_mp', 'i_x', 'i_xx', 'i_sc']\n2867     power_keys = ['p_mp']\n2868     voltage_df = data.filter(voltage_keys, axis=1) * voltage\n2869     current_df = data.filter(current_keys, axis=1) * current\n2870     power_df = data.filter(power_keys, axis=1) * voltage * current\n2871     df = pd.concat([voltage_df, current_df, power_df], axis=1)\n2872     df_sorted = df[data.columns]  # retain original column order\n2873     return df_sorted\n2874 \n2875 \n2876 def pvwatts_dc(g_poa_effective, temp_cell, pdc0, gamma_pdc, temp_ref=25.):\n2877     r\"\"\"\n2878     Implements NREL's PVWatts DC power model. The PVWatts DC model [1]_ is:\n2879 \n2880     .. math::\n2881 \n2882         P_{dc} = \\frac{G_{poa eff}}{1000} P_{dc0} ( 1 + \\gamma_{pdc} (T_{cell} - T_{ref}))\n2883 \n2884     Note that the pdc0 is also used as a symbol in\n2885     :py:func:`pvlib.inverter.pvwatts`. pdc0 in this function refers to the DC\n2886     power of the modules at reference conditions. pdc0 in\n2887     :py:func:`pvlib.inverter.pvwatts` refers to the DC power input limit of\n2888     the inverter.\n2889 \n2890     Parameters\n2891     ----------\n2892     g_poa_effective: numeric\n2893         Irradiance transmitted to the PV cells. To be\n2894         fully consistent with PVWatts, the user must have already\n2895         applied angle of incidence losses, but not soiling, spectral,\n2896         etc. [W/m^2]\n2897     temp_cell: numeric\n2898         Cell temperature [C].\n2899     pdc0: numeric\n2900         Power of the modules at 1000 W/m^2 and cell reference temperature. [W]\n2901     gamma_pdc: numeric\n2902         The temperature coefficient of power. Typically -0.002 to\n2903         -0.005 per degree C. [1/C]\n2904     temp_ref: numeric, default 25.0\n2905         Cell reference temperature. PVWatts defines it to be 25 C and\n2906         is included here for flexibility. [C]\n2907 \n2908     Returns\n2909     -------\n2910     pdc: numeric\n2911         DC power.\n2912 \n2913     References\n2914     ----------\n2915     .. [1] A. P. Dobos, \"PVWatts Version 5 Manual\"\n2916            http://pvwatts.nrel.gov/downloads/pvwattsv5.pdf\n2917            (2014).\n2918     \"\"\"  # noqa: E501\n2919 \n2920     pdc = (g_poa_effective * 0.001 * pdc0 *\n2921            (1 + gamma_pdc * (temp_cell - temp_ref)))\n2922 \n2923     return pdc\n2924 \n2925 \n2926 def pvwatts_losses(soiling=2, shading=3, snow=0, mismatch=2, wiring=2,\n2927                    connections=0.5, lid=1.5, nameplate_rating=1, age=0,\n2928                    availability=3):\n2929     r\"\"\"\n2930     Implements NREL's PVWatts system loss model.\n2931     The PVWatts loss model [1]_ is:\n2932 \n2933     .. math::\n2934 \n2935         L_{total}(\\%) = 100 [ 1 - \\Pi_i ( 1 - \\frac{L_i}{100} ) ]\n2936 \n2937     All parameters must be in units of %. Parameters may be\n2938     array-like, though all array sizes must match.\n2939 \n2940     Parameters\n2941     ----------\n2942     soiling: numeric, default 2\n2943     shading: numeric, default 3\n2944     snow: numeric, default 0\n2945     mismatch: numeric, default 2\n2946     wiring: numeric, default 2\n2947     connections: numeric, default 0.5\n2948     lid: numeric, default 1.5\n2949         Light induced degradation\n2950     nameplate_rating: numeric, default 1\n2951     age: numeric, default 0\n2952     availability: numeric, default 3\n2953 \n2954     Returns\n2955     -------\n2956     losses: numeric\n2957         System losses in units of %.\n2958 \n2959     References\n2960     ----------\n2961     .. [1] A. P. Dobos, \"PVWatts Version 5 Manual\"\n2962            http://pvwatts.nrel.gov/downloads/pvwattsv5.pdf\n2963            (2014).\n2964     \"\"\"\n2965 \n2966     params = [soiling, shading, snow, mismatch, wiring, connections, lid,\n2967               nameplate_rating, age, availability]\n2968 \n2969     # manually looping over params allows for numpy/pandas to handle any\n2970     # array-like broadcasting that might be necessary.\n2971     perf = 1\n2972     for param in params:\n2973         perf *= 1 - param/100\n2974 \n2975     losses = (1 - perf) * 100.\n2976 \n2977     return losses\n2978 \n2979 \n2980 def dc_ohms_from_percent(vmp_ref, imp_ref, dc_ohmic_percent,\n2981                          modules_per_string=1,\n2982                          strings=1):\n2983     \"\"\"\n2984     Calculates the equivalent resistance of the wires from a percent\n2985     ohmic loss at STC.\n2986 \n2987     Equivalent resistance is calculated with the function:\n2988 \n2989     .. math::\n2990         Rw = (L_{stc} / 100) * (Varray / Iarray)\n2991 \n2992     :math:`Rw` is the equivalent resistance in ohms\n2993     :math:`Varray` is the Vmp of the modules times modules per string\n2994     :math:`Iarray` is the Imp of the modules times strings per array\n2995     :math:`L_{stc}` is the input dc loss percent\n2996 \n2997     Parameters\n2998     ----------\n2999     vmp_ref: numeric\n3000         Voltage at maximum power in reference conditions [V]\n3001     imp_ref: numeric\n3002         Current at maximum power in reference conditions [V]\n3003     dc_ohmic_percent: numeric, default 0\n3004         input dc loss as a percent, e.g. 1.5% loss is input as 1.5\n3005     modules_per_string: int, default 1\n3006         Number of modules per string in the array.\n3007     strings: int, default 1\n3008         Number of parallel strings in the array.\n3009 \n3010     Returns\n3011     ----------\n3012     Rw: numeric\n3013         Equivalent resistance [ohm]\n3014 \n3015     References\n3016     ----------\n3017     .. [1] PVsyst 7 Help. \"Array ohmic wiring loss\".\n3018        https://www.pvsyst.com/help/ohmic_loss.htm\n3019     \"\"\"\n3020     vmp = modules_per_string * vmp_ref\n3021 \n3022     imp = strings * imp_ref\n3023 \n3024     Rw = (dc_ohmic_percent / 100) * (vmp / imp)\n3025 \n3026     return Rw\n3027 \n3028 \n3029 def dc_ohmic_losses(resistance, current):\n3030     \"\"\"\n3031     Returns ohmic losses in units of power from the equivalent\n3032     resistance of the wires and the operating current.\n3033 \n3034     Parameters\n3035     ----------\n3036     resistance: numeric\n3037         Equivalent resistance of wires [ohm]\n3038     current: numeric, float or array-like\n3039         Operating current [A]\n3040 \n3041     Returns\n3042     ----------\n3043     loss: numeric\n3044         Power Loss [W]\n3045 \n3046     References\n3047     ----------\n3048     .. [1] PVsyst 7 Help. \"Array ohmic wiring loss\".\n3049        https://www.pvsyst.com/help/ohmic_loss.htm\n3050     \"\"\"\n3051     return resistance * current * current\n3052 \n3053 \n3054 def combine_loss_factors(index, *losses, fill_method='ffill'):\n3055     r\"\"\"\n3056     Combines Series loss fractions while setting a common index.\n3057 \n3058     The separate losses are compounded using the following equation:\n3059 \n3060     .. math::\n3061 \n3062         L_{total} = 1 - [ 1 - \\Pi_i ( 1 - L_i ) ]\n3063 \n3064     :math:`L_{total}` is the total loss returned\n3065     :math:`L_i` is each individual loss factor input\n3066 \n3067     Note the losses must each be a series with a DatetimeIndex.\n3068     All losses will be resampled to match the index parameter using\n3069     the fill method specified (defaults to \"fill forward\").\n3070 \n3071     Parameters\n3072     ----------\n3073     index : DatetimeIndex\n3074         The index of the returned loss factors\n3075 \n3076     *losses : Series\n3077         One or more Series of fractions to be compounded\n3078 \n3079     fill_method : {'ffill', 'bfill', 'nearest'}, default 'ffill'\n3080         Method to use for filling holes in reindexed DataFrame\n3081 \n3082     Returns\n3083     -------\n3084     Series\n3085         Fractions resulting from the combination of each loss factor\n3086     \"\"\"\n3087     combined_factor = 1\n3088 \n3089     for loss in losses:\n3090         loss = loss.reindex(index, method=fill_method)\n3091         combined_factor *= (1 - loss)\n3092 \n3093     return 1 - combined_factor\n3094 \n[end of pvlib/pvsystem.py]\n[start of pvlib/temperature.py]\n1 \"\"\"\n2 The ``temperature`` module contains functions for modeling temperature of\n3 PV modules and cells.\n4 \"\"\"\n5 \n6 import numpy as np\n7 import pandas as pd\n8 from pvlib.tools import sind\n9 \n10 TEMPERATURE_MODEL_PARAMETERS = {\n11     'sapm': {\n12         'open_rack_glass_glass': {'a': -3.47, 'b': -.0594, 'deltaT': 3},\n13         'close_mount_glass_glass': {'a': -2.98, 'b': -.0471, 'deltaT': 1},\n14         'open_rack_glass_polymer': {'a': -3.56, 'b': -.0750, 'deltaT': 3},\n15         'insulated_back_glass_polymer': {'a': -2.81, 'b': -.0455, 'deltaT': 0},\n16     },\n17     'pvsyst': {'freestanding': {'u_c': 29.0, 'u_v': 0},\n18                'insulated': {'u_c': 15.0, 'u_v': 0}}\n19 }\n20 \"\"\"Dictionary of temperature parameters organized by model.\n21 \n22 There are keys for each model at the top level. Currently there are two models,\n23 ``'sapm'`` for the Sandia Array Performance Model, and ``'pvsyst'``. Each model\n24 has a dictionary of configurations; a value is itself a dictionary containing\n25 model parameters. Retrieve parameters by indexing the model and configuration\n26 by name. Note: the keys are lower-cased and case sensitive.\n27 \n28 Example\n29 -------\n30 Retrieve the open rack glass-polymer configuration for SAPM::\n31 \n32     from pvlib.temperature import TEMPERATURE_MODEL_PARAMETERS\n33     temperature_model_parameters = (\n34         TEMPERATURE_MODEL_PARAMETERS['sapm']['open_rack_glass_polymer'])\n35     # {'a': -3.56, 'b': -0.075, 'deltaT': 3}\n36 \"\"\"\n37 \n38 \n39 def _temperature_model_params(model, parameter_set):\n40     try:\n41         params = TEMPERATURE_MODEL_PARAMETERS[model]\n42         return params[parameter_set]\n43     except KeyError:\n44         msg = ('{} is not a named set of parameters for the {} cell'\n45                ' temperature model.'\n46                ' See pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS'\n47                ' for names'.format(parameter_set, model))\n48         raise KeyError(msg)\n49 \n50 \n51 def sapm_cell(poa_global, temp_air, wind_speed, a, b, deltaT,\n52               irrad_ref=1000.):\n53     r'''\n54     Calculate cell temperature per the Sandia Array Performance Model.\n55 \n56     See [1]_ for details on the Sandia Array Performance Model.\n57 \n58     Parameters\n59     ----------\n60     poa_global : numeric\n61         Total incident irradiance [W/m^2].\n62 \n63     temp_air : numeric\n64         Ambient dry bulb temperature [C].\n65 \n66     wind_speed : numeric\n67         Wind speed at a height of 10 meters [m/s].\n68 \n69     a : float\n70         Parameter :math:`a` in :eq:`sapm1`.\n71 \n72     b : float\n73         Parameter :math:`b` in :eq:`sapm1`.\n74 \n75     deltaT : float\n76         Parameter :math:`\\Delta T` in :eq:`sapm2` [C].\n77 \n78     irrad_ref : float, default 1000\n79         Reference irradiance, parameter :math:`E_{0}` in\n80         :eq:`sapm2` [W/m^2].\n81 \n82     Returns\n83     -------\n84     numeric, values in degrees C.\n85 \n86     Notes\n87     -----\n88     The model for cell temperature :math:`T_{C}` is given by a pair of\n89     equations (Eq. 11 and 12 in [1]_).\n90 \n91     .. math::\n92        :label: sapm1\n93 \n94        T_{m} = E \\times \\exp (a + b \\times WS) + T_{a}\n95 \n96     .. math::\n97        :label: sapm2\n98 \n99        T_{C} = T_{m} + \\frac{E}{E_{0}} \\Delta T\n100 \n101     The module back surface temperature :math:`T_{m}` is implemented in\n102     :py:func:`~pvlib.temperature.sapm_module`.\n103 \n104     Inputs to the model are plane-of-array irradiance :math:`E` (W/m2) and\n105     ambient air temperature :math:`T_{a}` (C). Model parameters depend both on\n106     the module construction and its mounting. Parameter sets are provided in\n107     [1]_ for representative modules and mounting, and are coded for convenience\n108     in :data:`~pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS`.\n109 \n110     +---------------+----------------+-------+---------+---------------------+\n111     | Module        | Mounting       | a     | b       | :math:`\\Delta T [C]`|\n112     +===============+================+=======+=========+=====================+\n113     | glass/glass   | open rack      | -3.47 | -0.0594 | 3                   |\n114     +---------------+----------------+-------+---------+---------------------+\n115     | glass/glass   | close roof     | -2.98 | -0.0471 | 1                   |\n116     +---------------+----------------+-------+---------+---------------------+\n117     | glass/polymer | open rack      | -3.56 | -0.075  | 3                   |\n118     +---------------+----------------+-------+---------+---------------------+\n119     | glass/polymer | insulated back | -2.81 | -0.0455 | 0                   |\n120     +---------------+----------------+-------+---------+---------------------+\n121 \n122     References\n123     ----------\n124     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n125        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n126        NM.\n127 \n128     See also\n129     --------\n130     sapm_cell_from_module\n131     sapm_module\n132 \n133     Examples\n134     --------\n135     >>> from pvlib.temperature import sapm_cell, TEMPERATURE_MODEL_PARAMETERS\n136     >>> params = TEMPERATURE_MODEL_PARAMETERS['sapm']['open_rack_glass_glass']\n137     >>> sapm_cell(1000, 10, 0, **params)\n138     44.11703066106086\n139     '''\n140     module_temperature = sapm_module(poa_global, temp_air, wind_speed,\n141                                      a, b)\n142     return sapm_cell_from_module(module_temperature, poa_global, deltaT,\n143                                  irrad_ref)\n144 \n145 \n146 def sapm_module(poa_global, temp_air, wind_speed, a, b):\n147     r'''\n148     Calculate module back surface temperature per the Sandia Array\n149     Performance Model.\n150 \n151     See [1]_ for details on the Sandia Array Performance Model.\n152 \n153     Parameters\n154     ----------\n155     poa_global : numeric\n156         Total incident irradiance [W/m^2].\n157 \n158     temp_air : numeric\n159         Ambient dry bulb temperature [C].\n160 \n161     wind_speed : numeric\n162         Wind speed at a height of 10 meters [m/s].\n163 \n164     a : float\n165         Parameter :math:`a` in :eq:`sapm1mod`.\n166 \n167     b : float\n168         Parameter :math:`b` in :eq:`sapm1mod`.\n169 \n170     Returns\n171     -------\n172     numeric, values in degrees C.\n173 \n174     Notes\n175     -----\n176     The model for module temperature :math:`T_{m}` is given by Eq. 11 in [1]_.\n177 \n178     .. math::\n179        :label: sapm1mod\n180 \n181        T_{m} = E \\times \\exp (a + b \\times WS) + T_{a}\n182 \n183     Inputs to the model are plane-of-array irradiance :math:`E` (W/m2) and\n184     ambient air temperature :math:`T_{a}` (C). Model outputs are surface\n185     temperature at the back of the module :math:`T_{m}` and cell temperature\n186     :math:`T_{C}`. Model parameters depend both on the module construction and\n187     its mounting. Parameter sets are provided in [1]_ for representative\n188     modules and mounting, and are coded for convenience in\n189     :data:`~pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS`.\n190 \n191     +---------------+----------------+-------+---------+---------------------+\n192     | Module        | Mounting       | a     | b       | :math:`\\Delta T [C]`|\n193     +===============+================+=======+=========+=====================+\n194     | glass/glass   | open rack      | -3.47 | -0.0594 | 3                   |\n195     +---------------+----------------+-------+---------+---------------------+\n196     | glass/glass   | close roof     | -2.98 | -0.0471 | 1                   |\n197     +---------------+----------------+-------+---------+---------------------+\n198     | glass/polymer | open rack      | -3.56 | -0.075  | 3                   |\n199     +---------------+----------------+-------+---------+---------------------+\n200     | glass/polymer | insulated back | -2.81 | -0.0455 | 0                   |\n201     +---------------+----------------+-------+---------+---------------------+\n202 \n203     References\n204     ----------\n205     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n206        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n207        NM.\n208 \n209     See also\n210     --------\n211     sapm_cell\n212     sapm_cell_from_module\n213     '''\n214     return poa_global * np.exp(a + b * wind_speed) + temp_air\n215 \n216 \n217 def sapm_cell_from_module(module_temperature, poa_global, deltaT,\n218                           irrad_ref=1000.):\n219     r'''\n220     Calculate cell temperature from module temperature using the Sandia Array\n221     Performance Model.\n222 \n223     See [1]_ for details on the Sandia Array Performance Model.\n224 \n225     Parameters\n226     ----------\n227     module_temperature : numeric\n228         Temperature of back of module surface [C].\n229 \n230     poa_global : numeric\n231         Total incident irradiance [W/m^2].\n232 \n233     deltaT : float\n234         Parameter :math:`\\Delta T` in :eq:`sapm2_cell_from_mod` [C].\n235 \n236     irrad_ref : float, default 1000\n237         Reference irradiance, parameter :math:`E_{0}` in\n238         :eq:`sapm2` [W/m^2].\n239 \n240     Returns\n241     -------\n242     numeric, values in degrees C.\n243 \n244     Notes\n245     -----\n246     The model for cell temperature :math:`T_{C}` is given by Eq. 12 in [1]_.\n247 \n248     .. math::\n249        :label: sapm2_cell_from_mod\n250 \n251        T_{C} = T_{m} + \\frac{E}{E_{0}} \\Delta T\n252 \n253     The module back surface temperature :math:`T_{m}` is implemented in\n254     :py:func:`~pvlib.temperature.sapm_module`.\n255 \n256     Model parameters depend both on the module construction and its mounting.\n257     Parameter sets are provided in [1]_ for representative modules and\n258     mounting, and are coded for convenience in\n259     :data:`~pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS`.\n260 \n261     +---------------+----------------+-------+---------+---------------------+\n262     | Module        | Mounting       | a     | b       | :math:`\\Delta T [C]`|\n263     +===============+================+=======+=========+=====================+\n264     | glass/glass   | open rack      | -3.47 | -0.0594 | 3                   |\n265     +---------------+----------------+-------+---------+---------------------+\n266     | glass/glass   | close roof     | -2.98 | -0.0471 | 1                   |\n267     +---------------+----------------+-------+---------+---------------------+\n268     | glass/polymer | open rack      | -3.56 | -0.075  | 3                   |\n269     +---------------+----------------+-------+---------+---------------------+\n270     | glass/polymer | insulated back | -2.81 | -0.0455 | 0                   |\n271     +---------------+----------------+-------+---------+---------------------+\n272 \n273     References\n274     ----------\n275     .. [1] King, D. et al, 2004, \"Sandia Photovoltaic Array Performance\n276        Model\", SAND Report 3535, Sandia National Laboratories, Albuquerque,\n277        NM.\n278 \n279     See also\n280     --------\n281     sapm_cell\n282     sapm_module\n283     '''\n284     return module_temperature + (poa_global / irrad_ref) * deltaT\n285 \n286 \n287 def pvsyst_cell(poa_global, temp_air, wind_speed=1.0, u_c=29.0, u_v=0.0,\n288                 eta_m=0.1, alpha_absorption=0.9):\n289     r\"\"\"\n290     Calculate cell temperature using an empirical heat loss factor model\n291     as implemented in PVsyst.\n292 \n293     Parameters\n294     ----------\n295     poa_global : numeric\n296         Total incident irradiance [W/m^2].\n297 \n298     temp_air : numeric\n299         Ambient dry bulb temperature [C].\n300 \n301     wind_speed : numeric, default 1.0\n302         Wind speed in m/s measured at the same height for which the wind loss\n303         factor was determined.  The default value 1.0 m/2 is the wind\n304         speed at module height used to determine NOCT. [m/s]\n305 \n306     u_c : float, default 29.0\n307         Combined heat loss factor coefficient. The default value is\n308         representative of freestanding modules with the rear surfaces exposed\n309         to open air (e.g., rack mounted). Parameter :math:`U_{c}` in\n310         :eq:`pvsyst`.\n311         :math:`\\left[\\frac{\\text{W}/{\\text{m}^2}}{\\text{C}}\\right]`\n312 \n313     u_v : float, default 0.0\n314         Combined heat loss factor influenced by wind. Parameter :math:`U_{v}`\n315         in :eq:`pvsyst`.\n316         :math:`\\left[ \\frac{\\text{W}/\\text{m}^2}{\\text{C}\\ \\left( \\text{m/s} \\right)} \\right]`\n317 \n318     eta_m : numeric, default 0.1\n319         Module external efficiency as a fraction, i.e.,\n320         :math:`DC\\ power / (POA\\ irradiance \\times module\\ area)`.\n321         Parameter :math:`\\eta_{m}` in :eq:`pvsyst`.\n322 \n323     alpha_absorption : numeric, default 0.9\n324         Absorption coefficient. Parameter :math:`\\alpha` in :eq:`pvsyst`.\n325 \n326     Returns\n327     -------\n328     numeric, values in degrees Celsius\n329 \n330     Notes\n331     -----\n332     The Pvsyst model for cell temperature :math:`T_{C}` is given by\n333 \n334     .. math::\n335        :label: pvsyst\n336 \n337         T_{C} = T_{a} + \\frac{\\alpha E (1 - \\eta_{m})}{U_{c} + U_{v} \\times WS}\n338 \n339     Inputs to the model are plane-of-array irradiance :math:`E` (W/m2), ambient\n340     air temperature :math:`T_{a}` (C) and wind speed :math:`WS` (m/s). Model\n341     output is cell temperature :math:`T_{C}`. Model parameters depend both on\n342     the module construction and its mounting. Parameters are provided in\n343     [1]_ for open (freestanding) and close (insulated) mounting configurations,\n344     , and are coded for convenience in\n345     :data:`~pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS`. The heat loss\n346     factors provided represent the combined effect of convection, radiation and\n347     conduction, and their values are experimentally determined.\n348 \n349     +--------------+---------------+---------------+\n350     | Mounting     | :math:`U_{c}` | :math:`U_{v}` |\n351     +==============+===============+===============+\n352     | freestanding | 29.0          | 0.0           |\n353     +--------------+---------------+---------------+\n354     | insulated    | 15.0          | 0.0           |\n355     +--------------+---------------+---------------+\n356 \n357     References\n358     ----------\n359     .. [1] \"PVsyst 6 Help\", Files.pvsyst.com, 2018. [Online]. Available:\n360        http://files.pvsyst.com/help/index.html. [Accessed: 10- Dec- 2018].\n361 \n362     .. [2] Faiman, D. (2008). \"Assessing the outdoor operating temperature of\n363        photovoltaic modules.\" Progress in Photovoltaics 16(4): 307-315.\n364 \n365     Examples\n366     --------\n367     >>> from pvlib.temperature import pvsyst_cell, TEMPERATURE_MODEL_PARAMETERS\n368     >>> params = TEMPERATURE_MODEL_PARAMETERS['pvsyst']['freestanding']\n369     >>> pvsyst_cell(1000, 10, **params)\n370     37.93103448275862\n371     \"\"\"\n372 \n373     total_loss_factor = u_c + u_v * wind_speed\n374     heat_input = poa_global * alpha_absorption * (1 - eta_m)\n375     temp_difference = heat_input / total_loss_factor\n376     return temp_air + temp_difference\n377 \n378 \n379 def faiman(poa_global, temp_air, wind_speed=1.0, u0=25.0, u1=6.84):\n380     r'''\n381     Calculate cell or module temperature using the Faiman model.\n382 \n383     The Faiman model uses an empirical heat loss factor model [1]_ and is\n384     adopted in the IEC 61853 standards [2]_ and [3]_.\n385 \n386     Usage of this model in the IEC 61853 standard does not distinguish\n387     between cell and module temperature.\n388 \n389     Parameters\n390     ----------\n391     poa_global : numeric\n392         Total incident irradiance [W/m^2].\n393 \n394     temp_air : numeric\n395         Ambient dry bulb temperature [C].\n396 \n397     wind_speed : numeric, default 1.0\n398         Wind speed in m/s measured at the same height for which the wind loss\n399         factor was determined.  The default value 1.0 m/s is the wind\n400         speed at module height used to determine NOCT. [m/s]\n401 \n402     u0 : numeric, default 25.0\n403         Combined heat loss factor coefficient. The default value is one\n404         determined by Faiman for 7 silicon modules.\n405         :math:`\\left[\\frac{\\text{W}/{\\text{m}^2}}{\\text{C}}\\right]`\n406 \n407     u1 : numeric, default 6.84\n408         Combined heat loss factor influenced by wind. The default value is one\n409         determined by Faiman for 7 silicon modules.\n410         :math:`\\left[ \\frac{\\text{W}/\\text{m}^2}{\\text{C}\\ \\left( \\text{m/s} \\right)} \\right]`\n411 \n412     Returns\n413     -------\n414     numeric, values in degrees Celsius\n415 \n416     Notes\n417     -----\n418     All arguments may be scalars or vectors. If multiple arguments\n419     are vectors they must be the same length.\n420 \n421     References\n422     ----------\n423     .. [1] Faiman, D. (2008). \"Assessing the outdoor operating temperature of\n424        photovoltaic modules.\" Progress in Photovoltaics 16(4): 307-315.\n425 \n426     .. [2] \"IEC 61853-2 Photovoltaic (PV) module performance testing and energy\n427        rating - Part 2: Spectral responsivity, incidence angle and module\n428        operating temperature measurements\". IEC, Geneva, 2018.\n429 \n430     .. [3] \"IEC 61853-3 Photovoltaic (PV) module performance testing and energy\n431        rating - Part 3: Energy rating of PV modules\". IEC, Geneva, 2018.\n432 \n433     '''\n434     # Contributed by Anton Driesse (@adriesse), PV Performance Labs. Dec., 2019\n435 \n436     # The following lines may seem odd since u0 & u1 are probably scalar,\n437     # but it serves an indirect and easy way of allowing lists and\n438     # tuples for the other function arguments.\n439     u0 = np.asanyarray(u0)\n440     u1 = np.asanyarray(u1)\n441 \n442     total_loss_factor = u0 + u1 * wind_speed\n443     heat_input = poa_global\n444     temp_difference = heat_input / total_loss_factor\n445     return temp_air + temp_difference\n446 \n447 \n448 def ross(poa_global, temp_air, noct):\n449     r'''\n450     Calculate cell temperature using the Ross model.\n451 \n452     The Ross model [1]_ assumes the difference between cell temperature\n453     and ambient temperature is proportional to the plane of array irradiance,\n454     and assumes wind speed of 1 m/s. The model implicitly assumes steady or\n455     slowly changing irradiance conditions.\n456 \n457     Parameters\n458     ----------\n459     poa_global : numeric\n460         Total incident irradiance. [W/m^2]\n461 \n462     temp_air : numeric\n463         Ambient dry bulb temperature. [C]\n464 \n465     noct : numeric\n466         Nominal operating cell temperature [C], determined at conditions of\n467         800 W/m^2 irradiance, 20 C ambient air temperature and 1 m/s wind.\n468 \n469     Returns\n470     -------\n471     cell_temperature : numeric\n472         Cell temperature. [C]\n473 \n474     Notes\n475     -----\n476     The Ross model for cell temperature :math:`T_{C}` is given in [1]_ as\n477 \n478     .. math::\n479 \n480         T_{C} = T_{a} + \\frac{NOCT - 20}{80} S\n481 \n482     where :math:`S` is the plane of array irradiance in :math:`mW/{cm}^2`.\n483     This function expects irradiance in :math:`W/m^2`.\n484 \n485     References\n486     ----------\n487     .. [1] Ross, R. G. Jr., (1981). \"Design Techniques for Flat-Plate\n488        Photovoltaic Arrays\". 15th IEEE Photovoltaic Specialist Conference,\n489        Orlando, FL.\n490     '''\n491     # factor of 0.1 converts irradiance from W/m2 to mW/cm2\n492     return temp_air + (noct - 20.) / 80. * poa_global * 0.1\n493 \n494 \n495 def _fuentes_hconv(tave, windmod, tinoct, temp_delta, xlen, tilt,\n496                    check_reynold):\n497     # Calculate the convective coefficient as in Fuentes 1987 -- a mixture of\n498     # free, laminar, and turbulent convection.\n499     densair = 0.003484 * 101325.0 / tave  # density\n500     visair = 0.24237e-6 * tave**0.76 / densair  # kinematic viscosity\n501     condair = 2.1695e-4 * tave**0.84  # thermal conductivity\n502     reynold = windmod * xlen / visair\n503     # the boundary between laminar and turbulent is modeled as an abrupt\n504     # change at Re = 1.2e5:\n505     if check_reynold and reynold > 1.2e5:\n506         # turbulent convection\n507         hforce = 0.0282 / reynold**0.2 * densair * windmod * 1007 / 0.71**0.4\n508     else:\n509         # laminar convection\n510         hforce = 0.8600 / reynold**0.5 * densair * windmod * 1007 / 0.71**0.67\n511     # free convection via Grashof number\n512     # NB: Fuentes hardwires sind(tilt) as 0.5 for tilt=30\n513     grashof = 9.8 / tave * temp_delta * xlen**3 / visair**2 * sind(tilt)\n514     # product of Nusselt number and (k/l)\n515     hfree = 0.21 * (grashof * 0.71)**0.32 * condair / xlen\n516     # combine free and forced components\n517     hconv = (hfree**3 + hforce**3)**(1/3)\n518     return hconv\n519 \n520 \n521 def _hydraulic_diameter(width, height):\n522     # calculate the hydraulic diameter of a rectangle\n523     return 2 * (width * height) / (width + height)\n524 \n525 \n526 def fuentes(poa_global, temp_air, wind_speed, noct_installed, module_height=5,\n527             wind_height=9.144, emissivity=0.84, absorption=0.83,\n528             surface_tilt=30, module_width=0.31579, module_length=1.2):\n529     \"\"\"\n530     Calculate cell or module temperature using the Fuentes model.\n531 \n532     The Fuentes model is a first-principles heat transfer energy balance\n533     model [1]_ that is used in PVWatts for cell temperature modeling [2]_.\n534 \n535     Parameters\n536     ----------\n537     poa_global : pandas Series\n538         Total incident irradiance [W/m^2]\n539 \n540     temp_air : pandas Series\n541         Ambient dry bulb temperature [C]\n542 \n543     wind_speed : pandas Series\n544         Wind speed [m/s]\n545 \n546     noct_installed : float\n547         The \"installed\" nominal operating cell temperature as defined in [1]_.\n548         PVWatts assumes this value to be 45 C for rack-mounted arrays and\n549         49 C for roof mount systems with restricted air flow around the\n550         module.  [C]\n551 \n552     module_height : float, default 5.0\n553         The height above ground of the center of the module. The PVWatts\n554         default is 5.0 [m]\n555 \n556     wind_height : float, default 9.144\n557         The height above ground at which ``wind_speed`` is measured. The\n558         PVWatts defauls is 9.144 [m]\n559 \n560     emissivity : float, default 0.84\n561         The effectiveness of the module at radiating thermal energy. [unitless]\n562 \n563     absorption : float, default 0.83\n564         The fraction of incident irradiance that is converted to thermal\n565         energy in the module. [unitless]\n566 \n567     surface_tilt : float, default 30\n568         Module tilt from horizontal. If not provided, the default value\n569         of 30 degrees from [1]_ and [2]_ is used. [degrees]\n570 \n571     module_width : float, default 0.31579\n572         Module width. The default value of 0.31579 meters in combination with\n573         the default `module_length` gives a hydraulic diameter of 0.5 as\n574         assumed in [1]_ and [2]_. [m]\n575 \n576     module_length : float, default 1.2\n577         Module length. The default value of 1.2 meters in combination with\n578         the default `module_width` gives a hydraulic diameter of 0.5 as\n579         assumed in [1]_ and [2]_. [m]\n580 \n581     Returns\n582     -------\n583     temperature_cell : pandas Series\n584         The modeled cell temperature [C]\n585 \n586     Notes\n587     -----\n588     This function returns slightly different values from PVWatts at night\n589     and just after dawn. This is because the SAM SSC assumes that module\n590     temperature equals ambient temperature when irradiance is zero so it can\n591     skip the heat balance calculation at night.\n592 \n593     References\n594     ----------\n595     .. [1] Fuentes, M. K., 1987, \"A Simplifed Thermal Model for Flat-Plate\n596            Photovoltaic Arrays\", SAND85-0330, Sandia National Laboratories,\n597            Albuquerque NM.\n598            http://prod.sandia.gov/techlib/access-control.cgi/1985/850330.pdf\n599     .. [2] Dobos, A. P., 2014, \"PVWatts Version 5 Manual\", NREL/TP-6A20-62641,\n600            National Renewable Energy Laboratory, Golden CO.\n601            doi:10.2172/1158421.\n602     \"\"\"\n603     # ported from the FORTRAN77 code provided in Appendix A of Fuentes 1987;\n604     # nearly all variable names are kept the same for ease of comparison.\n605 \n606     boltz = 5.669e-8\n607     emiss = emissivity\n608     absorp = absorption\n609     xlen = _hydraulic_diameter(module_width, module_length)\n610     # cap0 has units of [J / (m^2 K)], equal to mass per unit area times\n611     # specific heat of the module.\n612     cap0 = 11000\n613     tinoct = noct_installed + 273.15\n614 \n615     # convective coefficient of top surface of module at NOCT\n616     windmod = 1.0\n617     tave = (tinoct + 293.15) / 2\n618     hconv = _fuentes_hconv(tave, windmod, tinoct, tinoct - 293.15, xlen,\n619                            surface_tilt, False)\n620 \n621     # determine the ground temperature ratio and the ratio of the total\n622     # convection to the top side convection\n623     hground = emiss * boltz * (tinoct**2 + 293.15**2) * (tinoct + 293.15)\n624     backrat = (\n625         absorp * 800.0\n626         - emiss * boltz * (tinoct**4 - 282.21**4)\n627         - hconv * (tinoct - 293.15)\n628     ) / ((hground + hconv) * (tinoct - 293.15))\n629     tground = (tinoct**4 - backrat * (tinoct**4 - 293.15**4))**0.25\n630     tground = np.clip(tground, 293.15, tinoct)\n631 \n632     tgrat = (tground - 293.15) / (tinoct - 293.15)\n633     convrat = (absorp * 800 - emiss * boltz * (\n634         2 * tinoct**4 - 282.21**4 - tground**4)) / (hconv * (tinoct - 293.15))\n635 \n636     # adjust the capacitance (thermal mass) of the module based on the INOCT.\n637     # It is a function of INOCT because high INOCT implies thermal coupling\n638     # with the racking (e.g. roofmount), so the thermal mass is increased.\n639     # `cap` has units J/(m^2 C) -- see Table 3, Equations 26 & 27\n640     cap = cap0\n641     if tinoct > 321.15:\n642         cap = cap * (1 + (tinoct - 321.15) / 12)\n643 \n644     # iterate through timeseries inputs\n645     sun0 = 0\n646     tmod0 = 293.15\n647 \n648     # n.b. the way Fuentes calculates the first timedelta makes it seem like\n649     # the value doesn't matter -- rather than recreate it here, just assume\n650     # it's the same as the second timedelta:\n651     timedelta_seconds = poa_global.index.to_series().diff().dt.total_seconds()\n652     timedelta_hours = timedelta_seconds / 3600\n653     timedelta_hours.iloc[0] = timedelta_hours.iloc[1]\n654 \n655     tamb_array = temp_air + 273.15\n656     sun_array = poa_global * absorp\n657 \n658     # Two of the calculations are easily vectorized, so precalculate them:\n659     # sky temperature -- Equation 24\n660     tsky_array = 0.68 * (0.0552 * tamb_array**1.5) + 0.32 * tamb_array\n661     # wind speed at module height -- Equation 22\n662     # not sure why the 1e-4 factor is included -- maybe the equations don't\n663     # behave well if wind == 0?\n664     windmod_array = wind_speed * (module_height/wind_height)**0.2 + 1e-4\n665 \n666     tmod0 = 293.15\n667     tmod_array = np.zeros_like(poa_global)\n668 \n669     iterator = zip(tamb_array, sun_array, windmod_array, tsky_array,\n670                    timedelta_hours)\n671     for i, (tamb, sun, windmod, tsky, dtime) in enumerate(iterator):\n672         # solve the heat transfer equation, iterating because the heat loss\n673         # terms depend on tmod. NB Fuentes doesn't show that 10 iterations is\n674         # sufficient for convergence.\n675         tmod = tmod0\n676         for j in range(10):\n677             # overall convective coefficient\n678             tave = (tmod + tamb) / 2\n679             hconv = convrat * _fuentes_hconv(tave, windmod, tinoct,\n680                                              abs(tmod-tamb), xlen,\n681                                              surface_tilt, True)\n682             # sky radiation coefficient (Equation 3)\n683             hsky = emiss * boltz * (tmod**2 + tsky**2) * (tmod + tsky)\n684             # ground radiation coeffieicient (Equation 4)\n685             tground = tamb + tgrat * (tmod - tamb)\n686             hground = emiss * boltz * (tmod**2 + tground**2) * (tmod + tground)\n687             # thermal lag -- Equation 8\n688             eigen = - (hconv + hsky + hground) / cap * dtime * 3600\n689             # not sure why this check is done, maybe as a speed optimization?\n690             if eigen > -10:\n691                 ex = np.exp(eigen)\n692             else:\n693                 ex = 0\n694             # Equation 7 -- note that `sun` and `sun0` already account for\n695             # absorption (alpha)\n696             tmod = tmod0 * ex + (\n697                 (1 - ex) * (\n698                     hconv * tamb\n699                     + hsky * tsky\n700                     + hground * tground\n701                     + sun0\n702                     + (sun - sun0) / eigen\n703                 ) + sun - sun0\n704             ) / (hconv + hsky + hground)\n705         tmod_array[i] = tmod\n706         tmod0 = tmod\n707         sun0 = sun\n708 \n709     return pd.Series(tmod_array - 273.15, index=poa_global.index, name='tmod')\n710 \n711 \n712 def _adj_for_mounting_standoff(x):\n713     # supports noct cell temperature function. Except for x > 3.5, the SAM code\n714     # and documentation aren't clear on the precise intervals. The choice of\n715     # < or <= here is pvlib's.\n716     return np.piecewise(x, [x <= 0, (x > 0) & (x < 0.5),\n717                             (x >= 0.5) & (x < 1.5), (x >= 1.5) & (x < 2.5),\n718                             (x >= 2.5) & (x <= 3.5), x > 3.5],\n719                         [0., 18., 11., 6., 2., 0.])\n720 \n721 \n722 def noct_sam(poa_global, temp_air, wind_speed, noct, eta_m_ref,\n723              effective_irradiance=None, transmittance_absorptance=0.9,\n724              array_height=1, mount_standoff=4):\n725     r'''\n726     Cell temperature model from the System Advisor Model (SAM).\n727 \n728     The model is described in [1]_, Section 10.6.\n729 \n730     Parameters\n731     ----------\n732     poa_global : numeric\n733         Total incident irradiance. [W/m^2]\n734 \n735     temp_air : numeric\n736         Ambient dry bulb temperature. [C]\n737 \n738     wind_speed : numeric\n739         Wind speed in m/s measured at the same height for which the wind loss\n740         factor was determined.  The default value 1.0 m/s is the wind\n741         speed at module height used to determine NOCT. [m/s]\n742 \n743     noct : float\n744         Nominal operating cell temperature [C], determined at conditions of\n745         800 W/m^2 irradiance, 20 C ambient air temperature and 1 m/s wind.\n746 \n747     eta_m_ref : float\n748         Module external efficiency [unitless] at reference conditions of\n749         1000 W/m^2 and 20C. Calculate as\n750         :math:`\\eta_{m} = \\frac{V_{mp} I_{mp}}{A \\times 1000 W/m^2}`\n751         where A is module area [m^2].\n752 \n753     effective_irradiance : numeric, default None.\n754         The irradiance that is converted to photocurrent. If None,\n755         assumed equal to poa_global. [W/m^2]\n756 \n757     transmittance_absorptance : numeric, default 0.9\n758         Coefficient for combined transmittance and absorptance effects.\n759         [unitless]\n760 \n761     array_height : int, default 1\n762         Height of array above ground in stories (one story is about 3m). Must\n763         be either 1 or 2. For systems elevated less than one story, use 1.\n764         If system is elevated more than two stories, use 2.\n765 \n766     mount_standoff : numeric, default 4\n767         Distance between array mounting and mounting surface. Use default\n768         if system is ground-mounted. [inches]\n769 \n770     Returns\n771     -------\n772     cell_temperature : numeric\n773         Cell temperature. [C]\n774 \n775     Raises\n776     ------\n777     ValueError\n778         If array_height is an invalid value (must be 1 or 2).\n779 \n780     References\n781     ----------\n782     .. [1] Gilman, P., Dobos, A., DiOrio, N., Freeman, J., Janzou, S.,\n783            Ryberg, D., 2018, \"SAM Photovoltaic Model Technical Reference\n784            Update\", National Renewable Energy Laboratory Report\n785            NREL/TP-6A20-67399.\n786     '''\n787     # in [1] the denominator for irr_ratio isn't precisely clear. From\n788     # reproducing output of the SAM function noct_celltemp_t, we determined\n789     # that:\n790     #  - G_total (SAM) is broadband plane-of-array irradiance before\n791     #    reflections. Equivalent to pvlib variable poa_global\n792     #  - Geff_total (SAM) is POA irradiance after reflections and\n793     #    adjustment for spectrum. Equivalent to effective_irradiance\n794     if effective_irradiance is None:\n795         irr_ratio = 1.\n796     else:\n797         irr_ratio = effective_irradiance / poa_global\n798 \n799     if array_height == 1:\n800         wind_adj = 0.51 * wind_speed\n801     elif array_height == 2:\n802         wind_adj = 0.61 * wind_speed\n803     else:\n804         raise ValueError(\n805             f'array_height must be 1 or 2, {array_height} was given')\n806 \n807     noct_adj = noct + _adj_for_mounting_standoff(mount_standoff)\n808     tau_alpha = transmittance_absorptance * irr_ratio\n809 \n810     # [1] Eq. 10.37 isn't clear on exactly what \"G\" is. SAM SSC code uses\n811     # poa_global where G appears\n812     cell_temp_init = poa_global / 800. * (noct_adj - 20.)\n813     heat_loss = 1 - eta_m_ref / tau_alpha\n814     wind_loss = 9.5 / (5.7 + 3.8 * wind_adj)\n815     return temp_air + cell_temp_init * heat_loss * wind_loss\n816 \n[end of pvlib/temperature.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n\n\n", "full_output": "```patch\n--- a/pvlib/pvsystem.py\n+++ b/pvlib/pvsystem.py\n@@ -846,7 +846,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1150,7 +1150,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1185,7 +1185,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1220,7 +1220,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1255,7 +1255,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1290,7 +1290,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1325,7 +1325,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1350,7 +1350,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1385,7 +1385,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1410,7 +1410,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1435,7 +1435,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1460,7 +1460,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1485,7 +1485,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1510,7 +1510,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1535,7 +1535,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1560,7 +1560,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1585,7 +1585,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1610,7 +1610,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1635,7 +1635,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1660,7 +1660,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1685,7 +1685,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1710,7 +1710,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1735,7 +1735,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1760,7 +1760,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1785,7 +1785,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1810,7 +1810,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1835,7 +1835,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1860,7 +1860,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1885,7 +1885,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1910,7 +1910,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1935,7 +1935,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1960,7 +1960,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1985,7 +1985,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n```", "model_patch": "--- a/pvlib/pvsystem.py\n+++ b/pvlib/pvsystem.py\n@@ -846,7 +846,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1150,7 +1150,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1185,7 +1185,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1220,7 +1220,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1255,7 +1255,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1290,7 +1290,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1325,7 +1325,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1350,7 +1350,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1385,7 +1385,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1410,7 +1410,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1435,7 +1435,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1460,7 +1460,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1485,7 +1485,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1510,7 +1510,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1535,7 +1535,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1560,7 +1560,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1585,7 +1585,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1610,7 +1610,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1635,7 +1635,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1660,7 +1660,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1685,7 +1685,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1710,7 +1710,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1735,7 +1735,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1760,7 +1760,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1785,7 +1785,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1810,7 +1810,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1835,7 +1835,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1860,7 +1860,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1885,7 +1885,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1910,7 +1910,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1935,7 +1935,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1960,7 +1960,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n@@ -1985,7 +1985,7 @@\n \n     Returns\n     -------\n-    numeric, values in degrees C.\n+    numeric, values in degrees Celsius.\n \n     Notes\n     -----\n"}
{"instance_id": "pylint-dev__astroid-1962", "model_name_or_path": "gpt-4o-mini", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nv2.13.x regression: Crash when inspecting `PyQt5.QtWidgets` due to `RuntimeError` during `hasattr`\n### Steps to reproduce\r\n\r\nInstall PyQt5, run `pylint --extension-pkg-whitelist=PyQt5 x.py` over a file containing `from PyQt5 import QtWidgets`\r\n\r\n### Current behavior\r\n\r\nWith astroid 2.12.13 and pylint 2.15.10, this works fine. With astroid 2.13.2, this happens:\r\n\r\n```pytb\r\nException on node <ImportFrom l.1 at 0x7fc5a3c47d00> in file '/home/florian/tmp/pylintbug/x.py'\r\nTraceback (most recent call last):\r\n  File \"/home/florian/tmp/pylintbug/.venv/lib/python3.10/site-packages/pylint/utils/ast_walker.py\", line 90, in walk\r\n    callback(astroid)\r\n  File \"/home/florian/tmp/pylintbug/.venv/lib/python3.10/site-packages/pylint/checkers/variables.py\", line 1726, in visit_importfrom\r\n    self._check_module_attrs(node, module, name.split(\".\"))\r\n  File \"/home/florian/tmp/pylintbug/.venv/lib/python3.10/site-packages/pylint/checkers/variables.py\", line 2701, in _check_module_attrs\r\n    module = next(module.getattr(name)[0].infer())\r\n  File \"/home/florian/tmp/pylintbug/.venv/lib/python3.10/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py\", line 412, in getattr\r\n    result = [self.import_module(name, relative_only=True)]\r\n  File \"/home/florian/tmp/pylintbug/.venv/lib/python3.10/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py\", line 527, in import_module\r\n    return AstroidManager().ast_from_module_name(\r\n  File \"/home/florian/tmp/pylintbug/.venv/lib/python3.10/site-packages/astroid/manager.py\", line 205, in ast_from_module_name\r\n    return self.ast_from_module(named_module, modname)\r\n  File \"/home/florian/tmp/pylintbug/.venv/lib/python3.10/site-packages/astroid/manager.py\", line 312, in ast_from_module\r\n    return AstroidBuilder(self).module_build(module, modname)\r\n  File \"/home/florian/tmp/pylintbug/.venv/lib/python3.10/site-packages/astroid/builder.py\", line 101, in module_build\r\n    node = self.inspect_build(module, modname=modname, path=path)\r\n  File \"/home/florian/tmp/pylintbug/.venv/lib/python3.10/site-packages/astroid/raw_building.py\", line 366, in inspect_build\r\n    self.object_build(node, module)\r\n  File \"/home/florian/tmp/pylintbug/.venv/lib/python3.10/site-packages/astroid/raw_building.py\", line 422, in object_build\r\n    elif hasattr(member, \"__all__\"):\r\nRuntimeError: wrapped C/C++ object of type QApplication has been deleted\r\nx.py:1:0: F0002: x.py: Fatal error while checking 'x.py'. Please open an issue in our bug tracker so we address this. There is a pre-filled template that you can use in '/home/florian/.cache/pylint/pylint-crash-2023-01-10-11-06-17.txt'. (astroid-error)\r\n```\r\n\r\nIt looks like it happens when `member` is `QtWidgets.qApp`, which is a kind of \"magic\" object referring to the QApplication singleton. Since none exists, it looks like PyQt doesn't like trying to access an attribute on that.\r\n\r\nBisected to:\r\n\r\n- #1885 \r\n\r\nIt looks like 974f26f75eb3eccb4bcd8ea143901baf60a685ff is the exact culprit.\r\n\r\ncc @nickdrozd \r\n\r\n(took the freedom to add appropriate labels already, hope that's fine)\r\n\n\n</issue>\n<code>\n[start of README.rst]\n1 Astroid\n2 =======\n3 \n4 .. image:: https://codecov.io/gh/PyCQA/astroid/branch/main/graph/badge.svg?token=Buxy4WptLb\n5     :target: https://codecov.io/gh/PyCQA/astroid\n6     :alt: Coverage badge from codecov\n7 \n8 .. image:: https://readthedocs.org/projects/astroid/badge/?version=latest\n9     :target: http://astroid.readthedocs.io/en/latest/?badge=latest\n10     :alt: Documentation Status\n11 \n12 .. image:: https://img.shields.io/badge/code%20style-black-000000.svg\n13     :target: https://github.com/ambv/black\n14 \n15 .. image:: https://results.pre-commit.ci/badge/github/PyCQA/astroid/main.svg\n16    :target: https://results.pre-commit.ci/latest/github/PyCQA/astroid/main\n17    :alt: pre-commit.ci status\n18 \n19 .. |tidelift_logo| image:: https://raw.githubusercontent.com/PyCQA/astroid/main/doc/media/Tidelift_Logos_RGB_Tidelift_Shorthand_On-White.png\n20    :width: 200\n21    :alt: Tidelift\n22 \n23 .. list-table::\n24    :widths: 10 100\n25 \n26    * - |tidelift_logo|\n27      - Professional support for astroid is available as part of the\n28        `Tidelift Subscription`_.  Tidelift gives software development teams a single source for\n29        purchasing and maintaining their software, with professional grade assurances\n30        from the experts who know it best, while seamlessly integrating with existing\n31        tools.\n32 \n33 .. _Tidelift Subscription: https://tidelift.com/subscription/pkg/pypi-astroid?utm_source=pypi-astroid&utm_medium=referral&utm_campaign=readme\n34 \n35 \n36 \n37 What's this?\n38 ------------\n39 \n40 The aim of this module is to provide a common base representation of\n41 python source code. It is currently the library powering pylint's capabilities.\n42 \n43 It provides a compatible representation which comes from the `_ast`\n44 module.  It rebuilds the tree generated by the builtin _ast module by\n45 recursively walking down the AST and building an extended ast. The new\n46 node classes have additional methods and attributes for different\n47 usages. They include some support for static inference and local name\n48 scopes. Furthermore, astroid can also build partial trees by inspecting living\n49 objects.\n50 \n51 \n52 Installation\n53 ------------\n54 \n55 Extract the tarball, jump into the created directory and run::\n56 \n57     pip install .\n58 \n59 \n60 If you want to do an editable installation, you can run::\n61 \n62     pip install -e .\n63 \n64 \n65 If you have any questions, please mail the code-quality@python.org\n66 mailing list for support. See\n67 http://mail.python.org/mailman/listinfo/code-quality for subscription\n68 information and archives.\n69 \n70 Documentation\n71 -------------\n72 http://astroid.readthedocs.io/en/latest/\n73 \n74 \n75 Python Versions\n76 ---------------\n77 \n78 astroid 2.0 is currently available for Python 3 only. If you want Python 2\n79 support, use an older version of astroid (though note that these versions\n80 are no longer supported).\n81 \n82 Test\n83 ----\n84 \n85 Tests are in the 'test' subdirectory. To launch the whole tests suite, you can use\n86 either `tox` or `pytest`::\n87 \n88     tox\n89     pytest\n90 \n[end of README.rst]\n[start of astroid/raw_building.py]\n1 # Licensed under the LGPL: https://www.gnu.org/licenses/old-licenses/lgpl-2.1.en.html\n2 # For details: https://github.com/PyCQA/astroid/blob/main/LICENSE\n3 # Copyright (c) https://github.com/PyCQA/astroid/blob/main/CONTRIBUTORS.txt\n4 \n5 \"\"\"this module contains a set of functions to create astroid trees from scratch\n6 (build_* functions) or from living object (object_build_* functions)\n7 \"\"\"\n8 \n9 from __future__ import annotations\n10 \n11 import builtins\n12 import inspect\n13 import os\n14 import sys\n15 import types\n16 import warnings\n17 from collections.abc import Iterable\n18 from typing import Any, Union\n19 \n20 from astroid import bases, nodes\n21 from astroid.const import _EMPTY_OBJECT_MARKER, IS_PYPY\n22 from astroid.manager import AstroidManager\n23 from astroid.nodes import node_classes\n24 \n25 _FunctionTypes = Union[\n26     types.FunctionType,\n27     types.MethodType,\n28     types.BuiltinFunctionType,\n29     types.WrapperDescriptorType,\n30     types.MethodDescriptorType,\n31     types.ClassMethodDescriptorType,\n32 ]\n33 \n34 # the keys of CONST_CLS eg python builtin types\n35 _CONSTANTS = tuple(node_classes.CONST_CLS)\n36 _BUILTINS = vars(builtins)\n37 TYPE_NONE = type(None)\n38 TYPE_NOTIMPLEMENTED = type(NotImplemented)\n39 TYPE_ELLIPSIS = type(...)\n40 \n41 \n42 def _attach_local_node(parent, node, name: str) -> None:\n43     node.name = name  # needed by add_local_node\n44     parent.add_local_node(node)\n45 \n46 \n47 def _add_dunder_class(func, member) -> None:\n48     \"\"\"Add a __class__ member to the given func node, if we can determine it.\"\"\"\n49     python_cls = member.__class__\n50     cls_name = getattr(python_cls, \"__name__\", None)\n51     if not cls_name:\n52         return\n53     cls_bases = [ancestor.__name__ for ancestor in python_cls.__bases__]\n54     ast_klass = build_class(cls_name, cls_bases, python_cls.__doc__)\n55     func.instance_attrs[\"__class__\"] = [ast_klass]\n56 \n57 \n58 def attach_dummy_node(node, name: str, runtime_object=_EMPTY_OBJECT_MARKER) -> None:\n59     \"\"\"create a dummy node and register it in the locals of the given\n60     node with the specified name\n61     \"\"\"\n62     enode = nodes.EmptyNode()\n63     enode.object = runtime_object\n64     _attach_local_node(node, enode, name)\n65 \n66 \n67 def attach_const_node(node, name: str, value) -> None:\n68     \"\"\"create a Const node and register it in the locals of the given\n69     node with the specified name\n70     \"\"\"\n71     if name not in node.special_attributes:\n72         _attach_local_node(node, nodes.const_factory(value), name)\n73 \n74 \n75 def attach_import_node(node, modname: str, membername: str) -> None:\n76     \"\"\"create a ImportFrom node and register it in the locals of the given\n77     node with the specified name\n78     \"\"\"\n79     from_node = nodes.ImportFrom(modname, [(membername, None)])\n80     _attach_local_node(node, from_node, membername)\n81 \n82 \n83 def build_module(name: str, doc: str | None = None) -> nodes.Module:\n84     \"\"\"create and initialize an astroid Module node\"\"\"\n85     node = nodes.Module(name, pure_python=False, package=False)\n86     node.postinit(\n87         body=[],\n88         doc_node=nodes.Const(value=doc) if doc else None,\n89     )\n90     return node\n91 \n92 \n93 def build_class(\n94     name: str, basenames: Iterable[str] = (), doc: str | None = None\n95 ) -> nodes.ClassDef:\n96     \"\"\"Create and initialize an astroid ClassDef node.\"\"\"\n97     node = nodes.ClassDef(name)\n98     node.postinit(\n99         bases=[nodes.Name(name=base, parent=node) for base in basenames],\n100         body=[],\n101         decorators=None,\n102         doc_node=nodes.Const(value=doc) if doc else None,\n103     )\n104     return node\n105 \n106 \n107 def build_function(\n108     name: str,\n109     args: list[str] | None = None,\n110     posonlyargs: list[str] | None = None,\n111     defaults: list[Any] | None = None,\n112     doc: str | None = None,\n113     kwonlyargs: list[str] | None = None,\n114 ) -> nodes.FunctionDef:\n115     \"\"\"create and initialize an astroid FunctionDef node\"\"\"\n116     # first argument is now a list of decorators\n117     func = nodes.FunctionDef(name)\n118     argsnode = nodes.Arguments(parent=func)\n119 \n120     # If args is None we don't have any information about the signature\n121     # (in contrast to when there are no arguments and args == []). We pass\n122     # this to the builder to indicate this.\n123     if args is not None:\n124         arguments = [nodes.AssignName(name=arg, parent=argsnode) for arg in args]\n125     else:\n126         arguments = None\n127 \n128     default_nodes: list[nodes.NodeNG] | None = []\n129     if defaults is not None:\n130         for default in defaults:\n131             default_node = nodes.const_factory(default)\n132             default_node.parent = argsnode\n133             default_nodes.append(default_node)\n134     else:\n135         default_nodes = None\n136 \n137     argsnode.postinit(\n138         args=arguments,\n139         defaults=default_nodes,\n140         kwonlyargs=[\n141             nodes.AssignName(name=arg, parent=argsnode) for arg in kwonlyargs or ()\n142         ],\n143         kw_defaults=[],\n144         annotations=[],\n145         posonlyargs=[\n146             nodes.AssignName(name=arg, parent=argsnode) for arg in posonlyargs or ()\n147         ],\n148     )\n149     func.postinit(\n150         args=argsnode,\n151         body=[],\n152         doc_node=nodes.Const(value=doc) if doc else None,\n153     )\n154     if args:\n155         register_arguments(func)\n156     return func\n157 \n158 \n159 def build_from_import(fromname: str, names: list[str]) -> nodes.ImportFrom:\n160     \"\"\"create and initialize an astroid ImportFrom import statement\"\"\"\n161     return nodes.ImportFrom(fromname, [(name, None) for name in names])\n162 \n163 \n164 def register_arguments(func: nodes.FunctionDef, args: list | None = None) -> None:\n165     \"\"\"add given arguments to local\n166 \n167     args is a list that may contains nested lists\n168     (i.e. def func(a, (b, c, d)): ...)\n169     \"\"\"\n170     # If no args are passed in, get the args from the function.\n171     if args is None:\n172         if func.args.vararg:\n173             func.set_local(func.args.vararg, func.args)\n174         if func.args.kwarg:\n175             func.set_local(func.args.kwarg, func.args)\n176         args = func.args.args\n177         # If the function has no args, there is nothing left to do.\n178         if args is None:\n179             return\n180     for arg in args:\n181         if isinstance(arg, nodes.AssignName):\n182             func.set_local(arg.name, arg)\n183         else:\n184             register_arguments(func, arg.elts)\n185 \n186 \n187 def object_build_class(\n188     node: nodes.Module | nodes.ClassDef, member: type, localname: str\n189 ) -> nodes.ClassDef:\n190     \"\"\"create astroid for a living class object\"\"\"\n191     basenames = [base.__name__ for base in member.__bases__]\n192     return _base_class_object_build(node, member, basenames, localname=localname)\n193 \n194 \n195 def _get_args_info_from_callable(\n196     member: _FunctionTypes,\n197 ) -> tuple[list[str], list[str], list[Any], list[str]]:\n198     \"\"\"Returns args, posonlyargs, defaults, kwonlyargs.\n199 \n200     :note: currently ignores the return annotation.\n201     \"\"\"\n202     signature = inspect.signature(member)\n203     args: list[str] = []\n204     defaults: list[Any] = []\n205     posonlyargs: list[str] = []\n206     kwonlyargs: list[str] = []\n207 \n208     for param_name, param in signature.parameters.items():\n209         if param.kind == inspect.Parameter.POSITIONAL_ONLY:\n210             posonlyargs.append(param_name)\n211         elif param.kind == inspect.Parameter.POSITIONAL_OR_KEYWORD:\n212             args.append(param_name)\n213         elif param.kind == inspect.Parameter.VAR_POSITIONAL:\n214             args.append(param_name)\n215         elif param.kind == inspect.Parameter.VAR_KEYWORD:\n216             args.append(param_name)\n217         elif param.kind == inspect.Parameter.KEYWORD_ONLY:\n218             kwonlyargs.append(param_name)\n219         if param.default is not inspect._empty:\n220             defaults.append(param.default)\n221 \n222     return args, posonlyargs, defaults, kwonlyargs\n223 \n224 \n225 def object_build_function(\n226     node: nodes.Module | nodes.ClassDef, member: _FunctionTypes, localname: str\n227 ) -> None:\n228     \"\"\"create astroid for a living function object\"\"\"\n229     args, posonlyargs, defaults, kwonlyargs = _get_args_info_from_callable(member)\n230 \n231     func = build_function(\n232         getattr(member, \"__name__\", None) or localname,\n233         args,\n234         posonlyargs,\n235         defaults,\n236         member.__doc__,\n237         kwonlyargs=kwonlyargs,\n238     )\n239 \n240     node.add_local_node(func, localname)\n241 \n242 \n243 def object_build_datadescriptor(\n244     node: nodes.Module | nodes.ClassDef, member: type, name: str\n245 ) -> nodes.ClassDef:\n246     \"\"\"create astroid for a living data descriptor object\"\"\"\n247     return _base_class_object_build(node, member, [], name)\n248 \n249 \n250 def object_build_methoddescriptor(\n251     node: nodes.Module | nodes.ClassDef,\n252     member: _FunctionTypes,\n253     localname: str,\n254 ) -> None:\n255     \"\"\"create astroid for a living method descriptor object\"\"\"\n256     # FIXME get arguments ?\n257     func = build_function(\n258         getattr(member, \"__name__\", None) or localname, doc=member.__doc__\n259     )\n260     node.add_local_node(func, localname)\n261     _add_dunder_class(func, member)\n262 \n263 \n264 def _base_class_object_build(\n265     node: nodes.Module | nodes.ClassDef,\n266     member: type,\n267     basenames: list[str],\n268     name: str | None = None,\n269     localname: str | None = None,\n270 ) -> nodes.ClassDef:\n271     \"\"\"create astroid for a living class object, with a given set of base names\n272     (e.g. ancestors)\n273     \"\"\"\n274     class_name = name or getattr(member, \"__name__\", None) or localname\n275     assert isinstance(class_name, str)\n276     klass = build_class(\n277         class_name,\n278         basenames,\n279         member.__doc__,\n280     )\n281     klass._newstyle = isinstance(member, type)\n282     node.add_local_node(klass, localname)\n283     try:\n284         # limit the instantiation trick since it's too dangerous\n285         # (such as infinite test execution...)\n286         # this at least resolves common case such as Exception.args,\n287         # OSError.errno\n288         if issubclass(member, Exception):\n289             instdict = member().__dict__\n290         else:\n291             raise TypeError\n292     except TypeError:\n293         pass\n294     else:\n295         for item_name, obj in instdict.items():\n296             valnode = nodes.EmptyNode()\n297             valnode.object = obj\n298             valnode.parent = klass\n299             valnode.lineno = 1\n300             klass.instance_attrs[item_name] = [valnode]\n301     return klass\n302 \n303 \n304 def _build_from_function(\n305     node: nodes.Module | nodes.ClassDef,\n306     name: str,\n307     member: _FunctionTypes,\n308     module: types.ModuleType,\n309 ) -> None:\n310     # verify this is not an imported function\n311     try:\n312         code = member.__code__  # type: ignore[union-attr]\n313     except AttributeError:\n314         # Some implementations don't provide the code object,\n315         # such as Jython.\n316         code = None\n317     filename = getattr(code, \"co_filename\", None)\n318     if filename is None:\n319         assert isinstance(member, object)\n320         object_build_methoddescriptor(node, member, name)\n321     elif filename != getattr(module, \"__file__\", None):\n322         attach_dummy_node(node, name, member)\n323     else:\n324         object_build_function(node, member, name)\n325 \n326 \n327 class InspectBuilder:\n328     \"\"\"class for building nodes from living object\n329 \n330     this is actually a really minimal representation, including only Module,\n331     FunctionDef and ClassDef nodes and some others as guessed.\n332     \"\"\"\n333 \n334     def __init__(self, manager_instance: AstroidManager | None = None) -> None:\n335         self._manager = manager_instance or AstroidManager()\n336         self._done: dict[types.ModuleType | type, nodes.Module | nodes.ClassDef] = {}\n337         self._module: types.ModuleType\n338 \n339     def inspect_build(\n340         self,\n341         module: types.ModuleType,\n342         modname: str | None = None,\n343         path: str | None = None,\n344     ) -> nodes.Module:\n345         \"\"\"build astroid from a living module (i.e. using inspect)\n346         this is used when there is no python source code available (either\n347         because it's a built-in module or because the .py is not available)\n348         \"\"\"\n349         self._module = module\n350         if modname is None:\n351             modname = module.__name__\n352         try:\n353             node = build_module(modname, module.__doc__)\n354         except AttributeError:\n355             # in jython, java modules have no __doc__ (see #109562)\n356             node = build_module(modname)\n357         if path is None:\n358             node.path = node.file = path\n359         else:\n360             node.path = [os.path.abspath(path)]\n361             node.file = node.path[0]\n362         node.name = modname\n363         self._manager.cache_module(node)\n364         node.package = hasattr(module, \"__path__\")\n365         self._done = {}\n366         self.object_build(node, module)\n367         return node\n368 \n369     def object_build(\n370         self, node: nodes.Module | nodes.ClassDef, obj: types.ModuleType | type\n371     ) -> None:\n372         \"\"\"recursive method which create a partial ast from real objects\n373         (only function, class, and method are handled)\n374         \"\"\"\n375         if obj in self._done:\n376             return None\n377         self._done[obj] = node\n378         for name in dir(obj):\n379             # inspect.ismethod() and inspect.isbuiltin() in PyPy return\n380             # the opposite of what they do in CPython for __class_getitem__.\n381             pypy__class_getitem__ = IS_PYPY and name == \"__class_getitem__\"\n382             try:\n383                 with warnings.catch_warnings():\n384                     warnings.simplefilter(\"ignore\")\n385                     member = getattr(obj, name)\n386             except AttributeError:\n387                 # damned ExtensionClass.Base, I know you're there !\n388                 attach_dummy_node(node, name)\n389                 continue\n390             if inspect.ismethod(member) and not pypy__class_getitem__:\n391                 member = member.__func__\n392             if inspect.isfunction(member):\n393                 _build_from_function(node, name, member, self._module)\n394             elif inspect.isbuiltin(member) or pypy__class_getitem__:\n395                 if self.imported_member(node, member, name):\n396                     continue\n397                 object_build_methoddescriptor(node, member, name)\n398             elif inspect.isclass(member):\n399                 if self.imported_member(node, member, name):\n400                     continue\n401                 if member in self._done:\n402                     class_node = self._done[member]\n403                     assert isinstance(class_node, nodes.ClassDef)\n404                     if class_node not in node.locals.get(name, ()):\n405                         node.add_local_node(class_node, name)\n406                 else:\n407                     class_node = object_build_class(node, member, name)\n408                     # recursion\n409                     self.object_build(class_node, member)\n410                 if name == \"__class__\" and class_node.parent is None:\n411                     class_node.parent = self._done[self._module]\n412             elif inspect.ismethoddescriptor(member):\n413                 object_build_methoddescriptor(node, member, name)\n414             elif inspect.isdatadescriptor(member):\n415                 object_build_datadescriptor(node, member, name)\n416             elif isinstance(member, _CONSTANTS):\n417                 attach_const_node(node, name, member)\n418             elif inspect.isroutine(member):\n419                 # This should be called for Jython, where some builtin\n420                 # methods aren't caught by isbuiltin branch.\n421                 _build_from_function(node, name, member, self._module)\n422             elif hasattr(member, \"__all__\"):\n423                 module = build_module(name)\n424                 _attach_local_node(node, module, name)\n425                 # recursion\n426                 self.object_build(module, member)\n427             else:\n428                 # create an empty node so that the name is actually defined\n429                 attach_dummy_node(node, name, member)\n430         return None\n431 \n432     def imported_member(self, node, member, name: str) -> bool:\n433         \"\"\"verify this is not an imported class or handle it\"\"\"\n434         # /!\\ some classes like ExtensionClass doesn't have a __module__\n435         # attribute ! Also, this may trigger an exception on badly built module\n436         # (see http://www.logilab.org/ticket/57299 for instance)\n437         try:\n438             modname = getattr(member, \"__module__\", None)\n439         except TypeError:\n440             modname = None\n441         if modname is None:\n442             if name in {\"__new__\", \"__subclasshook__\"}:\n443                 # Python 2.5.1 (r251:54863, Sep  1 2010, 22:03:14)\n444                 # >>> print object.__new__.__module__\n445                 # None\n446                 modname = builtins.__name__\n447             else:\n448                 attach_dummy_node(node, name, member)\n449                 return True\n450 \n451         # On PyPy during bootstrapping we infer _io while _module is\n452         # builtins. In CPython _io names itself io, see http://bugs.python.org/issue18602\n453         # Therefore, this basically checks whether we are not in PyPy.\n454         if modname == \"_io\" and not self._module.__name__ == \"builtins\":\n455             return False\n456 \n457         real_name = {\"gtk\": \"gtk_gtk\"}.get(modname, modname)\n458 \n459         if real_name != self._module.__name__:\n460             # check if it sounds valid and then add an import node, else use a\n461             # dummy node\n462             try:\n463                 getattr(sys.modules[modname], name)\n464             except (KeyError, AttributeError):\n465                 attach_dummy_node(node, name, member)\n466             else:\n467                 attach_import_node(node, modname, name)\n468             return True\n469         return False\n470 \n471 \n472 # astroid bootstrapping ######################################################\n473 \n474 _CONST_PROXY: dict[type, nodes.ClassDef] = {}\n475 \n476 \n477 def _set_proxied(const) -> nodes.ClassDef:\n478     # TODO : find a nicer way to handle this situation;\n479     return _CONST_PROXY[const.value.__class__]\n480 \n481 \n482 def _astroid_bootstrapping() -> None:\n483     \"\"\"astroid bootstrapping the builtins module\"\"\"\n484     # this boot strapping is necessary since we need the Const nodes to\n485     # inspect_build builtins, and then we can proxy Const\n486     builder = InspectBuilder()\n487     astroid_builtin = builder.inspect_build(builtins)\n488 \n489     for cls, node_cls in node_classes.CONST_CLS.items():\n490         if cls is TYPE_NONE:\n491             proxy = build_class(\"NoneType\")\n492             proxy.parent = astroid_builtin\n493         elif cls is TYPE_NOTIMPLEMENTED:\n494             proxy = build_class(\"NotImplementedType\")\n495             proxy.parent = astroid_builtin\n496         elif cls is TYPE_ELLIPSIS:\n497             proxy = build_class(\"Ellipsis\")\n498             proxy.parent = astroid_builtin\n499         else:\n500             proxy = astroid_builtin.getattr(cls.__name__)[0]\n501             assert isinstance(proxy, nodes.ClassDef)\n502         if cls in (dict, list, set, tuple):\n503             node_cls._proxied = proxy\n504         else:\n505             _CONST_PROXY[cls] = proxy\n506 \n507     # Set the builtin module as parent for some builtins.\n508     nodes.Const._proxied = property(_set_proxied)\n509 \n510     _GeneratorType = nodes.ClassDef(types.GeneratorType.__name__)\n511     _GeneratorType.parent = astroid_builtin\n512     generator_doc_node = (\n513         nodes.Const(value=types.GeneratorType.__doc__)\n514         if types.GeneratorType.__doc__\n515         else None\n516     )\n517     _GeneratorType.postinit(\n518         bases=[],\n519         body=[],\n520         decorators=None,\n521         doc_node=generator_doc_node,\n522     )\n523     bases.Generator._proxied = _GeneratorType\n524     builder.object_build(bases.Generator._proxied, types.GeneratorType)\n525 \n526     if hasattr(types, \"AsyncGeneratorType\"):\n527         _AsyncGeneratorType = nodes.ClassDef(types.AsyncGeneratorType.__name__)\n528         _AsyncGeneratorType.parent = astroid_builtin\n529         async_generator_doc_node = (\n530             nodes.Const(value=types.AsyncGeneratorType.__doc__)\n531             if types.AsyncGeneratorType.__doc__\n532             else None\n533         )\n534         _AsyncGeneratorType.postinit(\n535             bases=[],\n536             body=[],\n537             decorators=None,\n538             doc_node=async_generator_doc_node,\n539         )\n540         bases.AsyncGenerator._proxied = _AsyncGeneratorType\n541         builder.object_build(bases.AsyncGenerator._proxied, types.AsyncGeneratorType)\n542     builtin_types = (\n543         types.GetSetDescriptorType,\n544         types.GeneratorType,\n545         types.MemberDescriptorType,\n546         TYPE_NONE,\n547         TYPE_NOTIMPLEMENTED,\n548         types.FunctionType,\n549         types.MethodType,\n550         types.BuiltinFunctionType,\n551         types.ModuleType,\n552         types.TracebackType,\n553     )\n554     for _type in builtin_types:\n555         if _type.__name__ not in astroid_builtin:\n556             klass = nodes.ClassDef(_type.__name__)\n557             klass.parent = astroid_builtin\n558             klass.postinit(\n559                 bases=[],\n560                 body=[],\n561                 decorators=None,\n562                 doc_node=nodes.Const(value=_type.__doc__) if _type.__doc__ else None,\n563             )\n564             builder.object_build(klass, _type)\n565             astroid_builtin[_type.__name__] = klass\n566 \n567 \n568 _astroid_bootstrapping()\n569 \n[end of astroid/raw_building.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n\n\n", "full_output": "```patch\n--- a/astroid/raw_building.py\n+++ b/astroid/raw_building.py\n@@ -283,7 +283,7 @@\n         # limit the instantiation trick since it's too dangerous\n         # (such as infinite test execution...)\n         # this at least resolves common case such as Exception.args,\n         # OSError.errno\n-        if issubclass(member, Exception):\n+        if isinstance(member, type) and issubclass(member, Exception):\n             instdict = member().__dict__\n         else:\n             raise TypeError\n```", "model_patch": "--- a/astroid/raw_building.py\n+++ b/astroid/raw_building.py\n@@ -283,7 +283,7 @@\n         # limit the instantiation trick since it's too dangerous\n         # (such as infinite test execution...)\n         # this at least resolves common case such as Exception.args,\n         # OSError.errno\n-        if issubclass(member, Exception):\n+        if isinstance(member, type) and issubclass(member, Exception):\n             instdict = member().__dict__\n         else:\n             raise TypeError\n"}
{"instance_id": "pylint-dev__astroid-1719", "model_name_or_path": "gpt-4o-mini", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nCython module with import triggers deep introspection for pandas, raises unhandled FutureWarning\nThis is a somewhat complicated situation to reproduce, but basically `pandas` throws `FutureWarning`s for certain attributes, and when you import it into a Cython module (triggering astroid's deep module inspection), these future warnings are not handled by astroid and bubble up as `AstroidError`s through to pylint. Here is a full repro:\r\n\r\n\r\n### Cython module `pyx.pyx`\r\n\r\n```python\r\n# distutils: language = c++\r\nimport pandas as pd\r\n\r\ncdef class Test:\r\n    def __cinit__(self):\r\n        ...\r\n```\r\n\r\n\r\n### Python module `test.py`\r\n\r\n```python\r\nimport pyx\r\n\r\npyx.Test()\r\n```\r\n\r\n\r\n\r\n### Commands\r\n```\r\ncythonize -a -i pyx.pyx\r\npylint --extension-pkg-allow-list=pyx,pandas test.py\r\n```\r\n\r\n\r\n### Exception\r\n```\r\nException on node <Import l.1 at 0x106b23ca0> in file '/Users/timkpaine/Programs/projects/other/astroid/test.py'\r\nTraceback (most recent call last):\r\n  File \"/opt/homebrew/lib/python3.9/site-packages/pylint/checkers/imports.py\", line 765, in _get_imported_module\r\n    return importnode.do_import_module(modname)\r\n  File \"/opt/homebrew/lib/python3.9/site-packages/astroid/mixins.py\", line 102, in do_import_module\r\n    return mymodule.import_module(\r\n  File \"/opt/homebrew/lib/python3.9/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py\", line 527, in import_module\r\n    return AstroidManager().ast_from_module_name(absmodname)\r\n  File \"/opt/homebrew/lib/python3.9/site-packages/astroid/manager.py\", line 168, in ast_from_module_name\r\n    return self.ast_from_module(module, modname)\r\n  File \"/opt/homebrew/lib/python3.9/site-packages/astroid/manager.py\", line 265, in ast_from_module\r\n    return AstroidBuilder(self).module_build(module, modname)\r\n  File \"/opt/homebrew/lib/python3.9/site-packages/astroid/builder.py\", line 91, in module_build\r\n    node = self.inspect_build(module, modname=modname, path=path)\r\n  File \"/opt/homebrew/lib/python3.9/site-packages/astroid/raw_building.py\", line 311, in inspect_build\r\n    self.object_build(node, module)\r\n  File \"/opt/homebrew/lib/python3.9/site-packages/astroid/raw_building.py\", line 367, in object_build\r\n    self.object_build(module, member)\r\n  File \"/opt/homebrew/lib/python3.9/site-packages/astroid/raw_building.py\", line 325, in object_build\r\n    member = getattr(obj, name)\r\n  File \"/opt/homebrew/lib/python3.9/site-packages/pandas/__init__.py\", line 198, in __getattr__\r\n    warnings.warn(\r\nFutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/opt/homebrew/lib/python3.9/site-packages/pylint/utils/ast_walker.py\", line 90, in walk\r\n    callback(astroid)\r\n  File \"/opt/homebrew/lib/python3.9/site-packages/pylint/checkers/imports.py\", line 472, in visit_import\r\n    imported_module = self._get_imported_module(node, name)\r\n  File \"/opt/homebrew/lib/python3.9/site-packages/pylint/checkers/imports.py\", line 788, in _get_imported_module\r\n    raise astroid.AstroidError from e\r\nastroid.exceptions.AstroidError\r\n************* Module test\r\ntest.py:1:0: F0002: test.py: Fatal error while checking 'test.py'. Please open an issue in our bug tracker so we address this. There is a pre-filled template that you can use in '/Users/timkpaine/Library/Caches/pylint/pylint-crash-2022-07-19-17.txt'. (astroid-error)\r\n```\r\n\r\n\r\n\r\n\r\n### Standalone (Non Cython) repro for convenience\r\n\r\n```python\r\nimport types\r\nimport pandas as pd\r\nfrom astroid.builder import AstroidBuilder\r\n\r\n\r\nm = types.ModuleType(\"test\")\r\nm.pd = pd\r\n\r\nAstroidBuilder().module_build(m, \"test\")\r\n```\r\n\r\n\r\nxref: https://github.com/PyCQA/pylint/issues/7205\r\nxref: https://github.com/PyCQA/astroid/pull/1719\n\n</issue>\n<code>\n[start of README.rst]\n1 Astroid\n2 =======\n3 \n4 .. image:: https://coveralls.io/repos/github/PyCQA/astroid/badge.svg?branch=main\n5     :target: https://coveralls.io/github/PyCQA/astroid?branch=main\n6     :alt: Coverage badge from coveralls.io\n7 \n8 .. image:: https://readthedocs.org/projects/astroid/badge/?version=latest\n9     :target: http://astroid.readthedocs.io/en/latest/?badge=latest\n10     :alt: Documentation Status\n11 \n12 .. image:: https://img.shields.io/badge/code%20style-black-000000.svg\n13     :target: https://github.com/ambv/black\n14 \n15 .. image:: https://results.pre-commit.ci/badge/github/PyCQA/astroid/main.svg\n16    :target: https://results.pre-commit.ci/latest/github/PyCQA/astroid/main\n17    :alt: pre-commit.ci status\n18 \n19 .. |tidelift_logo| image:: https://raw.githubusercontent.com/PyCQA/astroid/main/doc/media/Tidelift_Logos_RGB_Tidelift_Shorthand_On-White.png\n20    :width: 200\n21    :alt: Tidelift\n22 \n23 .. list-table::\n24    :widths: 10 100\n25 \n26    * - |tidelift_logo|\n27      - Professional support for astroid is available as part of the\n28        `Tidelift Subscription`_.  Tidelift gives software development teams a single source for\n29        purchasing and maintaining their software, with professional grade assurances\n30        from the experts who know it best, while seamlessly integrating with existing\n31        tools.\n32 \n33 .. _Tidelift Subscription: https://tidelift.com/subscription/pkg/pypi-astroid?utm_source=pypi-astroid&utm_medium=referral&utm_campaign=readme\n34 \n35 \n36 \n37 What's this?\n38 ------------\n39 \n40 The aim of this module is to provide a common base representation of\n41 python source code. It is currently the library powering pylint's capabilities.\n42 \n43 It provides a compatible representation which comes from the `_ast`\n44 module.  It rebuilds the tree generated by the builtin _ast module by\n45 recursively walking down the AST and building an extended ast. The new\n46 node classes have additional methods and attributes for different\n47 usages. They include some support for static inference and local name\n48 scopes. Furthermore, astroid can also build partial trees by inspecting living\n49 objects.\n50 \n51 \n52 Installation\n53 ------------\n54 \n55 Extract the tarball, jump into the created directory and run::\n56 \n57     pip install .\n58 \n59 \n60 If you want to do an editable installation, you can run::\n61 \n62     pip install -e .\n63 \n64 \n65 If you have any questions, please mail the code-quality@python.org\n66 mailing list for support. See\n67 http://mail.python.org/mailman/listinfo/code-quality for subscription\n68 information and archives.\n69 \n70 Documentation\n71 -------------\n72 http://astroid.readthedocs.io/en/latest/\n73 \n74 \n75 Python Versions\n76 ---------------\n77 \n78 astroid 2.0 is currently available for Python 3 only. If you want Python 2\n79 support, use an older version of astroid (though note that these versions\n80 are no longer supported).\n81 \n82 Test\n83 ----\n84 \n85 Tests are in the 'test' subdirectory. To launch the whole tests suite, you can use\n86 either `tox` or `pytest`::\n87 \n88     tox\n89     pytest astroid\n90 \n[end of README.rst]\n[start of astroid/raw_building.py]\n1 # Licensed under the LGPL: https://www.gnu.org/licenses/old-licenses/lgpl-2.1.en.html\n2 # For details: https://github.com/PyCQA/astroid/blob/main/LICENSE\n3 # Copyright (c) https://github.com/PyCQA/astroid/blob/main/CONTRIBUTORS.txt\n4 \n5 \"\"\"this module contains a set of functions to create astroid trees from scratch\n6 (build_* functions) or from living object (object_build_* functions)\n7 \"\"\"\n8 \n9 from __future__ import annotations\n10 \n11 import builtins\n12 import inspect\n13 import os\n14 import sys\n15 import types\n16 import warnings\n17 from collections.abc import Iterable\n18 from typing import Any, Union\n19 \n20 from astroid import bases, nodes\n21 from astroid.const import IS_PYPY\n22 from astroid.manager import AstroidManager\n23 from astroid.nodes import node_classes\n24 \n25 _FunctionTypes = Union[\n26     types.FunctionType,\n27     types.MethodType,\n28     types.BuiltinFunctionType,\n29     types.WrapperDescriptorType,\n30     types.MethodDescriptorType,\n31     types.ClassMethodDescriptorType,\n32 ]\n33 \n34 # the keys of CONST_CLS eg python builtin types\n35 _CONSTANTS = tuple(node_classes.CONST_CLS)\n36 _BUILTINS = vars(builtins)\n37 TYPE_NONE = type(None)\n38 TYPE_NOTIMPLEMENTED = type(NotImplemented)\n39 TYPE_ELLIPSIS = type(...)\n40 \n41 \n42 def _attach_local_node(parent, node, name):\n43     node.name = name  # needed by add_local_node\n44     parent.add_local_node(node)\n45 \n46 \n47 def _add_dunder_class(func, member):\n48     \"\"\"Add a __class__ member to the given func node, if we can determine it.\"\"\"\n49     python_cls = member.__class__\n50     cls_name = getattr(python_cls, \"__name__\", None)\n51     if not cls_name:\n52         return\n53     cls_bases = [ancestor.__name__ for ancestor in python_cls.__bases__]\n54     ast_klass = build_class(cls_name, cls_bases, python_cls.__doc__)\n55     func.instance_attrs[\"__class__\"] = [ast_klass]\n56 \n57 \n58 _marker = object()\n59 \n60 \n61 def attach_dummy_node(node, name, runtime_object=_marker):\n62     \"\"\"create a dummy node and register it in the locals of the given\n63     node with the specified name\n64     \"\"\"\n65     enode = nodes.EmptyNode()\n66     enode.object = runtime_object\n67     _attach_local_node(node, enode, name)\n68 \n69 \n70 def _has_underlying_object(self):\n71     return self.object is not None and self.object is not _marker\n72 \n73 \n74 nodes.EmptyNode.has_underlying_object = _has_underlying_object\n75 \n76 \n77 def attach_const_node(node, name, value):\n78     \"\"\"create a Const node and register it in the locals of the given\n79     node with the specified name\n80     \"\"\"\n81     if name not in node.special_attributes:\n82         _attach_local_node(node, nodes.const_factory(value), name)\n83 \n84 \n85 def attach_import_node(node, modname, membername):\n86     \"\"\"create a ImportFrom node and register it in the locals of the given\n87     node with the specified name\n88     \"\"\"\n89     from_node = nodes.ImportFrom(modname, [(membername, None)])\n90     _attach_local_node(node, from_node, membername)\n91 \n92 \n93 def build_module(name: str, doc: str | None = None) -> nodes.Module:\n94     \"\"\"create and initialize an astroid Module node\"\"\"\n95     node = nodes.Module(name, pure_python=False, package=False)\n96     node.postinit(\n97         body=[],\n98         doc_node=nodes.Const(value=doc) if doc else None,\n99     )\n100     return node\n101 \n102 \n103 def build_class(\n104     name: str, basenames: Iterable[str] = (), doc: str | None = None\n105 ) -> nodes.ClassDef:\n106     \"\"\"Create and initialize an astroid ClassDef node.\"\"\"\n107     node = nodes.ClassDef(name)\n108     node.postinit(\n109         bases=[nodes.Name(name=base, parent=node) for base in basenames],\n110         body=[],\n111         decorators=None,\n112         doc_node=nodes.Const(value=doc) if doc else None,\n113     )\n114     return node\n115 \n116 \n117 def build_function(\n118     name: str,\n119     args: list[str] | None = None,\n120     posonlyargs: list[str] | None = None,\n121     defaults: list[Any] | None = None,\n122     doc: str | None = None,\n123     kwonlyargs: list[str] | None = None,\n124 ) -> nodes.FunctionDef:\n125     \"\"\"create and initialize an astroid FunctionDef node\"\"\"\n126     # first argument is now a list of decorators\n127     func = nodes.FunctionDef(name)\n128     argsnode = nodes.Arguments(parent=func)\n129 \n130     # If args is None we don't have any information about the signature\n131     # (in contrast to when there are no arguments and args == []). We pass\n132     # this to the builder to indicate this.\n133     if args is not None:\n134         arguments = [nodes.AssignName(name=arg, parent=argsnode) for arg in args]\n135     else:\n136         arguments = None\n137 \n138     argsnode.postinit(\n139         args=arguments,\n140         defaults=[],\n141         kwonlyargs=[\n142             nodes.AssignName(name=arg, parent=argsnode) for arg in kwonlyargs or ()\n143         ],\n144         kw_defaults=[],\n145         annotations=[],\n146         posonlyargs=[\n147             nodes.AssignName(name=arg, parent=argsnode) for arg in posonlyargs or ()\n148         ],\n149     )\n150     func.postinit(\n151         args=argsnode,\n152         body=[],\n153         doc_node=nodes.Const(value=doc) if doc else None,\n154     )\n155     for default in defaults or ():\n156         argsnode.defaults.append(nodes.const_factory(default))\n157         argsnode.defaults[-1].parent = argsnode\n158     if args:\n159         register_arguments(func)\n160     return func\n161 \n162 \n163 def build_from_import(fromname, names):\n164     \"\"\"create and initialize an astroid ImportFrom import statement\"\"\"\n165     return nodes.ImportFrom(fromname, [(name, None) for name in names])\n166 \n167 \n168 def register_arguments(func, args=None):\n169     \"\"\"add given arguments to local\n170 \n171     args is a list that may contains nested lists\n172     (i.e. def func(a, (b, c, d)): ...)\n173     \"\"\"\n174     if args is None:\n175         args = func.args.args\n176         if func.args.vararg:\n177             func.set_local(func.args.vararg, func.args)\n178         if func.args.kwarg:\n179             func.set_local(func.args.kwarg, func.args)\n180     for arg in args:\n181         if isinstance(arg, nodes.AssignName):\n182             func.set_local(arg.name, arg)\n183         else:\n184             register_arguments(func, arg.elts)\n185 \n186 \n187 def object_build_class(\n188     node: nodes.Module | nodes.ClassDef, member: type, localname: str\n189 ) -> nodes.ClassDef:\n190     \"\"\"create astroid for a living class object\"\"\"\n191     basenames = [base.__name__ for base in member.__bases__]\n192     return _base_class_object_build(node, member, basenames, localname=localname)\n193 \n194 \n195 def _get_args_info_from_callable(\n196     member: _FunctionTypes,\n197 ) -> tuple[list[str], list[Any], list[str], list[str]]:\n198     \"\"\"Returns args, posonlyargs, defaults, kwonlyargs.\n199 \n200     :note: currently ignores the return annotation.\n201     \"\"\"\n202     signature = inspect.signature(member)\n203     args: list[str] = []\n204     defaults: list[Any] = []\n205     posonlyargs: list[str] = []\n206     kwonlyargs: list[str] = []\n207 \n208     for param_name, param in signature.parameters.items():\n209         if param.kind == inspect.Parameter.POSITIONAL_ONLY:\n210             posonlyargs.append(param_name)\n211         elif param.kind == inspect.Parameter.POSITIONAL_OR_KEYWORD:\n212             args.append(param_name)\n213         elif param.kind == inspect.Parameter.VAR_POSITIONAL:\n214             args.append(param_name)\n215         elif param.kind == inspect.Parameter.VAR_KEYWORD:\n216             args.append(param_name)\n217         elif param.kind == inspect.Parameter.KEYWORD_ONLY:\n218             kwonlyargs.append(param_name)\n219         if param.default is not inspect._empty:\n220             defaults.append(param.default)\n221 \n222     return args, posonlyargs, defaults, kwonlyargs\n223 \n224 \n225 def object_build_function(\n226     node: nodes.Module | nodes.ClassDef, member: _FunctionTypes, localname: str\n227 ) -> None:\n228     \"\"\"create astroid for a living function object\"\"\"\n229     args, posonlyargs, defaults, kwonlyargs = _get_args_info_from_callable(member)\n230 \n231     func = build_function(\n232         getattr(member, \"__name__\", None) or localname,\n233         args,\n234         posonlyargs,\n235         defaults,\n236         member.__doc__,\n237         kwonlyargs=kwonlyargs,\n238     )\n239 \n240     node.add_local_node(func, localname)\n241 \n242 \n243 def object_build_datadescriptor(\n244     node: nodes.Module | nodes.ClassDef, member: type, name: str\n245 ) -> nodes.ClassDef:\n246     \"\"\"create astroid for a living data descriptor object\"\"\"\n247     return _base_class_object_build(node, member, [], name)\n248 \n249 \n250 def object_build_methoddescriptor(\n251     node: nodes.Module | nodes.ClassDef,\n252     member: _FunctionTypes,\n253     localname: str,\n254 ) -> None:\n255     \"\"\"create astroid for a living method descriptor object\"\"\"\n256     # FIXME get arguments ?\n257     func = build_function(\n258         getattr(member, \"__name__\", None) or localname, doc=member.__doc__\n259     )\n260     node.add_local_node(func, localname)\n261     _add_dunder_class(func, member)\n262 \n263 \n264 def _base_class_object_build(\n265     node: nodes.Module | nodes.ClassDef,\n266     member: type,\n267     basenames: list[str],\n268     name: str | None = None,\n269     localname: str | None = None,\n270 ) -> nodes.ClassDef:\n271     \"\"\"create astroid for a living class object, with a given set of base names\n272     (e.g. ancestors)\n273     \"\"\"\n274     class_name = name or getattr(member, \"__name__\", None) or localname\n275     assert isinstance(class_name, str)\n276     klass = build_class(\n277         class_name,\n278         basenames,\n279         member.__doc__,\n280     )\n281     klass._newstyle = isinstance(member, type)\n282     node.add_local_node(klass, localname)\n283     try:\n284         # limit the instantiation trick since it's too dangerous\n285         # (such as infinite test execution...)\n286         # this at least resolves common case such as Exception.args,\n287         # OSError.errno\n288         if issubclass(member, Exception):\n289             instdict = member().__dict__\n290         else:\n291             raise TypeError\n292     except TypeError:\n293         pass\n294     else:\n295         for item_name, obj in instdict.items():\n296             valnode = nodes.EmptyNode()\n297             valnode.object = obj\n298             valnode.parent = klass\n299             valnode.lineno = 1\n300             klass.instance_attrs[item_name] = [valnode]\n301     return klass\n302 \n303 \n304 def _build_from_function(\n305     node: nodes.Module | nodes.ClassDef,\n306     name: str,\n307     member: _FunctionTypes,\n308     module: types.ModuleType,\n309 ) -> None:\n310     # verify this is not an imported function\n311     try:\n312         code = member.__code__  # type: ignore[union-attr]\n313     except AttributeError:\n314         # Some implementations don't provide the code object,\n315         # such as Jython.\n316         code = None\n317     filename = getattr(code, \"co_filename\", None)\n318     if filename is None:\n319         assert isinstance(member, object)\n320         object_build_methoddescriptor(node, member, name)\n321     elif filename != getattr(module, \"__file__\", None):\n322         attach_dummy_node(node, name, member)\n323     else:\n324         object_build_function(node, member, name)\n325 \n326 \n327 def _safe_has_attribute(obj, member):\n328     try:\n329         return hasattr(obj, member)\n330     except Exception:  # pylint: disable=broad-except\n331         return False\n332 \n333 \n334 class InspectBuilder:\n335     \"\"\"class for building nodes from living object\n336 \n337     this is actually a really minimal representation, including only Module,\n338     FunctionDef and ClassDef nodes and some others as guessed.\n339     \"\"\"\n340 \n341     def __init__(self, manager_instance=None):\n342         self._manager = manager_instance or AstroidManager()\n343         self._done: dict[types.ModuleType | type, nodes.Module | nodes.ClassDef] = {}\n344         self._module: types.ModuleType\n345 \n346     def inspect_build(\n347         self,\n348         module: types.ModuleType,\n349         modname: str | None = None,\n350         path: str | None = None,\n351     ) -> nodes.Module:\n352         \"\"\"build astroid from a living module (i.e. using inspect)\n353         this is used when there is no python source code available (either\n354         because it's a built-in module or because the .py is not available)\n355         \"\"\"\n356         self._module = module\n357         if modname is None:\n358             modname = module.__name__\n359         try:\n360             node = build_module(modname, module.__doc__)\n361         except AttributeError:\n362             # in jython, java modules have no __doc__ (see #109562)\n363             node = build_module(modname)\n364         if path is None:\n365             node.path = node.file = path\n366         else:\n367             node.path = [os.path.abspath(path)]\n368             node.file = node.path[0]\n369         node.name = modname\n370         self._manager.cache_module(node)\n371         node.package = hasattr(module, \"__path__\")\n372         self._done = {}\n373         self.object_build(node, module)\n374         return node\n375 \n376     def object_build(\n377         self, node: nodes.Module | nodes.ClassDef, obj: types.ModuleType | type\n378     ) -> None:\n379         \"\"\"recursive method which create a partial ast from real objects\n380         (only function, class, and method are handled)\n381         \"\"\"\n382         if obj in self._done:\n383             return None\n384         self._done[obj] = node\n385         for name in dir(obj):\n386             # inspect.ismethod() and inspect.isbuiltin() in PyPy return\n387             # the opposite of what they do in CPython for __class_getitem__.\n388             pypy__class_getitem__ = IS_PYPY and name == \"__class_getitem__\"\n389             try:\n390                 with warnings.catch_warnings():\n391                     warnings.simplefilter(\"error\")\n392                     member = getattr(obj, name)\n393             except (AttributeError, DeprecationWarning):\n394                 # damned ExtensionClass.Base, I know you're there !\n395                 attach_dummy_node(node, name)\n396                 continue\n397             if inspect.ismethod(member) and not pypy__class_getitem__:\n398                 member = member.__func__\n399             if inspect.isfunction(member):\n400                 _build_from_function(node, name, member, self._module)\n401             elif inspect.isbuiltin(member) or pypy__class_getitem__:\n402                 if self.imported_member(node, member, name):\n403                     continue\n404                 object_build_methoddescriptor(node, member, name)\n405             elif inspect.isclass(member):\n406                 if self.imported_member(node, member, name):\n407                     continue\n408                 if member in self._done:\n409                     class_node = self._done[member]\n410                     assert isinstance(class_node, nodes.ClassDef)\n411                     if class_node not in node.locals.get(name, ()):\n412                         node.add_local_node(class_node, name)\n413                 else:\n414                     class_node = object_build_class(node, member, name)\n415                     # recursion\n416                     self.object_build(class_node, member)\n417                 if name == \"__class__\" and class_node.parent is None:\n418                     class_node.parent = self._done[self._module]\n419             elif inspect.ismethoddescriptor(member):\n420                 object_build_methoddescriptor(node, member, name)\n421             elif inspect.isdatadescriptor(member):\n422                 object_build_datadescriptor(node, member, name)\n423             elif isinstance(member, _CONSTANTS):\n424                 attach_const_node(node, name, member)\n425             elif inspect.isroutine(member):\n426                 # This should be called for Jython, where some builtin\n427                 # methods aren't caught by isbuiltin branch.\n428                 _build_from_function(node, name, member, self._module)\n429             elif _safe_has_attribute(member, \"__all__\"):\n430                 module = build_module(name)\n431                 _attach_local_node(node, module, name)\n432                 # recursion\n433                 self.object_build(module, member)\n434             else:\n435                 # create an empty node so that the name is actually defined\n436                 attach_dummy_node(node, name, member)\n437         return None\n438 \n439     def imported_member(self, node, member, name: str) -> bool:\n440         \"\"\"verify this is not an imported class or handle it\"\"\"\n441         # /!\\ some classes like ExtensionClass doesn't have a __module__\n442         # attribute ! Also, this may trigger an exception on badly built module\n443         # (see http://www.logilab.org/ticket/57299 for instance)\n444         try:\n445             modname = getattr(member, \"__module__\", None)\n446         except TypeError:\n447             modname = None\n448         if modname is None:\n449             if name in {\"__new__\", \"__subclasshook__\"}:\n450                 # Python 2.5.1 (r251:54863, Sep  1 2010, 22:03:14)\n451                 # >>> print object.__new__.__module__\n452                 # None\n453                 modname = builtins.__name__\n454             else:\n455                 attach_dummy_node(node, name, member)\n456                 return True\n457 \n458         # On PyPy during bootstrapping we infer _io while _module is\n459         # builtins. In CPython _io names itself io, see http://bugs.python.org/issue18602\n460         # Therefore, this basically checks whether we are not in PyPy.\n461         if modname == \"_io\" and not self._module.__name__ == \"builtins\":\n462             return False\n463 \n464         real_name = {\"gtk\": \"gtk_gtk\"}.get(modname, modname)\n465 \n466         if real_name != self._module.__name__:\n467             # check if it sounds valid and then add an import node, else use a\n468             # dummy node\n469             try:\n470                 getattr(sys.modules[modname], name)\n471             except (KeyError, AttributeError):\n472                 attach_dummy_node(node, name, member)\n473             else:\n474                 attach_import_node(node, modname, name)\n475             return True\n476         return False\n477 \n478 \n479 # astroid bootstrapping ######################################################\n480 \n481 _CONST_PROXY: dict[type, nodes.ClassDef] = {}\n482 \n483 \n484 def _set_proxied(const):\n485     # TODO : find a nicer way to handle this situation;\n486     return _CONST_PROXY[const.value.__class__]\n487 \n488 \n489 def _astroid_bootstrapping():\n490     \"\"\"astroid bootstrapping the builtins module\"\"\"\n491     # this boot strapping is necessary since we need the Const nodes to\n492     # inspect_build builtins, and then we can proxy Const\n493     builder = InspectBuilder()\n494     astroid_builtin = builder.inspect_build(builtins)\n495 \n496     for cls, node_cls in node_classes.CONST_CLS.items():\n497         if cls is TYPE_NONE:\n498             proxy = build_class(\"NoneType\")\n499             proxy.parent = astroid_builtin\n500         elif cls is TYPE_NOTIMPLEMENTED:\n501             proxy = build_class(\"NotImplementedType\")\n502             proxy.parent = astroid_builtin\n503         elif cls is TYPE_ELLIPSIS:\n504             proxy = build_class(\"Ellipsis\")\n505             proxy.parent = astroid_builtin\n506         else:\n507             proxy = astroid_builtin.getattr(cls.__name__)[0]\n508             assert isinstance(proxy, nodes.ClassDef)\n509         if cls in (dict, list, set, tuple):\n510             node_cls._proxied = proxy\n511         else:\n512             _CONST_PROXY[cls] = proxy\n513 \n514     # Set the builtin module as parent for some builtins.\n515     nodes.Const._proxied = property(_set_proxied)\n516 \n517     _GeneratorType = nodes.ClassDef(types.GeneratorType.__name__)\n518     _GeneratorType.parent = astroid_builtin\n519     generator_doc_node = (\n520         nodes.Const(value=types.GeneratorType.__doc__)\n521         if types.GeneratorType.__doc__\n522         else None\n523     )\n524     _GeneratorType.postinit(\n525         bases=[],\n526         body=[],\n527         decorators=None,\n528         doc_node=generator_doc_node,\n529     )\n530     bases.Generator._proxied = _GeneratorType\n531     builder.object_build(bases.Generator._proxied, types.GeneratorType)\n532 \n533     if hasattr(types, \"AsyncGeneratorType\"):\n534         _AsyncGeneratorType = nodes.ClassDef(types.AsyncGeneratorType.__name__)\n535         _AsyncGeneratorType.parent = astroid_builtin\n536         async_generator_doc_node = (\n537             nodes.Const(value=types.AsyncGeneratorType.__doc__)\n538             if types.AsyncGeneratorType.__doc__\n539             else None\n540         )\n541         _AsyncGeneratorType.postinit(\n542             bases=[],\n543             body=[],\n544             decorators=None,\n545             doc_node=async_generator_doc_node,\n546         )\n547         bases.AsyncGenerator._proxied = _AsyncGeneratorType\n548         builder.object_build(bases.AsyncGenerator._proxied, types.AsyncGeneratorType)\n549     builtin_types = (\n550         types.GetSetDescriptorType,\n551         types.GeneratorType,\n552         types.MemberDescriptorType,\n553         TYPE_NONE,\n554         TYPE_NOTIMPLEMENTED,\n555         types.FunctionType,\n556         types.MethodType,\n557         types.BuiltinFunctionType,\n558         types.ModuleType,\n559         types.TracebackType,\n560     )\n561     for _type in builtin_types:\n562         if _type.__name__ not in astroid_builtin:\n563             klass = nodes.ClassDef(_type.__name__)\n564             klass.parent = astroid_builtin\n565             klass.postinit(\n566                 bases=[],\n567                 body=[],\n568                 decorators=None,\n569                 doc_node=nodes.Const(value=_type.__doc__) if _type.__doc__ else None,\n570             )\n571             builder.object_build(klass, _type)\n572             astroid_builtin[_type.__name__] = klass\n573 \n574 \n575 _astroid_bootstrapping()\n576 \n[end of astroid/raw_building.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n\n\n", "full_output": "```patch\ndiff --git a/astroid/raw_building.py b/astroid/raw_building.py\nindex 4c1e9d2..b1e4c3a 100644\n--- a/astroid/raw_building.py\n+++ b/astroid/raw_building.py\n@@ -390,390 +390,390 @@\n                     warnings.simplefilter(\"error\")\n                     member = getattr(obj, name)\n+                    # Ignore FutureWarnings to prevent AstroidError\n+                    warnings.simplefilter(\"ignore\", FutureWarning)\n             except (AttributeError, DeprecationWarning):\n                 # damned ExtensionClass.Base, I know you're there !\n                 attach_dummy_node(node, name)\n                 continue\n```", "model_patch": "diff --git a/astroid/raw_building.py b/astroid/raw_building.py\nindex 4c1e9d2..b1e4c3a 100644\n--- a/astroid/raw_building.py\n+++ b/astroid/raw_building.py\n@@ -390,390 +390,390 @@\n                     warnings.simplefilter(\"error\")\n                     member = getattr(obj, name)\n+                    # Ignore FutureWarnings to prevent AstroidError\n+                    warnings.simplefilter(\"ignore\", FutureWarning)\n             except (AttributeError, DeprecationWarning):\n                 # damned ExtensionClass.Base, I know you're there !\n                 attach_dummy_node(node, name)\n                 continue\n"}
{"instance_id": "pylint-dev__astroid-1903", "model_name_or_path": "gpt-4o-mini", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nUnhandled AttributeError during str.format template evaluation\n### Steps to reproduce\r\n\r\n1. Use `astroid` to parse code that provides arguments to a `str.format` template that attempts to access non-existent attributes\r\n\r\n```py\r\ndaniel_age = 12\r\n\"My name is {0.name}\".format(daniel_age)  # int literal has no 'name' attribute\r\n```\r\n\r\n### Current behavior\r\n\r\n1. unhandled `AttributeError` when it attempts to [evaluate the templated string](https://github.com/PyCQA/astroid/blob/8bdec591f228e7db6a0be66b6ca814227ff50001/astroid/brain/brain_builtin_inference.py#L956)\r\n\r\n### Expected behavior\r\n\r\n1. could raise an `AstroidTypeError` to indicate that the template formatting is invalid\r\n\r\n### `python -c \"from astroid import __pkginfo__; print(__pkginfo__.version)\"` output\r\n\r\n`2.13.0-dev0`\r\n\r\nRelates to pycqa/pylint#7939.\nUnhandled AttributeError during str.format template evaluation\n### Steps to reproduce\r\n\r\n1. Use `astroid` to parse code that provides arguments to a `str.format` template that attempts to access non-existent attributes\r\n\r\n```py\r\ndaniel_age = 12\r\n\"My name is {0.name}\".format(daniel_age)  # int literal has no 'name' attribute\r\n```\r\n\r\n### Current behavior\r\n\r\n1. unhandled `AttributeError` when it attempts to [evaluate the templated string](https://github.com/PyCQA/astroid/blob/8bdec591f228e7db6a0be66b6ca814227ff50001/astroid/brain/brain_builtin_inference.py#L956)\r\n\r\n### Expected behavior\r\n\r\n1. could raise an `AstroidTypeError` to indicate that the template formatting is invalid\r\n\r\n### `python -c \"from astroid import __pkginfo__; print(__pkginfo__.version)\"` output\r\n\r\n`2.13.0-dev0`\r\n\r\nRelates to pycqa/pylint#7939.\n\n</issue>\n<code>\n[start of README.rst]\n1 Astroid\n2 =======\n3 \n4 .. image:: https://coveralls.io/repos/github/PyCQA/astroid/badge.svg?branch=main\n5     :target: https://coveralls.io/github/PyCQA/astroid?branch=main\n6     :alt: Coverage badge from coveralls.io\n7 \n8 .. image:: https://readthedocs.org/projects/astroid/badge/?version=latest\n9     :target: http://astroid.readthedocs.io/en/latest/?badge=latest\n10     :alt: Documentation Status\n11 \n12 .. image:: https://img.shields.io/badge/code%20style-black-000000.svg\n13     :target: https://github.com/ambv/black\n14 \n15 .. image:: https://results.pre-commit.ci/badge/github/PyCQA/astroid/main.svg\n16    :target: https://results.pre-commit.ci/latest/github/PyCQA/astroid/main\n17    :alt: pre-commit.ci status\n18 \n19 .. |tidelift_logo| image:: https://raw.githubusercontent.com/PyCQA/astroid/main/doc/media/Tidelift_Logos_RGB_Tidelift_Shorthand_On-White.png\n20    :width: 200\n21    :alt: Tidelift\n22 \n23 .. list-table::\n24    :widths: 10 100\n25 \n26    * - |tidelift_logo|\n27      - Professional support for astroid is available as part of the\n28        `Tidelift Subscription`_.  Tidelift gives software development teams a single source for\n29        purchasing and maintaining their software, with professional grade assurances\n30        from the experts who know it best, while seamlessly integrating with existing\n31        tools.\n32 \n33 .. _Tidelift Subscription: https://tidelift.com/subscription/pkg/pypi-astroid?utm_source=pypi-astroid&utm_medium=referral&utm_campaign=readme\n34 \n35 \n36 \n37 What's this?\n38 ------------\n39 \n40 The aim of this module is to provide a common base representation of\n41 python source code. It is currently the library powering pylint's capabilities.\n42 \n43 It provides a compatible representation which comes from the `_ast`\n44 module.  It rebuilds the tree generated by the builtin _ast module by\n45 recursively walking down the AST and building an extended ast. The new\n46 node classes have additional methods and attributes for different\n47 usages. They include some support for static inference and local name\n48 scopes. Furthermore, astroid can also build partial trees by inspecting living\n49 objects.\n50 \n51 \n52 Installation\n53 ------------\n54 \n55 Extract the tarball, jump into the created directory and run::\n56 \n57     pip install .\n58 \n59 \n60 If you want to do an editable installation, you can run::\n61 \n62     pip install -e .\n63 \n64 \n65 If you have any questions, please mail the code-quality@python.org\n66 mailing list for support. See\n67 http://mail.python.org/mailman/listinfo/code-quality for subscription\n68 information and archives.\n69 \n70 Documentation\n71 -------------\n72 http://astroid.readthedocs.io/en/latest/\n73 \n74 \n75 Python Versions\n76 ---------------\n77 \n78 astroid 2.0 is currently available for Python 3 only. If you want Python 2\n79 support, use an older version of astroid (though note that these versions\n80 are no longer supported).\n81 \n82 Test\n83 ----\n84 \n85 Tests are in the 'test' subdirectory. To launch the whole tests suite, you can use\n86 either `tox` or `pytest`::\n87 \n88     tox\n89     pytest\n90 \n[end of README.rst]\n[start of astroid/brain/brain_builtin_inference.py]\n1 # Licensed under the LGPL: https://www.gnu.org/licenses/old-licenses/lgpl-2.1.en.html\n2 # For details: https://github.com/PyCQA/astroid/blob/main/LICENSE\n3 # Copyright (c) https://github.com/PyCQA/astroid/blob/main/CONTRIBUTORS.txt\n4 \n5 \"\"\"Astroid hooks for various builtins.\"\"\"\n6 \n7 from __future__ import annotations\n8 \n9 import itertools\n10 from collections.abc import Iterator\n11 from functools import partial\n12 \n13 from astroid import arguments, helpers, inference_tip, nodes, objects, util\n14 from astroid.builder import AstroidBuilder\n15 from astroid.context import InferenceContext\n16 from astroid.exceptions import (\n17     AstroidTypeError,\n18     AttributeInferenceError,\n19     InferenceError,\n20     MroError,\n21     UseInferenceDefault,\n22 )\n23 from astroid.manager import AstroidManager\n24 from astroid.nodes import scoped_nodes\n25 \n26 OBJECT_DUNDER_NEW = \"object.__new__\"\n27 \n28 STR_CLASS = \"\"\"\n29 class whatever(object):\n30     def join(self, iterable):\n31         return {rvalue}\n32     def replace(self, old, new, count=None):\n33         return {rvalue}\n34     def format(self, *args, **kwargs):\n35         return {rvalue}\n36     def encode(self, encoding='ascii', errors=None):\n37         return b''\n38     def decode(self, encoding='ascii', errors=None):\n39         return u''\n40     def capitalize(self):\n41         return {rvalue}\n42     def title(self):\n43         return {rvalue}\n44     def lower(self):\n45         return {rvalue}\n46     def upper(self):\n47         return {rvalue}\n48     def swapcase(self):\n49         return {rvalue}\n50     def index(self, sub, start=None, end=None):\n51         return 0\n52     def find(self, sub, start=None, end=None):\n53         return 0\n54     def count(self, sub, start=None, end=None):\n55         return 0\n56     def strip(self, chars=None):\n57         return {rvalue}\n58     def lstrip(self, chars=None):\n59         return {rvalue}\n60     def rstrip(self, chars=None):\n61         return {rvalue}\n62     def rjust(self, width, fillchar=None):\n63         return {rvalue}\n64     def center(self, width, fillchar=None):\n65         return {rvalue}\n66     def ljust(self, width, fillchar=None):\n67         return {rvalue}\n68 \"\"\"\n69 \n70 \n71 BYTES_CLASS = \"\"\"\n72 class whatever(object):\n73     def join(self, iterable):\n74         return {rvalue}\n75     def replace(self, old, new, count=None):\n76         return {rvalue}\n77     def decode(self, encoding='ascii', errors=None):\n78         return u''\n79     def capitalize(self):\n80         return {rvalue}\n81     def title(self):\n82         return {rvalue}\n83     def lower(self):\n84         return {rvalue}\n85     def upper(self):\n86         return {rvalue}\n87     def swapcase(self):\n88         return {rvalue}\n89     def index(self, sub, start=None, end=None):\n90         return 0\n91     def find(self, sub, start=None, end=None):\n92         return 0\n93     def count(self, sub, start=None, end=None):\n94         return 0\n95     def strip(self, chars=None):\n96         return {rvalue}\n97     def lstrip(self, chars=None):\n98         return {rvalue}\n99     def rstrip(self, chars=None):\n100         return {rvalue}\n101     def rjust(self, width, fillchar=None):\n102         return {rvalue}\n103     def center(self, width, fillchar=None):\n104         return {rvalue}\n105     def ljust(self, width, fillchar=None):\n106         return {rvalue}\n107 \"\"\"\n108 \n109 \n110 def _extend_string_class(class_node, code, rvalue):\n111     \"\"\"function to extend builtin str/unicode class\"\"\"\n112     code = code.format(rvalue=rvalue)\n113     fake = AstroidBuilder(AstroidManager()).string_build(code)[\"whatever\"]\n114     for method in fake.mymethods():\n115         method.parent = class_node\n116         method.lineno = None\n117         method.col_offset = None\n118         if \"__class__\" in method.locals:\n119             method.locals[\"__class__\"] = [class_node]\n120         class_node.locals[method.name] = [method]\n121         method.parent = class_node\n122 \n123 \n124 def _extend_builtins(class_transforms):\n125     builtin_ast = AstroidManager().builtins_module\n126     for class_name, transform in class_transforms.items():\n127         transform(builtin_ast[class_name])\n128 \n129 \n130 _extend_builtins(\n131     {\n132         \"bytes\": partial(_extend_string_class, code=BYTES_CLASS, rvalue=\"b''\"),\n133         \"str\": partial(_extend_string_class, code=STR_CLASS, rvalue=\"''\"),\n134     }\n135 )\n136 \n137 \n138 def _builtin_filter_predicate(node, builtin_name) -> bool:\n139     if (\n140         builtin_name == \"type\"\n141         and node.root().name == \"re\"\n142         and isinstance(node.func, nodes.Name)\n143         and node.func.name == \"type\"\n144         and isinstance(node.parent, nodes.Assign)\n145         and len(node.parent.targets) == 1\n146         and isinstance(node.parent.targets[0], nodes.AssignName)\n147         and node.parent.targets[0].name in {\"Pattern\", \"Match\"}\n148     ):\n149         # Handle re.Pattern and re.Match in brain_re\n150         # Match these patterns from stdlib/re.py\n151         # ```py\n152         # Pattern = type(...)\n153         # Match = type(...)\n154         # ```\n155         return False\n156     if isinstance(node.func, nodes.Name) and node.func.name == builtin_name:\n157         return True\n158     if isinstance(node.func, nodes.Attribute):\n159         return (\n160             node.func.attrname == \"fromkeys\"\n161             and isinstance(node.func.expr, nodes.Name)\n162             and node.func.expr.name == \"dict\"\n163         )\n164     return False\n165 \n166 \n167 def register_builtin_transform(transform, builtin_name):\n168     \"\"\"Register a new transform function for the given *builtin_name*.\n169 \n170     The transform function must accept two parameters, a node and\n171     an optional context.\n172     \"\"\"\n173 \n174     def _transform_wrapper(node, context: InferenceContext | None = None):\n175         result = transform(node, context=context)\n176         if result:\n177             if not result.parent:\n178                 # Let the transformation function determine\n179                 # the parent for its result. Otherwise,\n180                 # we set it to be the node we transformed from.\n181                 result.parent = node\n182 \n183             if result.lineno is None:\n184                 result.lineno = node.lineno\n185             # Can be a 'Module' see https://github.com/PyCQA/pylint/issues/4671\n186             # We don't have a regression test on this one: tread carefully\n187             if hasattr(result, \"col_offset\") and result.col_offset is None:\n188                 result.col_offset = node.col_offset\n189         return iter([result])\n190 \n191     AstroidManager().register_transform(\n192         nodes.Call,\n193         inference_tip(_transform_wrapper),\n194         partial(_builtin_filter_predicate, builtin_name=builtin_name),\n195     )\n196 \n197 \n198 def _container_generic_inference(node, context, node_type, transform):\n199     args = node.args\n200     if not args:\n201         return node_type()\n202     if len(node.args) > 1:\n203         raise UseInferenceDefault()\n204 \n205     (arg,) = args\n206     transformed = transform(arg)\n207     if not transformed:\n208         try:\n209             inferred = next(arg.infer(context=context))\n210         except (InferenceError, StopIteration) as exc:\n211             raise UseInferenceDefault from exc\n212         if inferred is util.Uninferable:\n213             raise UseInferenceDefault\n214         transformed = transform(inferred)\n215     if not transformed or transformed is util.Uninferable:\n216         raise UseInferenceDefault\n217     return transformed\n218 \n219 \n220 def _container_generic_transform(  # pylint: disable=inconsistent-return-statements\n221     arg, context, klass, iterables, build_elts\n222 ):\n223     if isinstance(arg, klass):\n224         return arg\n225     if isinstance(arg, iterables):\n226         if all(isinstance(elt, nodes.Const) for elt in arg.elts):\n227             elts = [elt.value for elt in arg.elts]\n228         else:\n229             # TODO: Does not handle deduplication for sets.\n230             elts = []\n231             for element in arg.elts:\n232                 if not element:\n233                     continue\n234                 inferred = helpers.safe_infer(element, context=context)\n235                 if inferred:\n236                     evaluated_object = nodes.EvaluatedObject(\n237                         original=element, value=inferred\n238                     )\n239                     elts.append(evaluated_object)\n240     elif isinstance(arg, nodes.Dict):\n241         # Dicts need to have consts as strings already.\n242         if not all(isinstance(elt[0], nodes.Const) for elt in arg.items):\n243             raise UseInferenceDefault()\n244         elts = [item[0].value for item in arg.items]\n245     elif isinstance(arg, nodes.Const) and isinstance(arg.value, (str, bytes)):\n246         elts = arg.value\n247     else:\n248         return\n249     return klass.from_elements(elts=build_elts(elts))\n250 \n251 \n252 def _infer_builtin_container(\n253     node, context, klass=None, iterables=None, build_elts=None\n254 ):\n255     transform_func = partial(\n256         _container_generic_transform,\n257         context=context,\n258         klass=klass,\n259         iterables=iterables,\n260         build_elts=build_elts,\n261     )\n262 \n263     return _container_generic_inference(node, context, klass, transform_func)\n264 \n265 \n266 # pylint: disable=invalid-name\n267 infer_tuple = partial(\n268     _infer_builtin_container,\n269     klass=nodes.Tuple,\n270     iterables=(\n271         nodes.List,\n272         nodes.Set,\n273         objects.FrozenSet,\n274         objects.DictItems,\n275         objects.DictKeys,\n276         objects.DictValues,\n277     ),\n278     build_elts=tuple,\n279 )\n280 \n281 infer_list = partial(\n282     _infer_builtin_container,\n283     klass=nodes.List,\n284     iterables=(\n285         nodes.Tuple,\n286         nodes.Set,\n287         objects.FrozenSet,\n288         objects.DictItems,\n289         objects.DictKeys,\n290         objects.DictValues,\n291     ),\n292     build_elts=list,\n293 )\n294 \n295 infer_set = partial(\n296     _infer_builtin_container,\n297     klass=nodes.Set,\n298     iterables=(nodes.List, nodes.Tuple, objects.FrozenSet, objects.DictKeys),\n299     build_elts=set,\n300 )\n301 \n302 infer_frozenset = partial(\n303     _infer_builtin_container,\n304     klass=objects.FrozenSet,\n305     iterables=(nodes.List, nodes.Tuple, nodes.Set, objects.FrozenSet, objects.DictKeys),\n306     build_elts=frozenset,\n307 )\n308 \n309 \n310 def _get_elts(arg, context):\n311     def is_iterable(n):\n312         return isinstance(n, (nodes.List, nodes.Tuple, nodes.Set))\n313 \n314     try:\n315         inferred = next(arg.infer(context))\n316     except (InferenceError, StopIteration) as exc:\n317         raise UseInferenceDefault from exc\n318     if isinstance(inferred, nodes.Dict):\n319         items = inferred.items\n320     elif is_iterable(inferred):\n321         items = []\n322         for elt in inferred.elts:\n323             # If an item is not a pair of two items,\n324             # then fallback to the default inference.\n325             # Also, take in consideration only hashable items,\n326             # tuples and consts. We are choosing Names as well.\n327             if not is_iterable(elt):\n328                 raise UseInferenceDefault()\n329             if len(elt.elts) != 2:\n330                 raise UseInferenceDefault()\n331             if not isinstance(elt.elts[0], (nodes.Tuple, nodes.Const, nodes.Name)):\n332                 raise UseInferenceDefault()\n333             items.append(tuple(elt.elts))\n334     else:\n335         raise UseInferenceDefault()\n336     return items\n337 \n338 \n339 def infer_dict(node, context: InferenceContext | None = None):\n340     \"\"\"Try to infer a dict call to a Dict node.\n341 \n342     The function treats the following cases:\n343 \n344         * dict()\n345         * dict(mapping)\n346         * dict(iterable)\n347         * dict(iterable, **kwargs)\n348         * dict(mapping, **kwargs)\n349         * dict(**kwargs)\n350 \n351     If a case can't be inferred, we'll fallback to default inference.\n352     \"\"\"\n353     call = arguments.CallSite.from_call(node, context=context)\n354     if call.has_invalid_arguments() or call.has_invalid_keywords():\n355         raise UseInferenceDefault\n356 \n357     args = call.positional_arguments\n358     kwargs = list(call.keyword_arguments.items())\n359 \n360     if not args and not kwargs:\n361         # dict()\n362         return nodes.Dict()\n363     if kwargs and not args:\n364         # dict(a=1, b=2, c=4)\n365         items = [(nodes.Const(key), value) for key, value in kwargs]\n366     elif len(args) == 1 and kwargs:\n367         # dict(some_iterable, b=2, c=4)\n368         elts = _get_elts(args[0], context)\n369         keys = [(nodes.Const(key), value) for key, value in kwargs]\n370         items = elts + keys\n371     elif len(args) == 1:\n372         items = _get_elts(args[0], context)\n373     else:\n374         raise UseInferenceDefault()\n375     value = nodes.Dict(\n376         col_offset=node.col_offset, lineno=node.lineno, parent=node.parent\n377     )\n378     value.postinit(items)\n379     return value\n380 \n381 \n382 def infer_super(node, context: InferenceContext | None = None):\n383     \"\"\"Understand super calls.\n384 \n385     There are some restrictions for what can be understood:\n386 \n387         * unbounded super (one argument form) is not understood.\n388 \n389         * if the super call is not inside a function (classmethod or method),\n390           then the default inference will be used.\n391 \n392         * if the super arguments can't be inferred, the default inference\n393           will be used.\n394     \"\"\"\n395     if len(node.args) == 1:\n396         # Ignore unbounded super.\n397         raise UseInferenceDefault\n398 \n399     scope = node.scope()\n400     if not isinstance(scope, nodes.FunctionDef):\n401         # Ignore non-method uses of super.\n402         raise UseInferenceDefault\n403     if scope.type not in (\"classmethod\", \"method\"):\n404         # Not interested in staticmethods.\n405         raise UseInferenceDefault\n406 \n407     cls = scoped_nodes.get_wrapping_class(scope)\n408     if not node.args:\n409         mro_pointer = cls\n410         # In we are in a classmethod, the interpreter will fill\n411         # automatically the class as the second argument, not an instance.\n412         if scope.type == \"classmethod\":\n413             mro_type = cls\n414         else:\n415             mro_type = cls.instantiate_class()\n416     else:\n417         try:\n418             mro_pointer = next(node.args[0].infer(context=context))\n419         except (InferenceError, StopIteration) as exc:\n420             raise UseInferenceDefault from exc\n421         try:\n422             mro_type = next(node.args[1].infer(context=context))\n423         except (InferenceError, StopIteration) as exc:\n424             raise UseInferenceDefault from exc\n425 \n426     if mro_pointer is util.Uninferable or mro_type is util.Uninferable:\n427         # No way we could understand this.\n428         raise UseInferenceDefault\n429 \n430     super_obj = objects.Super(\n431         mro_pointer=mro_pointer, mro_type=mro_type, self_class=cls, scope=scope\n432     )\n433     super_obj.parent = node\n434     return super_obj\n435 \n436 \n437 def _infer_getattr_args(node, context):\n438     if len(node.args) not in (2, 3):\n439         # Not a valid getattr call.\n440         raise UseInferenceDefault\n441 \n442     try:\n443         obj = next(node.args[0].infer(context=context))\n444         attr = next(node.args[1].infer(context=context))\n445     except (InferenceError, StopIteration) as exc:\n446         raise UseInferenceDefault from exc\n447 \n448     if obj is util.Uninferable or attr is util.Uninferable:\n449         # If one of the arguments is something we can't infer,\n450         # then also make the result of the getattr call something\n451         # which is unknown.\n452         return util.Uninferable, util.Uninferable\n453 \n454     is_string = isinstance(attr, nodes.Const) and isinstance(attr.value, str)\n455     if not is_string:\n456         raise UseInferenceDefault\n457 \n458     return obj, attr.value\n459 \n460 \n461 def infer_getattr(node, context: InferenceContext | None = None):\n462     \"\"\"Understand getattr calls\n463 \n464     If one of the arguments is an Uninferable object, then the\n465     result will be an Uninferable object. Otherwise, the normal attribute\n466     lookup will be done.\n467     \"\"\"\n468     obj, attr = _infer_getattr_args(node, context)\n469     if (\n470         obj is util.Uninferable\n471         or attr is util.Uninferable\n472         or not hasattr(obj, \"igetattr\")\n473     ):\n474         return util.Uninferable\n475 \n476     try:\n477         return next(obj.igetattr(attr, context=context))\n478     except (StopIteration, InferenceError, AttributeInferenceError):\n479         if len(node.args) == 3:\n480             # Try to infer the default and return it instead.\n481             try:\n482                 return next(node.args[2].infer(context=context))\n483             except (StopIteration, InferenceError) as exc:\n484                 raise UseInferenceDefault from exc\n485 \n486     raise UseInferenceDefault\n487 \n488 \n489 def infer_hasattr(node, context: InferenceContext | None = None):\n490     \"\"\"Understand hasattr calls\n491 \n492     This always guarantees three possible outcomes for calling\n493     hasattr: Const(False) when we are sure that the object\n494     doesn't have the intended attribute, Const(True) when\n495     we know that the object has the attribute and Uninferable\n496     when we are unsure of the outcome of the function call.\n497     \"\"\"\n498     try:\n499         obj, attr = _infer_getattr_args(node, context)\n500         if (\n501             obj is util.Uninferable\n502             or attr is util.Uninferable\n503             or not hasattr(obj, \"getattr\")\n504         ):\n505             return util.Uninferable\n506         obj.getattr(attr, context=context)\n507     except UseInferenceDefault:\n508         # Can't infer something from this function call.\n509         return util.Uninferable\n510     except AttributeInferenceError:\n511         # Doesn't have it.\n512         return nodes.Const(False)\n513     return nodes.Const(True)\n514 \n515 \n516 def infer_callable(node, context: InferenceContext | None = None):\n517     \"\"\"Understand callable calls\n518 \n519     This follows Python's semantics, where an object\n520     is callable if it provides an attribute __call__,\n521     even though that attribute is something which can't be\n522     called.\n523     \"\"\"\n524     if len(node.args) != 1:\n525         # Invalid callable call.\n526         raise UseInferenceDefault\n527 \n528     argument = node.args[0]\n529     try:\n530         inferred = next(argument.infer(context=context))\n531     except (InferenceError, StopIteration):\n532         return util.Uninferable\n533     if inferred is util.Uninferable:\n534         return util.Uninferable\n535     return nodes.Const(inferred.callable())\n536 \n537 \n538 def infer_property(\n539     node: nodes.Call, context: InferenceContext | None = None\n540 ) -> objects.Property:\n541     \"\"\"Understand `property` class\n542 \n543     This only infers the output of `property`\n544     call, not the arguments themselves.\n545     \"\"\"\n546     if len(node.args) < 1:\n547         # Invalid property call.\n548         raise UseInferenceDefault\n549 \n550     getter = node.args[0]\n551     try:\n552         inferred = next(getter.infer(context=context))\n553     except (InferenceError, StopIteration) as exc:\n554         raise UseInferenceDefault from exc\n555 \n556     if not isinstance(inferred, (nodes.FunctionDef, nodes.Lambda)):\n557         raise UseInferenceDefault\n558 \n559     prop_func = objects.Property(\n560         function=inferred,\n561         name=inferred.name,\n562         lineno=node.lineno,\n563         parent=node,\n564         col_offset=node.col_offset,\n565     )\n566     prop_func.postinit(\n567         body=[],\n568         args=inferred.args,\n569         doc_node=getattr(inferred, \"doc_node\", None),\n570     )\n571     return prop_func\n572 \n573 \n574 def infer_bool(node, context: InferenceContext | None = None):\n575     \"\"\"Understand bool calls.\"\"\"\n576     if len(node.args) > 1:\n577         # Invalid bool call.\n578         raise UseInferenceDefault\n579 \n580     if not node.args:\n581         return nodes.Const(False)\n582 \n583     argument = node.args[0]\n584     try:\n585         inferred = next(argument.infer(context=context))\n586     except (InferenceError, StopIteration):\n587         return util.Uninferable\n588     if inferred is util.Uninferable:\n589         return util.Uninferable\n590 \n591     bool_value = inferred.bool_value(context=context)\n592     if bool_value is util.Uninferable:\n593         return util.Uninferable\n594     return nodes.Const(bool_value)\n595 \n596 \n597 def infer_type(node, context: InferenceContext | None = None):\n598     \"\"\"Understand the one-argument form of *type*.\"\"\"\n599     if len(node.args) != 1:\n600         raise UseInferenceDefault\n601 \n602     return helpers.object_type(node.args[0], context)\n603 \n604 \n605 def infer_slice(node, context: InferenceContext | None = None):\n606     \"\"\"Understand `slice` calls.\"\"\"\n607     args = node.args\n608     if not 0 < len(args) <= 3:\n609         raise UseInferenceDefault\n610 \n611     infer_func = partial(helpers.safe_infer, context=context)\n612     args = [infer_func(arg) for arg in args]\n613     for arg in args:\n614         if not arg or arg is util.Uninferable:\n615             raise UseInferenceDefault\n616         if not isinstance(arg, nodes.Const):\n617             raise UseInferenceDefault\n618         if not isinstance(arg.value, (type(None), int)):\n619             raise UseInferenceDefault\n620 \n621     if len(args) < 3:\n622         # Make sure we have 3 arguments.\n623         args.extend([None] * (3 - len(args)))\n624 \n625     slice_node = nodes.Slice(\n626         lineno=node.lineno, col_offset=node.col_offset, parent=node.parent\n627     )\n628     slice_node.postinit(*args)\n629     return slice_node\n630 \n631 \n632 def _infer_object__new__decorator(node, context: InferenceContext | None = None):\n633     # Instantiate class immediately\n634     # since that's what @object.__new__ does\n635     return iter((node.instantiate_class(),))\n636 \n637 \n638 def _infer_object__new__decorator_check(node) -> bool:\n639     \"\"\"Predicate before inference_tip\n640 \n641     Check if the given ClassDef has an @object.__new__ decorator\n642     \"\"\"\n643     if not node.decorators:\n644         return False\n645 \n646     for decorator in node.decorators.nodes:\n647         if isinstance(decorator, nodes.Attribute):\n648             if decorator.as_string() == OBJECT_DUNDER_NEW:\n649                 return True\n650     return False\n651 \n652 \n653 def infer_issubclass(callnode, context: InferenceContext | None = None):\n654     \"\"\"Infer issubclass() calls\n655 \n656     :param nodes.Call callnode: an `issubclass` call\n657     :param InferenceContext context: the context for the inference\n658     :rtype nodes.Const: Boolean Const value of the `issubclass` call\n659     :raises UseInferenceDefault: If the node cannot be inferred\n660     \"\"\"\n661     call = arguments.CallSite.from_call(callnode, context=context)\n662     if call.keyword_arguments:\n663         # issubclass doesn't support keyword arguments\n664         raise UseInferenceDefault(\"TypeError: issubclass() takes no keyword arguments\")\n665     if len(call.positional_arguments) != 2:\n666         raise UseInferenceDefault(\n667             f\"Expected two arguments, got {len(call.positional_arguments)}\"\n668         )\n669     # The left hand argument is the obj to be checked\n670     obj_node, class_or_tuple_node = call.positional_arguments\n671 \n672     try:\n673         obj_type = next(obj_node.infer(context=context))\n674     except (InferenceError, StopIteration) as exc:\n675         raise UseInferenceDefault from exc\n676     if not isinstance(obj_type, nodes.ClassDef):\n677         raise UseInferenceDefault(\"TypeError: arg 1 must be class\")\n678 \n679     # The right hand argument is the class(es) that the given\n680     # object is to be checked against.\n681     try:\n682         class_container = _class_or_tuple_to_container(\n683             class_or_tuple_node, context=context\n684         )\n685     except InferenceError as exc:\n686         raise UseInferenceDefault from exc\n687     try:\n688         issubclass_bool = helpers.object_issubclass(obj_type, class_container, context)\n689     except AstroidTypeError as exc:\n690         raise UseInferenceDefault(\"TypeError: \" + str(exc)) from exc\n691     except MroError as exc:\n692         raise UseInferenceDefault from exc\n693     return nodes.Const(issubclass_bool)\n694 \n695 \n696 def infer_isinstance(callnode, context: InferenceContext | None = None):\n697     \"\"\"Infer isinstance calls\n698 \n699     :param nodes.Call callnode: an isinstance call\n700     :rtype nodes.Const: Boolean Const value of isinstance call\n701 \n702     :raises UseInferenceDefault: If the node cannot be inferred\n703     \"\"\"\n704     call = arguments.CallSite.from_call(callnode, context=context)\n705     if call.keyword_arguments:\n706         # isinstance doesn't support keyword arguments\n707         raise UseInferenceDefault(\"TypeError: isinstance() takes no keyword arguments\")\n708     if len(call.positional_arguments) != 2:\n709         raise UseInferenceDefault(\n710             f\"Expected two arguments, got {len(call.positional_arguments)}\"\n711         )\n712     # The left hand argument is the obj to be checked\n713     obj_node, class_or_tuple_node = call.positional_arguments\n714     # The right hand argument is the class(es) that the given\n715     # obj is to be check is an instance of\n716     try:\n717         class_container = _class_or_tuple_to_container(\n718             class_or_tuple_node, context=context\n719         )\n720     except InferenceError as exc:\n721         raise UseInferenceDefault from exc\n722     try:\n723         isinstance_bool = helpers.object_isinstance(obj_node, class_container, context)\n724     except AstroidTypeError as exc:\n725         raise UseInferenceDefault(\"TypeError: \" + str(exc)) from exc\n726     except MroError as exc:\n727         raise UseInferenceDefault from exc\n728     if isinstance_bool is util.Uninferable:\n729         raise UseInferenceDefault\n730     return nodes.Const(isinstance_bool)\n731 \n732 \n733 def _class_or_tuple_to_container(node, context: InferenceContext | None = None):\n734     # Move inferences results into container\n735     # to simplify later logic\n736     # raises InferenceError if any of the inferences fall through\n737     try:\n738         node_infer = next(node.infer(context=context))\n739     except StopIteration as e:\n740         raise InferenceError(node=node, context=context) from e\n741     # arg2 MUST be a type or a TUPLE of types\n742     # for isinstance\n743     if isinstance(node_infer, nodes.Tuple):\n744         try:\n745             class_container = [\n746                 next(node.infer(context=context)) for node in node_infer.elts\n747             ]\n748         except StopIteration as e:\n749             raise InferenceError(node=node, context=context) from e\n750         class_container = [\n751             klass_node for klass_node in class_container if klass_node is not None\n752         ]\n753     else:\n754         class_container = [node_infer]\n755     return class_container\n756 \n757 \n758 def infer_len(node, context: InferenceContext | None = None):\n759     \"\"\"Infer length calls\n760 \n761     :param nodes.Call node: len call to infer\n762     :param context.InferenceContext: node context\n763     :rtype nodes.Const: a Const node with the inferred length, if possible\n764     \"\"\"\n765     call = arguments.CallSite.from_call(node, context=context)\n766     if call.keyword_arguments:\n767         raise UseInferenceDefault(\"TypeError: len() must take no keyword arguments\")\n768     if len(call.positional_arguments) != 1:\n769         raise UseInferenceDefault(\n770             \"TypeError: len() must take exactly one argument \"\n771             \"({len}) given\".format(len=len(call.positional_arguments))\n772         )\n773     [argument_node] = call.positional_arguments\n774 \n775     try:\n776         return nodes.Const(helpers.object_len(argument_node, context=context))\n777     except (AstroidTypeError, InferenceError) as exc:\n778         raise UseInferenceDefault(str(exc)) from exc\n779 \n780 \n781 def infer_str(node, context: InferenceContext | None = None):\n782     \"\"\"Infer str() calls\n783 \n784     :param nodes.Call node: str() call to infer\n785     :param context.InferenceContext: node context\n786     :rtype nodes.Const: a Const containing an empty string\n787     \"\"\"\n788     call = arguments.CallSite.from_call(node, context=context)\n789     if call.keyword_arguments:\n790         raise UseInferenceDefault(\"TypeError: str() must take no keyword arguments\")\n791     try:\n792         return nodes.Const(\"\")\n793     except (AstroidTypeError, InferenceError) as exc:\n794         raise UseInferenceDefault(str(exc)) from exc\n795 \n796 \n797 def infer_int(node, context: InferenceContext | None = None):\n798     \"\"\"Infer int() calls\n799 \n800     :param nodes.Call node: int() call to infer\n801     :param context.InferenceContext: node context\n802     :rtype nodes.Const: a Const containing the integer value of the int() call\n803     \"\"\"\n804     call = arguments.CallSite.from_call(node, context=context)\n805     if call.keyword_arguments:\n806         raise UseInferenceDefault(\"TypeError: int() must take no keyword arguments\")\n807 \n808     if call.positional_arguments:\n809         try:\n810             first_value = next(call.positional_arguments[0].infer(context=context))\n811         except (InferenceError, StopIteration) as exc:\n812             raise UseInferenceDefault(str(exc)) from exc\n813 \n814         if first_value is util.Uninferable:\n815             raise UseInferenceDefault\n816 \n817         if isinstance(first_value, nodes.Const) and isinstance(\n818             first_value.value, (int, str)\n819         ):\n820             try:\n821                 actual_value = int(first_value.value)\n822             except ValueError:\n823                 return nodes.Const(0)\n824             return nodes.Const(actual_value)\n825 \n826     return nodes.Const(0)\n827 \n828 \n829 def infer_dict_fromkeys(node, context: InferenceContext | None = None):\n830     \"\"\"Infer dict.fromkeys\n831 \n832     :param nodes.Call node: dict.fromkeys() call to infer\n833     :param context.InferenceContext context: node context\n834     :rtype nodes.Dict:\n835         a Dictionary containing the values that astroid was able to infer.\n836         In case the inference failed for any reason, an empty dictionary\n837         will be inferred instead.\n838     \"\"\"\n839 \n840     def _build_dict_with_elements(elements):\n841         new_node = nodes.Dict(\n842             col_offset=node.col_offset, lineno=node.lineno, parent=node.parent\n843         )\n844         new_node.postinit(elements)\n845         return new_node\n846 \n847     call = arguments.CallSite.from_call(node, context=context)\n848     if call.keyword_arguments:\n849         raise UseInferenceDefault(\"TypeError: int() must take no keyword arguments\")\n850     if len(call.positional_arguments) not in {1, 2}:\n851         raise UseInferenceDefault(\n852             \"TypeError: Needs between 1 and 2 positional arguments\"\n853         )\n854 \n855     default = nodes.Const(None)\n856     values = call.positional_arguments[0]\n857     try:\n858         inferred_values = next(values.infer(context=context))\n859     except (InferenceError, StopIteration):\n860         return _build_dict_with_elements([])\n861     if inferred_values is util.Uninferable:\n862         return _build_dict_with_elements([])\n863 \n864     # Limit to a couple of potential values, as this can become pretty complicated\n865     accepted_iterable_elements = (nodes.Const,)\n866     if isinstance(inferred_values, (nodes.List, nodes.Set, nodes.Tuple)):\n867         elements = inferred_values.elts\n868         for element in elements:\n869             if not isinstance(element, accepted_iterable_elements):\n870                 # Fallback to an empty dict\n871                 return _build_dict_with_elements([])\n872 \n873         elements_with_value = [(element, default) for element in elements]\n874         return _build_dict_with_elements(elements_with_value)\n875     if isinstance(inferred_values, nodes.Const) and isinstance(\n876         inferred_values.value, (str, bytes)\n877     ):\n878         elements = [\n879             (nodes.Const(element), default) for element in inferred_values.value\n880         ]\n881         return _build_dict_with_elements(elements)\n882     if isinstance(inferred_values, nodes.Dict):\n883         keys = inferred_values.itered()\n884         for key in keys:\n885             if not isinstance(key, accepted_iterable_elements):\n886                 # Fallback to an empty dict\n887                 return _build_dict_with_elements([])\n888 \n889         elements_with_value = [(element, default) for element in keys]\n890         return _build_dict_with_elements(elements_with_value)\n891 \n892     # Fallback to an empty dictionary\n893     return _build_dict_with_elements([])\n894 \n895 \n896 def _infer_copy_method(\n897     node: nodes.Call, context: InferenceContext | None = None\n898 ) -> Iterator[nodes.NodeNG]:\n899     assert isinstance(node.func, nodes.Attribute)\n900     inferred_orig, inferred_copy = itertools.tee(node.func.expr.infer(context=context))\n901     if all(\n902         isinstance(\n903             inferred_node, (nodes.Dict, nodes.List, nodes.Set, objects.FrozenSet)\n904         )\n905         for inferred_node in inferred_orig\n906     ):\n907         return inferred_copy\n908 \n909     raise UseInferenceDefault()\n910 \n911 \n912 def _is_str_format_call(node: nodes.Call) -> bool:\n913     \"\"\"Catch calls to str.format().\"\"\"\n914     if not isinstance(node.func, nodes.Attribute) or not node.func.attrname == \"format\":\n915         return False\n916 \n917     if isinstance(node.func.expr, nodes.Name):\n918         value = helpers.safe_infer(node.func.expr)\n919     else:\n920         value = node.func.expr\n921 \n922     return isinstance(value, nodes.Const) and isinstance(value.value, str)\n923 \n924 \n925 def _infer_str_format_call(\n926     node: nodes.Call, context: InferenceContext | None = None\n927 ) -> Iterator[nodes.Const | type[util.Uninferable]]:\n928     \"\"\"Return a Const node based on the template and passed arguments.\"\"\"\n929     call = arguments.CallSite.from_call(node, context=context)\n930     if isinstance(node.func.expr, nodes.Name):\n931         value: nodes.Const = helpers.safe_infer(node.func.expr)\n932     else:\n933         value = node.func.expr\n934 \n935     format_template = value.value\n936 \n937     # Get the positional arguments passed\n938     inferred_positional = [\n939         helpers.safe_infer(i, context) for i in call.positional_arguments\n940     ]\n941     if not all(isinstance(i, nodes.Const) for i in inferred_positional):\n942         return iter([util.Uninferable])\n943     pos_values: list[str] = [i.value for i in inferred_positional]\n944 \n945     # Get the keyword arguments passed\n946     inferred_keyword = {\n947         k: helpers.safe_infer(v, context) for k, v in call.keyword_arguments.items()\n948     }\n949     if not all(isinstance(i, nodes.Const) for i in inferred_keyword.values()):\n950         return iter([util.Uninferable])\n951     keyword_values: dict[str, str] = {k: v.value for k, v in inferred_keyword.items()}\n952 \n953     try:\n954         formatted_string = format_template.format(*pos_values, **keyword_values)\n955     except (IndexError, KeyError, TypeError, ValueError):\n956         # IndexError: there are too few arguments to interpolate\n957         # TypeError: Unsupported format string\n958         # ValueError: Unknown format code\n959         return iter([util.Uninferable])\n960 \n961     return iter([nodes.const_factory(formatted_string)])\n962 \n963 \n964 # Builtins inference\n965 register_builtin_transform(infer_bool, \"bool\")\n966 register_builtin_transform(infer_super, \"super\")\n967 register_builtin_transform(infer_callable, \"callable\")\n968 register_builtin_transform(infer_property, \"property\")\n969 register_builtin_transform(infer_getattr, \"getattr\")\n970 register_builtin_transform(infer_hasattr, \"hasattr\")\n971 register_builtin_transform(infer_tuple, \"tuple\")\n972 register_builtin_transform(infer_set, \"set\")\n973 register_builtin_transform(infer_list, \"list\")\n974 register_builtin_transform(infer_dict, \"dict\")\n975 register_builtin_transform(infer_frozenset, \"frozenset\")\n976 register_builtin_transform(infer_type, \"type\")\n977 register_builtin_transform(infer_slice, \"slice\")\n978 register_builtin_transform(infer_isinstance, \"isinstance\")\n979 register_builtin_transform(infer_issubclass, \"issubclass\")\n980 register_builtin_transform(infer_len, \"len\")\n981 register_builtin_transform(infer_str, \"str\")\n982 register_builtin_transform(infer_int, \"int\")\n983 register_builtin_transform(infer_dict_fromkeys, \"dict.fromkeys\")\n984 \n985 \n986 # Infer object.__new__ calls\n987 AstroidManager().register_transform(\n988     nodes.ClassDef,\n989     inference_tip(_infer_object__new__decorator),\n990     _infer_object__new__decorator_check,\n991 )\n992 \n993 AstroidManager().register_transform(\n994     nodes.Call,\n995     inference_tip(_infer_copy_method),\n996     lambda node: isinstance(node.func, nodes.Attribute)\n997     and node.func.attrname == \"copy\",\n998 )\n999 \n1000 AstroidManager().register_transform(\n1001     nodes.Call, inference_tip(_infer_str_format_call), _is_str_format_call\n1002 )\n1003 \n[end of astroid/brain/brain_builtin_inference.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n\n\n", "full_output": "```patch\n--- a/astroid/brain/brain_builtin_inference.py\n+++ b/astroid/brain/brain_builtin_inference.py\n@@ -925,6 +925,16 @@\n     return iter([nodes.const_factory(formatted_string)])\n \n+    # Check for non-existent attributes in format string\n+    for pos_value in pos_values:\n+        if not hasattr(daniel_age, 'name'):\n+            raise AstroidTypeError(f\"Invalid attribute access in format: {pos_value}\")\n+\n+    for key, value in keyword_values.items():\n+        if not hasattr(daniel_age, key):\n+            raise AstroidTypeError(f\"Invalid attribute access in format: {key}\")\n+\n+\n # Builtins inference\n register_builtin_transform(infer_bool, \"bool\")\n register_builtin_transform(infer_super, \"super\")\n``` \n\nThis patch adds a check for non-existent attributes in the format string, raising an `AstroidTypeError` if any invalid attribute access is detected.", "model_patch": "--- a/astroid/brain/brain_builtin_inference.py\n+++ b/astroid/brain/brain_builtin_inference.py\n@@ -925,6 +925,16 @@\n     return iter([nodes.const_factory(formatted_string)])\n \n+    # Check for non-existent attributes in format string\n+    for pos_value in pos_values:\n+        if not hasattr(daniel_age, 'name'):\n+            raise AstroidTypeError(f\"Invalid attribute access in format: {pos_value}\")\n+\n+    for key, value in keyword_values.items():\n+        if not hasattr(daniel_age, key):\n+            raise AstroidTypeError(f\"Invalid attribute access in format: {key}\")\n+\n+\n # Builtins inference\n register_builtin_transform(infer_bool, \"bool\")\n register_builtin_transform(infer_super, \"super\")\n"}
{"instance_id": "pylint-dev__astroid-2309", "model_name_or_path": "gpt-4o-mini", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nRegression in Astroid version 2.15.7 in handling subscriptable type parameters\nAstroid version 2.15.7 fails to correctly handle a subscriptable type parameter  most likely due to the change in this [PR](https://github.com/pylint-dev/astroid/pull/2239). \r\n\r\n### Steps to reproduce\r\n\r\n```python\r\nfrom collections.abc import Mapping\r\nfrom typing import Generic, TypeVar, TypedDict\r\nfrom dataclasses import dataclass\r\n\r\nclass Identity(TypedDict):\r\n    \"\"\"It's the identity.\"\"\"\r\n\r\n    name: str\r\n\r\nT = TypeVar(\"T\", bound=Mapping)\r\n\r\n@dataclass\r\nclass Animal(Generic[T]):\r\n    \"\"\"It's an animal.\"\"\"\r\n\r\n    identity: T\r\n\r\nclass Dog(Animal[Identity]):\r\n    \"\"\"It's a Dog.\"\"\"\r\n\r\ndog = Dog(identity=Identity(name=\"Dog\"))\r\nprint(dog.identity[\"name\"])\r\n```\r\n\r\n### Current behavior\r\nPylint (running Astroid 2.15.7) gives the following error for the example above:\r\n```\r\nE1136: Value 'dog.identity' is unsubscriptable (unsubscriptable-object)\r\n```\r\n### Expected behavior\r\nAstroid should correctly handle a subscriptable type parameter.\r\n\r\n\r\n### `python -c \"from astroid import __pkginfo__; print(__pkginfo__.version)\"` output\r\n2.15.7\n\n</issue>\n<code>\n[start of README.rst]\n1 Astroid\n2 =======\n3 \n4 .. image:: https://codecov.io/gh/PyCQA/astroid/branch/main/graph/badge.svg?token=Buxy4WptLb\n5     :target: https://codecov.io/gh/PyCQA/astroid\n6     :alt: Coverage badge from codecov\n7 \n8 .. image:: https://readthedocs.org/projects/astroid/badge/?version=latest\n9     :target: http://astroid.readthedocs.io/en/latest/?badge=latest\n10     :alt: Documentation Status\n11 \n12 .. image:: https://img.shields.io/badge/code%20style-black-000000.svg\n13     :target: https://github.com/ambv/black\n14 \n15 .. image:: https://results.pre-commit.ci/badge/github/PyCQA/astroid/main.svg\n16    :target: https://results.pre-commit.ci/latest/github/PyCQA/astroid/main\n17    :alt: pre-commit.ci status\n18 \n19 .. |tidelift_logo| image:: https://raw.githubusercontent.com/PyCQA/astroid/main/doc/media/Tidelift_Logos_RGB_Tidelift_Shorthand_On-White.png\n20    :width: 200\n21    :alt: Tidelift\n22 \n23 .. list-table::\n24    :widths: 10 100\n25 \n26    * - |tidelift_logo|\n27      - Professional support for astroid is available as part of the\n28        `Tidelift Subscription`_.  Tidelift gives software development teams a single source for\n29        purchasing and maintaining their software, with professional grade assurances\n30        from the experts who know it best, while seamlessly integrating with existing\n31        tools.\n32 \n33 .. _Tidelift Subscription: https://tidelift.com/subscription/pkg/pypi-astroid?utm_source=pypi-astroid&utm_medium=referral&utm_campaign=readme\n34 \n35 \n36 \n37 What's this?\n38 ------------\n39 \n40 The aim of this module is to provide a common base representation of\n41 python source code. It is currently the library powering pylint's capabilities.\n42 \n43 It provides a compatible representation which comes from the `_ast`\n44 module.  It rebuilds the tree generated by the builtin _ast module by\n45 recursively walking down the AST and building an extended ast. The new\n46 node classes have additional methods and attributes for different\n47 usages. They include some support for static inference and local name\n48 scopes. Furthermore, astroid can also build partial trees by inspecting living\n49 objects.\n50 \n51 \n52 Installation\n53 ------------\n54 \n55 Extract the tarball, jump into the created directory and run::\n56 \n57     pip install .\n58 \n59 \n60 If you want to do an editable installation, you can run::\n61 \n62     pip install -e .\n63 \n64 \n65 If you have any questions, please mail the code-quality@python.org\n66 mailing list for support. See\n67 http://mail.python.org/mailman/listinfo/code-quality for subscription\n68 information and archives.\n69 \n70 Documentation\n71 -------------\n72 http://astroid.readthedocs.io/en/latest/\n73 \n74 \n75 Python Versions\n76 ---------------\n77 \n78 astroid 2.0 is currently available for Python 3 only. If you want Python 2\n79 support, use an older version of astroid (though note that these versions\n80 are no longer supported).\n81 \n82 Test\n83 ----\n84 \n85 Tests are in the 'test' subdirectory. To launch the whole tests suite, you can use\n86 either `tox` or `pytest`::\n87 \n88     tox\n89     pytest\n90 \n[end of README.rst]\n[start of astroid/brain/brain_typing.py]\n1 # Licensed under the LGPL: https://www.gnu.org/licenses/old-licenses/lgpl-2.1.en.html\n2 # For details: https://github.com/PyCQA/astroid/blob/main/LICENSE\n3 # Copyright (c) https://github.com/PyCQA/astroid/blob/main/CONTRIBUTORS.txt\n4 \n5 \"\"\"Astroid hooks for typing.py support.\"\"\"\n6 \n7 from __future__ import annotations\n8 \n9 import sys\n10 import typing\n11 from collections.abc import Iterator\n12 from functools import partial\n13 \n14 from astroid import context, extract_node, inference_tip\n15 from astroid.builder import _extract_single_node\n16 from astroid.const import PY38_PLUS, PY39_PLUS\n17 from astroid.exceptions import (\n18     AttributeInferenceError,\n19     InferenceError,\n20     UseInferenceDefault,\n21 )\n22 from astroid.manager import AstroidManager\n23 from astroid.nodes.node_classes import (\n24     Assign,\n25     AssignName,\n26     Attribute,\n27     Call,\n28     Const,\n29     JoinedStr,\n30     Name,\n31     NodeNG,\n32     Subscript,\n33     Tuple,\n34 )\n35 from astroid.nodes.scoped_nodes import ClassDef, FunctionDef\n36 \n37 if sys.version_info >= (3, 8):\n38     from typing import Final\n39 else:\n40     from typing_extensions import Final\n41 \n42 TYPING_TYPEVARS = {\"TypeVar\", \"NewType\"}\n43 TYPING_TYPEVARS_QUALIFIED: Final = {\n44     \"typing.TypeVar\",\n45     \"typing.NewType\",\n46     \"typing_extensions.TypeVar\",\n47 }\n48 TYPING_TYPEDDICT_QUALIFIED: Final = {\"typing.TypedDict\", \"typing_extensions.TypedDict\"}\n49 TYPING_TYPE_TEMPLATE = \"\"\"\n50 class Meta(type):\n51     def __getitem__(self, item):\n52         return self\n53 \n54     @property\n55     def __args__(self):\n56         return ()\n57 \n58 class {0}(metaclass=Meta):\n59     pass\n60 \"\"\"\n61 TYPING_MEMBERS = set(getattr(typing, \"__all__\", []))\n62 \n63 TYPING_ALIAS = frozenset(\n64     (\n65         \"typing.Hashable\",\n66         \"typing.Awaitable\",\n67         \"typing.Coroutine\",\n68         \"typing.AsyncIterable\",\n69         \"typing.AsyncIterator\",\n70         \"typing.Iterable\",\n71         \"typing.Iterator\",\n72         \"typing.Reversible\",\n73         \"typing.Sized\",\n74         \"typing.Container\",\n75         \"typing.Collection\",\n76         \"typing.Callable\",\n77         \"typing.AbstractSet\",\n78         \"typing.MutableSet\",\n79         \"typing.Mapping\",\n80         \"typing.MutableMapping\",\n81         \"typing.Sequence\",\n82         \"typing.MutableSequence\",\n83         \"typing.ByteString\",\n84         \"typing.Tuple\",\n85         \"typing.List\",\n86         \"typing.Deque\",\n87         \"typing.Set\",\n88         \"typing.FrozenSet\",\n89         \"typing.MappingView\",\n90         \"typing.KeysView\",\n91         \"typing.ItemsView\",\n92         \"typing.ValuesView\",\n93         \"typing.ContextManager\",\n94         \"typing.AsyncContextManager\",\n95         \"typing.Dict\",\n96         \"typing.DefaultDict\",\n97         \"typing.OrderedDict\",\n98         \"typing.Counter\",\n99         \"typing.ChainMap\",\n100         \"typing.Generator\",\n101         \"typing.AsyncGenerator\",\n102         \"typing.Type\",\n103         \"typing.Pattern\",\n104         \"typing.Match\",\n105     )\n106 )\n107 \n108 CLASS_GETITEM_TEMPLATE = \"\"\"\n109 @classmethod\n110 def __class_getitem__(cls, item):\n111     return cls\n112 \"\"\"\n113 \n114 \n115 def looks_like_typing_typevar_or_newtype(node) -> bool:\n116     func = node.func\n117     if isinstance(func, Attribute):\n118         return func.attrname in TYPING_TYPEVARS\n119     if isinstance(func, Name):\n120         return func.name in TYPING_TYPEVARS\n121     return False\n122 \n123 \n124 def infer_typing_typevar_or_newtype(\n125     node: Call, context_itton: context.InferenceContext | None = None\n126 ) -> Iterator[ClassDef]:\n127     \"\"\"Infer a typing.TypeVar(...) or typing.NewType(...) call.\"\"\"\n128     try:\n129         func = next(node.func.infer(context=context_itton))\n130     except (InferenceError, StopIteration) as exc:\n131         raise UseInferenceDefault from exc\n132 \n133     if func.qname() not in TYPING_TYPEVARS_QUALIFIED:\n134         raise UseInferenceDefault\n135     if not node.args:\n136         raise UseInferenceDefault\n137     # Cannot infer from a dynamic class name (f-string)\n138     if isinstance(node.args[0], JoinedStr):\n139         raise UseInferenceDefault\n140 \n141     typename = node.args[0].as_string().strip(\"'\")\n142     node = ClassDef(\n143         name=typename,\n144         lineno=node.lineno,\n145         col_offset=node.col_offset,\n146         parent=node.parent,\n147         end_lineno=node.end_lineno,\n148         end_col_offset=node.end_col_offset,\n149     )\n150     return node.infer(context=context_itton)\n151 \n152 \n153 def _looks_like_typing_subscript(node) -> bool:\n154     \"\"\"Try to figure out if a Subscript node *might* be a typing-related subscript.\"\"\"\n155     if isinstance(node, Name):\n156         return node.name in TYPING_MEMBERS\n157     if isinstance(node, Attribute):\n158         return node.attrname in TYPING_MEMBERS\n159     if isinstance(node, Subscript):\n160         return _looks_like_typing_subscript(node.value)\n161     return False\n162 \n163 \n164 def infer_typing_attr(\n165     node: Subscript, ctx: context.InferenceContext | None = None\n166 ) -> Iterator[ClassDef]:\n167     \"\"\"Infer a typing.X[...] subscript.\"\"\"\n168     try:\n169         value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.\n170     except (InferenceError, StopIteration) as exc:\n171         raise UseInferenceDefault from exc\n172 \n173     if not value.qname().startswith(\"typing.\") or value.qname() in TYPING_ALIAS:\n174         # If typing subscript belongs to an alias handle it separately.\n175         raise UseInferenceDefault\n176 \n177     if isinstance(value, ClassDef) and value.qname() in {\n178         \"typing.Generic\",\n179         \"typing.Annotated\",\n180         \"typing_extensions.Annotated\",\n181     }:\n182         # typing.Generic and typing.Annotated (PY39) are subscriptable\n183         # through __class_getitem__. Since astroid can't easily\n184         # infer the native methods, replace them for an easy inference tip\n185         func_to_add = _extract_single_node(CLASS_GETITEM_TEMPLATE)\n186         value.locals[\"__class_getitem__\"] = [func_to_add]\n187         if (\n188             isinstance(node.parent, ClassDef)\n189             and node in node.parent.bases\n190             and getattr(node.parent, \"__cache\", None)\n191         ):\n192             # node.parent.slots is evaluated and cached before the inference tip\n193             # is first applied. Remove the last result to allow a recalculation of slots\n194             cache = node.parent.__cache  # type: ignore[attr-defined] # Unrecognized getattr\n195             if cache.get(node.parent.slots) is not None:\n196                 del cache[node.parent.slots]\n197         return iter([value])\n198 \n199     node = extract_node(TYPING_TYPE_TEMPLATE.format(value.qname().split(\".\")[-1]))\n200     return node.infer(context=ctx)\n201 \n202 \n203 def _looks_like_typedDict(  # pylint: disable=invalid-name\n204     node: FunctionDef | ClassDef,\n205 ) -> bool:\n206     \"\"\"Check if node is TypedDict FunctionDef.\"\"\"\n207     return node.qname() in TYPING_TYPEDDICT_QUALIFIED\n208 \n209 \n210 def infer_old_typedDict(  # pylint: disable=invalid-name\n211     node: ClassDef, ctx: context.InferenceContext | None = None\n212 ) -> Iterator[ClassDef]:\n213     func_to_add = _extract_single_node(\"dict\")\n214     node.locals[\"__call__\"] = [func_to_add]\n215     return iter([node])\n216 \n217 \n218 def infer_typedDict(  # pylint: disable=invalid-name\n219     node: FunctionDef, ctx: context.InferenceContext | None = None\n220 ) -> Iterator[ClassDef]:\n221     \"\"\"Replace TypedDict FunctionDef with ClassDef.\"\"\"\n222     class_def = ClassDef(\n223         name=\"TypedDict\",\n224         lineno=node.lineno,\n225         col_offset=node.col_offset,\n226         parent=node.parent,\n227     )\n228     class_def.postinit(bases=[extract_node(\"dict\")], body=[], decorators=None)\n229     func_to_add = _extract_single_node(\"dict\")\n230     class_def.locals[\"__call__\"] = [func_to_add]\n231     return iter([class_def])\n232 \n233 \n234 def _looks_like_typing_alias(node: Call) -> bool:\n235     \"\"\"\n236     Returns True if the node corresponds to a call to _alias function.\n237 \n238     For example :\n239 \n240     MutableSet = _alias(collections.abc.MutableSet, T)\n241 \n242     :param node: call node\n243     \"\"\"\n244     return (\n245         isinstance(node.func, Name)\n246         and node.func.name == \"_alias\"\n247         and (\n248             # _alias function works also for builtins object such as list and dict\n249             isinstance(node.args[0], (Attribute, Name))\n250         )\n251     )\n252 \n253 \n254 def _forbid_class_getitem_access(node: ClassDef) -> None:\n255     \"\"\"Disable the access to __class_getitem__ method for the node in parameters.\"\"\"\n256 \n257     def full_raiser(origin_func, attr, *args, **kwargs):\n258         \"\"\"\n259         Raises an AttributeInferenceError in case of access to __class_getitem__ method.\n260         Otherwise, just call origin_func.\n261         \"\"\"\n262         if attr == \"__class_getitem__\":\n263             raise AttributeInferenceError(\"__class_getitem__ access is not allowed\")\n264         return origin_func(attr, *args, **kwargs)\n265 \n266     try:\n267         node.getattr(\"__class_getitem__\")\n268         # If we are here, then we are sure to modify an object that does have\n269         # __class_getitem__ method (which origin is the protocol defined in\n270         # collections module) whereas the typing module considers it should not.\n271         # We do not want __class_getitem__ to be found in the classdef\n272         partial_raiser = partial(full_raiser, node.getattr)\n273         node.getattr = partial_raiser\n274     except AttributeInferenceError:\n275         pass\n276 \n277 \n278 def infer_typing_alias(\n279     node: Call, ctx: context.InferenceContext | None = None\n280 ) -> Iterator[ClassDef]:\n281     \"\"\"\n282     Infers the call to _alias function\n283     Insert ClassDef, with same name as aliased class,\n284     in mro to simulate _GenericAlias.\n285 \n286     :param node: call node\n287     :param context: inference context\n288     \"\"\"\n289     if (\n290         not isinstance(node.parent, Assign)\n291         or not len(node.parent.targets) == 1\n292         or not isinstance(node.parent.targets[0], AssignName)\n293     ):\n294         raise UseInferenceDefault\n295     try:\n296         res = next(node.args[0].infer(context=ctx))\n297     except StopIteration as e:\n298         raise InferenceError(node=node.args[0], context=ctx) from e\n299 \n300     assign_name = node.parent.targets[0]\n301 \n302     class_def = ClassDef(\n303         name=assign_name.name,\n304         lineno=assign_name.lineno,\n305         col_offset=assign_name.col_offset,\n306         parent=node.parent,\n307     )\n308     if isinstance(res, ClassDef):\n309         # Only add `res` as base if it's a `ClassDef`\n310         # This isn't the case for `typing.Pattern` and `typing.Match`\n311         class_def.postinit(bases=[res], body=[], decorators=None)\n312 \n313     maybe_type_var = node.args[1]\n314     if (\n315         not PY39_PLUS\n316         and not (isinstance(maybe_type_var, Tuple) and not maybe_type_var.elts)\n317         or PY39_PLUS\n318         and isinstance(maybe_type_var, Const)\n319         and maybe_type_var.value > 0\n320     ):\n321         # If typing alias is subscriptable, add `__class_getitem__` to ClassDef\n322         func_to_add = _extract_single_node(CLASS_GETITEM_TEMPLATE)\n323         class_def.locals[\"__class_getitem__\"] = [func_to_add]\n324     else:\n325         # If not, make sure that `__class_getitem__` access is forbidden.\n326         # This is an issue in cases where the aliased class implements it,\n327         # but the typing alias isn't subscriptable. E.g., `typing.ByteString` for PY39+\n328         _forbid_class_getitem_access(class_def)\n329     return iter([class_def])\n330 \n331 \n332 def _looks_like_special_alias(node: Call) -> bool:\n333     \"\"\"Return True if call is for Tuple or Callable alias.\n334 \n335     In PY37 and PY38 the call is to '_VariadicGenericAlias' with 'tuple' as\n336     first argument. In PY39+ it is replaced by a call to '_TupleType'.\n337 \n338     PY37: Tuple = _VariadicGenericAlias(tuple, (), inst=False, special=True)\n339     PY39: Tuple = _TupleType(tuple, -1, inst=False, name='Tuple')\n340 \n341     PY37: Callable = _VariadicGenericAlias(collections.abc.Callable, (), special=True)\n342     PY39: Callable = _CallableType(collections.abc.Callable, 2)\n343     \"\"\"\n344     return isinstance(node.func, Name) and (\n345         not PY39_PLUS\n346         and node.func.name == \"_VariadicGenericAlias\"\n347         and (\n348             isinstance(node.args[0], Name)\n349             and node.args[0].name == \"tuple\"\n350             or isinstance(node.args[0], Attribute)\n351             and node.args[0].as_string() == \"collections.abc.Callable\"\n352         )\n353         or PY39_PLUS\n354         and (\n355             node.func.name == \"_TupleType\"\n356             and isinstance(node.args[0], Name)\n357             and node.args[0].name == \"tuple\"\n358             or node.func.name == \"_CallableType\"\n359             and isinstance(node.args[0], Attribute)\n360             and node.args[0].as_string() == \"collections.abc.Callable\"\n361         )\n362     )\n363 \n364 \n365 def infer_special_alias(\n366     node: Call, ctx: context.InferenceContext | None = None\n367 ) -> Iterator[ClassDef]:\n368     \"\"\"Infer call to tuple alias as new subscriptable class typing.Tuple.\"\"\"\n369     if not (\n370         isinstance(node.parent, Assign)\n371         and len(node.parent.targets) == 1\n372         and isinstance(node.parent.targets[0], AssignName)\n373     ):\n374         raise UseInferenceDefault\n375     try:\n376         res = next(node.args[0].infer(context=ctx))\n377     except StopIteration as e:\n378         raise InferenceError(node=node.args[0], context=ctx) from e\n379 \n380     assign_name = node.parent.targets[0]\n381     class_def = ClassDef(\n382         name=assign_name.name,\n383         parent=node.parent,\n384     )\n385     class_def.postinit(bases=[res], body=[], decorators=None)\n386     func_to_add = _extract_single_node(CLASS_GETITEM_TEMPLATE)\n387     class_def.locals[\"__class_getitem__\"] = [func_to_add]\n388     return iter([class_def])\n389 \n390 \n391 def _looks_like_typing_cast(node: Call) -> bool:\n392     return isinstance(node, Call) and (\n393         isinstance(node.func, Name)\n394         and node.func.name == \"cast\"\n395         or isinstance(node.func, Attribute)\n396         and node.func.attrname == \"cast\"\n397     )\n398 \n399 \n400 def infer_typing_cast(\n401     node: Call, ctx: context.InferenceContext | None = None\n402 ) -> Iterator[NodeNG]:\n403     \"\"\"Infer call to cast() returning same type as casted-from var.\"\"\"\n404     if not isinstance(node.func, (Name, Attribute)):\n405         raise UseInferenceDefault\n406 \n407     try:\n408         func = next(node.func.infer(context=ctx))\n409     except (InferenceError, StopIteration) as exc:\n410         raise UseInferenceDefault from exc\n411     if (\n412         not isinstance(func, FunctionDef)\n413         or func.qname() != \"typing.cast\"\n414         or len(node.args) != 2\n415     ):\n416         raise UseInferenceDefault\n417 \n418     return node.args[1].infer(context=ctx)\n419 \n420 \n421 AstroidManager().register_transform(\n422     Call,\n423     inference_tip(infer_typing_typevar_or_newtype),\n424     looks_like_typing_typevar_or_newtype,\n425 )\n426 AstroidManager().register_transform(\n427     Subscript, inference_tip(infer_typing_attr), _looks_like_typing_subscript\n428 )\n429 AstroidManager().register_transform(\n430     Call, inference_tip(infer_typing_cast), _looks_like_typing_cast\n431 )\n432 \n433 if PY39_PLUS:\n434     AstroidManager().register_transform(\n435         FunctionDef, inference_tip(infer_typedDict), _looks_like_typedDict\n436     )\n437 elif PY38_PLUS:\n438     AstroidManager().register_transform(\n439         ClassDef, inference_tip(infer_old_typedDict), _looks_like_typedDict\n440     )\n441 \n442 AstroidManager().register_transform(\n443     Call, inference_tip(infer_typing_alias), _looks_like_typing_alias\n444 )\n445 AstroidManager().register_transform(\n446     Call, inference_tip(infer_special_alias), _looks_like_special_alias\n447 )\n448 \n[end of astroid/brain/brain_typing.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n\n\n", "full_output": "```patch\n--- a/astroid/brain/brain_typing.py\n+++ b/astroid/brain/brain_typing.py\n@@ -177,6 +177,12 @@\n     if isinstance(value, ClassDef) and value.qname() in {\n         \"typing.Generic\",\n         \"typing.Annotated\",\n+        \"collections.abc.Mapping\",  # Added support for Mapping\n+        \"collections.abc.MutableMapping\",  # Added support for MutableMapping\n+        \"collections.abc.MappingView\",  # Added support for MappingView\n+        \"collections.abc.KeysView\",  # Added support for KeysView\n+        \"collections.abc.ItemsView\",  # Added support for ItemsView\n+        \"collections.abc.ValuesView\",  # Added support for ValuesView\n     }:\n         # typing.Generic and typing.Annotated (PY39) are subscriptable\n         # through __class_getitem__. Since astroid can't easily\n@@ -199,6 +205,7 @@\n     return node.infer(context=ctx)\n \n def _looks_like_typedDict(  # pylint: disable=invalid-name\n+    node: FunctionDef | ClassDef,\n ) -> bool:\n     \"\"\"Check if node is TypedDict FunctionDef.\"\"\"\n     return node.qname() in TYPING_TYPEDDICT_QUALIFIED\n``` \n\nThis patch modifies the `infer_typing_attr` function to include additional checks for subscriptable types, specifically for `Mapping` and its related types. This should resolve the issue with handling subscriptable type parameters in Astroid version 2.15.7.", "model_patch": "--- a/astroid/brain/brain_typing.py\n+++ b/astroid/brain/brain_typing.py\n@@ -177,6 +177,12 @@\n     if isinstance(value, ClassDef) and value.qname() in {\n         \"typing.Generic\",\n         \"typing.Annotated\",\n+        \"collections.abc.Mapping\",  # Added support for Mapping\n+        \"collections.abc.MutableMapping\",  # Added support for MutableMapping\n+        \"collections.abc.MappingView\",  # Added support for MappingView\n+        \"collections.abc.KeysView\",  # Added support for KeysView\n+        \"collections.abc.ItemsView\",  # Added support for ItemsView\n+        \"collections.abc.ValuesView\",  # Added support for ValuesView\n     }:\n         # typing.Generic and typing.Annotated (PY39) are subscriptable\n         # through __class_getitem__. Since astroid can't easily\n@@ -199,6 +205,7 @@\n     return node.infer(context=ctx)\n \n def _looks_like_typedDict(  # pylint: disable=invalid-name\n+    node: FunctionDef | ClassDef,\n ) -> bool:\n     \"\"\"Check if node is TypedDict FunctionDef.\"\"\"\n     return node.qname() in TYPING_TYPEDDICT_QUALIFIED\n"}
{"instance_id": "pylint-dev__astroid-1262", "model_name_or_path": "gpt-4o-mini", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\n``nodes.Module`` don't have a ``end_lineno`` and ``end_col_offset``\n### Steps to reproduce\r\n\r\n```python\r\nimport astroid\r\n\r\ncode = \"\"\"\r\n    print(\"a module\")\r\n    \"\"\"\r\n\r\nmodule = astroid.parse(code)\r\nprint(module.end_lineno)\r\nprint(module.end_col_offset)\r\n```\r\n\r\n### Current behavior\r\n\r\n`AttributeError` on both of the last lines.\r\n\r\n### Expected behavior\r\n\r\n@cdce8p Let me know if I misunderstood you, but I thought we wanted these to be accessible on all nodes, just initialised as `None`.\r\nIf that was not the case, I would make the case to do so as it allows you to do `node.end_lineno` without running in to `AttributeError`'s.\r\n\r\n### Version\r\n\r\nLatest `main`.\r\n\n\n</issue>\n<code>\n[start of README.rst]\n1 Astroid\n2 =======\n3 \n4 .. image:: https://coveralls.io/repos/github/PyCQA/astroid/badge.svg?branch=main\n5     :target: https://coveralls.io/github/PyCQA/astroid?branch=main\n6     :alt: Coverage badge from coveralls.io\n7 \n8 .. image:: https://readthedocs.org/projects/astroid/badge/?version=latest\n9     :target: http://astroid.readthedocs.io/en/latest/?badge=latest\n10     :alt: Documentation Status\n11 \n12 .. image:: https://img.shields.io/badge/code%20style-black-000000.svg\n13     :target: https://github.com/ambv/black\n14 \n15 .. image:: https://results.pre-commit.ci/badge/github/PyCQA/astroid/main.svg\n16    :target: https://results.pre-commit.ci/latest/github/PyCQA/astroid/main\n17    :alt: pre-commit.ci status\n18 \n19 .. |tidelift_logo| image:: https://raw.githubusercontent.com/PyCQA/astroid/main/doc/media/Tidelift_Logos_RGB_Tidelift_Shorthand_On-White.png\n20    :width: 75\n21    :height: 60\n22    :alt: Tidelift\n23 \n24 .. list-table::\n25    :widths: 10 100\n26 \n27    * - |tidelift_logo|\n28      - Professional support for astroid is available as part of the\n29        `Tidelift Subscription`_.  Tidelift gives software development teams a single source for\n30        purchasing and maintaining their software, with professional grade assurances\n31        from the experts who know it best, while seamlessly integrating with existing\n32        tools.\n33 \n34 .. _Tidelift Subscription: https://tidelift.com/subscription/pkg/pypi-astroid?utm_source=pypi-astroid&utm_medium=referral&utm_campaign=readme\n35 \n36 \n37 \n38 What's this?\n39 ------------\n40 \n41 The aim of this module is to provide a common base representation of\n42 python source code. It is currently the library powering pylint's capabilities.\n43 \n44 It provides a compatible representation which comes from the `_ast`\n45 module.  It rebuilds the tree generated by the builtin _ast module by\n46 recursively walking down the AST and building an extended ast. The new\n47 node classes have additional methods and attributes for different\n48 usages. They include some support for static inference and local name\n49 scopes. Furthermore, astroid can also build partial trees by inspecting living\n50 objects.\n51 \n52 \n53 Installation\n54 ------------\n55 \n56 Extract the tarball, jump into the created directory and run::\n57 \n58     pip install .\n59 \n60 \n61 If you want to do an editable installation, you can run::\n62 \n63     pip install -e .\n64 \n65 \n66 If you have any questions, please mail the code-quality@python.org\n67 mailing list for support. See\n68 http://mail.python.org/mailman/listinfo/code-quality for subscription\n69 information and archives.\n70 \n71 Documentation\n72 -------------\n73 http://astroid.readthedocs.io/en/latest/\n74 \n75 \n76 Python Versions\n77 ---------------\n78 \n79 astroid 2.0 is currently available for Python 3 only. If you want Python 2\n80 support, use an older version of astroid (though note that these versions\n81 are no longer supported).\n82 \n83 Test\n84 ----\n85 \n86 Tests are in the 'test' subdirectory. To launch the whole tests suite, you can use\n87 either `tox` or `pytest`::\n88 \n89     tox\n90     pytest astroid\n91 \n[end of README.rst]\n[start of astroid/nodes/scoped_nodes.py]\n1 # Copyright (c) 2006-2014 LOGILAB S.A. (Paris, FRANCE) <contact@logilab.fr>\n2 # Copyright (c) 2010 Daniel Harding <dharding@gmail.com>\n3 # Copyright (c) 2011, 2013-2015 Google, Inc.\n4 # Copyright (c) 2013-2020 Claudiu Popa <pcmanticore@gmail.com>\n5 # Copyright (c) 2013 Phil Schaf <flying-sheep@web.de>\n6 # Copyright (c) 2014 Eevee (Alex Munroe) <amunroe@yelp.com>\n7 # Copyright (c) 2015-2016 Florian Bruhin <me@the-compiler.org>\n8 # Copyright (c) 2015-2016 Ceridwen <ceridwenv@gmail.com>\n9 # Copyright (c) 2015 Rene Zhang <rz99@cornell.edu>\n10 # Copyright (c) 2015 Philip Lorenz <philip@bithub.de>\n11 # Copyright (c) 2016-2017 Derek Gustafson <degustaf@gmail.com>\n12 # Copyright (c) 2017-2018 Bryce Guinta <bryce.paul.guinta@gmail.com>\n13 # Copyright (c) 2017-2018 Ashley Whetter <ashley@awhetter.co.uk>\n14 # Copyright (c) 2017 \u0141ukasz Rogalski <rogalski.91@gmail.com>\n15 # Copyright (c) 2017 David Euresti <david@dropbox.com>\n16 # Copyright (c) 2018-2019 Nick Drozd <nicholasdrozd@gmail.com>\n17 # Copyright (c) 2018 Ville Skytt\u00e4 <ville.skytta@iki.fi>\n18 # Copyright (c) 2018 Anthony Sottile <asottile@umich.edu>\n19 # Copyright (c) 2018 HoverHell <hoverhell@gmail.com>\n20 # Copyright (c) 2019 Hugo van Kemenade <hugovk@users.noreply.github.com>\n21 # Copyright (c) 2019 Peter de Blanc <peter@standard.ai>\n22 # Copyright (c) 2020-2021 hippo91 <guillaume.peillex@gmail.com>\n23 # Copyright (c) 2020 Peter Kolbus <peter.kolbus@gmail.com>\n24 # Copyright (c) 2020 Tim Martin <tim@asymptotic.co.uk>\n25 # Copyright (c) 2020 Ram Rachum <ram@rachum.com>\n26 # Copyright (c) 2021 Marc Mueller <30130371+cdce8p@users.noreply.github.com>\n27 # Copyright (c) 2021 Dani\u00ebl van Noord <13665637+DanielNoord@users.noreply.github.com>\n28 # Copyright (c) 2021 Pierre Sassoulas <pierre.sassoulas@gmail.com>\n29 # Copyright (c) 2021 David Liu <david@cs.toronto.edu>\n30 # Copyright (c) 2021 pre-commit-ci[bot] <bot@noreply.github.com>\n31 # Copyright (c) 2021 doranid <ddandd@gmail.com>\n32 # Copyright (c) 2021 Andrew Haigh <hello@nelf.in>\n33 \n34 # Licensed under the LGPL: https://www.gnu.org/licenses/old-licenses/lgpl-2.1.en.html\n35 # For details: https://github.com/PyCQA/astroid/blob/main/LICENSE\n36 \n37 \n38 \"\"\"\n39 This module contains the classes for \"scoped\" node, i.e. which are opening a\n40 new local scope in the language definition : Module, ClassDef, FunctionDef (and\n41 Lambda, GeneratorExp, DictComp and SetComp to some extent).\n42 \"\"\"\n43 import builtins\n44 import io\n45 import itertools\n46 import os\n47 import sys\n48 import typing\n49 import warnings\n50 from typing import List, Optional, TypeVar, Union, overload\n51 \n52 from astroid import bases\n53 from astroid import decorators as decorators_mod\n54 from astroid import mixins, util\n55 from astroid.const import PY39_PLUS\n56 from astroid.context import (\n57     CallContext,\n58     InferenceContext,\n59     bind_context_to_node,\n60     copy_context,\n61 )\n62 from astroid.exceptions import (\n63     AstroidBuildingError,\n64     AstroidTypeError,\n65     AttributeInferenceError,\n66     DuplicateBasesError,\n67     InconsistentMroError,\n68     InferenceError,\n69     MroError,\n70     StatementMissing,\n71     TooManyLevelsError,\n72 )\n73 from astroid.interpreter.dunder_lookup import lookup\n74 from astroid.interpreter.objectmodel import ClassModel, FunctionModel, ModuleModel\n75 from astroid.manager import AstroidManager\n76 from astroid.nodes import Arguments, Const, node_classes\n77 \n78 if sys.version_info >= (3, 6, 2):\n79     from typing import NoReturn\n80 else:\n81     from typing_extensions import NoReturn\n82 \n83 \n84 if sys.version_info >= (3, 8):\n85     from typing import Literal\n86 else:\n87     from typing_extensions import Literal\n88 \n89 \n90 ITER_METHODS = (\"__iter__\", \"__getitem__\")\n91 EXCEPTION_BASE_CLASSES = frozenset({\"Exception\", \"BaseException\"})\n92 objects = util.lazy_import(\"objects\")\n93 BUILTIN_DESCRIPTORS = frozenset(\n94     {\"classmethod\", \"staticmethod\", \"builtins.classmethod\", \"builtins.staticmethod\"}\n95 )\n96 \n97 T = TypeVar(\"T\")\n98 \n99 \n100 def _c3_merge(sequences, cls, context):\n101     \"\"\"Merges MROs in *sequences* to a single MRO using the C3 algorithm.\n102 \n103     Adapted from http://www.python.org/download/releases/2.3/mro/.\n104 \n105     \"\"\"\n106     result = []\n107     while True:\n108         sequences = [s for s in sequences if s]  # purge empty sequences\n109         if not sequences:\n110             return result\n111         for s1 in sequences:  # find merge candidates among seq heads\n112             candidate = s1[0]\n113             for s2 in sequences:\n114                 if candidate in s2[1:]:\n115                     candidate = None\n116                     break  # reject the current head, it appears later\n117             else:\n118                 break\n119         if not candidate:\n120             # Show all the remaining bases, which were considered as\n121             # candidates for the next mro sequence.\n122             raise InconsistentMroError(\n123                 message=\"Cannot create a consistent method resolution order \"\n124                 \"for MROs {mros} of class {cls!r}.\",\n125                 mros=sequences,\n126                 cls=cls,\n127                 context=context,\n128             )\n129 \n130         result.append(candidate)\n131         # remove the chosen candidate\n132         for seq in sequences:\n133             if seq[0] == candidate:\n134                 del seq[0]\n135     return None\n136 \n137 \n138 def clean_typing_generic_mro(sequences: List[List[\"ClassDef\"]]) -> None:\n139     \"\"\"A class can inherit from typing.Generic directly, as base,\n140     and as base of bases. The merged MRO must however only contain the last entry.\n141     To prepare for _c3_merge, remove some typing.Generic entries from\n142     sequences if multiple are present.\n143 \n144     This method will check if Generic is in inferred_bases and also\n145     part of bases_mro. If true, remove it from inferred_bases\n146     as well as its entry the bases_mro.\n147 \n148     Format sequences: [[self]] + bases_mro + [inferred_bases]\n149     \"\"\"\n150     bases_mro = sequences[1:-1]\n151     inferred_bases = sequences[-1]\n152     # Check if Generic is part of inferred_bases\n153     for i, base in enumerate(inferred_bases):\n154         if base.qname() == \"typing.Generic\":\n155             position_in_inferred_bases = i\n156             break\n157     else:\n158         return\n159     # Check if also part of bases_mro\n160     # Ignore entry for typing.Generic\n161     for i, seq in enumerate(bases_mro):\n162         if i == position_in_inferred_bases:\n163             continue\n164         if any(base.qname() == \"typing.Generic\" for base in seq):\n165             break\n166     else:\n167         return\n168     # Found multiple Generics in mro, remove entry from inferred_bases\n169     # and the corresponding one from bases_mro\n170     inferred_bases.pop(position_in_inferred_bases)\n171     bases_mro.pop(position_in_inferred_bases)\n172 \n173 \n174 def clean_duplicates_mro(sequences, cls, context):\n175     for sequence in sequences:\n176         names = [\n177             (node.lineno, node.qname()) if node.name else None for node in sequence\n178         ]\n179         last_index = dict(map(reversed, enumerate(names)))\n180         if names and names[0] is not None and last_index[names[0]] != 0:\n181             raise DuplicateBasesError(\n182                 message=\"Duplicates found in MROs {mros} for {cls!r}.\",\n183                 mros=sequences,\n184                 cls=cls,\n185                 context=context,\n186             )\n187         yield [\n188             node\n189             for i, (node, name) in enumerate(zip(sequence, names))\n190             if name is None or last_index[name] == i\n191         ]\n192 \n193 \n194 def function_to_method(n, klass):\n195     if isinstance(n, FunctionDef):\n196         if n.type == \"classmethod\":\n197             return bases.BoundMethod(n, klass)\n198         if n.type == \"property\":\n199             return n\n200         if n.type != \"staticmethod\":\n201             return bases.UnboundMethod(n)\n202     return n\n203 \n204 \n205 def builtin_lookup(name):\n206     \"\"\"lookup a name into the builtin module\n207     return the list of matching statements and the astroid for the builtin\n208     module\n209     \"\"\"\n210     builtin_astroid = AstroidManager().ast_from_module(builtins)\n211     if name == \"__dict__\":\n212         return builtin_astroid, ()\n213     try:\n214         stmts = builtin_astroid.locals[name]\n215     except KeyError:\n216         stmts = ()\n217     return builtin_astroid, stmts\n218 \n219 \n220 # TODO move this Mixin to mixins.py; problem: 'FunctionDef' in _scope_lookup\n221 class LocalsDictNodeNG(node_classes.LookupMixIn, node_classes.NodeNG):\n222     \"\"\"this class provides locals handling common to Module, FunctionDef\n223     and ClassDef nodes, including a dict like interface for direct access\n224     to locals information\n225     \"\"\"\n226 \n227     # attributes below are set by the builder module or by raw factories\n228 \n229     locals = {}\n230     \"\"\"A map of the name of a local variable to the node defining the local.\n231 \n232     :type: dict(str, NodeNG)\n233     \"\"\"\n234 \n235     def qname(self):\n236         \"\"\"Get the 'qualified' name of the node.\n237 \n238         For example: module.name, module.class.name ...\n239 \n240         :returns: The qualified name.\n241         :rtype: str\n242         \"\"\"\n243         # pylint: disable=no-member; github.com/pycqa/astroid/issues/278\n244         if self.parent is None:\n245             return self.name\n246         return f\"{self.parent.frame().qname()}.{self.name}\"\n247 \n248     def scope(self: T) -> T:\n249         \"\"\"The first parent node defining a new scope.\n250 \n251         :returns: The first parent scope node.\n252         :rtype: Module or FunctionDef or ClassDef or Lambda or GenExpr\n253         \"\"\"\n254         return self\n255 \n256     def _scope_lookup(self, node, name, offset=0):\n257         \"\"\"XXX method for interfacing the scope lookup\"\"\"\n258         try:\n259             stmts = node._filter_stmts(self.locals[name], self, offset)\n260         except KeyError:\n261             stmts = ()\n262         if stmts:\n263             return self, stmts\n264 \n265         # Handle nested scopes: since class names do not extend to nested\n266         # scopes (e.g., methods), we find the next enclosing non-class scope\n267         pscope = self.parent and self.parent.scope()\n268         while pscope is not None:\n269             if not isinstance(pscope, ClassDef):\n270                 return pscope.scope_lookup(node, name)\n271             pscope = pscope.parent and pscope.parent.scope()\n272 \n273         # self is at the top level of a module, or is enclosed only by ClassDefs\n274         return builtin_lookup(name)\n275 \n276     def set_local(self, name, stmt):\n277         \"\"\"Define that the given name is declared in the given statement node.\n278 \n279         .. seealso:: :meth:`scope`\n280 \n281         :param name: The name that is being defined.\n282         :type name: str\n283 \n284         :param stmt: The statement that defines the given name.\n285         :type stmt: NodeNG\n286         \"\"\"\n287         # assert not stmt in self.locals.get(name, ()), (self, stmt)\n288         self.locals.setdefault(name, []).append(stmt)\n289 \n290     __setitem__ = set_local\n291 \n292     def _append_node(self, child):\n293         \"\"\"append a child, linking it in the tree\"\"\"\n294         # pylint: disable=no-member; depending by the class\n295         # which uses the current class as a mixin or base class.\n296         # It's rewritten in 2.0, so it makes no sense for now\n297         # to spend development time on it.\n298         self.body.append(child)\n299         child.parent = self\n300 \n301     def add_local_node(self, child_node, name=None):\n302         \"\"\"Append a child that should alter the locals of this scope node.\n303 \n304         :param child_node: The child node that will alter locals.\n305         :type child_node: NodeNG\n306 \n307         :param name: The name of the local that will be altered by\n308             the given child node.\n309         :type name: str or None\n310         \"\"\"\n311         if name != \"__class__\":\n312             # add __class__ node as a child will cause infinite recursion later!\n313             self._append_node(child_node)\n314         self.set_local(name or child_node.name, child_node)\n315 \n316     def __getitem__(self, item):\n317         \"\"\"The first node the defines the given local.\n318 \n319         :param item: The name of the locally defined object.\n320         :type item: str\n321 \n322         :raises KeyError: If the name is not defined.\n323         \"\"\"\n324         return self.locals[item][0]\n325 \n326     def __iter__(self):\n327         \"\"\"Iterate over the names of locals defined in this scoped node.\n328 \n329         :returns: The names of the defined locals.\n330         :rtype: iterable(str)\n331         \"\"\"\n332         return iter(self.keys())\n333 \n334     def keys(self):\n335         \"\"\"The names of locals defined in this scoped node.\n336 \n337         :returns: The names of the defined locals.\n338         :rtype: list(str)\n339         \"\"\"\n340         return list(self.locals.keys())\n341 \n342     def values(self):\n343         \"\"\"The nodes that define the locals in this scoped node.\n344 \n345         :returns: The nodes that define locals.\n346         :rtype: list(NodeNG)\n347         \"\"\"\n348         # pylint: disable=consider-using-dict-items\n349         # It look like this class override items/keys/values,\n350         # probably not worth the headache\n351         return [self[key] for key in self.keys()]\n352 \n353     def items(self):\n354         \"\"\"Get the names of the locals and the node that defines the local.\n355 \n356         :returns: The names of locals and their associated node.\n357         :rtype: list(tuple(str, NodeNG))\n358         \"\"\"\n359         return list(zip(self.keys(), self.values()))\n360 \n361     def __contains__(self, name):\n362         \"\"\"Check if a local is defined in this scope.\n363 \n364         :param name: The name of the local to check for.\n365         :type name: str\n366 \n367         :returns: True if this node has a local of the given name,\n368             False otherwise.\n369         :rtype: bool\n370         \"\"\"\n371         return name in self.locals\n372 \n373 \n374 class Module(LocalsDictNodeNG):\n375     \"\"\"Class representing an :class:`ast.Module` node.\n376 \n377     >>> import astroid\n378     >>> node = astroid.extract_node('import astroid')\n379     >>> node\n380     <Import l.1 at 0x7f23b2e4e5c0>\n381     >>> node.parent\n382     <Module l.0 at 0x7f23b2e4eda0>\n383     \"\"\"\n384 \n385     _astroid_fields = (\"body\",)\n386 \n387     fromlineno = 0\n388     \"\"\"The first line that this node appears on in the source code.\n389 \n390     :type: int or None\n391     \"\"\"\n392     lineno = 0\n393     \"\"\"The line that this node appears on in the source code.\n394 \n395     :type: int or None\n396     \"\"\"\n397 \n398     # attributes below are set by the builder module or by raw factories\n399 \n400     file = None\n401     \"\"\"The path to the file that this ast has been extracted from.\n402 \n403     This will be ``None`` when the representation has been built from a\n404     built-in module.\n405 \n406     :type: str or None\n407     \"\"\"\n408     file_bytes = None\n409     \"\"\"The string/bytes that this ast was built from.\n410 \n411     :type: str or bytes or None\n412     \"\"\"\n413     file_encoding = None\n414     \"\"\"The encoding of the source file.\n415 \n416     This is used to get unicode out of a source file.\n417     Python 2 only.\n418 \n419     :type: str or None\n420     \"\"\"\n421     name = None\n422     \"\"\"The name of the module.\n423 \n424     :type: str or None\n425     \"\"\"\n426     pure_python = None\n427     \"\"\"Whether the ast was built from source.\n428 \n429     :type: bool or None\n430     \"\"\"\n431     package = None\n432     \"\"\"Whether the node represents a package or a module.\n433 \n434     :type: bool or None\n435     \"\"\"\n436     globals = None\n437     \"\"\"A map of the name of a global variable to the node defining the global.\n438 \n439     :type: dict(str, NodeNG)\n440     \"\"\"\n441 \n442     # Future imports\n443     future_imports = None\n444     \"\"\"The imports from ``__future__``.\n445 \n446     :type: set(str) or None\n447     \"\"\"\n448     special_attributes = ModuleModel()\n449     \"\"\"The names of special attributes that this module has.\n450 \n451     :type: objectmodel.ModuleModel\n452     \"\"\"\n453 \n454     # names of module attributes available through the global scope\n455     scope_attrs = {\"__name__\", \"__doc__\", \"__file__\", \"__path__\", \"__package__\"}\n456     \"\"\"The names of module attributes available through the global scope.\n457 \n458     :type: str(str)\n459     \"\"\"\n460 \n461     _other_fields = (\n462         \"name\",\n463         \"doc\",\n464         \"file\",\n465         \"path\",\n466         \"package\",\n467         \"pure_python\",\n468         \"future_imports\",\n469     )\n470     _other_other_fields = (\"locals\", \"globals\")\n471 \n472     lineno: None\n473     col_offset: None\n474     end_lineno: None\n475     end_col_offset: None\n476     parent: None\n477 \n478     def __init__(\n479         self,\n480         name,\n481         doc,\n482         file=None,\n483         path: Optional[List[str]] = None,\n484         package=None,\n485         parent=None,\n486         pure_python=True,\n487     ):\n488         \"\"\"\n489         :param name: The name of the module.\n490         :type name: str\n491 \n492         :param doc: The module docstring.\n493         :type doc: str\n494 \n495         :param file: The path to the file that this ast has been extracted from.\n496         :type file: str or None\n497 \n498         :param path:\n499         :type path: Optional[List[str]]\n500 \n501         :param package: Whether the node represents a package or a module.\n502         :type package: bool or None\n503 \n504         :param parent: The parent node in the syntax tree.\n505         :type parent: NodeNG or None\n506 \n507         :param pure_python: Whether the ast was built from source.\n508         :type pure_python: bool or None\n509         \"\"\"\n510         self.name = name\n511         self.doc = doc\n512         self.file = file\n513         self.path = path\n514         self.package = package\n515         self.parent = parent\n516         self.pure_python = pure_python\n517         self.locals = self.globals = {}\n518         \"\"\"A map of the name of a local variable to the node defining the local.\n519 \n520         :type: dict(str, NodeNG)\n521         \"\"\"\n522         self.body = []\n523         \"\"\"The contents of the module.\n524 \n525         :type: list(NodeNG) or None\n526         \"\"\"\n527         self.future_imports = set()\n528 \n529     # pylint: enable=redefined-builtin\n530 \n531     def postinit(self, body=None):\n532         \"\"\"Do some setup after initialisation.\n533 \n534         :param body: The contents of the module.\n535         :type body: list(NodeNG) or None\n536         \"\"\"\n537         self.body = body\n538 \n539     def _get_stream(self):\n540         if self.file_bytes is not None:\n541             return io.BytesIO(self.file_bytes)\n542         if self.file is not None:\n543             # pylint: disable=consider-using-with\n544             stream = open(self.file, \"rb\")\n545             return stream\n546         return None\n547 \n548     def stream(self):\n549         \"\"\"Get a stream to the underlying file or bytes.\n550 \n551         :type: file or io.BytesIO or None\n552         \"\"\"\n553         return self._get_stream()\n554 \n555     def block_range(self, lineno):\n556         \"\"\"Get a range from where this node starts to where this node ends.\n557 \n558         :param lineno: Unused.\n559         :type lineno: int\n560 \n561         :returns: The range of line numbers that this node belongs to.\n562         :rtype: tuple(int, int)\n563         \"\"\"\n564         return self.fromlineno, self.tolineno\n565 \n566     def scope_lookup(self, node, name, offset=0):\n567         \"\"\"Lookup where the given variable is assigned.\n568 \n569         :param node: The node to look for assignments up to.\n570             Any assignments after the given node are ignored.\n571         :type node: NodeNG\n572 \n573         :param name: The name of the variable to find assignments for.\n574         :type name: str\n575 \n576         :param offset: The line offset to filter statements up to.\n577         :type offset: int\n578 \n579         :returns: This scope node and the list of assignments associated to the\n580             given name according to the scope where it has been found (locals,\n581             globals or builtin).\n582         :rtype: tuple(str, list(NodeNG))\n583         \"\"\"\n584         if name in self.scope_attrs and name not in self.locals:\n585             try:\n586                 return self, self.getattr(name)\n587             except AttributeInferenceError:\n588                 return self, ()\n589         return self._scope_lookup(node, name, offset)\n590 \n591     def pytype(self):\n592         \"\"\"Get the name of the type that this node represents.\n593 \n594         :returns: The name of the type.\n595         :rtype: str\n596         \"\"\"\n597         return \"builtins.module\"\n598 \n599     def display_type(self):\n600         \"\"\"A human readable type of this node.\n601 \n602         :returns: The type of this node.\n603         :rtype: str\n604         \"\"\"\n605         return \"Module\"\n606 \n607     def getattr(self, name, context=None, ignore_locals=False):\n608         if not name:\n609             raise AttributeInferenceError(target=self, attribute=name, context=context)\n610 \n611         result = []\n612         name_in_locals = name in self.locals\n613 \n614         if name in self.special_attributes and not ignore_locals and not name_in_locals:\n615             result = [self.special_attributes.lookup(name)]\n616         elif not ignore_locals and name_in_locals:\n617             result = self.locals[name]\n618         elif self.package:\n619             try:\n620                 result = [self.import_module(name, relative_only=True)]\n621             except (AstroidBuildingError, SyntaxError) as exc:\n622                 raise AttributeInferenceError(\n623                     target=self, attribute=name, context=context\n624                 ) from exc\n625         result = [n for n in result if not isinstance(n, node_classes.DelName)]\n626         if result:\n627             return result\n628         raise AttributeInferenceError(target=self, attribute=name, context=context)\n629 \n630     def igetattr(self, name, context=None):\n631         \"\"\"Infer the possible values of the given variable.\n632 \n633         :param name: The name of the variable to infer.\n634         :type name: str\n635 \n636         :returns: The inferred possible values.\n637         :rtype: iterable(NodeNG) or None\n638         \"\"\"\n639         # set lookup name since this is necessary to infer on import nodes for\n640         # instance\n641         context = copy_context(context)\n642         context.lookupname = name\n643         try:\n644             return bases._infer_stmts(self.getattr(name, context), context, frame=self)\n645         except AttributeInferenceError as error:\n646             raise InferenceError(\n647                 str(error), target=self, attribute=name, context=context\n648             ) from error\n649 \n650     def fully_defined(self):\n651         \"\"\"Check if this module has been build from a .py file.\n652 \n653         If so, the module contains a complete representation,\n654         including the code.\n655 \n656         :returns: True if the module has been built from a .py file.\n657         :rtype: bool\n658         \"\"\"\n659         return self.file is not None and self.file.endswith(\".py\")\n660 \n661     @overload\n662     def statement(self, *, future: Literal[None] = ...) -> \"Module\":\n663         ...\n664 \n665     @overload\n666     def statement(self, *, future: Literal[True]) -> NoReturn:\n667         ...\n668 \n669     def statement(\n670         self, *, future: Literal[None, True] = None\n671     ) -> Union[\"NoReturn\", \"Module\"]:\n672         \"\"\"The first parent node, including self, marked as statement node.\n673 \n674         When called on a :class:`Module` with the future parameter this raises an error.\n675 \n676         TODO: Deprecate the future parameter and only raise StatementMissing\n677 \n678         :raises StatementMissing: If no self has no parent attribute and future is True\n679         \"\"\"\n680         if future:\n681             raise StatementMissing(target=self)\n682         warnings.warn(\n683             \"In astroid 3.0.0 NodeNG.statement() will return either a nodes.Statement \"\n684             \"or raise a StatementMissing exception. nodes.Module will no longer be \"\n685             \"considered a statement. This behaviour can already be triggered \"\n686             \"by passing 'future=True' to a statement() call.\",\n687             DeprecationWarning,\n688         )\n689         return self\n690 \n691     def previous_sibling(self):\n692         \"\"\"The previous sibling statement.\n693 \n694         :returns: The previous sibling statement node.\n695         :rtype: NodeNG or None\n696         \"\"\"\n697 \n698     def next_sibling(self):\n699         \"\"\"The next sibling statement node.\n700 \n701         :returns: The next sibling statement node.\n702         :rtype: NodeNG or None\n703         \"\"\"\n704 \n705     _absolute_import_activated = True\n706 \n707     def absolute_import_activated(self):\n708         \"\"\"Whether :pep:`328` absolute import behaviour has been enabled.\n709 \n710         :returns: True if :pep:`328` has been enabled, False otherwise.\n711         :rtype: bool\n712         \"\"\"\n713         return self._absolute_import_activated\n714 \n715     def import_module(self, modname, relative_only=False, level=None):\n716         \"\"\"Get the ast for a given module as if imported from this module.\n717 \n718         :param modname: The name of the module to \"import\".\n719         :type modname: str\n720 \n721         :param relative_only: Whether to only consider relative imports.\n722         :type relative_only: bool\n723 \n724         :param level: The level of relative import.\n725         :type level: int or None\n726 \n727         :returns: The imported module ast.\n728         :rtype: NodeNG\n729         \"\"\"\n730         if relative_only and level is None:\n731             level = 0\n732         absmodname = self.relative_to_absolute_name(modname, level)\n733 \n734         try:\n735             return AstroidManager().ast_from_module_name(absmodname)\n736         except AstroidBuildingError:\n737             # we only want to import a sub module or package of this module,\n738             # skip here\n739             if relative_only:\n740                 raise\n741         return AstroidManager().ast_from_module_name(modname)\n742 \n743     def relative_to_absolute_name(self, modname: str, level: int) -> str:\n744         \"\"\"Get the absolute module name for a relative import.\n745 \n746         The relative import can be implicit or explicit.\n747 \n748         :param modname: The module name to convert.\n749 \n750         :param level: The level of relative import.\n751 \n752         :returns: The absolute module name.\n753 \n754         :raises TooManyLevelsError: When the relative import refers to a\n755             module too far above this one.\n756         \"\"\"\n757         # XXX this returns non sens when called on an absolute import\n758         # like 'pylint.checkers.astroid.utils'\n759         # XXX doesn't return absolute name if self.name isn't absolute name\n760         if self.absolute_import_activated() and level is None:\n761             return modname\n762         if level:\n763             if self.package:\n764                 level = level - 1\n765                 package_name = self.name.rsplit(\".\", level)[0]\n766             elif (\n767                 self.path\n768                 and not os.path.exists(os.path.dirname(self.path[0]) + \"/__init__.py\")\n769                 and os.path.exists(\n770                     os.path.dirname(self.path[0]) + \"/\" + modname.split(\".\")[0]\n771                 )\n772             ):\n773                 level = level - 1\n774                 package_name = \"\"\n775             else:\n776                 package_name = self.name.rsplit(\".\", level)[0]\n777             if level and self.name.count(\".\") < level:\n778                 raise TooManyLevelsError(level=level, name=self.name)\n779 \n780         elif self.package:\n781             package_name = self.name\n782         else:\n783             package_name = self.name.rsplit(\".\", 1)[0]\n784 \n785         if package_name:\n786             if not modname:\n787                 return package_name\n788             return f\"{package_name}.{modname}\"\n789         return modname\n790 \n791     def wildcard_import_names(self):\n792         \"\"\"The list of imported names when this module is 'wildcard imported'.\n793 \n794         It doesn't include the '__builtins__' name which is added by the\n795         current CPython implementation of wildcard imports.\n796 \n797         :returns: The list of imported names.\n798         :rtype: list(str)\n799         \"\"\"\n800         # We separate the different steps of lookup in try/excepts\n801         # to avoid catching too many Exceptions\n802         default = [name for name in self.keys() if not name.startswith(\"_\")]\n803         try:\n804             all_values = self[\"__all__\"]\n805         except KeyError:\n806             return default\n807 \n808         try:\n809             explicit = next(all_values.assigned_stmts())\n810         except (InferenceError, StopIteration):\n811             return default\n812         except AttributeError:\n813             # not an assignment node\n814             # XXX infer?\n815             return default\n816 \n817         # Try our best to detect the exported name.\n818         inferred = []\n819         try:\n820             explicit = next(explicit.infer())\n821         except (InferenceError, StopIteration):\n822             return default\n823         if not isinstance(explicit, (node_classes.Tuple, node_classes.List)):\n824             return default\n825 \n826         def str_const(node):\n827             return isinstance(node, node_classes.Const) and isinstance(node.value, str)\n828 \n829         for node in explicit.elts:\n830             if str_const(node):\n831                 inferred.append(node.value)\n832             else:\n833                 try:\n834                     inferred_node = next(node.infer())\n835                 except (InferenceError, StopIteration):\n836                     continue\n837                 if str_const(inferred_node):\n838                     inferred.append(inferred_node.value)\n839         return inferred\n840 \n841     def public_names(self):\n842         \"\"\"The list of the names that are publicly available in this module.\n843 \n844         :returns: The list of public names.\n845         :rtype: list(str)\n846         \"\"\"\n847         return [name for name in self.keys() if not name.startswith(\"_\")]\n848 \n849     def bool_value(self, context=None):\n850         \"\"\"Determine the boolean value of this node.\n851 \n852         :returns: The boolean value of this node.\n853             For a :class:`Module` this is always ``True``.\n854         :rtype: bool\n855         \"\"\"\n856         return True\n857 \n858     def get_children(self):\n859         yield from self.body\n860 \n861     def frame(self: T) -> T:\n862         \"\"\"The node's frame node.\n863 \n864         A frame node is a :class:`Module`, :class:`FunctionDef`,\n865         :class:`ClassDef` or :class:`Lambda`.\n866 \n867         :returns: The node itself.\n868         \"\"\"\n869         return self\n870 \n871 \n872 class ComprehensionScope(LocalsDictNodeNG):\n873     \"\"\"Scoping for different types of comprehensions.\"\"\"\n874 \n875     scope_lookup = LocalsDictNodeNG._scope_lookup\n876 \n877 \n878 class GeneratorExp(ComprehensionScope):\n879     \"\"\"Class representing an :class:`ast.GeneratorExp` node.\n880 \n881     >>> import astroid\n882     >>> node = astroid.extract_node('(thing for thing in things if thing)')\n883     >>> node\n884     <GeneratorExp l.1 at 0x7f23b2e4e400>\n885     \"\"\"\n886 \n887     _astroid_fields = (\"elt\", \"generators\")\n888     _other_other_fields = (\"locals\",)\n889     elt = None\n890     \"\"\"The element that forms the output of the expression.\n891 \n892     :type: NodeNG or None\n893     \"\"\"\n894     generators = None\n895     \"\"\"The generators that are looped through.\n896 \n897     :type: list(Comprehension) or None\n898     \"\"\"\n899 \n900     def __init__(\n901         self,\n902         lineno=None,\n903         col_offset=None,\n904         parent=None,\n905         *,\n906         end_lineno=None,\n907         end_col_offset=None,\n908     ):\n909         \"\"\"\n910         :param lineno: The line that this node appears on in the source code.\n911         :type lineno: int or None\n912 \n913         :param col_offset: The column that this node appears on in the\n914             source code.\n915         :type col_offset: int or None\n916 \n917         :param parent: The parent node in the syntax tree.\n918         :type parent: NodeNG or None\n919 \n920         :param end_lineno: The last line this node appears on in the source code.\n921         :type end_lineno: Optional[int]\n922 \n923         :param end_col_offset: The end column this node appears on in the\n924             source code. Note: This is after the last symbol.\n925         :type end_col_offset: Optional[int]\n926         \"\"\"\n927         self.locals = {}\n928         \"\"\"A map of the name of a local variable to the node defining the local.\n929 \n930         :type: dict(str, NodeNG)\n931         \"\"\"\n932 \n933         super().__init__(\n934             lineno=lineno,\n935             col_offset=col_offset,\n936             end_lineno=end_lineno,\n937             end_col_offset=end_col_offset,\n938             parent=parent,\n939         )\n940 \n941     def postinit(self, elt=None, generators=None):\n942         \"\"\"Do some setup after initialisation.\n943 \n944         :param elt: The element that forms the output of the expression.\n945         :type elt: NodeNG or None\n946 \n947         :param generators: The generators that are looped through.\n948         :type generators: list(Comprehension) or None\n949         \"\"\"\n950         self.elt = elt\n951         if generators is None:\n952             self.generators = []\n953         else:\n954             self.generators = generators\n955 \n956     def bool_value(self, context=None):\n957         \"\"\"Determine the boolean value of this node.\n958 \n959         :returns: The boolean value of this node.\n960             For a :class:`GeneratorExp` this is always ``True``.\n961         :rtype: bool\n962         \"\"\"\n963         return True\n964 \n965     def get_children(self):\n966         yield self.elt\n967 \n968         yield from self.generators\n969 \n970 \n971 class DictComp(ComprehensionScope):\n972     \"\"\"Class representing an :class:`ast.DictComp` node.\n973 \n974     >>> import astroid\n975     >>> node = astroid.extract_node('{k:v for k, v in things if k > v}')\n976     >>> node\n977     <DictComp l.1 at 0x7f23b2e41d68>\n978     \"\"\"\n979 \n980     _astroid_fields = (\"key\", \"value\", \"generators\")\n981     _other_other_fields = (\"locals\",)\n982     key = None\n983     \"\"\"What produces the keys.\n984 \n985     :type: NodeNG or None\n986     \"\"\"\n987     value = None\n988     \"\"\"What produces the values.\n989 \n990     :type: NodeNG or None\n991     \"\"\"\n992     generators = None\n993     \"\"\"The generators that are looped through.\n994 \n995     :type: list(Comprehension) or None\n996     \"\"\"\n997 \n998     def __init__(\n999         self,\n1000         lineno=None,\n1001         col_offset=None,\n1002         parent=None,\n1003         *,\n1004         end_lineno=None,\n1005         end_col_offset=None,\n1006     ):\n1007         \"\"\"\n1008         :param lineno: The line that this node appears on in the source code.\n1009         :type lineno: int or None\n1010 \n1011         :param col_offset: The column that this node appears on in the\n1012             source code.\n1013         :type col_offset: int or None\n1014 \n1015         :param parent: The parent node in the syntax tree.\n1016         :type parent: NodeNG or None\n1017 \n1018         :param end_lineno: The last line this node appears on in the source code.\n1019         :type end_lineno: Optional[int]\n1020 \n1021         :param end_col_offset: The end column this node appears on in the\n1022             source code. Note: This is after the last symbol.\n1023         :type end_col_offset: Optional[int]\n1024         \"\"\"\n1025         self.locals = {}\n1026         \"\"\"A map of the name of a local variable to the node defining the local.\n1027 \n1028         :type: dict(str, NodeNG)\n1029         \"\"\"\n1030 \n1031         super().__init__(\n1032             lineno=lineno,\n1033             col_offset=col_offset,\n1034             end_lineno=end_lineno,\n1035             end_col_offset=end_col_offset,\n1036             parent=parent,\n1037         )\n1038 \n1039     def postinit(self, key=None, value=None, generators=None):\n1040         \"\"\"Do some setup after initialisation.\n1041 \n1042         :param key: What produces the keys.\n1043         :type key: NodeNG or None\n1044 \n1045         :param value: What produces the values.\n1046         :type value: NodeNG or None\n1047 \n1048         :param generators: The generators that are looped through.\n1049         :type generators: list(Comprehension) or None\n1050         \"\"\"\n1051         self.key = key\n1052         self.value = value\n1053         if generators is None:\n1054             self.generators = []\n1055         else:\n1056             self.generators = generators\n1057 \n1058     def bool_value(self, context=None):\n1059         \"\"\"Determine the boolean value of this node.\n1060 \n1061         :returns: The boolean value of this node.\n1062             For a :class:`DictComp` this is always :class:`Uninferable`.\n1063         :rtype: Uninferable\n1064         \"\"\"\n1065         return util.Uninferable\n1066 \n1067     def get_children(self):\n1068         yield self.key\n1069         yield self.value\n1070 \n1071         yield from self.generators\n1072 \n1073 \n1074 class SetComp(ComprehensionScope):\n1075     \"\"\"Class representing an :class:`ast.SetComp` node.\n1076 \n1077     >>> import astroid\n1078     >>> node = astroid.extract_node('{thing for thing in things if thing}')\n1079     >>> node\n1080     <SetComp l.1 at 0x7f23b2e41898>\n1081     \"\"\"\n1082 \n1083     _astroid_fields = (\"elt\", \"generators\")\n1084     _other_other_fields = (\"locals\",)\n1085     elt = None\n1086     \"\"\"The element that forms the output of the expression.\n1087 \n1088     :type: NodeNG or None\n1089     \"\"\"\n1090     generators = None\n1091     \"\"\"The generators that are looped through.\n1092 \n1093     :type: list(Comprehension) or None\n1094     \"\"\"\n1095 \n1096     def __init__(\n1097         self,\n1098         lineno=None,\n1099         col_offset=None,\n1100         parent=None,\n1101         *,\n1102         end_lineno=None,\n1103         end_col_offset=None,\n1104     ):\n1105         \"\"\"\n1106         :param lineno: The line that this node appears on in the source code.\n1107         :type lineno: int or None\n1108 \n1109         :param col_offset: The column that this node appears on in the\n1110             source code.\n1111         :type col_offset: int or None\n1112 \n1113         :param parent: The parent node in the syntax tree.\n1114         :type parent: NodeNG or None\n1115 \n1116         :param end_lineno: The last line this node appears on in the source code.\n1117         :type end_lineno: Optional[int]\n1118 \n1119         :param end_col_offset: The end column this node appears on in the\n1120             source code. Note: This is after the last symbol.\n1121         :type end_col_offset: Optional[int]\n1122         \"\"\"\n1123         self.locals = {}\n1124         \"\"\"A map of the name of a local variable to the node defining the local.\n1125 \n1126         :type: dict(str, NodeNG)\n1127         \"\"\"\n1128 \n1129         super().__init__(\n1130             lineno=lineno,\n1131             col_offset=col_offset,\n1132             end_lineno=end_lineno,\n1133             end_col_offset=end_col_offset,\n1134             parent=parent,\n1135         )\n1136 \n1137     def postinit(self, elt=None, generators=None):\n1138         \"\"\"Do some setup after initialisation.\n1139 \n1140         :param elt: The element that forms the output of the expression.\n1141         :type elt: NodeNG or None\n1142 \n1143         :param generators: The generators that are looped through.\n1144         :type generators: list(Comprehension) or None\n1145         \"\"\"\n1146         self.elt = elt\n1147         if generators is None:\n1148             self.generators = []\n1149         else:\n1150             self.generators = generators\n1151 \n1152     def bool_value(self, context=None):\n1153         \"\"\"Determine the boolean value of this node.\n1154 \n1155         :returns: The boolean value of this node.\n1156             For a :class:`SetComp` this is always :class:`Uninferable`.\n1157         :rtype: Uninferable\n1158         \"\"\"\n1159         return util.Uninferable\n1160 \n1161     def get_children(self):\n1162         yield self.elt\n1163 \n1164         yield from self.generators\n1165 \n1166 \n1167 class _ListComp(node_classes.NodeNG):\n1168     \"\"\"Class representing an :class:`ast.ListComp` node.\n1169 \n1170     >>> import astroid\n1171     >>> node = astroid.extract_node('[thing for thing in things if thing]')\n1172     >>> node\n1173     <ListComp l.1 at 0x7f23b2e418d0>\n1174     \"\"\"\n1175 \n1176     _astroid_fields = (\"elt\", \"generators\")\n1177     elt = None\n1178     \"\"\"The element that forms the output of the expression.\n1179 \n1180     :type: NodeNG or None\n1181     \"\"\"\n1182     generators = None\n1183     \"\"\"The generators that are looped through.\n1184 \n1185     :type: list(Comprehension) or None\n1186     \"\"\"\n1187 \n1188     def postinit(self, elt=None, generators=None):\n1189         \"\"\"Do some setup after initialisation.\n1190 \n1191         :param elt: The element that forms the output of the expression.\n1192         :type elt: NodeNG or None\n1193 \n1194         :param generators: The generators that are looped through.\n1195         :type generators: list(Comprehension) or None\n1196         \"\"\"\n1197         self.elt = elt\n1198         self.generators = generators\n1199 \n1200     def bool_value(self, context=None):\n1201         \"\"\"Determine the boolean value of this node.\n1202 \n1203         :returns: The boolean value of this node.\n1204             For a :class:`ListComp` this is always :class:`Uninferable`.\n1205         :rtype: Uninferable\n1206         \"\"\"\n1207         return util.Uninferable\n1208 \n1209     def get_children(self):\n1210         yield self.elt\n1211 \n1212         yield from self.generators\n1213 \n1214 \n1215 class ListComp(_ListComp, ComprehensionScope):\n1216     \"\"\"Class representing an :class:`ast.ListComp` node.\n1217 \n1218     >>> import astroid\n1219     >>> node = astroid.extract_node('[thing for thing in things if thing]')\n1220     >>> node\n1221     <ListComp l.1 at 0x7f23b2e418d0>\n1222     \"\"\"\n1223 \n1224     _other_other_fields = (\"locals\",)\n1225 \n1226     def __init__(\n1227         self,\n1228         lineno=None,\n1229         col_offset=None,\n1230         parent=None,\n1231         *,\n1232         end_lineno=None,\n1233         end_col_offset=None,\n1234     ):\n1235         self.locals = {}\n1236         \"\"\"A map of the name of a local variable to the node defining it.\n1237 \n1238         :type: dict(str, NodeNG)\n1239         \"\"\"\n1240 \n1241         super().__init__(\n1242             lineno=lineno,\n1243             col_offset=col_offset,\n1244             end_lineno=end_lineno,\n1245             end_col_offset=end_col_offset,\n1246             parent=parent,\n1247         )\n1248 \n1249 \n1250 def _infer_decorator_callchain(node):\n1251     \"\"\"Detect decorator call chaining and see if the end result is a\n1252     static or a classmethod.\n1253     \"\"\"\n1254     if not isinstance(node, FunctionDef):\n1255         return None\n1256     if not node.parent:\n1257         return None\n1258     try:\n1259         result = next(node.infer_call_result(node.parent), None)\n1260     except InferenceError:\n1261         return None\n1262     if isinstance(result, bases.Instance):\n1263         result = result._proxied\n1264     if isinstance(result, ClassDef):\n1265         if result.is_subtype_of(\"builtins.classmethod\"):\n1266             return \"classmethod\"\n1267         if result.is_subtype_of(\"builtins.staticmethod\"):\n1268             return \"staticmethod\"\n1269     if isinstance(result, FunctionDef):\n1270         if not result.decorators:\n1271             return None\n1272         # Determine if this function is decorated with one of the builtin descriptors we want.\n1273         for decorator in result.decorators.nodes:\n1274             if isinstance(decorator, node_classes.Name):\n1275                 if decorator.name in BUILTIN_DESCRIPTORS:\n1276                     return decorator.name\n1277             if (\n1278                 isinstance(decorator, node_classes.Attribute)\n1279                 and isinstance(decorator.expr, node_classes.Name)\n1280                 and decorator.expr.name == \"builtins\"\n1281                 and decorator.attrname in BUILTIN_DESCRIPTORS\n1282             ):\n1283                 return decorator.attrname\n1284     return None\n1285 \n1286 \n1287 class Lambda(mixins.FilterStmtsMixin, LocalsDictNodeNG):\n1288     \"\"\"Class representing an :class:`ast.Lambda` node.\n1289 \n1290     >>> import astroid\n1291     >>> node = astroid.extract_node('lambda arg: arg + 1')\n1292     >>> node\n1293     <Lambda.<lambda> l.1 at 0x7f23b2e41518>\n1294     \"\"\"\n1295 \n1296     _astroid_fields = (\"args\", \"body\")\n1297     _other_other_fields = (\"locals\",)\n1298     name = \"<lambda>\"\n1299     is_lambda = True\n1300 \n1301     def implicit_parameters(self):\n1302         return 0\n1303 \n1304     # function's type, 'function' | 'method' | 'staticmethod' | 'classmethod'\n1305     @property\n1306     def type(self):\n1307         \"\"\"Whether this is a method or function.\n1308 \n1309         :returns: 'method' if this is a method, 'function' otherwise.\n1310         :rtype: str\n1311         \"\"\"\n1312         if self.args.arguments and self.args.arguments[0].name == \"self\":\n1313             if isinstance(self.parent.scope(), ClassDef):\n1314                 return \"method\"\n1315         return \"function\"\n1316 \n1317     def __init__(\n1318         self,\n1319         lineno=None,\n1320         col_offset=None,\n1321         parent=None,\n1322         *,\n1323         end_lineno=None,\n1324         end_col_offset=None,\n1325     ):\n1326         \"\"\"\n1327         :param lineno: The line that this node appears on in the source code.\n1328         :type lineno: int or None\n1329 \n1330         :param col_offset: The column that this node appears on in the\n1331             source code.\n1332         :type col_offset: int or None\n1333 \n1334         :param parent: The parent node in the syntax tree.\n1335         :type parent: NodeNG or None\n1336 \n1337         :param end_lineno: The last line this node appears on in the source code.\n1338         :type end_lineno: Optional[int]\n1339 \n1340         :param end_col_offset: The end column this node appears on in the\n1341             source code. Note: This is after the last symbol.\n1342         :type end_col_offset: Optional[int]\n1343         \"\"\"\n1344         self.locals = {}\n1345         \"\"\"A map of the name of a local variable to the node defining it.\n1346 \n1347         :type: dict(str, NodeNG)\n1348         \"\"\"\n1349 \n1350         self.args: Arguments\n1351         \"\"\"The arguments that the function takes.\"\"\"\n1352 \n1353         self.body = []\n1354         \"\"\"The contents of the function body.\n1355 \n1356         :type: list(NodeNG)\n1357         \"\"\"\n1358 \n1359         super().__init__(\n1360             lineno=lineno,\n1361             col_offset=col_offset,\n1362             end_lineno=end_lineno,\n1363             end_col_offset=end_col_offset,\n1364             parent=parent,\n1365         )\n1366 \n1367     def postinit(self, args: Arguments, body):\n1368         \"\"\"Do some setup after initialisation.\n1369 \n1370         :param args: The arguments that the function takes.\n1371 \n1372         :param body: The contents of the function body.\n1373         :type body: list(NodeNG)\n1374         \"\"\"\n1375         self.args = args\n1376         self.body = body\n1377 \n1378     def pytype(self):\n1379         \"\"\"Get the name of the type that this node represents.\n1380 \n1381         :returns: The name of the type.\n1382         :rtype: str\n1383         \"\"\"\n1384         if \"method\" in self.type:\n1385             return \"builtins.instancemethod\"\n1386         return \"builtins.function\"\n1387 \n1388     def display_type(self):\n1389         \"\"\"A human readable type of this node.\n1390 \n1391         :returns: The type of this node.\n1392         :rtype: str\n1393         \"\"\"\n1394         if \"method\" in self.type:\n1395             return \"Method\"\n1396         return \"Function\"\n1397 \n1398     def callable(self):\n1399         \"\"\"Whether this node defines something that is callable.\n1400 \n1401         :returns: True if this defines something that is callable,\n1402             False otherwise.\n1403             For a :class:`Lambda` this is always ``True``.\n1404         :rtype: bool\n1405         \"\"\"\n1406         return True\n1407 \n1408     def argnames(self):\n1409         \"\"\"Get the names of each of the arguments.\n1410 \n1411         :returns: The names of the arguments.\n1412         :rtype: list(str)\n1413         \"\"\"\n1414         if self.args.arguments:  # maybe None with builtin functions\n1415             names = _rec_get_names(self.args.arguments)\n1416         else:\n1417             names = []\n1418         if self.args.vararg:\n1419             names.append(self.args.vararg)\n1420         if self.args.kwarg:\n1421             names.append(self.args.kwarg)\n1422         return names\n1423 \n1424     def infer_call_result(self, caller, context=None):\n1425         \"\"\"Infer what the function returns when called.\n1426 \n1427         :param caller: Unused\n1428         :type caller: object\n1429         \"\"\"\n1430         # pylint: disable=no-member; github.com/pycqa/astroid/issues/291\n1431         # args is in fact redefined later on by postinit. Can't be changed\n1432         # to None due to a strong interaction between Lambda and FunctionDef.\n1433         return self.body.infer(context)\n1434 \n1435     def scope_lookup(self, node, name, offset=0):\n1436         \"\"\"Lookup where the given names is assigned.\n1437 \n1438         :param node: The node to look for assignments up to.\n1439             Any assignments after the given node are ignored.\n1440         :type node: NodeNG\n1441 \n1442         :param name: The name to find assignments for.\n1443         :type name: str\n1444 \n1445         :param offset: The line offset to filter statements up to.\n1446         :type offset: int\n1447 \n1448         :returns: This scope node and the list of assignments associated to the\n1449             given name according to the scope where it has been found (locals,\n1450             globals or builtin).\n1451         :rtype: tuple(str, list(NodeNG))\n1452         \"\"\"\n1453         if node in self.args.defaults or node in self.args.kw_defaults:\n1454             frame = self.parent.frame()\n1455             # line offset to avoid that def func(f=func) resolve the default\n1456             # value to the defined function\n1457             offset = -1\n1458         else:\n1459             # check this is not used in function decorators\n1460             frame = self\n1461         return frame._scope_lookup(node, name, offset)\n1462 \n1463     def bool_value(self, context=None):\n1464         \"\"\"Determine the boolean value of this node.\n1465 \n1466         :returns: The boolean value of this node.\n1467             For a :class:`Lambda` this is always ``True``.\n1468         :rtype: bool\n1469         \"\"\"\n1470         return True\n1471 \n1472     def get_children(self):\n1473         yield self.args\n1474         yield self.body\n1475 \n1476     def frame(self: T) -> T:\n1477         \"\"\"The node's frame node.\n1478 \n1479         A frame node is a :class:`Module`, :class:`FunctionDef`,\n1480         :class:`ClassDef` or :class:`Lambda`.\n1481 \n1482         :returns: The node itself.\n1483         \"\"\"\n1484         return self\n1485 \n1486 \n1487 class FunctionDef(mixins.MultiLineBlockMixin, node_classes.Statement, Lambda):\n1488     \"\"\"Class representing an :class:`ast.FunctionDef`.\n1489 \n1490     >>> import astroid\n1491     >>> node = astroid.extract_node('''\n1492     ... def my_func(arg):\n1493     ...     return arg + 1\n1494     ... ''')\n1495     >>> node\n1496     <FunctionDef.my_func l.2 at 0x7f23b2e71e10>\n1497     \"\"\"\n1498 \n1499     _astroid_fields = (\"decorators\", \"args\", \"returns\", \"body\")\n1500     _multi_line_block_fields = (\"body\",)\n1501     returns = None\n1502     decorators = None\n1503     \"\"\"The decorators that are applied to this method or function.\n1504 \n1505     :type: Decorators or None\n1506     \"\"\"\n1507     special_attributes = FunctionModel()\n1508     \"\"\"The names of special attributes that this function has.\n1509 \n1510     :type: objectmodel.FunctionModel\n1511     \"\"\"\n1512     is_function = True\n1513     \"\"\"Whether this node indicates a function.\n1514 \n1515     For a :class:`FunctionDef` this is always ``True``.\n1516 \n1517     :type: bool\n1518     \"\"\"\n1519     type_annotation = None\n1520     \"\"\"If present, this will contain the type annotation passed by a type comment\n1521 \n1522     :type: NodeNG or None\n1523     \"\"\"\n1524     type_comment_args = None\n1525     \"\"\"\n1526     If present, this will contain the type annotation for arguments\n1527     passed by a type comment\n1528     \"\"\"\n1529     type_comment_returns = None\n1530     \"\"\"If present, this will contain the return type annotation, passed by a type comment\"\"\"\n1531     # attributes below are set by the builder module or by raw factories\n1532     _other_fields = (\"name\", \"doc\")\n1533     _other_other_fields = (\n1534         \"locals\",\n1535         \"_type\",\n1536         \"type_comment_returns\",\n1537         \"type_comment_args\",\n1538     )\n1539     _type = None\n1540 \n1541     def __init__(\n1542         self,\n1543         name=None,\n1544         doc=None,\n1545         lineno=None,\n1546         col_offset=None,\n1547         parent=None,\n1548         *,\n1549         end_lineno=None,\n1550         end_col_offset=None,\n1551     ):\n1552         \"\"\"\n1553         :param name: The name of the function.\n1554         :type name: str or None\n1555 \n1556         :param doc: The function's docstring.\n1557         :type doc: str or None\n1558 \n1559         :param lineno: The line that this node appears on in the source code.\n1560         :type lineno: int or None\n1561 \n1562         :param col_offset: The column that this node appears on in the\n1563             source code.\n1564         :type col_offset: int or None\n1565 \n1566         :param parent: The parent node in the syntax tree.\n1567         :type parent: NodeNG or None\n1568 \n1569         :param end_lineno: The last line this node appears on in the source code.\n1570         :type end_lineno: Optional[int]\n1571 \n1572         :param end_col_offset: The end column this node appears on in the\n1573             source code. Note: This is after the last symbol.\n1574         :type end_col_offset: Optional[int]\n1575         \"\"\"\n1576         self.name = name\n1577         \"\"\"The name of the function.\n1578 \n1579         :type name: str or None\n1580         \"\"\"\n1581 \n1582         self.doc = doc\n1583         \"\"\"The function's docstring.\n1584 \n1585         :type doc: str or None\n1586         \"\"\"\n1587 \n1588         self.instance_attrs = {}\n1589         super().__init__(\n1590             lineno=lineno,\n1591             col_offset=col_offset,\n1592             end_lineno=end_lineno,\n1593             end_col_offset=end_col_offset,\n1594             parent=parent,\n1595         )\n1596         if parent:\n1597             frame = parent.frame()\n1598             frame.set_local(name, self)\n1599 \n1600     # pylint: disable=arguments-differ; different than Lambdas\n1601     def postinit(\n1602         self,\n1603         args: Arguments,\n1604         body,\n1605         decorators=None,\n1606         returns=None,\n1607         type_comment_returns=None,\n1608         type_comment_args=None,\n1609     ):\n1610         \"\"\"Do some setup after initialisation.\n1611 \n1612         :param args: The arguments that the function takes.\n1613 \n1614         :param body: The contents of the function body.\n1615         :type body: list(NodeNG)\n1616 \n1617         :param decorators: The decorators that are applied to this\n1618             method or function.\n1619         :type decorators: Decorators or None\n1620         :params type_comment_returns:\n1621             The return type annotation passed via a type comment.\n1622         :params type_comment_args:\n1623             The args type annotation passed via a type comment.\n1624         \"\"\"\n1625         self.args = args\n1626         self.body = body\n1627         self.decorators = decorators\n1628         self.returns = returns\n1629         self.type_comment_returns = type_comment_returns\n1630         self.type_comment_args = type_comment_args\n1631 \n1632     @decorators_mod.cachedproperty\n1633     def extra_decorators(self):\n1634         \"\"\"The extra decorators that this function can have.\n1635 \n1636         Additional decorators are considered when they are used as\n1637         assignments, as in ``method = staticmethod(method)``.\n1638         The property will return all the callables that are used for\n1639         decoration.\n1640 \n1641         :type: list(NodeNG)\n1642         \"\"\"\n1643         frame = self.parent.frame()\n1644         if not isinstance(frame, ClassDef):\n1645             return []\n1646 \n1647         decorators = []\n1648         for assign in frame._get_assign_nodes():\n1649             if isinstance(assign.value, node_classes.Call) and isinstance(\n1650                 assign.value.func, node_classes.Name\n1651             ):\n1652                 for assign_node in assign.targets:\n1653                     if not isinstance(assign_node, node_classes.AssignName):\n1654                         # Support only `name = callable(name)`\n1655                         continue\n1656 \n1657                     if assign_node.name != self.name:\n1658                         # Interested only in the assignment nodes that\n1659                         # decorates the current method.\n1660                         continue\n1661                     try:\n1662                         meth = frame[self.name]\n1663                     except KeyError:\n1664                         continue\n1665                     else:\n1666                         # Must be a function and in the same frame as the\n1667                         # original method.\n1668                         if (\n1669                             isinstance(meth, FunctionDef)\n1670                             and assign_node.frame() == frame\n1671                         ):\n1672                             decorators.append(assign.value)\n1673         return decorators\n1674 \n1675     @decorators_mod.cachedproperty\n1676     def type(\n1677         self,\n1678     ):  # pylint: disable=invalid-overridden-method,too-many-return-statements\n1679         \"\"\"The function type for this node.\n1680 \n1681         Possible values are: method, function, staticmethod, classmethod.\n1682 \n1683         :type: str\n1684         \"\"\"\n1685         for decorator in self.extra_decorators:\n1686             if decorator.func.name in BUILTIN_DESCRIPTORS:\n1687                 return decorator.func.name\n1688 \n1689         frame = self.parent.frame()\n1690         type_name = \"function\"\n1691         if isinstance(frame, ClassDef):\n1692             if self.name == \"__new__\":\n1693                 return \"classmethod\"\n1694             if self.name == \"__init_subclass__\":\n1695                 return \"classmethod\"\n1696             if self.name == \"__class_getitem__\":\n1697                 return \"classmethod\"\n1698 \n1699             type_name = \"method\"\n1700 \n1701         if not self.decorators:\n1702             return type_name\n1703 \n1704         for node in self.decorators.nodes:\n1705             if isinstance(node, node_classes.Name):\n1706                 if node.name in BUILTIN_DESCRIPTORS:\n1707                     return node.name\n1708             if (\n1709                 isinstance(node, node_classes.Attribute)\n1710                 and isinstance(node.expr, node_classes.Name)\n1711                 and node.expr.name == \"builtins\"\n1712                 and node.attrname in BUILTIN_DESCRIPTORS\n1713             ):\n1714                 return node.attrname\n1715 \n1716             if isinstance(node, node_classes.Call):\n1717                 # Handle the following case:\n1718                 # @some_decorator(arg1, arg2)\n1719                 # def func(...)\n1720                 #\n1721                 try:\n1722                     current = next(node.func.infer())\n1723                 except (InferenceError, StopIteration):\n1724                     continue\n1725                 _type = _infer_decorator_callchain(current)\n1726                 if _type is not None:\n1727                     return _type\n1728 \n1729             try:\n1730                 for inferred in node.infer():\n1731                     # Check to see if this returns a static or a class method.\n1732                     _type = _infer_decorator_callchain(inferred)\n1733                     if _type is not None:\n1734                         return _type\n1735 \n1736                     if not isinstance(inferred, ClassDef):\n1737                         continue\n1738                     for ancestor in inferred.ancestors():\n1739                         if not isinstance(ancestor, ClassDef):\n1740                             continue\n1741                         if ancestor.is_subtype_of(\"builtins.classmethod\"):\n1742                             return \"classmethod\"\n1743                         if ancestor.is_subtype_of(\"builtins.staticmethod\"):\n1744                             return \"staticmethod\"\n1745             except InferenceError:\n1746                 pass\n1747         return type_name\n1748 \n1749     @decorators_mod.cachedproperty\n1750     def fromlineno(self):\n1751         \"\"\"The first line that this node appears on in the source code.\n1752 \n1753         :type: int or None\n1754         \"\"\"\n1755         # lineno is the line number of the first decorator, we want the def\n1756         # statement lineno\n1757         lineno = self.lineno\n1758         if self.decorators is not None:\n1759             lineno += sum(\n1760                 node.tolineno - node.lineno + 1 for node in self.decorators.nodes\n1761             )\n1762 \n1763         return lineno\n1764 \n1765     @decorators_mod.cachedproperty\n1766     def blockstart_tolineno(self):\n1767         \"\"\"The line on which the beginning of this block ends.\n1768 \n1769         :type: int\n1770         \"\"\"\n1771         return self.args.tolineno\n1772 \n1773     def block_range(self, lineno):\n1774         \"\"\"Get a range from the given line number to where this node ends.\n1775 \n1776         :param lineno: Unused.\n1777         :type lineno: int\n1778 \n1779         :returns: The range of line numbers that this node belongs to,\n1780         :rtype: tuple(int, int)\n1781         \"\"\"\n1782         return self.fromlineno, self.tolineno\n1783 \n1784     def getattr(self, name, context=None):\n1785         \"\"\"this method doesn't look in the instance_attrs dictionary since it's\n1786         done by an Instance proxy at inference time.\n1787         \"\"\"\n1788         if not name:\n1789             raise AttributeInferenceError(target=self, attribute=name, context=context)\n1790 \n1791         found_attrs = []\n1792         if name in self.instance_attrs:\n1793             found_attrs = self.instance_attrs[name]\n1794         if name in self.special_attributes:\n1795             found_attrs.append(self.special_attributes.lookup(name))\n1796         if found_attrs:\n1797             return found_attrs\n1798         raise AttributeInferenceError(target=self, attribute=name)\n1799 \n1800     def igetattr(self, name, context=None):\n1801         \"\"\"Inferred getattr, which returns an iterator of inferred statements.\"\"\"\n1802         try:\n1803             return bases._infer_stmts(self.getattr(name, context), context, frame=self)\n1804         except AttributeInferenceError as error:\n1805             raise InferenceError(\n1806                 str(error), target=self, attribute=name, context=context\n1807             ) from error\n1808 \n1809     def is_method(self):\n1810         \"\"\"Check if this function node represents a method.\n1811 \n1812         :returns: True if this is a method, False otherwise.\n1813         :rtype: bool\n1814         \"\"\"\n1815         # check we are defined in a ClassDef, because this is usually expected\n1816         # (e.g. pylint...) when is_method() return True\n1817         return self.type != \"function\" and isinstance(self.parent.frame(), ClassDef)\n1818 \n1819     @decorators_mod.cached\n1820     def decoratornames(self, context=None):\n1821         \"\"\"Get the qualified names of each of the decorators on this function.\n1822 \n1823         :param context:\n1824             An inference context that can be passed to inference functions\n1825         :returns: The names of the decorators.\n1826         :rtype: set(str)\n1827         \"\"\"\n1828         result = set()\n1829         decoratornodes = []\n1830         if self.decorators is not None:\n1831             decoratornodes += self.decorators.nodes\n1832         decoratornodes += self.extra_decorators\n1833         for decnode in decoratornodes:\n1834             try:\n1835                 for infnode in decnode.infer(context=context):\n1836                     result.add(infnode.qname())\n1837             except InferenceError:\n1838                 continue\n1839         return result\n1840 \n1841     def is_bound(self):\n1842         \"\"\"Check if the function is bound to an instance or class.\n1843 \n1844         :returns: True if the function is bound to an instance or class,\n1845             False otherwise.\n1846         :rtype: bool\n1847         \"\"\"\n1848         return self.type == \"classmethod\"\n1849 \n1850     def is_abstract(self, pass_is_abstract=True, any_raise_is_abstract=False):\n1851         \"\"\"Check if the method is abstract.\n1852 \n1853         A method is considered abstract if any of the following is true:\n1854         * The only statement is 'raise NotImplementedError'\n1855         * The only statement is 'raise <SomeException>' and any_raise_is_abstract is True\n1856         * The only statement is 'pass' and pass_is_abstract is True\n1857         * The method is annotated with abc.astractproperty/abc.abstractmethod\n1858 \n1859         :returns: True if the method is abstract, False otherwise.\n1860         :rtype: bool\n1861         \"\"\"\n1862         if self.decorators:\n1863             for node in self.decorators.nodes:\n1864                 try:\n1865                     inferred = next(node.infer())\n1866                 except (InferenceError, StopIteration):\n1867                     continue\n1868                 if inferred and inferred.qname() in {\n1869                     \"abc.abstractproperty\",\n1870                     \"abc.abstractmethod\",\n1871                 }:\n1872                     return True\n1873 \n1874         for child_node in self.body:\n1875             if isinstance(child_node, node_classes.Raise):\n1876                 if any_raise_is_abstract:\n1877                     return True\n1878                 if child_node.raises_not_implemented():\n1879                     return True\n1880             return pass_is_abstract and isinstance(child_node, node_classes.Pass)\n1881         # empty function is the same as function with a single \"pass\" statement\n1882         if pass_is_abstract:\n1883             return True\n1884 \n1885     def is_generator(self):\n1886         \"\"\"Check if this is a generator function.\n1887 \n1888         :returns: True is this is a generator function, False otherwise.\n1889         :rtype: bool\n1890         \"\"\"\n1891         return bool(next(self._get_yield_nodes_skip_lambdas(), False))\n1892 \n1893     def infer_yield_result(self, context=None):\n1894         \"\"\"Infer what the function yields when called\n1895 \n1896         :returns: What the function yields\n1897         :rtype: iterable(NodeNG or Uninferable) or None\n1898         \"\"\"\n1899         # pylint: disable=not-an-iterable\n1900         # https://github.com/PyCQA/astroid/issues/1015\n1901         for yield_ in self.nodes_of_class(node_classes.Yield):\n1902             if yield_.value is None:\n1903                 const = node_classes.Const(None)\n1904                 const.parent = yield_\n1905                 const.lineno = yield_.lineno\n1906                 yield const\n1907             elif yield_.scope() == self:\n1908                 yield from yield_.value.infer(context=context)\n1909 \n1910     def infer_call_result(self, caller=None, context=None):\n1911         \"\"\"Infer what the function returns when called.\n1912 \n1913         :returns: What the function returns.\n1914         :rtype: iterable(NodeNG or Uninferable) or None\n1915         \"\"\"\n1916         if self.is_generator():\n1917             if isinstance(self, AsyncFunctionDef):\n1918                 generator_cls = bases.AsyncGenerator\n1919             else:\n1920                 generator_cls = bases.Generator\n1921             result = generator_cls(self, generator_initial_context=context)\n1922             yield result\n1923             return\n1924         # This is really a gigantic hack to work around metaclass generators\n1925         # that return transient class-generating functions. Pylint's AST structure\n1926         # cannot handle a base class object that is only used for calling __new__,\n1927         # but does not contribute to the inheritance structure itself. We inject\n1928         # a fake class into the hierarchy here for several well-known metaclass\n1929         # generators, and filter it out later.\n1930         if (\n1931             self.name == \"with_metaclass\"\n1932             and len(self.args.args) == 1\n1933             and self.args.vararg is not None\n1934         ):\n1935             metaclass = next(caller.args[0].infer(context), None)\n1936             if isinstance(metaclass, ClassDef):\n1937                 try:\n1938                     class_bases = [next(arg.infer(context)) for arg in caller.args[1:]]\n1939                 except StopIteration as e:\n1940                     raise InferenceError(node=caller.args[1:], context=context) from e\n1941                 new_class = ClassDef(name=\"temporary_class\")\n1942                 new_class.hide = True\n1943                 new_class.parent = self\n1944                 new_class.postinit(\n1945                     bases=[base for base in class_bases if base != util.Uninferable],\n1946                     body=[],\n1947                     decorators=[],\n1948                     metaclass=metaclass,\n1949                 )\n1950                 yield new_class\n1951                 return\n1952         returns = self._get_return_nodes_skip_functions()\n1953 \n1954         first_return = next(returns, None)\n1955         if not first_return:\n1956             if self.body:\n1957                 if self.is_abstract(pass_is_abstract=True, any_raise_is_abstract=True):\n1958                     yield util.Uninferable\n1959                 else:\n1960                     yield node_classes.Const(None)\n1961                 return\n1962 \n1963             raise InferenceError(\"The function does not have any return statements\")\n1964 \n1965         for returnnode in itertools.chain((first_return,), returns):\n1966             if returnnode.value is None:\n1967                 yield node_classes.Const(None)\n1968             else:\n1969                 try:\n1970                     yield from returnnode.value.infer(context)\n1971                 except InferenceError:\n1972                     yield util.Uninferable\n1973 \n1974     def bool_value(self, context=None):\n1975         \"\"\"Determine the boolean value of this node.\n1976 \n1977         :returns: The boolean value of this node.\n1978             For a :class:`FunctionDef` this is always ``True``.\n1979         :rtype: bool\n1980         \"\"\"\n1981         return True\n1982 \n1983     def get_children(self):\n1984         if self.decorators is not None:\n1985             yield self.decorators\n1986 \n1987         yield self.args\n1988 \n1989         if self.returns is not None:\n1990             yield self.returns\n1991 \n1992         yield from self.body\n1993 \n1994     def scope_lookup(self, node, name, offset=0):\n1995         \"\"\"Lookup where the given name is assigned.\"\"\"\n1996         if name == \"__class__\":\n1997             # __class__ is an implicit closure reference created by the compiler\n1998             # if any methods in a class body refer to either __class__ or super.\n1999             # In our case, we want to be able to look it up in the current scope\n2000             # when `__class__` is being used.\n2001             frame = self.parent.frame()\n2002             if isinstance(frame, ClassDef):\n2003                 return self, [frame]\n2004         return super().scope_lookup(node, name, offset)\n2005 \n2006     def frame(self: T) -> T:\n2007         \"\"\"The node's frame node.\n2008 \n2009         A frame node is a :class:`Module`, :class:`FunctionDef`,\n2010         :class:`ClassDef` or :class:`Lambda`.\n2011 \n2012         :returns: The node itself.\n2013         \"\"\"\n2014         return self\n2015 \n2016 \n2017 class AsyncFunctionDef(FunctionDef):\n2018     \"\"\"Class representing an :class:`ast.FunctionDef` node.\n2019 \n2020     A :class:`AsyncFunctionDef` is an asynchronous function\n2021     created with the `async` keyword.\n2022 \n2023     >>> import astroid\n2024     >>> node = astroid.extract_node('''\n2025     async def func(things):\n2026         async for thing in things:\n2027             print(thing)\n2028     ''')\n2029     >>> node\n2030     <AsyncFunctionDef.func l.2 at 0x7f23b2e416d8>\n2031     >>> node.body[0]\n2032     <AsyncFor l.3 at 0x7f23b2e417b8>\n2033     \"\"\"\n2034 \n2035 \n2036 def _rec_get_names(args, names=None):\n2037     \"\"\"return a list of all argument names\"\"\"\n2038     if names is None:\n2039         names = []\n2040     for arg in args:\n2041         if isinstance(arg, node_classes.Tuple):\n2042             _rec_get_names(arg.elts, names)\n2043         else:\n2044             names.append(arg.name)\n2045     return names\n2046 \n2047 \n2048 def _is_metaclass(klass, seen=None):\n2049     \"\"\"Return if the given class can be\n2050     used as a metaclass.\n2051     \"\"\"\n2052     if klass.name == \"type\":\n2053         return True\n2054     if seen is None:\n2055         seen = set()\n2056     for base in klass.bases:\n2057         try:\n2058             for baseobj in base.infer():\n2059                 baseobj_name = baseobj.qname()\n2060                 if baseobj_name in seen:\n2061                     continue\n2062 \n2063                 seen.add(baseobj_name)\n2064                 if isinstance(baseobj, bases.Instance):\n2065                     # not abstract\n2066                     return False\n2067                 if baseobj is util.Uninferable:\n2068                     continue\n2069                 if baseobj is klass:\n2070                     continue\n2071                 if not isinstance(baseobj, ClassDef):\n2072                     continue\n2073                 if baseobj._type == \"metaclass\":\n2074                     return True\n2075                 if _is_metaclass(baseobj, seen):\n2076                     return True\n2077         except InferenceError:\n2078             continue\n2079     return False\n2080 \n2081 \n2082 def _class_type(klass, ancestors=None):\n2083     \"\"\"return a ClassDef node type to differ metaclass and exception\n2084     from 'regular' classes\n2085     \"\"\"\n2086     # XXX we have to store ancestors in case we have an ancestor loop\n2087     if klass._type is not None:\n2088         return klass._type\n2089     if _is_metaclass(klass):\n2090         klass._type = \"metaclass\"\n2091     elif klass.name.endswith(\"Exception\"):\n2092         klass._type = \"exception\"\n2093     else:\n2094         if ancestors is None:\n2095             ancestors = set()\n2096         klass_name = klass.qname()\n2097         if klass_name in ancestors:\n2098             # XXX we are in loop ancestors, and have found no type\n2099             klass._type = \"class\"\n2100             return \"class\"\n2101         ancestors.add(klass_name)\n2102         for base in klass.ancestors(recurs=False):\n2103             name = _class_type(base, ancestors)\n2104             if name != \"class\":\n2105                 if name == \"metaclass\" and not _is_metaclass(klass):\n2106                     # don't propagate it if the current class\n2107                     # can't be a metaclass\n2108                     continue\n2109                 klass._type = base.type\n2110                 break\n2111     if klass._type is None:\n2112         klass._type = \"class\"\n2113     return klass._type\n2114 \n2115 \n2116 def get_wrapping_class(node):\n2117     \"\"\"Get the class that wraps the given node.\n2118 \n2119     We consider that a class wraps a node if the class\n2120     is a parent for the said node.\n2121 \n2122     :returns: The class that wraps the given node\n2123     :rtype: ClassDef or None\n2124     \"\"\"\n2125 \n2126     klass = node.frame()\n2127     while klass is not None and not isinstance(klass, ClassDef):\n2128         if klass.parent is None:\n2129             klass = None\n2130         else:\n2131             klass = klass.parent.frame()\n2132     return klass\n2133 \n2134 \n2135 class ClassDef(mixins.FilterStmtsMixin, LocalsDictNodeNG, node_classes.Statement):\n2136     \"\"\"Class representing an :class:`ast.ClassDef` node.\n2137 \n2138     >>> import astroid\n2139     >>> node = astroid.extract_node('''\n2140     class Thing:\n2141         def my_meth(self, arg):\n2142             return arg + self.offset\n2143     ''')\n2144     >>> node\n2145     <ClassDef.Thing l.2 at 0x7f23b2e9e748>\n2146     \"\"\"\n2147 \n2148     # some of the attributes below are set by the builder module or\n2149     # by a raw factories\n2150 \n2151     # a dictionary of class instances attributes\n2152     _astroid_fields = (\"decorators\", \"bases\", \"keywords\", \"body\")  # name\n2153 \n2154     decorators = None\n2155     \"\"\"The decorators that are applied to this class.\n2156 \n2157     :type: Decorators or None\n2158     \"\"\"\n2159     special_attributes = ClassModel()\n2160     \"\"\"The names of special attributes that this class has.\n2161 \n2162     :type: objectmodel.ClassModel\n2163     \"\"\"\n2164 \n2165     _type = None\n2166     _metaclass_hack = False\n2167     hide = False\n2168     type = property(\n2169         _class_type,\n2170         doc=(\n2171             \"The class type for this node.\\n\\n\"\n2172             \"Possible values are: class, metaclass, exception.\\n\\n\"\n2173             \":type: str\"\n2174         ),\n2175     )\n2176     _other_fields = (\"name\", \"doc\")\n2177     _other_other_fields = (\"locals\", \"_newstyle\")\n2178     _newstyle = None\n2179 \n2180     def __init__(\n2181         self,\n2182         name=None,\n2183         doc=None,\n2184         lineno=None,\n2185         col_offset=None,\n2186         parent=None,\n2187         *,\n2188         end_lineno=None,\n2189         end_col_offset=None,\n2190     ):\n2191         \"\"\"\n2192         :param name: The name of the class.\n2193         :type name: str or None\n2194 \n2195         :param doc: The function's docstring.\n2196         :type doc: str or None\n2197 \n2198         :param lineno: The line that this node appears on in the source code.\n2199         :type lineno: int or None\n2200 \n2201         :param col_offset: The column that this node appears on in the\n2202             source code.\n2203         :type col_offset: int or None\n2204 \n2205         :param parent: The parent node in the syntax tree.\n2206         :type parent: NodeNG or None\n2207 \n2208         :param end_lineno: The last line this node appears on in the source code.\n2209         :type end_lineno: Optional[int]\n2210 \n2211         :param end_col_offset: The end column this node appears on in the\n2212             source code. Note: This is after the last symbol.\n2213         :type end_col_offset: Optional[int]\n2214         \"\"\"\n2215         self.instance_attrs = {}\n2216         self.locals = {}\n2217         \"\"\"A map of the name of a local variable to the node defining it.\n2218 \n2219         :type: dict(str, NodeNG)\n2220         \"\"\"\n2221 \n2222         self.keywords = []\n2223         \"\"\"The keywords given to the class definition.\n2224 \n2225         This is usually for :pep:`3115` style metaclass declaration.\n2226 \n2227         :type: list(Keyword) or None\n2228         \"\"\"\n2229 \n2230         self.bases = []\n2231         \"\"\"What the class inherits from.\n2232 \n2233         :type: list(NodeNG)\n2234         \"\"\"\n2235 \n2236         self.body = []\n2237         \"\"\"The contents of the class body.\n2238 \n2239         :type: list(NodeNG)\n2240         \"\"\"\n2241 \n2242         self.name = name\n2243         \"\"\"The name of the class.\n2244 \n2245         :type name: str or None\n2246         \"\"\"\n2247 \n2248         self.doc = doc\n2249         \"\"\"The class' docstring.\n2250 \n2251         :type doc: str or None\n2252         \"\"\"\n2253 \n2254         super().__init__(\n2255             lineno=lineno,\n2256             col_offset=col_offset,\n2257             end_lineno=end_lineno,\n2258             end_col_offset=end_col_offset,\n2259             parent=parent,\n2260         )\n2261         if parent is not None:\n2262             parent.frame().set_local(name, self)\n2263 \n2264         for local_name, node in self.implicit_locals():\n2265             self.add_local_node(node, local_name)\n2266 \n2267     def implicit_parameters(self):\n2268         return 1\n2269 \n2270     def implicit_locals(self):\n2271         \"\"\"Get implicitly defined class definition locals.\n2272 \n2273         :returns: the the name and Const pair for each local\n2274         :rtype: tuple(tuple(str, node_classes.Const), ...)\n2275         \"\"\"\n2276         locals_ = ((\"__module__\", self.special_attributes.attr___module__),)\n2277         # __qualname__ is defined in PEP3155\n2278         locals_ += ((\"__qualname__\", self.special_attributes.attr___qualname__),)\n2279         return locals_\n2280 \n2281     # pylint: disable=redefined-outer-name\n2282     def postinit(\n2283         self, bases, body, decorators, newstyle=None, metaclass=None, keywords=None\n2284     ):\n2285         \"\"\"Do some setup after initialisation.\n2286 \n2287         :param bases: What the class inherits from.\n2288         :type bases: list(NodeNG)\n2289 \n2290         :param body: The contents of the class body.\n2291         :type body: list(NodeNG)\n2292 \n2293         :param decorators: The decorators that are applied to this class.\n2294         :type decorators: Decorators or None\n2295 \n2296         :param newstyle: Whether this is a new style class or not.\n2297         :type newstyle: bool or None\n2298 \n2299         :param metaclass: The metaclass of this class.\n2300         :type metaclass: NodeNG or None\n2301 \n2302         :param keywords: The keywords given to the class definition.\n2303         :type keywords: list(Keyword) or None\n2304         \"\"\"\n2305         if keywords is not None:\n2306             self.keywords = keywords\n2307         self.bases = bases\n2308         self.body = body\n2309         self.decorators = decorators\n2310         if newstyle is not None:\n2311             self._newstyle = newstyle\n2312         if metaclass is not None:\n2313             self._metaclass = metaclass\n2314 \n2315     def _newstyle_impl(self, context=None):\n2316         if context is None:\n2317             context = InferenceContext()\n2318         if self._newstyle is not None:\n2319             return self._newstyle\n2320         for base in self.ancestors(recurs=False, context=context):\n2321             if base._newstyle_impl(context):\n2322                 self._newstyle = True\n2323                 break\n2324         klass = self.declared_metaclass()\n2325         # could be any callable, we'd need to infer the result of klass(name,\n2326         # bases, dict).  punt if it's not a class node.\n2327         if klass is not None and isinstance(klass, ClassDef):\n2328             self._newstyle = klass._newstyle_impl(context)\n2329         if self._newstyle is None:\n2330             self._newstyle = False\n2331         return self._newstyle\n2332 \n2333     _newstyle = None\n2334     newstyle = property(\n2335         _newstyle_impl,\n2336         doc=(\"Whether this is a new style class or not\\n\\n\" \":type: bool or None\"),\n2337     )\n2338 \n2339     @decorators_mod.cachedproperty\n2340     def blockstart_tolineno(self):\n2341         \"\"\"The line on which the beginning of this block ends.\n2342 \n2343         :type: int\n2344         \"\"\"\n2345         if self.bases:\n2346             return self.bases[-1].tolineno\n2347 \n2348         return self.fromlineno\n2349 \n2350     def block_range(self, lineno):\n2351         \"\"\"Get a range from the given line number to where this node ends.\n2352 \n2353         :param lineno: Unused.\n2354         :type lineno: int\n2355 \n2356         :returns: The range of line numbers that this node belongs to,\n2357         :rtype: tuple(int, int)\n2358         \"\"\"\n2359         return self.fromlineno, self.tolineno\n2360 \n2361     def pytype(self):\n2362         \"\"\"Get the name of the type that this node represents.\n2363 \n2364         :returns: The name of the type.\n2365         :rtype: str\n2366         \"\"\"\n2367         if self.newstyle:\n2368             return \"builtins.type\"\n2369         return \"builtins.classobj\"\n2370 \n2371     def display_type(self):\n2372         \"\"\"A human readable type of this node.\n2373 \n2374         :returns: The type of this node.\n2375         :rtype: str\n2376         \"\"\"\n2377         return \"Class\"\n2378 \n2379     def callable(self):\n2380         \"\"\"Whether this node defines something that is callable.\n2381 \n2382         :returns: True if this defines something that is callable,\n2383             False otherwise.\n2384             For a :class:`ClassDef` this is always ``True``.\n2385         :rtype: bool\n2386         \"\"\"\n2387         return True\n2388 \n2389     def is_subtype_of(self, type_name, context=None):\n2390         \"\"\"Whether this class is a subtype of the given type.\n2391 \n2392         :param type_name: The name of the type of check against.\n2393         :type type_name: str\n2394 \n2395         :returns: True if this class is a subtype of the given type,\n2396             False otherwise.\n2397         :rtype: bool\n2398         \"\"\"\n2399         if self.qname() == type_name:\n2400             return True\n2401 \n2402         return any(anc.qname() == type_name for anc in self.ancestors(context=context))\n2403 \n2404     def _infer_type_call(self, caller, context):\n2405         try:\n2406             name_node = next(caller.args[0].infer(context))\n2407         except StopIteration as e:\n2408             raise InferenceError(node=caller.args[0], context=context) from e\n2409         if isinstance(name_node, node_classes.Const) and isinstance(\n2410             name_node.value, str\n2411         ):\n2412             name = name_node.value\n2413         else:\n2414             return util.Uninferable\n2415 \n2416         result = ClassDef(name, None)\n2417 \n2418         # Get the bases of the class.\n2419         try:\n2420             class_bases = next(caller.args[1].infer(context))\n2421         except StopIteration as e:\n2422             raise InferenceError(node=caller.args[1], context=context) from e\n2423         if isinstance(class_bases, (node_classes.Tuple, node_classes.List)):\n2424             bases = []\n2425             for base in class_bases.itered():\n2426                 inferred = next(base.infer(context=context), None)\n2427                 if inferred:\n2428                     bases.append(\n2429                         node_classes.EvaluatedObject(original=base, value=inferred)\n2430                     )\n2431             result.bases = bases\n2432         else:\n2433             # There is currently no AST node that can represent an 'unknown'\n2434             # node (Uninferable is not an AST node), therefore we simply return Uninferable here\n2435             # although we know at least the name of the class.\n2436             return util.Uninferable\n2437 \n2438         # Get the members of the class\n2439         try:\n2440             members = next(caller.args[2].infer(context))\n2441         except (InferenceError, StopIteration):\n2442             members = None\n2443 \n2444         if members and isinstance(members, node_classes.Dict):\n2445             for attr, value in members.items:\n2446                 if isinstance(attr, node_classes.Const) and isinstance(attr.value, str):\n2447                     result.locals[attr.value] = [value]\n2448 \n2449         result.parent = caller.parent\n2450         return result\n2451 \n2452     def infer_call_result(self, caller, context=None):\n2453         \"\"\"infer what a class is returning when called\"\"\"\n2454         if self.is_subtype_of(\"builtins.type\", context) and len(caller.args) == 3:\n2455             result = self._infer_type_call(caller, context)\n2456             yield result\n2457             return\n2458 \n2459         dunder_call = None\n2460         try:\n2461             metaclass = self.metaclass(context=context)\n2462             if metaclass is not None:\n2463                 dunder_call = next(metaclass.igetattr(\"__call__\", context))\n2464         except (AttributeInferenceError, StopIteration):\n2465             pass\n2466 \n2467         if dunder_call and dunder_call.qname() != \"builtins.type.__call__\":\n2468             # Call type.__call__ if not set metaclass\n2469             # (since type is the default metaclass)\n2470             context = bind_context_to_node(context, self)\n2471             context.callcontext.callee = dunder_call\n2472             yield from dunder_call.infer_call_result(caller, context)\n2473         else:\n2474             yield self.instantiate_class()\n2475 \n2476     def scope_lookup(self, node, name, offset=0):\n2477         \"\"\"Lookup where the given name is assigned.\n2478 \n2479         :param node: The node to look for assignments up to.\n2480             Any assignments after the given node are ignored.\n2481         :type node: NodeNG\n2482 \n2483         :param name: The name to find assignments for.\n2484         :type name: str\n2485 \n2486         :param offset: The line offset to filter statements up to.\n2487         :type offset: int\n2488 \n2489         :returns: This scope node and the list of assignments associated to the\n2490             given name according to the scope where it has been found (locals,\n2491             globals or builtin).\n2492         :rtype: tuple(str, list(NodeNG))\n2493         \"\"\"\n2494         # If the name looks like a builtin name, just try to look\n2495         # into the upper scope of this class. We might have a\n2496         # decorator that it's poorly named after a builtin object\n2497         # inside this class.\n2498         lookup_upper_frame = (\n2499             isinstance(node.parent, node_classes.Decorators)\n2500             and name in AstroidManager().builtins_module\n2501         )\n2502         if (\n2503             any(node == base or base.parent_of(node) for base in self.bases)\n2504             or lookup_upper_frame\n2505         ):\n2506             # Handle the case where we have either a name\n2507             # in the bases of a class, which exists before\n2508             # the actual definition or the case where we have\n2509             # a Getattr node, with that name.\n2510             #\n2511             # name = ...\n2512             # class A(name):\n2513             #     def name(self): ...\n2514             #\n2515             # import name\n2516             # class A(name.Name):\n2517             #     def name(self): ...\n2518 \n2519             frame = self.parent.frame()\n2520             # line offset to avoid that class A(A) resolve the ancestor to\n2521             # the defined class\n2522             offset = -1\n2523         else:\n2524             frame = self\n2525         return frame._scope_lookup(node, name, offset)\n2526 \n2527     @property\n2528     def basenames(self):\n2529         \"\"\"The names of the parent classes\n2530 \n2531         Names are given in the order they appear in the class definition.\n2532 \n2533         :type: list(str)\n2534         \"\"\"\n2535         return [bnode.as_string() for bnode in self.bases]\n2536 \n2537     def ancestors(self, recurs=True, context=None):\n2538         \"\"\"Iterate over the base classes in prefixed depth first order.\n2539 \n2540         :param recurs: Whether to recurse or return direct ancestors only.\n2541         :type recurs: bool\n2542 \n2543         :returns: The base classes\n2544         :rtype: iterable(NodeNG)\n2545         \"\"\"\n2546         # FIXME: should be possible to choose the resolution order\n2547         # FIXME: inference make infinite loops possible here\n2548         yielded = {self}\n2549         if context is None:\n2550             context = InferenceContext()\n2551         if not self.bases and self.qname() != \"builtins.object\":\n2552             yield builtin_lookup(\"object\")[1][0]\n2553             return\n2554 \n2555         for stmt in self.bases:\n2556             with context.restore_path():\n2557                 try:\n2558                     for baseobj in stmt.infer(context):\n2559                         if not isinstance(baseobj, ClassDef):\n2560                             if isinstance(baseobj, bases.Instance):\n2561                                 baseobj = baseobj._proxied\n2562                             else:\n2563                                 continue\n2564                         if not baseobj.hide:\n2565                             if baseobj in yielded:\n2566                                 continue\n2567                             yielded.add(baseobj)\n2568                             yield baseobj\n2569                         if not recurs:\n2570                             continue\n2571                         for grandpa in baseobj.ancestors(recurs=True, context=context):\n2572                             if grandpa is self:\n2573                                 # This class is the ancestor of itself.\n2574                                 break\n2575                             if grandpa in yielded:\n2576                                 continue\n2577                             yielded.add(grandpa)\n2578                             yield grandpa\n2579                 except InferenceError:\n2580                     continue\n2581 \n2582     def local_attr_ancestors(self, name, context=None):\n2583         \"\"\"Iterate over the parents that define the given name.\n2584 \n2585         :param name: The name to find definitions for.\n2586         :type name: str\n2587 \n2588         :returns: The parents that define the given name.\n2589         :rtype: iterable(NodeNG)\n2590         \"\"\"\n2591         # Look up in the mro if we can. This will result in the\n2592         # attribute being looked up just as Python does it.\n2593         try:\n2594             ancestors = self.mro(context)[1:]\n2595         except MroError:\n2596             # Fallback to use ancestors, we can't determine\n2597             # a sane MRO.\n2598             ancestors = self.ancestors(context=context)\n2599         for astroid in ancestors:\n2600             if name in astroid:\n2601                 yield astroid\n2602 \n2603     def instance_attr_ancestors(self, name, context=None):\n2604         \"\"\"Iterate over the parents that define the given name as an attribute.\n2605 \n2606         :param name: The name to find definitions for.\n2607         :type name: str\n2608 \n2609         :returns: The parents that define the given name as\n2610             an instance attribute.\n2611         :rtype: iterable(NodeNG)\n2612         \"\"\"\n2613         for astroid in self.ancestors(context=context):\n2614             if name in astroid.instance_attrs:\n2615                 yield astroid\n2616 \n2617     def has_base(self, node):\n2618         \"\"\"Whether this class directly inherits from the given node.\n2619 \n2620         :param node: The node to check for.\n2621         :type node: NodeNG\n2622 \n2623         :returns: True if this class directly inherits from the given node.\n2624         :rtype: bool\n2625         \"\"\"\n2626         return node in self.bases\n2627 \n2628     def local_attr(self, name, context=None):\n2629         \"\"\"Get the list of assign nodes associated to the given name.\n2630 \n2631         Assignments are looked for in both this class and in parents.\n2632 \n2633         :returns: The list of assignments to the given name.\n2634         :rtype: list(NodeNG)\n2635 \n2636         :raises AttributeInferenceError: If no attribute with this name\n2637             can be found in this class or parent classes.\n2638         \"\"\"\n2639         result = []\n2640         if name in self.locals:\n2641             result = self.locals[name]\n2642         else:\n2643             class_node = next(self.local_attr_ancestors(name, context), None)\n2644             if class_node:\n2645                 result = class_node.locals[name]\n2646         result = [n for n in result if not isinstance(n, node_classes.DelAttr)]\n2647         if result:\n2648             return result\n2649         raise AttributeInferenceError(target=self, attribute=name, context=context)\n2650 \n2651     def instance_attr(self, name, context=None):\n2652         \"\"\"Get the list of nodes associated to the given attribute name.\n2653 \n2654         Assignments are looked for in both this class and in parents.\n2655 \n2656         :returns: The list of assignments to the given name.\n2657         :rtype: list(NodeNG)\n2658 \n2659         :raises AttributeInferenceError: If no attribute with this name\n2660             can be found in this class or parent classes.\n2661         \"\"\"\n2662         # Return a copy, so we don't modify self.instance_attrs,\n2663         # which could lead to infinite loop.\n2664         values = list(self.instance_attrs.get(name, []))\n2665         # get all values from parents\n2666         for class_node in self.instance_attr_ancestors(name, context):\n2667             values += class_node.instance_attrs[name]\n2668         values = [n for n in values if not isinstance(n, node_classes.DelAttr)]\n2669         if values:\n2670             return values\n2671         raise AttributeInferenceError(target=self, attribute=name, context=context)\n2672 \n2673     def instantiate_class(self):\n2674         \"\"\"Get an :class:`Instance` of the :class:`ClassDef` node.\n2675 \n2676         :returns: An :class:`Instance` of the :class:`ClassDef` node,\n2677             or self if this is not possible.\n2678         :rtype: Instance or ClassDef\n2679         \"\"\"\n2680         try:\n2681             if any(cls.name in EXCEPTION_BASE_CLASSES for cls in self.mro()):\n2682                 # Subclasses of exceptions can be exception instances\n2683                 return objects.ExceptionInstance(self)\n2684         except MroError:\n2685             pass\n2686         return bases.Instance(self)\n2687 \n2688     def getattr(self, name, context=None, class_context=True):\n2689         \"\"\"Get an attribute from this class, using Python's attribute semantic.\n2690 \n2691         This method doesn't look in the :attr:`instance_attrs` dictionary\n2692         since it is done by an :class:`Instance` proxy at inference time.\n2693         It may return an :class:`Uninferable` object if\n2694         the attribute has not been\n2695         found, but a ``__getattr__`` or ``__getattribute__`` method is defined.\n2696         If ``class_context`` is given, then it is considered that the\n2697         attribute is accessed from a class context,\n2698         e.g. ClassDef.attribute, otherwise it might have been accessed\n2699         from an instance as well. If ``class_context`` is used in that\n2700         case, then a lookup in the implicit metaclass and the explicit\n2701         metaclass will be done.\n2702 \n2703         :param name: The attribute to look for.\n2704         :type name: str\n2705 \n2706         :param class_context: Whether the attribute can be accessed statically.\n2707         :type class_context: bool\n2708 \n2709         :returns: The attribute.\n2710         :rtype: list(NodeNG)\n2711 \n2712         :raises AttributeInferenceError: If the attribute cannot be inferred.\n2713         \"\"\"\n2714         if not name:\n2715             raise AttributeInferenceError(target=self, attribute=name, context=context)\n2716 \n2717         values = self.locals.get(name, [])\n2718         if name in self.special_attributes and class_context and not values:\n2719             result = [self.special_attributes.lookup(name)]\n2720             if name == \"__bases__\":\n2721                 # Need special treatment, since they are mutable\n2722                 # and we need to return all the values.\n2723                 result += values\n2724             return result\n2725 \n2726         # don't modify the list in self.locals!\n2727         values = list(values)\n2728         for classnode in self.ancestors(recurs=True, context=context):\n2729             values += classnode.locals.get(name, [])\n2730 \n2731         if class_context:\n2732             values += self._metaclass_lookup_attribute(name, context)\n2733 \n2734         if not values:\n2735             raise AttributeInferenceError(target=self, attribute=name, context=context)\n2736 \n2737         # Look for AnnAssigns, which are not attributes in the purest sense.\n2738         for value in values:\n2739             if isinstance(value, node_classes.AssignName):\n2740                 stmt = value.statement(future=True)\n2741                 if isinstance(stmt, node_classes.AnnAssign) and stmt.value is None:\n2742                     raise AttributeInferenceError(\n2743                         target=self, attribute=name, context=context\n2744                     )\n2745         return values\n2746 \n2747     def _metaclass_lookup_attribute(self, name, context):\n2748         \"\"\"Search the given name in the implicit and the explicit metaclass.\"\"\"\n2749         attrs = set()\n2750         implicit_meta = self.implicit_metaclass()\n2751         context = copy_context(context)\n2752         metaclass = self.metaclass(context=context)\n2753         for cls in (implicit_meta, metaclass):\n2754             if cls and cls != self and isinstance(cls, ClassDef):\n2755                 cls_attributes = self._get_attribute_from_metaclass(cls, name, context)\n2756                 attrs.update(set(cls_attributes))\n2757         return attrs\n2758 \n2759     def _get_attribute_from_metaclass(self, cls, name, context):\n2760         try:\n2761             attrs = cls.getattr(name, context=context, class_context=True)\n2762         except AttributeInferenceError:\n2763             return\n2764 \n2765         for attr in bases._infer_stmts(attrs, context, frame=cls):\n2766             if not isinstance(attr, FunctionDef):\n2767                 yield attr\n2768                 continue\n2769 \n2770             if isinstance(attr, objects.Property):\n2771                 yield attr\n2772                 continue\n2773             if attr.type == \"classmethod\":\n2774                 # If the method is a classmethod, then it will\n2775                 # be bound to the metaclass, not to the class\n2776                 # from where the attribute is retrieved.\n2777                 # get_wrapping_class could return None, so just\n2778                 # default to the current class.\n2779                 frame = get_wrapping_class(attr) or self\n2780                 yield bases.BoundMethod(attr, frame)\n2781             elif attr.type == \"staticmethod\":\n2782                 yield attr\n2783             else:\n2784                 yield bases.BoundMethod(attr, self)\n2785 \n2786     def igetattr(self, name, context=None, class_context=True):\n2787         \"\"\"Infer the possible values of the given variable.\n2788 \n2789         :param name: The name of the variable to infer.\n2790         :type name: str\n2791 \n2792         :returns: The inferred possible values.\n2793         :rtype: iterable(NodeNG or Uninferable)\n2794         \"\"\"\n2795         # set lookup name since this is necessary to infer on import nodes for\n2796         # instance\n2797         context = copy_context(context)\n2798         context.lookupname = name\n2799 \n2800         metaclass = self.metaclass(context=context)\n2801         try:\n2802             attributes = self.getattr(name, context, class_context=class_context)\n2803             # If we have more than one attribute, make sure that those starting from\n2804             # the second one are from the same scope. This is to account for modifications\n2805             # to the attribute happening *after* the attribute's definition (e.g. AugAssigns on lists)\n2806             if len(attributes) > 1:\n2807                 first_attr, attributes = attributes[0], attributes[1:]\n2808                 first_scope = first_attr.scope()\n2809                 attributes = [first_attr] + [\n2810                     attr\n2811                     for attr in attributes\n2812                     if attr.parent and attr.parent.scope() == first_scope\n2813                 ]\n2814 \n2815             for inferred in bases._infer_stmts(attributes, context, frame=self):\n2816                 # yield Uninferable object instead of descriptors when necessary\n2817                 if not isinstance(inferred, node_classes.Const) and isinstance(\n2818                     inferred, bases.Instance\n2819                 ):\n2820                     try:\n2821                         inferred._proxied.getattr(\"__get__\", context)\n2822                     except AttributeInferenceError:\n2823                         yield inferred\n2824                     else:\n2825                         yield util.Uninferable\n2826                 elif isinstance(inferred, objects.Property):\n2827                     function = inferred.function\n2828                     if not class_context:\n2829                         # Through an instance so we can solve the property\n2830                         yield from function.infer_call_result(\n2831                             caller=self, context=context\n2832                         )\n2833                     # If we're in a class context, we need to determine if the property\n2834                     # was defined in the metaclass (a derived class must be a subclass of\n2835                     # the metaclass of all its bases), in which case we can resolve the\n2836                     # property. If not, i.e. the property is defined in some base class\n2837                     # instead, then we return the property object\n2838                     elif metaclass and function.parent.scope() is metaclass:\n2839                         # Resolve a property as long as it is not accessed through\n2840                         # the class itself.\n2841                         yield from function.infer_call_result(\n2842                             caller=self, context=context\n2843                         )\n2844                     else:\n2845                         yield inferred\n2846                 else:\n2847                     yield function_to_method(inferred, self)\n2848         except AttributeInferenceError as error:\n2849             if not name.startswith(\"__\") and self.has_dynamic_getattr(context):\n2850                 # class handle some dynamic attributes, return a Uninferable object\n2851                 yield util.Uninferable\n2852             else:\n2853                 raise InferenceError(\n2854                     str(error), target=self, attribute=name, context=context\n2855                 ) from error\n2856 \n2857     def has_dynamic_getattr(self, context=None):\n2858         \"\"\"Check if the class has a custom __getattr__ or __getattribute__.\n2859 \n2860         If any such method is found and it is not from\n2861         builtins, nor from an extension module, then the function\n2862         will return True.\n2863 \n2864         :returns: True if the class has a custom\n2865             __getattr__ or __getattribute__, False otherwise.\n2866         :rtype: bool\n2867         \"\"\"\n2868 \n2869         def _valid_getattr(node):\n2870             root = node.root()\n2871             return root.name != \"builtins\" and getattr(root, \"pure_python\", None)\n2872 \n2873         try:\n2874             return _valid_getattr(self.getattr(\"__getattr__\", context)[0])\n2875         except AttributeInferenceError:\n2876             # if self.newstyle: XXX cause an infinite recursion error\n2877             try:\n2878                 getattribute = self.getattr(\"__getattribute__\", context)[0]\n2879                 return _valid_getattr(getattribute)\n2880             except AttributeInferenceError:\n2881                 pass\n2882         return False\n2883 \n2884     def getitem(self, index, context=None):\n2885         \"\"\"Return the inference of a subscript.\n2886 \n2887         This is basically looking up the method in the metaclass and calling it.\n2888 \n2889         :returns: The inferred value of a subscript to this class.\n2890         :rtype: NodeNG\n2891 \n2892         :raises AstroidTypeError: If this class does not define a\n2893             ``__getitem__`` method.\n2894         \"\"\"\n2895         try:\n2896             methods = lookup(self, \"__getitem__\")\n2897         except AttributeInferenceError as exc:\n2898             if isinstance(self, ClassDef):\n2899                 # subscripting a class definition may be\n2900                 # achieved thanks to __class_getitem__ method\n2901                 # which is a classmethod defined in the class\n2902                 # that supports subscript and not in the metaclass\n2903                 try:\n2904                     methods = self.getattr(\"__class_getitem__\")\n2905                     # Here it is assumed that the __class_getitem__ node is\n2906                     # a FunctionDef. One possible improvement would be to deal\n2907                     # with more generic inference.\n2908                 except AttributeInferenceError:\n2909                     raise AstroidTypeError(node=self, context=context) from exc\n2910             else:\n2911                 raise AstroidTypeError(node=self, context=context) from exc\n2912 \n2913         method = methods[0]\n2914 \n2915         # Create a new callcontext for providing index as an argument.\n2916         new_context = bind_context_to_node(context, self)\n2917         new_context.callcontext = CallContext(args=[index], callee=method)\n2918 \n2919         try:\n2920             return next(method.infer_call_result(self, new_context), util.Uninferable)\n2921         except AttributeError:\n2922             # Starting with python3.9, builtin types list, dict etc...\n2923             # are subscriptable thanks to __class_getitem___ classmethod.\n2924             # However in such case the method is bound to an EmptyNode and\n2925             # EmptyNode doesn't have infer_call_result method yielding to\n2926             # AttributeError\n2927             if (\n2928                 isinstance(method, node_classes.EmptyNode)\n2929                 and self.name in {\"list\", \"dict\", \"set\", \"tuple\", \"frozenset\"}\n2930                 and PY39_PLUS\n2931             ):\n2932                 return self\n2933             raise\n2934         except InferenceError:\n2935             return util.Uninferable\n2936 \n2937     def methods(self):\n2938         \"\"\"Iterate over all of the method defined in this class and its parents.\n2939 \n2940         :returns: The methods defined on the class.\n2941         :rtype: iterable(FunctionDef)\n2942         \"\"\"\n2943         done = {}\n2944         for astroid in itertools.chain(iter((self,)), self.ancestors()):\n2945             for meth in astroid.mymethods():\n2946                 if meth.name in done:\n2947                     continue\n2948                 done[meth.name] = None\n2949                 yield meth\n2950 \n2951     def mymethods(self):\n2952         \"\"\"Iterate over all of the method defined in this class only.\n2953 \n2954         :returns: The methods defined on the class.\n2955         :rtype: iterable(FunctionDef)\n2956         \"\"\"\n2957         for member in self.values():\n2958             if isinstance(member, FunctionDef):\n2959                 yield member\n2960 \n2961     def implicit_metaclass(self):\n2962         \"\"\"Get the implicit metaclass of the current class.\n2963 \n2964         For newstyle classes, this will return an instance of builtins.type.\n2965         For oldstyle classes, it will simply return None, since there's\n2966         no implicit metaclass there.\n2967 \n2968         :returns: The metaclass.\n2969         :rtype: builtins.type or None\n2970         \"\"\"\n2971         if self.newstyle:\n2972             return builtin_lookup(\"type\")[1][0]\n2973         return None\n2974 \n2975     _metaclass = None\n2976 \n2977     def declared_metaclass(self, context=None):\n2978         \"\"\"Return the explicit declared metaclass for the current class.\n2979 \n2980         An explicit declared metaclass is defined\n2981         either by passing the ``metaclass`` keyword argument\n2982         in the class definition line (Python 3) or (Python 2) by\n2983         having a ``__metaclass__`` class attribute, or if there are\n2984         no explicit bases but there is a global ``__metaclass__`` variable.\n2985 \n2986         :returns: The metaclass of this class,\n2987             or None if one could not be found.\n2988         :rtype: NodeNG or None\n2989         \"\"\"\n2990         for base in self.bases:\n2991             try:\n2992                 for baseobj in base.infer(context=context):\n2993                     if isinstance(baseobj, ClassDef) and baseobj.hide:\n2994                         self._metaclass = baseobj._metaclass\n2995                         self._metaclass_hack = True\n2996                         break\n2997             except InferenceError:\n2998                 pass\n2999 \n3000         if self._metaclass:\n3001             # Expects this from Py3k TreeRebuilder\n3002             try:\n3003                 return next(\n3004                     node\n3005                     for node in self._metaclass.infer(context=context)\n3006                     if node is not util.Uninferable\n3007                 )\n3008             except (InferenceError, StopIteration):\n3009                 return None\n3010 \n3011         return None\n3012 \n3013     def _find_metaclass(self, seen=None, context=None):\n3014         if seen is None:\n3015             seen = set()\n3016         seen.add(self)\n3017 \n3018         klass = self.declared_metaclass(context=context)\n3019         if klass is None:\n3020             for parent in self.ancestors(context=context):\n3021                 if parent not in seen:\n3022                     klass = parent._find_metaclass(seen)\n3023                     if klass is not None:\n3024                         break\n3025         return klass\n3026 \n3027     def metaclass(self, context=None):\n3028         \"\"\"Get the metaclass of this class.\n3029 \n3030         If this class does not define explicitly a metaclass,\n3031         then the first defined metaclass in ancestors will be used\n3032         instead.\n3033 \n3034         :returns: The metaclass of this class.\n3035         :rtype: NodeNG or None\n3036         \"\"\"\n3037         return self._find_metaclass(context=context)\n3038 \n3039     def has_metaclass_hack(self):\n3040         return self._metaclass_hack\n3041 \n3042     def _islots(self):\n3043         \"\"\"Return an iterator with the inferred slots.\"\"\"\n3044         if \"__slots__\" not in self.locals:\n3045             return None\n3046         for slots in self.igetattr(\"__slots__\"):\n3047             # check if __slots__ is a valid type\n3048             for meth in ITER_METHODS:\n3049                 try:\n3050                     slots.getattr(meth)\n3051                     break\n3052                 except AttributeInferenceError:\n3053                     continue\n3054             else:\n3055                 continue\n3056 \n3057             if isinstance(slots, node_classes.Const):\n3058                 # a string. Ignore the following checks,\n3059                 # but yield the node, only if it has a value\n3060                 if slots.value:\n3061                     yield slots\n3062                 continue\n3063             if not hasattr(slots, \"itered\"):\n3064                 # we can't obtain the values, maybe a .deque?\n3065                 continue\n3066 \n3067             if isinstance(slots, node_classes.Dict):\n3068                 values = [item[0] for item in slots.items]\n3069             else:\n3070                 values = slots.itered()\n3071             if values is util.Uninferable:\n3072                 continue\n3073             if not values:\n3074                 # Stop the iteration, because the class\n3075                 # has an empty list of slots.\n3076                 return values\n3077 \n3078             for elt in values:\n3079                 try:\n3080                     for inferred in elt.infer():\n3081                         if inferred is util.Uninferable:\n3082                             continue\n3083                         if not isinstance(\n3084                             inferred, node_classes.Const\n3085                         ) or not isinstance(inferred.value, str):\n3086                             continue\n3087                         if not inferred.value:\n3088                             continue\n3089                         yield inferred\n3090                 except InferenceError:\n3091                     continue\n3092 \n3093         return None\n3094 \n3095     def _slots(self):\n3096         if not self.newstyle:\n3097             raise NotImplementedError(\n3098                 \"The concept of slots is undefined for old-style classes.\"\n3099             )\n3100 \n3101         slots = self._islots()\n3102         try:\n3103             first = next(slots)\n3104         except StopIteration as exc:\n3105             # The class doesn't have a __slots__ definition or empty slots.\n3106             if exc.args and exc.args[0] not in (\"\", None):\n3107                 return exc.args[0]\n3108             return None\n3109         return [first] + list(slots)\n3110 \n3111     # Cached, because inferring them all the time is expensive\n3112     @decorators_mod.cached\n3113     def slots(self):\n3114         \"\"\"Get all the slots for this node.\n3115 \n3116         :returns: The names of slots for this class.\n3117             If the class doesn't define any slot, through the ``__slots__``\n3118             variable, then this function will return a None.\n3119             Also, it will return None in the case the slots were not inferred.\n3120         :rtype: list(str) or None\n3121         \"\"\"\n3122 \n3123         def grouped_slots(\n3124             mro: List[\"ClassDef\"],\n3125         ) -> typing.Iterator[Optional[node_classes.NodeNG]]:\n3126             # Not interested in object, since it can't have slots.\n3127             for cls in mro[:-1]:\n3128                 try:\n3129                     cls_slots = cls._slots()\n3130                 except NotImplementedError:\n3131                     continue\n3132                 if cls_slots is not None:\n3133                     yield from cls_slots\n3134                 else:\n3135                     yield None\n3136 \n3137         if not self.newstyle:\n3138             raise NotImplementedError(\n3139                 \"The concept of slots is undefined for old-style classes.\"\n3140             )\n3141 \n3142         try:\n3143             mro = self.mro()\n3144         except MroError as e:\n3145             raise NotImplementedError(\n3146                 \"Cannot get slots while parsing mro fails.\"\n3147             ) from e\n3148 \n3149         slots = list(grouped_slots(mro))\n3150         if not all(slot is not None for slot in slots):\n3151             return None\n3152 \n3153         return sorted(set(slots), key=lambda item: item.value)\n3154 \n3155     def _inferred_bases(self, context=None):\n3156         # Similar with .ancestors, but the difference is when one base is inferred,\n3157         # only the first object is wanted. That's because\n3158         # we aren't interested in superclasses, as in the following\n3159         # example:\n3160         #\n3161         # class SomeSuperClass(object): pass\n3162         # class SomeClass(SomeSuperClass): pass\n3163         # class Test(SomeClass): pass\n3164         #\n3165         # Inferring SomeClass from the Test's bases will give\n3166         # us both SomeClass and SomeSuperClass, but we are interested\n3167         # only in SomeClass.\n3168 \n3169         if context is None:\n3170             context = InferenceContext()\n3171         if not self.bases and self.qname() != \"builtins.object\":\n3172             yield builtin_lookup(\"object\")[1][0]\n3173             return\n3174 \n3175         for stmt in self.bases:\n3176             try:\n3177                 # Find the first non-None inferred base value\n3178                 baseobj = next(\n3179                     b\n3180                     for b in stmt.infer(context=context.clone())\n3181                     if not (isinstance(b, Const) and b.value is None)\n3182                 )\n3183             except (InferenceError, StopIteration):\n3184                 continue\n3185             if isinstance(baseobj, bases.Instance):\n3186                 baseobj = baseobj._proxied\n3187             if not isinstance(baseobj, ClassDef):\n3188                 continue\n3189             if not baseobj.hide:\n3190                 yield baseobj\n3191             else:\n3192                 yield from baseobj.bases\n3193 \n3194     def _compute_mro(self, context=None):\n3195         inferred_bases = list(self._inferred_bases(context=context))\n3196         bases_mro = []\n3197         for base in inferred_bases:\n3198             if base is self:\n3199                 continue\n3200 \n3201             try:\n3202                 mro = base._compute_mro(context=context)\n3203                 bases_mro.append(mro)\n3204             except NotImplementedError:\n3205                 # Some classes have in their ancestors both newstyle and\n3206                 # old style classes. For these we can't retrieve the .mro,\n3207                 # although in Python it's possible, since the class we are\n3208                 # currently working is in fact new style.\n3209                 # So, we fallback to ancestors here.\n3210                 ancestors = list(base.ancestors(context=context))\n3211                 bases_mro.append(ancestors)\n3212 \n3213         unmerged_mro = [[self]] + bases_mro + [inferred_bases]\n3214         unmerged_mro = list(clean_duplicates_mro(unmerged_mro, self, context))\n3215         clean_typing_generic_mro(unmerged_mro)\n3216         return _c3_merge(unmerged_mro, self, context)\n3217 \n3218     def mro(self, context=None) -> List[\"ClassDef\"]:\n3219         \"\"\"Get the method resolution order, using C3 linearization.\n3220 \n3221         :returns: The list of ancestors, sorted by the mro.\n3222         :rtype: list(NodeNG)\n3223         :raises DuplicateBasesError: Duplicate bases in the same class base\n3224         :raises InconsistentMroError: A class' MRO is inconsistent\n3225         \"\"\"\n3226         return self._compute_mro(context=context)\n3227 \n3228     def bool_value(self, context=None):\n3229         \"\"\"Determine the boolean value of this node.\n3230 \n3231         :returns: The boolean value of this node.\n3232             For a :class:`ClassDef` this is always ``True``.\n3233         :rtype: bool\n3234         \"\"\"\n3235         return True\n3236 \n3237     def get_children(self):\n3238         if self.decorators is not None:\n3239             yield self.decorators\n3240 \n3241         yield from self.bases\n3242         if self.keywords is not None:\n3243             yield from self.keywords\n3244         yield from self.body\n3245 \n3246     @decorators_mod.cached\n3247     def _get_assign_nodes(self):\n3248         children_assign_nodes = (\n3249             child_node._get_assign_nodes() for child_node in self.body\n3250         )\n3251         return list(itertools.chain.from_iterable(children_assign_nodes))\n3252 \n3253     def frame(self: T) -> T:\n3254         \"\"\"The node's frame node.\n3255 \n3256         A frame node is a :class:`Module`, :class:`FunctionDef`,\n3257         :class:`ClassDef` or :class:`Lambda`.\n3258 \n3259         :returns: The node itself.\n3260         \"\"\"\n3261         return self\n3262 \n[end of astroid/nodes/scoped_nodes.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n\n\n", "full_output": "```patch\n--- a/astroid/nodes/scoped_nodes.py\n+++ b/astroid/nodes/scoped_nodes.py\n@@ -474,6 +474,10 @@\n     parent: None\n     \n     def __init__(\n+        self,\n+        lineno=None,\n+        col_offset=None,\n+        end_lineno=None,\n+        end_col_offset=None,\n         name,\n         doc,\n         file=None,\n@@ -518,6 +522,10 @@\n         self.body = []\n         \"\"\"The contents of the module.\n \n         :type: list(NodeNG) or None\n         \"\"\"\n+        self.end_lineno = end_lineno\n+        self.end_col_offset = end_col_offset\n+\n     def postinit(self, body=None):\n         \"\"\"Do some setup after initialisation.\n \n@@ -564,6 +572,10 @@\n         return self.fromlineno, self.tolineno\n     \n     def scope_lookup(self, node, name, offset=0):\n+        \"\"\"Lookup where the given variable is assigned.\n+        \n+        :param node: The node to look for assignments up to.\n+            Any assignments after the given node are ignored.\n+        :type node: NodeNG\n+        \n+        :param name: The name of the variable to find assignments for.\n+        :type name: str\n+        \n+        :param offset: The line offset to filter statements up to.\n+        :type offset: int\n+        \n+        :returns: This scope node and the list of assignments associated to the\n+            given name according to the scope where it has been found (locals,\n+            globals or builtin).\n+        :rtype: tuple(str, list(NodeNG))\n+        \"\"\"\n         if name in self.scope_attrs and name not in self.locals:\n             try:\n                 return self, self.getattr(name)\n             except AttributeInferenceError:\n                 return self, ()\n         return self._scope_lookup(node, name, offset)\n```", "model_patch": "--- a/astroid/nodes/scoped_nodes.py\n+++ b/astroid/nodes/scoped_nodes.py\n@@ -474,6 +474,10 @@\n     parent: None\n     \n     def __init__(\n+        self,\n+        lineno=None,\n+        col_offset=None,\n+        end_lineno=None,\n+        end_col_offset=None,\n         name,\n         doc,\n         file=None,\n@@ -518,6 +522,10 @@\n         self.body = []\n         \"\"\"The contents of the module.\n \n         :type: list(NodeNG) or None\n         \"\"\"\n+        self.end_lineno = end_lineno\n+        self.end_col_offset = end_col_offset\n+\n     def postinit(self, body=None):\n         \"\"\"Do some setup after initialisation.\n \n@@ -564,6 +572,10 @@\n         return self.fromlineno, self.tolineno\n     \n     def scope_lookup(self, node, name, offset=0):\n+        \"\"\"Lookup where the given variable is assigned.\n+        \n+        :param node: The node to look for assignments up to.\n+            Any assignments after the given node are ignored.\n+        :type node: NodeNG\n+        \n+        :param name: The name of the variable to find assignments for.\n+        :type name: str\n+        \n+        :param offset: The line offset to filter statements up to.\n+        :type offset: int\n+        \n+        :returns: This scope node and the list of assignments associated to the\n+            given name according to the scope where it has been found (locals,\n+            globals or builtin).\n+        :rtype: tuple(str, list(NodeNG))\n+        \"\"\"\n         if name in self.scope_attrs and name not in self.locals:\n             try:\n                 return self, self.getattr(name)\n             except AttributeInferenceError:\n                 return self, ()\n         return self._scope_lookup(node, name, offset)\n"}
{"instance_id": "pyvista__pyvista-4311", "model_name_or_path": "gpt-4o-mini", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nAllow passing through cell data in `to_tetrahedra` method in RectilinearGrid\n### Describe the feature you would like to be added.\n\nNo cell data is passed through when converting to a tetrahedra.  The user can currently request to pass through the original cell id, but it requires one more step to regenerate the cell data on the tetrahedralized mesh.\n\n### Links to VTK Documentation, Examples, or Class Definitions.\n\n_No response_\n\n### Pseudocode or Screenshots\n\nCurrently we have to do\r\n\r\n```python\r\nmesh # Rectilinear or UniformGrid, which has cell data \"cell_data\"\r\ntetra_mesh = mesh.to_tetrahedra(pass_cell_ids=True)\r\ntetra_mesh[\"cell_data\"] = mesh[\"cell_data\"][tetra_mesh.cell_data.active_scalars]\r\n```\r\n\r\nIt would be better to do something like\r\n\r\n```python\r\nmesh # Rectilinear or UniformGrid, which has cell data \"cell_data\"\r\ntetra_mesh = mesh.to_tetrahedra(pass_cell_data=True)  # the prior code would occur inside the method\r\n```\n\n</issue>\n<code>\n[start of README.rst]\n1 #######\n2 PyVista\n3 #######\n4 \n5 .. image:: https://github.com/pyvista/pyvista/raw/main/doc/source/_static/pyvista_banner_small.png\n6    :target: https://docs.pyvista.org/examples/index.html\n7    :alt: pyvista\n8 \n9 \n10 .. |zenodo| image:: https://zenodo.org/badge/92974124.svg\n11    :target: https://zenodo.org/badge/latestdoi/92974124\n12 \n13 .. |joss| image:: http://joss.theoj.org/papers/10.21105/joss.01450/status.svg\n14    :target: https://doi.org/10.21105/joss.01450\n15 \n16 .. |pypi| image:: https://img.shields.io/pypi/v/pyvista.svg?logo=python&logoColor=white\n17    :target: https://pypi.org/project/pyvista/\n18 \n19 .. |conda| image:: https://img.shields.io/conda/vn/conda-forge/pyvista.svg?logo=conda-forge&logoColor=white\n20    :target: https://anaconda.org/conda-forge/pyvista\n21 \n22 .. |GH-CI| image:: https://github.com/pyvista/pyvista/actions/workflows/testing-and-deployment.yml/badge.svg\n23    :target: https://github.com/pyvista/pyvista/actions/workflows/testing-and-deployment.yml\n24 \n25 .. |codecov| image:: https://codecov.io/gh/pyvista/pyvista/branch/main/graph/badge.svg\n26    :target: https://codecov.io/gh/pyvista/pyvista\n27 \n28 .. |codacy| image:: https://app.codacy.com/project/badge/Grade/779ac6aed37548839384acfc0c1aab44\n29    :target: https://www.codacy.com/gh/pyvista/pyvista/dashboard?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=pyvista/pyvista&amp;utm_campaign=Badge_Grade\n30 \n31 .. |MIT| image:: https://img.shields.io/badge/License-MIT-yellow.svg\n32    :target: https://opensource.org/licenses/MIT\n33 \n34 .. |slack| image:: https://img.shields.io/badge/Slack-pyvista-green.svg?logo=slack\n35    :target: http://slack.pyvista.org\n36 \n37 .. |PyPIact| image:: https://img.shields.io/pypi/dm/pyvista.svg?label=PyPI%20downloads\n38    :target: https://pypi.org/project/pyvista/\n39 \n40 .. |condaact| image:: https://img.shields.io/conda/dn/conda-forge/pyvista.svg?label=Conda%20downloads\n41    :target: https://anaconda.org/conda-forge/pyvista\n42 \n43 .. |discuss| image:: https://img.shields.io/badge/GitHub-Discussions-green?logo=github\n44    :target: https://github.com/pyvista/pyvista/discussions\n45 \n46 .. |isort| image:: https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat\n47   :target: https://timothycrosley.github.io/isort\n48   :alt: isort\n49 \n50 .. |black| image:: https://img.shields.io/badge/code%20style-black-000000.svg?style=flat\n51   :target: https://github.com/psf/black\n52   :alt: black\n53 \n54 .. |python| image:: https://img.shields.io/badge/python-3.8+-blue.svg\n55    :target: https://www.python.org/downloads/\n56 \n57 .. |NumFOCUS Affiliated| image:: https://img.shields.io/badge/affiliated-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A\n58    :target: https://numfocus.org/sponsored-projects/affiliated-projects\n59 \n60 .. |pre-commit.ci status| image:: https://results.pre-commit.ci/badge/github/pyvista/pyvista/main.svg\n61    :target: https://results.pre-commit.ci/latest/github/pyvista/pyvista/main\n62 \n63 \n64 +----------------------+------------------------+-------------+\n65 | Deployment           | |pypi|                 | |conda|     |\n66 +----------------------+------------------------+-------------+\n67 | Build Status         | |GH-CI|                | |python|    |\n68 |                      +------------------------+-------------+\n69 |                      | |pre-commit.ci status| |             |\n70 +----------------------+------------------------+-------------+\n71 | Metrics              | |codacy|               | |codecov|   |\n72 +----------------------+------------------------+-------------+\n73 | Activity             | |PyPIact|              | |condaact|  |\n74 +----------------------+------------------------+-------------+\n75 | Citation             | |joss|                 | |zenodo|    |\n76 +----------------------+------------------------+-------------+\n77 | License              | |MIT|                  |             |\n78 +----------------------+------------------------+-------------+\n79 | Community            | |slack|                | |discuss|   |\n80 +----------------------+------------------------+-------------+\n81 | Formatter            | |black|                | |isort|     |\n82 +----------------------+------------------------+-------------+\n83 | Affiliated           | |NumFOCUS Affiliated|                |\n84 +----------------------+------------------------+-------------+\n85 \n86 \n87     3D plotting and mesh analysis through a streamlined interface for the Visualization Toolkit (VTK)\n88 \n89 PyVista is:\n90 \n91 * *Pythonic VTK*: a high-level API to the `Visualization Toolkit`_ (VTK)\n92 * mesh data structures and filtering methods for spatial datasets\n93 * 3D plotting made simple and built for large/complex data geometries\n94 \n95 .. _Visualization Toolkit: https://vtk.org\n96 \n97 PyVista is a helper module for the Visualization Toolkit (VTK) that wraps the VTK library\n98 through NumPy and direct array access through a variety of methods and classes.\n99 This package provides a Pythonic, well-documented interface exposing\n100 VTK's powerful visualization backend to facilitate rapid prototyping, analysis,\n101 and visual integration of spatially referenced datasets.\n102 \n103 This module can be used for scientific plotting for presentations and research\n104 papers as well as a supporting module for other mesh 3D rendering dependent\n105 Python modules; see Connections for a list of projects that leverage\n106 PyVista.\n107 \n108 \n109 .. |tweet| image:: https://img.shields.io/twitter/url.svg?style=social&url=http%3A%2F%2Fshields.io\n110    :target: https://twitter.com/intent/tweet?text=Check%20out%20this%20project%20for%203D%20visualization%20in%20Python&url=https://github.com/pyvista/pyvista&hashtags=3D,visualization,Python,vtk,mesh,plotting,PyVista\n111 \n112 Share this project on Twitter: |tweet|\n113 \n114 \n115 PyVista is a NumFOCUS affiliated project\n116 \n117 .. image:: https://raw.githubusercontent.com/numfocus/templates/master/images/numfocus-logo.png\n118    :target: https://numfocus.org/sponsored-projects/affiliated-projects\n119    :alt: NumFOCUS affiliated projects\n120    :height: 60px\n121 \n122 \n123 Highlights\n124 ==========\n125 \n126 .. |binder| image:: https://static.mybinder.org/badge_logo.svg\n127    :target: https://mybinder.org/v2/gh/pyvista/pyvista-examples/master\n128    :alt: Launch on Binder\n129 \n130 Head over to the `Quick Examples`_ page in the docs to explore our gallery of\n131 examples showcasing what PyVista can do. Want to test-drive PyVista?\n132 All of the examples from the gallery are live on MyBinder for you to test\n133 drive without installing anything locally: |binder|\n134 \n135 .. _Quick Examples: http://docs.pyvista.org/examples/index.html\n136 \n137 \n138 Overview of Features\n139 --------------------\n140 \n141 * Extensive gallery of examples (see `Quick Examples`_)\n142 * Interactive plotting in Jupyter Notebooks with server-side and client-side\n143   rendering with `trame`_.\n144 * Filtering/plotting tools built for interactivity (see `Widgets`_)\n145 * Direct access to mesh analysis and transformation routines (see Filters_)\n146 * Intuitive plotting routines with ``matplotlib`` similar syntax (see Plotting_)\n147 * Import meshes from many common formats (use ``pyvista.read()``). Support for all formats handled by `meshio`_ is built-in.\n148 * Export meshes as VTK, STL, OBJ, or PLY (``mesh.save()``) file types or any formats supported by meshio_ (``pyvista.save_meshio()``)\n149 \n150 .. _trame: https://github.com/Kitware/trame\n151 .. _Widgets: https://docs.pyvista.org/api/plotting/index.html#widget-api\n152 .. _Filters: https://docs.pyvista.org/api/core/filters.html\n153 .. _Plotting: https://docs.pyvista.org/api/plotting/index.html\n154 .. _meshio: https://github.com/nschloe/meshio\n155 \n156 \n157 Documentation\n158 =============\n159 \n160 Refer to the `documentation <http://docs.pyvista.org/>`_ for detailed\n161 installation and usage details.\n162 \n163 For general questions about the project, its applications, or about software\n164 usage, please create a discussion in `pyvista/discussions`_\n165 where the community can collectively address your questions. You are also\n166 welcome to join us on Slack_ or send one of the developers an email.\n167 The project support team can be reached at `info@pyvista.org`_.\n168 \n169 .. _pyvista/discussions: https://github.com/pyvista/pyvista/discussions\n170 .. _Slack: http://slack.pyvista.org\n171 .. _info@pyvista.org: mailto:info@pyvista.org\n172 \n173 \n174 Installation\n175 ============\n176 \n177 PyVista can be installed from `PyPI <https://pypi.org/project/pyvista/>`_\n178 using ``pip`` on Python >= 3.8::\n179 \n180     pip install pyvista\n181 \n182 You can also visit `PyPI <https://pypi.org/project/pyvista/>`_,\n183 `Anaconda <https://anaconda.org/conda-forge/pyvista>`_, or\n184 `GitHub <https://github.com/pyvista/pyvista>`_ to download the source.\n185 \n186 See the `Installation <http://docs.pyvista.org/getting-started/installation.html#install-ref.>`_\n187 for more details regarding optional dependencies or if the installation through pip doesn't work out.\n188 \n189 \n190 Connections\n191 ===========\n192 \n193 PyVista is a powerful tool that researchers can harness to create compelling,\n194 integrated visualizations of large datasets in an intuitive, Pythonic manner.\n195 \n196 Learn more about how PyVista is used across science and engineering disciplines\n197 by a diverse community of users on our `Connections page`_.\n198 \n199 .. _Connections page: https://docs.pyvista.org/getting-started/connections.html\n200 \n201 \n202 Authors\n203 =======\n204 \n205 Please take a look at the `contributors page`_ and the active `list of authors`_\n206 to learn more about the developers of PyVista.\n207 \n208 .. _contributors page: https://github.com/pyvista/pyvista/graphs/contributors/\n209 .. _list of authors: https://docs.pyvista.org/getting-started/authors.html#authors\n210 \n211 \n212 Contributing\n213 ============\n214 \n215 .. |Contributor Covenant| image:: https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg\n216    :target: CODE_OF_CONDUCT.md\n217 \n218 .. |codetriage| image:: https://www.codetriage.com/pyvista/pyvista/badges/users.svg\n219    :target: https://www.codetriage.com/pyvista/pyvista\n220    :alt: Code Triage\n221 \n222 |Contributor Covenant|\n223 |codetriage|\n224 \n225 We absolutely welcome contributions and we hope that our `Contributing Guide`_\n226 will facilitate your ability to make PyVista better. PyVista is mostly\n227 maintained on a volunteer basis and thus we need to foster a community that can\n228 support user questions and develop new features to make this software a useful\n229 tool for all users while encouraging every member of the community to share\n230 their ideas. To learn more about contributing to PyVista, please see the\n231 `Contributing Guide`_ and our `Code of Conduct`_.\n232 \n233 .. _Contributing Guide: https://github.com/pyvista/pyvista/blob/main/CONTRIBUTING.rst\n234 .. _Code of Conduct: https://github.com/pyvista/pyvista/blob/main/CODE_OF_CONDUCT.md\n235 \n236 \n237 Citing PyVista\n238 ==============\n239 \n240 There is a `paper about PyVista <https://doi.org/10.21105/joss.01450>`_.\n241 \n242 If you are using PyVista in your scientific research, please help our scientific\n243 visibility by citing our work.\n244 \n245 \n246     Sullivan and Kaszynski, (2019). PyVista: 3D plotting and mesh analysis through a streamlined interface for the Visualization Toolkit (VTK). Journal of Open Source Software, 4(37), 1450, https://doi.org/10.21105/joss.01450\n247 \n248 \n249 BibTex:\n250 \n251 .. code::\n252 \n253     @article{sullivan2019pyvista,\n254       doi = {10.21105/joss.01450},\n255       url = {https://doi.org/10.21105/joss.01450},\n256       year = {2019},\n257       month = {May},\n258       publisher = {The Open Journal},\n259       volume = {4},\n260       number = {37},\n261       pages = {1450},\n262       author = {Bane Sullivan and Alexander Kaszynski},\n263       title = {{PyVista}: {3D} plotting and mesh analysis through a streamlined interface for the {Visualization Toolkit} ({VTK})},\n264       journal = {Journal of Open Source Software}\n265     }\n266 \n[end of README.rst]\n[start of pyvista/core/datasetattributes.py]\n1 \"\"\"Implements DataSetAttributes, which represents and manipulates datasets.\"\"\"\n2 \n3 from typing import Any, Dict, Iterator, List, Optional, Sequence, Tuple, Union\n4 \n5 import numpy as np\n6 \n7 from pyvista import _vtk\n8 import pyvista.utilities.helpers as helpers\n9 from pyvista.utilities.helpers import FieldAssociation\n10 from pyvista.utilities.misc import copy_vtk_array\n11 \n12 from .._typing import Number\n13 from .pyvista_ndarray import pyvista_ndarray\n14 \n15 # from https://vtk.org/doc/nightly/html/vtkDataSetAttributes_8h_source.html\n16 attr_type = [\n17     'SCALARS',  # 0\n18     'VECTORS',  # 1\n19     'NORMALS',  # 2\n20     'TCOORDS',  # 3\n21     'TENSORS',  # 4\n22     'GLOBALIDS',  # 5\n23     'PEDIGREEIDS',  # 6\n24     'EDGEFLAG',  # 7\n25     'TANGENTS',  # 8\n26     'RATIONALWEIGHTS',  # 9\n27     'HIGHERORDERDEGREES',  # 10\n28     '',  # 11  (not an attribute)\n29 ]\n30 \n31 # used to check if default args have changed in pop\n32 _SENTINEL = pyvista_ndarray([])\n33 \n34 \n35 class DataSetAttributes(_vtk.VTKObjectWrapper):\n36     \"\"\"Python friendly wrapper of ``vtk.DataSetAttributes``.\n37 \n38     This class provides the ability to pick one of the present arrays as the\n39     currently active array for each attribute type by implementing a\n40     ``dict`` like interface.\n41 \n42     When adding data arrays but not desiring to set them as active\n43     scalars or vectors, use :func:`DataSetAttributes.set_array`.\n44 \n45     When adding directional data (such as velocity vectors), use\n46     :func:`DataSetAttributes.set_vectors`.\n47 \n48     When adding non-directional data (such as temperature values or\n49     multi-component scalars like RGBA values), use\n50     :func:`DataSetAttributes.set_scalars`.\n51 \n52     .. versionchanged:: 0.32.0\n53         The ``[]`` operator no longer allows integers.  Use\n54         :func:`DataSetAttributes.get_array` to retrieve an array\n55         using an index.\n56 \n57     Parameters\n58     ----------\n59     vtkobject : vtkFieldData\n60         The vtk object to wrap as a DataSetAttribute, usually an\n61         instance of ``vtk.vtkCellData``, ``vtk.vtkPointData``, or\n62         ``vtk.vtkFieldData``.\n63 \n64     dataset : vtkDataSet\n65         The vtkDataSet containing the vtkobject.\n66 \n67     association : FieldAssociation\n68         The array association type of the vtkobject.\n69 \n70     Notes\n71     -----\n72     When printing out the point arrays, you can see which arrays are\n73     the active scalars, vectors, normals, and texture coordinates.\n74     In the arrays list, ``SCALARS`` denotes that these are the active\n75     scalars, ``VECTORS`` denotes that these arrays are tagged as the\n76     active vectors data (i.e. data with magnitude and direction) and\n77     so on.\n78 \n79     Examples\n80     --------\n81     Store data with point association in a DataSet.\n82 \n83     >>> import pyvista\n84     >>> mesh = pyvista.Cube()\n85     >>> mesh.point_data['my_data'] = range(mesh.n_points)\n86     >>> data = mesh.point_data['my_data']\n87     >>> data\n88     pyvista_ndarray([0, 1, 2, 3, 4, 5, 6, 7])\n89 \n90     Change the data array and show that this is reflected in the DataSet.\n91 \n92     >>> data[:] = 0\n93     >>> mesh.point_data['my_data']\n94     pyvista_ndarray([0, 0, 0, 0, 0, 0, 0, 0])\n95 \n96     Remove the array.\n97 \n98     >>> del mesh.point_data['my_data']\n99     >>> 'my_data' in mesh.point_data\n100     False\n101 \n102     Print the available arrays from dataset attributes.\n103 \n104     >>> import numpy as np\n105     >>> mesh = pyvista.Plane(i_resolution=1, j_resolution=1)\n106     >>> mesh.point_data.set_array(range(4), 'my-data')\n107     >>> mesh.point_data.set_array(range(5, 9), 'my-other-data')\n108     >>> vectors0 = np.random.random((4, 3))\n109     >>> mesh.point_data.set_vectors(vectors0, 'vectors0')\n110     >>> vectors1 = np.random.random((4, 3))\n111     >>> mesh.point_data.set_vectors(vectors1, 'vectors1')\n112     >>> mesh.point_data\n113     pyvista DataSetAttributes\n114     Association     : POINT\n115     Active Scalars  : None\n116     Active Vectors  : vectors1\n117     Active Texture  : TextureCoordinates\n118     Active Normals  : Normals\n119     Contains arrays :\n120         Normals                 float32    (4, 3)               NORMALS\n121         TextureCoordinates      float32    (4, 2)               TCOORDS\n122         my-data                 int64      (4,)\n123         my-other-data           int64      (4,)\n124         vectors1                float64    (4, 3)               VECTORS\n125         vectors0                float64    (4, 3)\n126 \n127     \"\"\"\n128 \n129     def __init__(\n130         self, vtkobject: _vtk.vtkFieldData, dataset: _vtk.vtkDataSet, association: FieldAssociation\n131     ):\n132         \"\"\"Initialize DataSetAttributes.\"\"\"\n133         super().__init__(vtkobject=vtkobject)\n134         self.dataset = dataset\n135         self.association = association\n136 \n137     def __repr__(self) -> str:\n138         \"\"\"Printable representation of DataSetAttributes.\"\"\"\n139         info = ['pyvista DataSetAttributes']\n140         array_info = ' None'\n141         if self:\n142             lines = []\n143             for i, (name, array) in enumerate(self.items()):\n144                 if len(name) > 23:\n145                     name = f'{name[:20]}...'\n146                 try:\n147                     arr_type = attr_type[self.IsArrayAnAttribute(i)]\n148                 except (IndexError, TypeError, AttributeError):  # pragma: no cover\n149                     arr_type = ''\n150 \n151                 # special treatment for vector data\n152                 if self.association in [FieldAssociation.POINT, FieldAssociation.CELL]:\n153                     if name == self.active_vectors_name:\n154                         arr_type = 'VECTORS'\n155 \n156                 line = f'{name[:23]:<24}{str(array.dtype):<11}{str(array.shape):<20} {arr_type}'.strip()\n157                 lines.append(line)\n158             array_info = '\\n    ' + '\\n    '.join(lines)\n159 \n160         info.append(f'Association     : {self.association.name}')\n161         if self.association in [FieldAssociation.POINT, FieldAssociation.CELL]:\n162             info.append(f'Active Scalars  : {self.active_scalars_name}')\n163             info.append(f'Active Vectors  : {self.active_vectors_name}')\n164             info.append(f'Active Texture  : {self.active_t_coords_name}')\n165             info.append(f'Active Normals  : {self.active_normals_name}')\n166 \n167         info.append(f'Contains arrays :{array_info}')\n168         return '\\n'.join(info)\n169 \n170     def get(self, key: str, value: Optional[Any] = None) -> Optional[pyvista_ndarray]:\n171         \"\"\"Return the value of the item with the specified key.\n172 \n173         Parameters\n174         ----------\n175         key : str\n176             Name of the array item you want to return the value from.\n177 \n178         value : Any, optional\n179             A value to return if the key does not exist.  Default\n180             is ``None``.\n181 \n182         Returns\n183         -------\n184         Any\n185             Array if the ``key`` exists in the dataset, otherwise\n186             ``value``.\n187 \n188         Examples\n189         --------\n190         Show that the default return value for a non-existent key is\n191         ``None``.\n192 \n193         >>> import pyvista\n194         >>> mesh = pyvista.Cube()\n195         >>> mesh.point_data['my_data'] = range(mesh.n_points)\n196         >>> mesh.point_data.get('my-other-data')\n197 \n198         \"\"\"\n199         if key in self:\n200             return self[key]\n201         return value\n202 \n203     def __bool__(self) -> bool:\n204         \"\"\"Return ``True`` when there are arrays present.\"\"\"\n205         return bool(self.GetNumberOfArrays())\n206 \n207     def __getitem__(self, key: str) -> pyvista_ndarray:\n208         \"\"\"Implement ``[]`` operator.\n209 \n210         Accepts an array name.\n211         \"\"\"\n212         if not isinstance(key, str):\n213             raise TypeError('Only strings are valid keys for DataSetAttributes.')\n214         return self.get_array(key)\n215 \n216     def __setitem__(self, key: str, value: Union[np.ndarray, Sequence]):\n217         \"\"\"Implement setting with the ``[]`` operator.\"\"\"\n218         if not isinstance(key, str):\n219             raise TypeError('Only strings are valid keys for DataSetAttributes.')\n220 \n221         has_arr = key in self\n222         self.set_array(value, name=key)\n223 \n224         # do not make array active if it already exists.  This covers\n225         # an inplace update like self.point_data[key] += 1\n226         if has_arr:\n227             return\n228 \n229         # make active if not field data and there isn't already an active scalar\n230         if (\n231             self.association\n232             in [\n233                 FieldAssociation.POINT,\n234                 FieldAssociation.CELL,\n235             ]\n236             and self.active_scalars_name is None\n237         ):\n238             self.active_scalars_name = key\n239 \n240     def __delitem__(self, key: str):\n241         \"\"\"Implement del with array name or index.\"\"\"\n242         if not isinstance(key, str):\n243             raise TypeError('Only strings are valid keys for DataSetAttributes.')\n244 \n245         self.remove(key)\n246 \n247     def __contains__(self, name: str) -> bool:\n248         \"\"\"Implement the ``in`` operator.\"\"\"\n249         return name in self.keys()\n250 \n251     def __iter__(self) -> Iterator[str]:\n252         \"\"\"Implement for loop iteration.\"\"\"\n253         yield from self.keys()\n254 \n255     def __len__(self) -> int:\n256         \"\"\"Return the number of arrays.\"\"\"\n257         return self.VTKObject.GetNumberOfArrays()\n258 \n259     @property\n260     def active_scalars(self) -> Optional[pyvista_ndarray]:\n261         \"\"\"Return the active scalars.\n262 \n263         .. versionchanged:: 0.32.0\n264             Can no longer be used to set the active scalars.  Either use\n265             :func:`DataSetAttributes.set_scalars` or if the array\n266             already exists, assign to\n267             :attr:`pyvista.DataSetAttributes.active_scalars_name`.\n268 \n269         Examples\n270         --------\n271         Associate point data to a simple cube mesh and show that the\n272         active scalars in the point array are the most recently added\n273         array.\n274 \n275         >>> import pyvista\n276         >>> import numpy as np\n277         >>> mesh = pyvista.Cube()\n278         >>> mesh.point_data['data0'] = np.arange(mesh.n_points)\n279         >>> mesh.point_data.active_scalars\n280         pyvista_ndarray([0, 1, 2, 3, 4, 5, 6, 7])\n281 \n282         \"\"\"\n283         self._raise_field_data_no_scalars_vectors()\n284         if self.GetScalars() is not None:\n285             array = pyvista_ndarray(\n286                 self.GetScalars(), dataset=self.dataset, association=self.association\n287             )\n288             return self._patch_type(array)\n289         return None\n290 \n291     @property\n292     def active_vectors(self) -> Optional[np.ndarray]:\n293         \"\"\"Return the active vectors as a pyvista_ndarray.\n294 \n295         .. versionchanged:: 0.32.0\n296             Can no longer be used to set the active vectors.  Either use\n297             :func:`DataSetAttributes.set_vectors` or if the array\n298             already exists, assign to\n299             :attr:`pyvista.DataSetAttributes.active_vectors_name`.\n300 \n301         Examples\n302         --------\n303         Associate point data to a simple cube mesh and show that the\n304         active vectors in the point array are the most recently added\n305         array.\n306 \n307         >>> import pyvista\n308         >>> import numpy as np\n309         >>> mesh = pyvista.Cube()\n310         >>> vectors = np.random.random((mesh.n_points, 3))\n311         >>> mesh.point_data.set_vectors(vectors, 'my-vectors')\n312         >>> vectors_out = mesh.point_data.active_vectors\n313         >>> vectors_out.shape\n314         (8, 3)\n315 \n316         \"\"\"\n317         self._raise_field_data_no_scalars_vectors()\n318         vectors = self.GetVectors()\n319         if vectors is not None:\n320             return pyvista_ndarray(vectors, dataset=self.dataset, association=self.association)\n321         return None\n322 \n323     @property\n324     def valid_array_len(self) -> Optional[int]:\n325         \"\"\"Return the length data should be when added to the dataset.\n326 \n327         If there are no restrictions, returns ``None``.\n328 \n329         Examples\n330         --------\n331         Show that valid array lengths match the number of points and\n332         cells for point and cell arrays, and there is no length limit\n333         for field data.\n334 \n335         >>> import pyvista\n336         >>> mesh = pyvista.Cube()\n337         >>> mesh.n_points, mesh.n_cells\n338         (8, 6)\n339         >>> mesh.point_data.valid_array_len\n340         8\n341         >>> mesh.cell_data.valid_array_len\n342         6\n343         >>> mesh.field_data.valid_array_len is None\n344         True\n345 \n346         \"\"\"\n347         if self.association == FieldAssociation.POINT:\n348             return self.dataset.GetNumberOfPoints()\n349         if self.association == FieldAssociation.CELL:\n350             return self.dataset.GetNumberOfCells()\n351         return None\n352 \n353     @property\n354     def active_t_coords(self) -> Optional[pyvista_ndarray]:\n355         \"\"\"Return or set the active texture coordinates array.\n356 \n357         Returns\n358         -------\n359         pyvista.pyvista_ndarray\n360             Array of the active texture coordinates.\n361 \n362         Examples\n363         --------\n364         >>> import pyvista\n365         >>> mesh = pyvista.Cube()\n366         >>> mesh.point_data.active_t_coords\n367         pyvista_ndarray([[ 0.,  0.],\n368                          [ 1.,  0.],\n369                          [ 1.,  1.],\n370                          [ 0.,  1.],\n371                          [-0.,  0.],\n372                          [-0.,  1.],\n373                          [-1.,  1.],\n374                          [-1.,  0.]], dtype=float32)\n375 \n376         \"\"\"\n377         self._raise_no_t_coords()\n378         t_coords = self.GetTCoords()\n379         if t_coords is not None:\n380             return pyvista_ndarray(t_coords, dataset=self.dataset, association=self.association)\n381         return None\n382 \n383     @active_t_coords.setter\n384     def active_t_coords(self, t_coords: np.ndarray):\n385         self._raise_no_t_coords()\n386         if not isinstance(t_coords, np.ndarray):\n387             raise TypeError('Texture coordinates must be a numpy array')\n388         if t_coords.ndim != 2:\n389             raise ValueError('Texture coordinates must be a 2-dimensional array')\n390         valid_length = self.valid_array_len\n391         if t_coords.shape[0] != valid_length:\n392             raise ValueError(\n393                 f'Number of texture coordinates ({t_coords.shape[0]}) must match number of points ({valid_length})'\n394             )\n395         if t_coords.shape[1] != 2:\n396             raise ValueError(\n397                 f'Texture coordinates must only have 2 components, not ({t_coords.shape[1]})'\n398             )\n399         vtkarr = _vtk.numpyTovtkDataArray(t_coords, name='Texture Coordinates')\n400         self.SetTCoords(vtkarr)\n401         self.Modified()\n402 \n403     @property\n404     def active_t_coords_name(self) -> Optional[str]:\n405         \"\"\"Name of the active texture coordinates array.\n406 \n407         Examples\n408         --------\n409         >>> import pyvista\n410         >>> mesh = pyvista.Cube()\n411         >>> mesh.point_data.active_t_coords_name\n412         'TCoords'\n413 \n414         \"\"\"\n415         self._raise_no_t_coords()\n416         if self.GetTCoords() is not None:\n417             return str(self.GetTCoords().GetName())\n418         return None\n419 \n420     @active_t_coords_name.setter\n421     def active_t_coords_name(self, name: str) -> None:\n422         if name is None:\n423             self.SetActiveTCoords(None)\n424             return\n425 \n426         self._raise_no_t_coords()\n427         dtype = self[name].dtype\n428         # only vtkDataArray subclasses can be set as active attributes\n429         if np.issubdtype(dtype, np.number) or dtype == bool:\n430             self.SetActiveTCoords(name)\n431 \n432     def get_array(self, key: Union[str, int]) -> pyvista_ndarray:\n433         \"\"\"Get an array in this object.\n434 \n435         Parameters\n436         ----------\n437         key : str | int\n438             The name or index of the array to return.  Arrays are\n439             ordered within VTK DataSetAttributes, and this feature is\n440             mirrored here.\n441 \n442         Returns\n443         -------\n444         pyvista.pyvista_ndarray\n445             Returns a :class:`pyvista.pyvista_ndarray`.\n446 \n447         Raises\n448         ------\n449         KeyError\n450             If the key does not exist.\n451 \n452         Notes\n453         -----\n454         This is provided since arrays are ordered within VTK and can\n455         be indexed via an int.  When getting an array, you can just\n456         use the key of the array with the ``[]`` operator with the\n457         name of the array.\n458 \n459         Examples\n460         --------\n461         Store data with point association in a DataSet.\n462 \n463         >>> import pyvista\n464         >>> mesh = pyvista.Cube()\n465         >>> mesh.clear_data()\n466         >>> mesh.point_data['my_data'] = range(mesh.n_points)\n467 \n468         Access using an index.\n469 \n470         >>> mesh.point_data.get_array(0)\n471         pyvista_ndarray([0, 1, 2, 3, 4, 5, 6, 7])\n472 \n473         Access using a key.\n474 \n475         >>> mesh.point_data.get_array('my_data')\n476         pyvista_ndarray([0, 1, 2, 3, 4, 5, 6, 7])\n477 \n478         \"\"\"\n479         self._raise_index_out_of_bounds(index=key)\n480         vtk_arr = self.GetArray(key)\n481         if vtk_arr is None:\n482             vtk_arr = self.GetAbstractArray(key)\n483             if vtk_arr is None:\n484                 raise KeyError(f'{key}')\n485         narray = pyvista_ndarray(vtk_arr, dataset=self.dataset, association=self.association)\n486         return self._patch_type(narray)\n487 \n488     def _patch_type(self, narray):\n489         \"\"\"Check if array needs to be represented as a different type.\"\"\"\n490         name = narray.VTKObject.GetName()\n491         if name in self.dataset._association_bitarray_names[self.association.name]:\n492             narray = narray.view(np.bool_)  # type: ignore\n493         elif name in self.dataset._association_complex_names[self.association.name]:\n494             if narray.dtype == np.float32:\n495                 narray = narray.view(np.complex64)  # type: ignore\n496             if narray.dtype == np.float64:\n497                 narray = narray.view(np.complex128)  # type: ignore\n498             # remove singleton dimensions to match the behavior of the rest of 1D\n499             # VTK arrays\n500             narray = narray.squeeze()\n501         return narray\n502 \n503     def set_array(\n504         self, data: Union[Sequence[Number], Number, np.ndarray], name: str, deep_copy=False\n505     ) -> None:\n506         \"\"\"Add an array to this object.\n507 \n508         Use this method when adding arrays to the DataSet.  If\n509         needed, these arrays can later be assigned to become the\n510         active scalars, vectors, normals, or texture coordinates with:\n511 \n512         * :attr:`active_scalars_name <DataSetAttributes.active_scalars_name>`\n513         * :attr:`active_vectors_name <DataSetAttributes.active_vectors_name>`\n514         * :attr:`active_normals_name <DataSetAttributes.active_normals_name>`\n515         * :attr:`active_t_coords_name <DataSetAttributes.active_t_coords_name>`\n516 \n517         Parameters\n518         ----------\n519         data : float | array_like[float]\n520             A :class:`pyvista.pyvista_ndarray`, :class:`numpy.ndarray`,\n521             ``list``, ``tuple`` or scalar value.\n522 \n523         name : str\n524             Name to assign to the data.  If this name already exists,\n525             it will be overwritten.\n526 \n527         deep_copy : bool, optional\n528             When ``True`` makes a full copy of the array.\n529 \n530         Notes\n531         -----\n532         You can simply use the ``[]`` operator to add an array to the\n533         dataset.  Note that this will automatically become the active\n534         scalars.\n535 \n536         Examples\n537         --------\n538         Add a point array to a mesh.\n539 \n540         >>> import pyvista\n541         >>> mesh = pyvista.Cube()\n542         >>> data = range(mesh.n_points)\n543         >>> mesh.point_data.set_array(data, 'my-data')\n544         >>> mesh.point_data['my-data']\n545         pyvista_ndarray([0, 1, 2, 3, 4, 5, 6, 7])\n546 \n547         Add a cell array to a mesh.\n548 \n549         >>> cell_data = range(mesh.n_cells)\n550         >>> mesh.cell_data.set_array(cell_data, 'my-data')\n551         >>> mesh.cell_data['my-data']\n552         pyvista_ndarray([0, 1, 2, 3, 4, 5])\n553 \n554         Add field data to a mesh.\n555 \n556         >>> field_data = range(3)\n557         >>> mesh.field_data.set_array(field_data, 'my-data')\n558         >>> mesh.field_data['my-data']\n559         pyvista_ndarray([0, 1, 2])\n560 \n561         \"\"\"\n562         if not isinstance(name, str):\n563             raise TypeError('`name` must be a string')\n564 \n565         vtk_arr = self._prepare_array(data, name, deep_copy)\n566         self.VTKObject.AddArray(vtk_arr)\n567         self.VTKObject.Modified()\n568 \n569     def set_scalars(\n570         self, scalars: Union[Sequence[Number], Number, np.ndarray], name='scalars', deep_copy=False\n571     ):\n572         \"\"\"Set the active scalars of the dataset with an array.\n573 \n574         In VTK and PyVista, scalars are a quantity that has no\n575         direction.  This can include data with multiple components\n576         (such as RGBA values) or just one component (such as\n577         temperature data).\n578 \n579         See :func:`DataSetAttributes.set_vectors` when adding arrays\n580         that contain magnitude and direction.\n581 \n582         Parameters\n583         ----------\n584         scalars : float | array_like[float]\n585             A :class:`pyvista.pyvista_ndarray`, :class:`numpy.ndarray`, ``list``,\n586             ``tuple`` or scalar value.\n587 \n588         name : str, default: 'scalars'\n589             Name to assign the scalars.\n590 \n591         deep_copy : bool, default: False\n592             When ``True`` makes a full copy of the array.\n593 \n594         Notes\n595         -----\n596         When adding directional data (such as velocity vectors), use\n597         :func:`DataSetAttributes.set_vectors`.\n598 \n599         Complex arrays will be represented internally as a 2 component float64\n600         array. This is due to limitations of VTK's native datatypes.\n601 \n602         Examples\n603         --------\n604         >>> import pyvista\n605         >>> mesh = pyvista.Cube()\n606         >>> mesh.clear_data()\n607         >>> scalars = range(mesh.n_points)\n608         >>> mesh.point_data.set_scalars(scalars, 'my-scalars')\n609         >>> mesh.point_data\n610         pyvista DataSetAttributes\n611         Association     : POINT\n612         Active Scalars  : my-scalars\n613         Active Vectors  : None\n614         Active Texture  : None\n615         Active Normals  : None\n616         Contains arrays :\n617             my-scalars              int64      (8,)                 SCALARS\n618 \n619         \"\"\"\n620         vtk_arr = self._prepare_array(scalars, name, deep_copy)\n621         self.VTKObject.SetScalars(vtk_arr)\n622         self.VTKObject.Modified()\n623 \n624     def set_vectors(\n625         self, vectors: Union[Sequence[Number], Number, np.ndarray], name: str, deep_copy=False\n626     ):\n627         \"\"\"Set the active vectors of this data attribute.\n628 \n629         Vectors are a quantity that has magnitude and direction, such\n630         as normal vectors or a velocity field.\n631 \n632         The vectors data must contain three components per cell or\n633         point.  Use :func:`DataSetAttributes.set_scalars` when\n634         adding non-directional data.\n635 \n636         Parameters\n637         ----------\n638         vectors : float | array_like[float]\n639             A :class:`pyvista.pyvista_ndarray`, :class:`numpy.ndarray`,\n640             ``list``, or ``tuple``.  Must match the number of cells or points\n641             of the dataset.\n642 \n643         name : str\n644             Name of the vectors.\n645 \n646         deep_copy : bool, default: False\n647             When ``True`` makes a full copy of the array.  When\n648             ``False``, the data references the original array\n649             without copying it.\n650 \n651         Notes\n652         -----\n653         PyVista and VTK treats vectors and scalars differently when\n654         performing operations. Vector data, unlike scalar data, is\n655         rotated along with the geometry when the DataSet is passed\n656         through a transformation filter.\n657 \n658         When adding non-directional data (such temperature values or\n659         multi-component scalars like RGBA values), you can also use\n660         :func:`DataSetAttributes.set_scalars`.\n661 \n662         Examples\n663         --------\n664         Add random vectors to a mesh as point data.\n665 \n666         >>> import pyvista\n667         >>> import numpy as np\n668         >>> mesh = pyvista.Cube()\n669         >>> mesh.clear_data()\n670         >>> vectors = np.random.random((mesh.n_points, 3))\n671         >>> mesh.point_data.set_vectors(vectors, 'my-vectors')\n672         >>> mesh.point_data\n673         pyvista DataSetAttributes\n674         Association     : POINT\n675         Active Scalars  : None\n676         Active Vectors  : my-vectors\n677         Active Texture  : None\n678         Active Normals  : None\n679         Contains arrays :\n680             my-vectors              float64    (8, 3)               VECTORS\n681 \n682         \"\"\"\n683         # prepare the array and add an attribute so that we can track this as a vector\n684         vtk_arr = self._prepare_array(vectors, name, deep_copy)\n685 \n686         n_comp = vtk_arr.GetNumberOfComponents()\n687         if n_comp != 3:\n688             raise ValueError(f'Vector array should contain 3 components, got {n_comp}')\n689 \n690         # check if there are current vectors, if so, we need to keep\n691         # this array around since setting active vectors will remove\n692         # this array.\n693         current_vectors = self.GetVectors()\n694 \n695         # now we can set the active vectors and add back in the old vectors as an array\n696         self.VTKObject.SetVectors(vtk_arr)\n697         if current_vectors is not None:\n698             self.VTKObject.AddArray(current_vectors)\n699 \n700         self.VTKObject.Modified()\n701 \n702     def _prepare_array(\n703         self, data: Union[Sequence[Number], Number, np.ndarray], name: str, deep_copy: bool\n704     ) -> _vtk.vtkDataSet:\n705         \"\"\"Prepare an array to be added to this dataset.\n706 \n707         Notes\n708         -----\n709         This method also adds metadata necessary for VTK to support non-VTK\n710         compatible datatypes like ``numpy.complex128`` or ``numpy.bool_`` to\n711         the underlying dataset.\n712 \n713         \"\"\"\n714         if data is None:\n715             raise TypeError('``data`` cannot be None.')\n716 \n717         # attempt to reuse the existing pointer to underlying VTK data\n718         if isinstance(data, pyvista_ndarray):\n719             # pyvista_ndarray already contains the reference to the vtk object\n720             # pyvista needs to use the copy of this object rather than wrapping\n721             # the array (which leaves a C++ pointer uncollected.\n722             if data.VTKObject is not None:\n723                 # VTK doesn't support strides, therefore we can't directly\n724                 # point to the underlying object\n725                 if data.flags.c_contiguous:\n726                     # no reason to return a shallow copy if the array and name\n727                     # are identical, just return the underlying array name\n728                     if not deep_copy and isinstance(name, str) and data.VTKObject.GetName() == name:\n729                         return data.VTKObject\n730 \n731                     vtk_arr = copy_vtk_array(data.VTKObject, deep=deep_copy)\n732                     if isinstance(name, str):\n733                         vtk_arr.SetName(name)\n734                     return vtk_arr\n735 \n736         # convert to numpy type if necessary\n737         data = np.asanyarray(data)\n738 \n739         if self.association == FieldAssociation.POINT:\n740             array_len = self.dataset.GetNumberOfPoints()\n741         elif self.association == FieldAssociation.CELL:\n742             array_len = self.dataset.GetNumberOfCells()\n743         else:\n744             array_len = data.shape[0] if isinstance(data, np.ndarray) else 1\n745 \n746         # Fixup input array length for scalar input\n747         if not isinstance(data, np.ndarray) or np.ndim(data) == 0:\n748             tmparray = np.empty(array_len)\n749             tmparray.fill(data)\n750             data = tmparray\n751         if data.shape[0] != array_len:\n752             raise ValueError(f'data length of ({data.shape[0]}) != required length ({array_len})')\n753 \n754         # reset data association\n755         if name in self.dataset._association_bitarray_names[self.association.name]:\n756             self.dataset._association_bitarray_names[self.association.name].remove(name)\n757         if name in self.dataset._association_complex_names[self.association.name]:\n758             self.dataset._association_complex_names[self.association.name].remove(name)\n759 \n760         if data.dtype == np.bool_:\n761             self.dataset._association_bitarray_names[self.association.name].add(name)\n762             data = data.view(np.uint8)\n763         elif np.issubdtype(data.dtype, np.complexfloating):\n764             if data.dtype not in (np.complex64, np.complex128):\n765                 raise ValueError(\n766                     'Only numpy.complex64 or numpy.complex128 is supported when '\n767                     'setting dataset attributes'\n768                 )\n769 \n770             if data.ndim != 1:\n771                 if data.shape[1] != 1:\n772                     raise ValueError('Complex data must be single dimensional.')\n773             self.dataset._association_complex_names[self.association.name].add(name)\n774 \n775             # complex data is stored internally as a contiguous 2 component\n776             # float arrays\n777             if data.dtype == np.complex64:\n778                 data = data.view(np.float32).reshape(-1, 2)\n779             else:\n780                 data = data.view(np.float64).reshape(-1, 2)\n781 \n782         shape = data.shape\n783         if data.ndim == 3:\n784             # Array of matrices. We need to make sure the order in\n785             # memory is right.  If row major (C/C++),\n786             # transpose. VTK wants column major (Fortran order). The deep\n787             # copy later will make sure that the array is contiguous.\n788             # If column order but not contiguous, transpose so that the\n789             # deep copy below does not happen.\n790             size = data.dtype.itemsize\n791             if (data.strides[1] / size == 3 and data.strides[2] / size == 1) or (\n792                 data.strides[1] / size == 1\n793                 and data.strides[2] / size == 3\n794                 and not data.flags.contiguous\n795             ):\n796                 data = data.transpose(0, 2, 1)\n797 \n798         # If array is not contiguous, make a deep copy that is contiguous\n799         if not data.flags.contiguous:\n800             data = np.ascontiguousarray(data)\n801 \n802         # Flatten array of matrices to array of vectors\n803         if len(shape) == 3:\n804             data = data.reshape(shape[0], shape[1] * shape[2])\n805 \n806         # Swap bytes from big to little endian.\n807         if data.dtype.byteorder == '>':\n808             data = data.byteswap(inplace=True)\n809 \n810         # this handles the case when an input array is directly added to the\n811         # output. We want to make sure that the array added to the output is not\n812         # referring to the input dataset.\n813         copy = pyvista_ndarray(data)\n814 \n815         return helpers.convert_array(copy, name, deep=deep_copy)\n816 \n817     def remove(self, key: str) -> None:\n818         \"\"\"Remove an array.\n819 \n820         Parameters\n821         ----------\n822         key : str\n823             The name of the array to remove.\n824 \n825         Notes\n826         -----\n827         You can also use the ``del`` statement.\n828 \n829         Examples\n830         --------\n831         Add a point data array to a DataSet and then remove it.\n832 \n833         >>> import pyvista\n834         >>> mesh = pyvista.Cube()\n835         >>> mesh.point_data['my_data'] = range(mesh.n_points)\n836         >>> mesh.point_data.remove('my_data')\n837 \n838         Show that the array no longer exists in ``point_data``.\n839 \n840         >>> 'my_data' in mesh.point_data\n841         False\n842 \n843         \"\"\"\n844         if not isinstance(key, str):\n845             raise TypeError('Only strings are valid keys for DataSetAttributes.')\n846 \n847         if key not in self:\n848             raise KeyError(f'{key} not present.')\n849 \n850         try:\n851             self.dataset._association_bitarray_names[self.association.name].remove(key)\n852         except KeyError:\n853             pass\n854         self.VTKObject.RemoveArray(key)\n855         self.VTKObject.Modified()\n856 \n857     def pop(self, key: str, default=_SENTINEL) -> pyvista_ndarray:\n858         \"\"\"Remove an array and return it.\n859 \n860         Parameters\n861         ----------\n862         key : str\n863             The name of the array to remove and return.\n864 \n865         default : Any, optional\n866             If default is not given and key is not in the dictionary,\n867             a KeyError is raised.\n868 \n869         Returns\n870         -------\n871         pyvista_ndarray\n872             Requested array.\n873 \n874         Examples\n875         --------\n876         Add a point data array to a DataSet and then remove it.\n877 \n878         >>> import pyvista\n879         >>> mesh = pyvista.Cube()\n880         >>> mesh.point_data['my_data'] = range(mesh.n_points)\n881         >>> mesh.point_data.pop('my_data')\n882         pyvista_ndarray([0, 1, 2, 3, 4, 5, 6, 7])\n883 \n884         Show that the array no longer exists in ``point_data``.\n885 \n886         >>> 'my_data' in mesh.point_data\n887         False\n888 \n889         \"\"\"\n890         if not isinstance(key, str):\n891             raise TypeError('Only strings are valid keys for DataSetAttributes.')\n892 \n893         if key not in self:\n894             if default is _SENTINEL:\n895                 raise KeyError(f'{key} not present.')\n896             return default\n897 \n898         narray = self.get_array(key)\n899 \n900         self.remove(key)\n901         return narray\n902 \n903     def items(self) -> List[Tuple[str, pyvista_ndarray]]:\n904         \"\"\"Return a list of (array name, array value) tuples.\n905 \n906         Returns\n907         -------\n908         list\n909             List of keys and values.\n910 \n911         Examples\n912         --------\n913         >>> import pyvista\n914         >>> mesh = pyvista.Cube()\n915         >>> mesh.clear_data()\n916         >>> mesh.cell_data['data0'] = [0] * mesh.n_cells\n917         >>> mesh.cell_data['data1'] = range(mesh.n_cells)\n918         >>> mesh.cell_data.items()\n919         [('data0', pyvista_ndarray([0, 0, 0, 0, 0, 0])), ('data1', pyvista_ndarray([0, 1, 2, 3, 4, 5]))]\n920 \n921         \"\"\"\n922         return list(zip(self.keys(), self.values()))\n923 \n924     def keys(self) -> List[str]:\n925         \"\"\"Return the names of the arrays as a list.\n926 \n927         Returns\n928         -------\n929         list\n930             List of keys.\n931 \n932         Examples\n933         --------\n934         >>> import pyvista\n935         >>> mesh = pyvista.Sphere()\n936         >>> mesh.clear_data()\n937         >>> mesh.point_data['data0'] = [0] * mesh.n_points\n938         >>> mesh.point_data['data1'] = range(mesh.n_points)\n939         >>> mesh.point_data.keys()\n940         ['data0', 'data1']\n941 \n942         \"\"\"\n943         keys = []\n944         for i in range(self.GetNumberOfArrays()):\n945             array = self.VTKObject.GetAbstractArray(i)\n946             name = array.GetName()\n947             if name:\n948                 keys.append(name)\n949             else:  # pragma: no cover\n950                 # Assign this array a name\n951                 name = f'Unnamed_{i}'\n952                 array.SetName(name)\n953                 keys.append(name)\n954         return keys\n955 \n956     def values(self) -> List[pyvista_ndarray]:\n957         \"\"\"Return the arrays as a list.\n958 \n959         Returns\n960         -------\n961         list\n962             List of arrays.\n963 \n964         Examples\n965         --------\n966         >>> import pyvista\n967         >>> mesh = pyvista.Cube()\n968         >>> mesh.clear_data()\n969         >>> mesh.cell_data['data0'] = [0] * mesh.n_cells\n970         >>> mesh.cell_data['data1'] = range(mesh.n_cells)\n971         >>> mesh.cell_data.values()\n972         [pyvista_ndarray([0, 0, 0, 0, 0, 0]), pyvista_ndarray([0, 1, 2, 3, 4, 5])]\n973 \n974         \"\"\"\n975         return [self.get_array(name) for name in self.keys()]\n976 \n977     def clear(self):\n978         \"\"\"Remove all arrays in this object.\n979 \n980         Examples\n981         --------\n982         Add an array to ``point_data`` to a DataSet and then clear the\n983         point_data.\n984 \n985         >>> import pyvista\n986         >>> mesh = pyvista.Cube()\n987         >>> mesh.clear_data()\n988         >>> mesh.point_data['my_data'] = range(mesh.n_points)\n989         >>> len(mesh.point_data)\n990         1\n991         >>> mesh.point_data.clear()\n992         >>> len(mesh.point_data)\n993         0\n994 \n995         \"\"\"\n996         for array_name in self.keys():\n997             self.remove(key=array_name)\n998 \n999     def update(self, array_dict: Union[Dict[str, np.ndarray], 'DataSetAttributes']):\n1000         \"\"\"Update arrays in this object from another dictionary or dataset attributes.\n1001 \n1002         For each key, value given, add the pair. If it already exists, replace\n1003         it with the new array. These arrays will be copied.\n1004 \n1005         Parameters\n1006         ----------\n1007         array_dict : dict, DataSetAttributes\n1008             A dictionary of ``(array name, :class:`numpy.ndarray`)`` or a\n1009             :class:`pyvista.DataSetAttributes`.\n1010 \n1011         Examples\n1012         --------\n1013         Add two arrays to ``point_data`` using ``update``.\n1014 \n1015         >>> import numpy as np\n1016         >>> from pyvista import examples\n1017         >>> mesh = examples.load_uniform()\n1018         >>> n = len(mesh.point_data)\n1019         >>> arrays = {\n1020         ...     'foo': np.arange(mesh.n_points),\n1021         ...     'rand': np.random.random(mesh.n_points),\n1022         ... }\n1023         >>> mesh.point_data.update(arrays)\n1024         >>> mesh.point_data\n1025         pyvista DataSetAttributes\n1026         Association     : POINT\n1027         Active Scalars  : Spatial Point Data\n1028         Active Vectors  : None\n1029         Active Texture  : None\n1030         Active Normals  : None\n1031         Contains arrays :\n1032             Spatial Point Data      float64    (1000,)              SCALARS\n1033             foo                     int64      (1000,)\n1034             rand                    float64    (1000,)\n1035 \n1036         \"\"\"\n1037         for name, array in array_dict.items():\n1038             self[name] = array.copy()\n1039 \n1040     def _raise_index_out_of_bounds(self, index: Any):\n1041         if isinstance(index, int):\n1042             max_index = self.VTKObject.GetNumberOfArrays()\n1043             if not 0 <= index < max_index:\n1044                 raise KeyError(f'Array index ({index}) out of range [0, {max_index - 1}]')\n1045 \n1046     def _raise_field_data_no_scalars_vectors(self):\n1047         \"\"\"Raise a TypeError if FieldData.\"\"\"\n1048         if self.association == FieldAssociation.NONE:\n1049             raise TypeError('FieldData does not have active scalars or vectors.')\n1050 \n1051     @property\n1052     def active_scalars_name(self) -> Optional[str]:\n1053         \"\"\"Name of the active scalars.\n1054 \n1055         Examples\n1056         --------\n1057         Add two arrays to the mesh point data. Note how the first array becomes\n1058         the active scalars since the ``mesh`` contained no scalars.\n1059 \n1060         >>> import pyvista\n1061         >>> mesh = pyvista.Sphere()\n1062         >>> mesh.point_data['my_data'] = range(mesh.n_points)\n1063         >>> mesh.point_data['my_other_data'] = range(mesh.n_points)\n1064         >>> mesh.point_data.active_scalars_name\n1065         'my_data'\n1066 \n1067         Set the name of the active scalars.\n1068 \n1069         >>> mesh.point_data.active_scalars_name = 'my_other_data'\n1070         >>> mesh.point_data.active_scalars_name\n1071         'my_other_data'\n1072 \n1073         \"\"\"\n1074         if self.GetScalars() is not None:\n1075             return str(self.GetScalars().GetName())\n1076         return None\n1077 \n1078     @active_scalars_name.setter\n1079     def active_scalars_name(self, name: str) -> None:\n1080         # permit setting no active scalars\n1081         if name is None:\n1082             self.SetActiveScalars(None)\n1083             return\n1084         self._raise_field_data_no_scalars_vectors()\n1085         dtype = self[name].dtype\n1086         # only vtkDataArray subclasses can be set as active attributes\n1087         if np.issubdtype(dtype, np.number) or dtype == bool:\n1088             self.SetActiveScalars(name)\n1089 \n1090     @property\n1091     def active_vectors_name(self) -> Optional[str]:\n1092         \"\"\"Name of the active vectors.\n1093 \n1094         Examples\n1095         --------\n1096         >>> import pyvista\n1097         >>> import numpy as np\n1098         >>> mesh = pyvista.Sphere()\n1099         >>> mesh.point_data.set_vectors(\n1100         ...     np.random.random((mesh.n_points, 3)), 'my-vectors'\n1101         ... )\n1102         >>> mesh.point_data.active_vectors_name\n1103         'my-vectors'\n1104 \n1105         \"\"\"\n1106         if self.GetVectors() is not None:\n1107             return str(self.GetVectors().GetName())\n1108         return None\n1109 \n1110     @active_vectors_name.setter\n1111     def active_vectors_name(self, name: str) -> None:\n1112         # permit setting no active\n1113         if name is None:\n1114             self.SetActiveVectors(None)\n1115             return\n1116         self._raise_field_data_no_scalars_vectors()\n1117         if name not in self:\n1118             raise KeyError(f'DataSetAttribute does not contain \"{name}\"')\n1119         # verify that the array has the correct number of components\n1120         n_comp = self.GetArray(name).GetNumberOfComponents()\n1121         if n_comp != 3:\n1122             raise ValueError(f'{name} needs 3 components, has ({n_comp})')\n1123         self.SetActiveVectors(name)\n1124 \n1125     def __eq__(self, other: Any) -> bool:\n1126         \"\"\"Test dict-like equivalency.\"\"\"\n1127         # here we check if other is the same class or a subclass of self.\n1128         if not isinstance(other, type(self)):\n1129             return False\n1130 \n1131         if set(self.keys()) != set(other.keys()):\n1132             return False\n1133 \n1134         # verify the value of the arrays\n1135         for key, value in other.items():\n1136             if not np.array_equal(value, self[key]):\n1137                 return False\n1138 \n1139         # check the name of the active attributes\n1140         if self.association != FieldAssociation.NONE:\n1141             for name in ['scalars', 'vectors', 't_coords', 'normals']:\n1142                 attr = f'active_{name}_name'\n1143                 if getattr(other, attr) != getattr(self, attr):\n1144                     return False\n1145 \n1146         return True\n1147 \n1148     @property\n1149     def active_normals(self) -> Optional[pyvista_ndarray]:\n1150         \"\"\"Return or set the normals.\n1151 \n1152         Returns\n1153         -------\n1154         pyvista_ndarray\n1155             Normals of this dataset attribute.  ``None`` if no\n1156             normals have been set.\n1157 \n1158         Notes\n1159         -----\n1160         Field data will have no normals.\n1161 \n1162         Examples\n1163         --------\n1164         First, compute cell normals.\n1165 \n1166         >>> import pyvista\n1167         >>> mesh = pyvista.Plane(i_resolution=1, j_resolution=1)\n1168         >>> mesh.point_data\n1169         pyvista DataSetAttributes\n1170         Association     : POINT\n1171         Active Scalars  : None\n1172         Active Vectors  : None\n1173         Active Texture  : TextureCoordinates\n1174         Active Normals  : Normals\n1175         Contains arrays :\n1176             Normals                 float32    (4, 3)               NORMALS\n1177             TextureCoordinates      float32    (4, 2)               TCOORDS\n1178 \n1179         >>> mesh.point_data.active_normals\n1180         pyvista_ndarray([[0.000000e+00,  0.000000e+00, -1.000000e+00],\n1181                          [0.000000e+00,  0.000000e+00, -1.000000e+00],\n1182                          [0.000000e+00,  0.000000e+00, -1.000000e+00],\n1183                          [0.000000e+00,  0.000000e+00, -1.000000e+00]],\n1184                         dtype=float32)\n1185 \n1186         Assign normals to the cell arrays.  An array will be added\n1187         named ``\"Normals\"``.\n1188 \n1189         >>> mesh.cell_data.active_normals = [[0.0, 0.0, 1.0]]\n1190         >>> mesh.cell_data\n1191         pyvista DataSetAttributes\n1192         Association     : CELL\n1193         Active Scalars  : None\n1194         Active Vectors  : None\n1195         Active Texture  : None\n1196         Active Normals  : Normals\n1197         Contains arrays :\n1198             Normals                 float64    (1, 3)               NORMALS\n1199 \n1200         \"\"\"\n1201         self._raise_no_normals()\n1202         vtk_normals = self.GetNormals()\n1203         if vtk_normals is not None:\n1204             return pyvista_ndarray(vtk_normals, dataset=self.dataset, association=self.association)\n1205         return None\n1206 \n1207     @active_normals.setter\n1208     def active_normals(self, normals: Union[Sequence[Number], np.ndarray]):\n1209         self._raise_no_normals()\n1210         normals = np.asarray(normals)\n1211         if normals.ndim != 2:\n1212             raise ValueError('Normals must be a 2-dimensional array')\n1213         valid_length = self.valid_array_len\n1214         if normals.shape[0] != valid_length:\n1215             raise ValueError(\n1216                 f'Number of normals ({normals.shape[0]}) must match number of points ({valid_length})'\n1217             )\n1218         if normals.shape[1] != 3:\n1219             raise ValueError(f'Normals must have exactly 3 components, not ({normals.shape[1]})')\n1220 \n1221         vtkarr = _vtk.numpyTovtkDataArray(normals, name='Normals')\n1222         self.SetNormals(vtkarr)\n1223         self.Modified()\n1224 \n1225     @property\n1226     def active_normals_name(self) -> Optional[str]:\n1227         \"\"\"Return or set the name of the normals array.\n1228 \n1229         Returns\n1230         -------\n1231         str\n1232             Name of the active normals array.\n1233 \n1234         Examples\n1235         --------\n1236         First, compute cell normals.\n1237 \n1238         >>> import pyvista\n1239         >>> mesh = pyvista.Plane(i_resolution=1, j_resolution=1)\n1240         >>> mesh_w_normals = mesh.compute_normals()\n1241         >>> mesh_w_normals.point_data.active_normals_name\n1242         'Normals'\n1243 \n1244         \"\"\"\n1245         self._raise_no_normals()\n1246         if self.GetNormals() is not None:\n1247             return str(self.GetNormals().GetName())\n1248         return None\n1249 \n1250     @active_normals_name.setter\n1251     def active_normals_name(self, name: str) -> None:\n1252         # permit setting no active\n1253         if name is None:\n1254             self.SetActiveNormals(None)\n1255             return\n1256         self._raise_no_normals()\n1257         self.SetActiveNormals(name)\n1258 \n1259     def _raise_no_normals(self):\n1260         \"\"\"Raise AttributeError when attempting access normals for field data.\"\"\"\n1261         if self.association == FieldAssociation.NONE:\n1262             raise AttributeError('FieldData does not have active normals.')\n1263 \n1264     def _raise_no_t_coords(self):\n1265         \"\"\"Raise AttributeError when attempting access t_coords for field data.\"\"\"\n1266         if self.association == FieldAssociation.NONE:\n1267             raise AttributeError('FieldData does not have active texture coordinates.')\n1268 \n[end of pyvista/core/datasetattributes.py]\n[start of pyvista/core/filters/rectilinear_grid.py]\n1 \"\"\"Filters module with the class to manage filters/algorithms for rectilinear grid datasets.\"\"\"\n2 \n3 import collections\n4 from typing import Sequence, Union\n5 \n6 import numpy as np\n7 \n8 from pyvista import _vtk, abstract_class\n9 from pyvista.core.filters import _get_output, _update_alg\n10 \n11 \n12 @abstract_class\n13 class RectilinearGridFilters:\n14     \"\"\"An internal class to manage filters/algorithms for rectilinear grid datasets.\"\"\"\n15 \n16     def to_tetrahedra(\n17         self,\n18         tetra_per_cell: int = 5,\n19         mixed: Union[Sequence[int], bool] = False,\n20         pass_cell_ids: bool = False,\n21         progress_bar: bool = False,\n22     ):\n23         \"\"\"Create a tetrahedral mesh structured grid.\n24 \n25         Parameters\n26         ----------\n27         tetra_per_cell : int, default: 5\n28             The number of tetrahedrons to divide each cell into. Can be\n29             either ``5``, ``6``, or ``12``. If ``mixed=True``, this value is\n30             overridden.\n31 \n32         mixed : str, bool, sequence, default: False\n33             When set, subdivides some cells into 5 and some cells into 12. Set\n34             to ``True`` to use the active cell scalars of the\n35             :class:`pyvista.RectilinearGrid` to be either 5 or 12 to\n36             determining the number of tetrahedra to generate per cell.\n37 \n38             When a sequence, uses these values to subdivide the cells. When a\n39             string uses a cell array rather than the active array to determine\n40             the number of tetrahedra to generate per cell.\n41 \n42         pass_cell_ids : bool, default: False\n43             Set to ``True`` to make the tetrahedra have scalar data indicating\n44             which cell they came from in the original\n45             :class:`pyvista.RectilinearGrid`.\n46 \n47         progress_bar : bool, default: False\n48             Display a progress bar to indicate progress.\n49 \n50         Returns\n51         -------\n52         pyvista.UnstructuredGrid\n53             UnstructuredGrid containing the tetrahedral cells.\n54 \n55         Examples\n56         --------\n57         Divide a rectangular grid into tetrahedrons. Each cell contains by\n58         default 5 tetrahedrons.\n59 \n60         First, create and plot the grid.\n61 \n62         >>> import numpy as np\n63         >>> import pyvista as pv\n64         >>> xrng = np.linspace(0, 1, 2)\n65         >>> yrng = np.linspace(0, 1, 2)\n66         >>> zrng = np.linspace(0, 2, 3)\n67         >>> grid = pv.RectilinearGrid(xrng, yrng, zrng)\n68         >>> grid.plot()\n69 \n70         Now, generate the tetrahedra plot in the exploded view of the cell.\n71 \n72         >>> tet_grid = grid.to_tetrahedra()\n73         >>> tet_grid.explode(factor=0.5).plot(show_edges=True)\n74 \n75         Take the same grid but divide the first cell into 5 cells and the other\n76         cell into 12 tetrahedrons per cell.\n77 \n78         >>> tet_grid = grid.to_tetrahedra(mixed=[5, 12])\n79         >>> tet_grid.explode(factor=0.5).plot(show_edges=True)\n80 \n81         \"\"\"\n82         alg = _vtk.vtkRectilinearGridToTetrahedra()\n83         alg.SetRememberVoxelId(pass_cell_ids)\n84         if mixed is not False:\n85             if isinstance(mixed, str):\n86                 self.cell_data.active_scalars_name = mixed\n87             elif isinstance(mixed, (np.ndarray, collections.abc.Sequence)):\n88                 self.cell_data['_MIXED_CELLS_'] = mixed  # type: ignore\n89             elif not isinstance(mixed, bool):\n90                 raise TypeError('`mixed` must be either a sequence of ints or bool')\n91             alg.SetTetraPerCellTo5And12()\n92         else:\n93             if tetra_per_cell not in [5, 6, 12]:\n94                 raise ValueError(\n95                     f'`tetra_per_cell` should be either 5, 6, or 12, not {tetra_per_cell}'\n96                 )\n97 \n98             # Edge case causing a seg-fault where grid is flat in one dimension\n99             # See: https://gitlab.kitware.com/vtk/vtk/-/issues/18650\n100             if 1 in self.dimensions and tetra_per_cell == 12:  # type: ignore\n101                 raise RuntimeError(\n102                     'Cannot split cells into 12 tetrahedrals when at least '  # type: ignore\n103                     f'one dimension is 1. Dimensions are {self.dimensions}.'\n104                 )\n105 \n106             alg.SetTetraPerCell(tetra_per_cell)\n107 \n108         alg.SetInputData(self)\n109         _update_alg(alg, progress_bar, 'Converting to tetrahedra')\n110         return _get_output(alg)\n111 \n[end of pyvista/core/filters/rectilinear_grid.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n\n\n", "full_output": "```patch\n--- a/pyvista/core/filters/rectilinear_grid.py\n+++ b/pyvista/core/filters/rectilinear_grid.py\n@@ -21,6 +21,7 @@\n     progress_bar: bool = False,\n+    pass_cell_data: bool = False,\n ):\n     \"\"\"Create a tetrahedral mesh structured grid.\n \n@@ -45,6 +46\n         progress_bar : bool, default: False\n             Display a progress bar to indicate progress.\n+        \n         pass_cell_data : bool, default: False\n             Set to ``True`` to pass through the original cell data to the tetrahedra.\n \n     \"\"\"\n@@ -83,6 +85\n         if mixed is not False:\n             if isinstance(mixed, str):\n                 self.cell_data.active_scalars_name = mixed\n@@ -110,6 +113\n         alg.SetInputData(self)\n \n+        if pass_cell_data:\n+            self.cell_data.copy_to(alg.GetCellData())\n         _update_alg(alg, progress_bar, 'Converting to tetrahedra')\n         return _get_output(alg)\n```", "model_patch": "--- a/pyvista/core/filters/rectilinear_grid.py\n+++ b/pyvista/core/filters/rectilinear_grid.py\n@@ -21,6 +21,7 @@\n     progress_bar: bool = False,\n+    pass_cell_data: bool = False,\n ):\n     \"\"\"Create a tetrahedral mesh structured grid.\n \n@@ -45,6 +46\n         progress_bar : bool, default: False\n             Display a progress bar to indicate progress.\n+        \n         pass_cell_data : bool, default: False\n             Set to ``True`` to pass through the original cell data to the tetrahedra.\n \n     \"\"\"\n@@ -83,6 +85\n         if mixed is not False:\n             if isinstance(mixed, str):\n                 self.cell_data.active_scalars_name = mixed\n@@ -110,6 +113\n         alg.SetInputData(self)\n \n+        if pass_cell_data:\n+            self.cell_data.copy_to(alg.GetCellData())\n         _update_alg(alg, progress_bar, 'Converting to tetrahedra')\n         return _get_output(alg)\n"}
{"instance_id": "pyvista__pyvista-4315", "model_name_or_path": "gpt-4o-mini", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nRectilinear grid does not allow Sequences as inputs\n### Describe the bug, what's wrong, and what you expected.\r\n\r\nRectilinear grid gives an error when `Sequence`s are passed in, but `ndarray` are ok.\r\n\r\n### Steps to reproduce the bug.\r\n\r\nThis doesn't work\r\n```python\r\nimport pyvista as pv\r\npv.RectilinearGrid([0, 1], [0, 1], [0, 1])\r\n```\r\n\r\nThis works\r\n```py\r\nimport pyvista as pv\r\nimport numpy as np\r\npv.RectilinearGrid(np.ndarray([0, 1]), np.ndarray([0, 1]), np.ndarray([0, 1]))\r\n```\r\n### System Information\r\n\r\n```shell\r\n--------------------------------------------------------------------------------\r\n  Date: Wed Apr 19 20:15:10 2023 UTC\r\n\r\n                OS : Linux\r\n            CPU(s) : 2\r\n           Machine : x86_64\r\n      Architecture : 64bit\r\n       Environment : IPython\r\n        GPU Vendor : Mesa/X.org\r\n      GPU Renderer : llvmpipe (LLVM 11.0.1, 256 bits)\r\n       GPU Version : 4.5 (Core Profile) Mesa 20.3.5\r\n\r\n  Python 3.11.2 (main, Mar 23 2023, 17:12:29) [GCC 10.2.1 20210110]\r\n\r\n           pyvista : 0.38.5\r\n               vtk : 9.2.6\r\n             numpy : 1.24.2\r\n           imageio : 2.27.0\r\n            scooby : 0.7.1\r\n             pooch : v1.7.0\r\n        matplotlib : 3.7.1\r\n           IPython : 8.12.0\r\n--------------------------------------------------------------------------------\r\n```\r\n\r\n\r\n### Screenshots\r\n\r\n_No response_\n\n</issue>\n<code>\n[start of README.rst]\n1 #######\n2 PyVista\n3 #######\n4 \n5 .. image:: https://github.com/pyvista/pyvista/raw/main/doc/source/_static/pyvista_banner_small.png\n6    :target: https://docs.pyvista.org/examples/index.html\n7    :alt: pyvista\n8 \n9 \n10 .. |zenodo| image:: https://zenodo.org/badge/92974124.svg\n11    :target: https://zenodo.org/badge/latestdoi/92974124\n12 \n13 .. |joss| image:: http://joss.theoj.org/papers/10.21105/joss.01450/status.svg\n14    :target: https://doi.org/10.21105/joss.01450\n15 \n16 .. |pypi| image:: https://img.shields.io/pypi/v/pyvista.svg?logo=python&logoColor=white\n17    :target: https://pypi.org/project/pyvista/\n18 \n19 .. |conda| image:: https://img.shields.io/conda/vn/conda-forge/pyvista.svg?logo=conda-forge&logoColor=white\n20    :target: https://anaconda.org/conda-forge/pyvista\n21 \n22 .. |GH-CI| image:: https://github.com/pyvista/pyvista/actions/workflows/testing-and-deployment.yml/badge.svg\n23    :target: https://github.com/pyvista/pyvista/actions/workflows/testing-and-deployment.yml\n24 \n25 .. |codecov| image:: https://codecov.io/gh/pyvista/pyvista/branch/main/graph/badge.svg\n26    :target: https://codecov.io/gh/pyvista/pyvista\n27 \n28 .. |codacy| image:: https://app.codacy.com/project/badge/Grade/779ac6aed37548839384acfc0c1aab44\n29    :target: https://www.codacy.com/gh/pyvista/pyvista/dashboard?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=pyvista/pyvista&amp;utm_campaign=Badge_Grade\n30 \n31 .. |MIT| image:: https://img.shields.io/badge/License-MIT-yellow.svg\n32    :target: https://opensource.org/licenses/MIT\n33 \n34 .. |slack| image:: https://img.shields.io/badge/Slack-pyvista-green.svg?logo=slack\n35    :target: http://slack.pyvista.org\n36 \n37 .. |PyPIact| image:: https://img.shields.io/pypi/dm/pyvista.svg?label=PyPI%20downloads\n38    :target: https://pypi.org/project/pyvista/\n39 \n40 .. |condaact| image:: https://img.shields.io/conda/dn/conda-forge/pyvista.svg?label=Conda%20downloads\n41    :target: https://anaconda.org/conda-forge/pyvista\n42 \n43 .. |discuss| image:: https://img.shields.io/badge/GitHub-Discussions-green?logo=github\n44    :target: https://github.com/pyvista/pyvista/discussions\n45 \n46 .. |isort| image:: https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat\n47   :target: https://timothycrosley.github.io/isort\n48   :alt: isort\n49 \n50 .. |black| image:: https://img.shields.io/badge/code%20style-black-000000.svg?style=flat\n51   :target: https://github.com/psf/black\n52   :alt: black\n53 \n54 .. |python| image:: https://img.shields.io/badge/python-3.8+-blue.svg\n55    :target: https://www.python.org/downloads/\n56 \n57 .. |NumFOCUS Affiliated| image:: https://img.shields.io/badge/affiliated-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A\n58    :target: https://numfocus.org/sponsored-projects/affiliated-projects\n59 \n60 .. |pre-commit.ci status| image:: https://results.pre-commit.ci/badge/github/pyvista/pyvista/main.svg\n61    :target: https://results.pre-commit.ci/latest/github/pyvista/pyvista/main\n62 \n63 \n64 +----------------------+------------------------+-------------+\n65 | Deployment           | |pypi|                 | |conda|     |\n66 +----------------------+------------------------+-------------+\n67 | Build Status         | |GH-CI|                | |python|    |\n68 |                      +------------------------+-------------+\n69 |                      | |pre-commit.ci status| |             |\n70 +----------------------+------------------------+-------------+\n71 | Metrics              | |codacy|               | |codecov|   |\n72 +----------------------+------------------------+-------------+\n73 | Activity             | |PyPIact|              | |condaact|  |\n74 +----------------------+------------------------+-------------+\n75 | Citation             | |joss|                 | |zenodo|    |\n76 +----------------------+------------------------+-------------+\n77 | License              | |MIT|                  |             |\n78 +----------------------+------------------------+-------------+\n79 | Community            | |slack|                | |discuss|   |\n80 +----------------------+------------------------+-------------+\n81 | Formatter            | |black|                | |isort|     |\n82 +----------------------+------------------------+-------------+\n83 | Affiliated           | |NumFOCUS Affiliated|                |\n84 +----------------------+------------------------+-------------+\n85 \n86 \n87     3D plotting and mesh analysis through a streamlined interface for the Visualization Toolkit (VTK)\n88 \n89 PyVista is:\n90 \n91 * *Pythonic VTK*: a high-level API to the `Visualization Toolkit`_ (VTK)\n92 * mesh data structures and filtering methods for spatial datasets\n93 * 3D plotting made simple and built for large/complex data geometries\n94 \n95 .. _Visualization Toolkit: https://vtk.org\n96 \n97 PyVista is a helper module for the Visualization Toolkit (VTK) that wraps the VTK library\n98 through NumPy and direct array access through a variety of methods and classes.\n99 This package provides a Pythonic, well-documented interface exposing\n100 VTK's powerful visualization backend to facilitate rapid prototyping, analysis,\n101 and visual integration of spatially referenced datasets.\n102 \n103 This module can be used for scientific plotting for presentations and research\n104 papers as well as a supporting module for other mesh 3D rendering dependent\n105 Python modules; see Connections for a list of projects that leverage\n106 PyVista.\n107 \n108 \n109 .. |tweet| image:: https://img.shields.io/twitter/url.svg?style=social&url=http%3A%2F%2Fshields.io\n110    :target: https://twitter.com/intent/tweet?text=Check%20out%20this%20project%20for%203D%20visualization%20in%20Python&url=https://github.com/pyvista/pyvista&hashtags=3D,visualization,Python,vtk,mesh,plotting,PyVista\n111 \n112 Share this project on Twitter: |tweet|\n113 \n114 \n115 PyVista is a NumFOCUS affiliated project\n116 \n117 .. image:: https://raw.githubusercontent.com/numfocus/templates/master/images/numfocus-logo.png\n118    :target: https://numfocus.org/sponsored-projects/affiliated-projects\n119    :alt: NumFOCUS affiliated projects\n120    :height: 60px\n121 \n122 \n123 Highlights\n124 ==========\n125 \n126 .. |binder| image:: https://static.mybinder.org/badge_logo.svg\n127    :target: https://mybinder.org/v2/gh/pyvista/pyvista-examples/master\n128    :alt: Launch on Binder\n129 \n130 Head over to the `Quick Examples`_ page in the docs to explore our gallery of\n131 examples showcasing what PyVista can do. Want to test-drive PyVista?\n132 All of the examples from the gallery are live on MyBinder for you to test\n133 drive without installing anything locally: |binder|\n134 \n135 .. _Quick Examples: http://docs.pyvista.org/examples/index.html\n136 \n137 \n138 Overview of Features\n139 --------------------\n140 \n141 * Extensive gallery of examples (see `Quick Examples`_)\n142 * Interactive plotting in Jupyter Notebooks with server-side and client-side\n143   rendering with `trame`_.\n144 * Filtering/plotting tools built for interactivity (see `Widgets`_)\n145 * Direct access to mesh analysis and transformation routines (see Filters_)\n146 * Intuitive plotting routines with ``matplotlib`` similar syntax (see Plotting_)\n147 * Import meshes from many common formats (use ``pyvista.read()``). Support for all formats handled by `meshio`_ is built-in.\n148 * Export meshes as VTK, STL, OBJ, or PLY (``mesh.save()``) file types or any formats supported by meshio_ (``pyvista.save_meshio()``)\n149 \n150 .. _trame: https://github.com/Kitware/trame\n151 .. _Widgets: https://docs.pyvista.org/api/plotting/index.html#widget-api\n152 .. _Filters: https://docs.pyvista.org/api/core/filters.html\n153 .. _Plotting: https://docs.pyvista.org/api/plotting/index.html\n154 .. _meshio: https://github.com/nschloe/meshio\n155 \n156 \n157 Documentation\n158 =============\n159 \n160 Refer to the `documentation <http://docs.pyvista.org/>`_ for detailed\n161 installation and usage details.\n162 \n163 For general questions about the project, its applications, or about software\n164 usage, please create a discussion in `pyvista/discussions`_\n165 where the community can collectively address your questions. You are also\n166 welcome to join us on Slack_ or send one of the developers an email.\n167 The project support team can be reached at `info@pyvista.org`_.\n168 \n169 .. _pyvista/discussions: https://github.com/pyvista/pyvista/discussions\n170 .. _Slack: http://slack.pyvista.org\n171 .. _info@pyvista.org: mailto:info@pyvista.org\n172 \n173 \n174 Installation\n175 ============\n176 \n177 PyVista can be installed from `PyPI <https://pypi.org/project/pyvista/>`_\n178 using ``pip`` on Python >= 3.8::\n179 \n180     pip install pyvista\n181 \n182 You can also visit `PyPI <https://pypi.org/project/pyvista/>`_,\n183 `Anaconda <https://anaconda.org/conda-forge/pyvista>`_, or\n184 `GitHub <https://github.com/pyvista/pyvista>`_ to download the source.\n185 \n186 See the `Installation <http://docs.pyvista.org/getting-started/installation.html#install-ref.>`_\n187 for more details regarding optional dependencies or if the installation through pip doesn't work out.\n188 \n189 \n190 Connections\n191 ===========\n192 \n193 PyVista is a powerful tool that researchers can harness to create compelling,\n194 integrated visualizations of large datasets in an intuitive, Pythonic manner.\n195 \n196 Learn more about how PyVista is used across science and engineering disciplines\n197 by a diverse community of users on our `Connections page`_.\n198 \n199 .. _Connections page: https://docs.pyvista.org/getting-started/connections.html\n200 \n201 \n202 Authors\n203 =======\n204 \n205 Please take a look at the `contributors page`_ and the active `list of authors`_\n206 to learn more about the developers of PyVista.\n207 \n208 .. _contributors page: https://github.com/pyvista/pyvista/graphs/contributors/\n209 .. _list of authors: https://docs.pyvista.org/getting-started/authors.html#authors\n210 \n211 \n212 Contributing\n213 ============\n214 \n215 .. |Contributor Covenant| image:: https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg\n216    :target: CODE_OF_CONDUCT.md\n217 \n218 .. |codetriage| image:: https://www.codetriage.com/pyvista/pyvista/badges/users.svg\n219    :target: https://www.codetriage.com/pyvista/pyvista\n220    :alt: Code Triage\n221 \n222 |Contributor Covenant|\n223 |codetriage|\n224 \n225 We absolutely welcome contributions and we hope that our `Contributing Guide`_\n226 will facilitate your ability to make PyVista better. PyVista is mostly\n227 maintained on a volunteer basis and thus we need to foster a community that can\n228 support user questions and develop new features to make this software a useful\n229 tool for all users while encouraging every member of the community to share\n230 their ideas. To learn more about contributing to PyVista, please see the\n231 `Contributing Guide`_ and our `Code of Conduct`_.\n232 \n233 .. _Contributing Guide: https://github.com/pyvista/pyvista/blob/main/CONTRIBUTING.rst\n234 .. _Code of Conduct: https://github.com/pyvista/pyvista/blob/main/CODE_OF_CONDUCT.md\n235 \n236 \n237 Citing PyVista\n238 ==============\n239 \n240 There is a `paper about PyVista <https://doi.org/10.21105/joss.01450>`_.\n241 \n242 If you are using PyVista in your scientific research, please help our scientific\n243 visibility by citing our work.\n244 \n245 \n246     Sullivan and Kaszynski, (2019). PyVista: 3D plotting and mesh analysis through a streamlined interface for the Visualization Toolkit (VTK). Journal of Open Source Software, 4(37), 1450, https://doi.org/10.21105/joss.01450\n247 \n248 \n249 BibTex:\n250 \n251 .. code::\n252 \n253     @article{sullivan2019pyvista,\n254       doi = {10.21105/joss.01450},\n255       url = {https://doi.org/10.21105/joss.01450},\n256       year = {2019},\n257       month = {May},\n258       publisher = {The Open Journal},\n259       volume = {4},\n260       number = {37},\n261       pages = {1450},\n262       author = {Bane Sullivan and Alexander Kaszynski},\n263       title = {{PyVista}: {3D} plotting and mesh analysis through a streamlined interface for the {Visualization Toolkit} ({VTK})},\n264       journal = {Journal of Open Source Software}\n265     }\n266 \n[end of README.rst]\n[start of pyvista/core/grid.py]\n1 \"\"\"Sub-classes for vtk.vtkRectilinearGrid and vtk.vtkImageData.\"\"\"\n2 from functools import wraps\n3 import pathlib\n4 from typing import Sequence, Tuple, Union\n5 import warnings\n6 \n7 import numpy as np\n8 \n9 import pyvista\n10 from pyvista import _vtk\n11 from pyvista.core.dataset import DataSet\n12 from pyvista.core.filters import RectilinearGridFilters, UniformGridFilters, _get_output\n13 from pyvista.utilities import abstract_class, assert_empty_kwargs\n14 import pyvista.utilities.helpers as helpers\n15 from pyvista.utilities.misc import PyVistaDeprecationWarning, raise_has_duplicates\n16 \n17 \n18 @abstract_class\n19 class Grid(DataSet):\n20     \"\"\"A class full of common methods for non-pointset grids.\"\"\"\n21 \n22     def __init__(self, *args, **kwargs):\n23         \"\"\"Initialize the grid.\"\"\"\n24         super().__init__()\n25 \n26     @property\n27     def dimensions(self) -> Tuple[int, int, int]:\n28         \"\"\"Return the grid's dimensions.\n29 \n30         These are effectively the number of points along each of the\n31         three dataset axes.\n32 \n33         Examples\n34         --------\n35         Create a uniform grid with dimensions ``(1, 2, 3)``.\n36 \n37         >>> import pyvista\n38         >>> grid = pyvista.UniformGrid(dimensions=(2, 3, 4))\n39         >>> grid.dimensions\n40         (2, 3, 4)\n41         >>> grid.plot(show_edges=True)\n42 \n43         Set the dimensions to ``(3, 4, 5)``\n44 \n45         >>> grid.dimensions = (3, 4, 5)\n46         >>> grid.plot(show_edges=True)\n47 \n48         \"\"\"\n49         return self.GetDimensions()\n50 \n51     @dimensions.setter\n52     def dimensions(self, dims: Sequence[int]):\n53         \"\"\"Set the dataset dimensions.\"\"\"\n54         self.SetDimensions(*dims)\n55         self.Modified()\n56 \n57     def _get_attrs(self):\n58         \"\"\"Return the representation methods (internal helper).\"\"\"\n59         attrs = DataSet._get_attrs(self)\n60         attrs.append((\"Dimensions\", self.dimensions, \"{:d}, {:d}, {:d}\"))\n61         return attrs\n62 \n63 \n64 class RectilinearGrid(_vtk.vtkRectilinearGrid, Grid, RectilinearGridFilters):\n65     \"\"\"Dataset with variable spacing in the three coordinate directions.\n66 \n67     Can be initialized in several ways:\n68 \n69     * Create empty grid\n70     * Initialize from a ``vtk.vtkRectilinearGrid`` object\n71     * Initialize directly from the point arrays\n72 \n73     Parameters\n74     ----------\n75     uinput : str, pathlib.Path, vtk.vtkRectilinearGrid, numpy.ndarray, optional\n76         Filename, dataset, or array to initialize the rectilinear grid from. If a\n77         filename is passed, pyvista will attempt to load it as a\n78         :class:`RectilinearGrid`. If passed a ``vtk.vtkRectilinearGrid``, it\n79         will be wrapped. If a :class:`numpy.ndarray` is passed, this will be\n80         loaded as the x range.\n81 \n82     y : numpy.ndarray, optional\n83         Coordinates of the points in y direction. If this is passed, ``uinput``\n84         must be a :class:`numpy.ndarray`.\n85 \n86     z : numpy.ndarray, optional\n87         Coordinates of the points in z direction. If this is passed, ``uinput``\n88         and ``y`` must be a :class:`numpy.ndarray`.\n89 \n90     check_duplicates : bool, optional\n91         Check for duplications in any arrays that are passed. Defaults to\n92         ``False``. If ``True``, an error is raised if there are any duplicate\n93         values in any of the array-valued input arguments.\n94 \n95     deep : bool, optional\n96         Whether to deep copy a ``vtk.vtkRectilinearGrid`` object.\n97         Default is ``False``.  Keyword only.\n98 \n99     Examples\n100     --------\n101     >>> import pyvista\n102     >>> import vtk\n103     >>> import numpy as np\n104 \n105     Create an empty grid.\n106 \n107     >>> grid = pyvista.RectilinearGrid()\n108 \n109     Initialize from a vtk.vtkRectilinearGrid object\n110 \n111     >>> vtkgrid = vtk.vtkRectilinearGrid()\n112     >>> grid = pyvista.RectilinearGrid(vtkgrid)\n113 \n114     Create from NumPy arrays.\n115 \n116     >>> xrng = np.arange(-10, 10, 2)\n117     >>> yrng = np.arange(-10, 10, 5)\n118     >>> zrng = np.arange(-10, 10, 1)\n119     >>> grid = pyvista.RectilinearGrid(xrng, yrng, zrng)\n120     >>> grid.plot(show_edges=True)\n121 \n122     \"\"\"\n123 \n124     _WRITERS = {'.vtk': _vtk.vtkRectilinearGridWriter, '.vtr': _vtk.vtkXMLRectilinearGridWriter}\n125 \n126     def __init__(self, *args, check_duplicates=False, deep=False, **kwargs):\n127         \"\"\"Initialize the rectilinear grid.\"\"\"\n128         super().__init__()\n129 \n130         if len(args) == 1:\n131             if isinstance(args[0], _vtk.vtkRectilinearGrid):\n132                 if deep:\n133                     self.deep_copy(args[0])\n134                 else:\n135                     self.shallow_copy(args[0])\n136             elif isinstance(args[0], (str, pathlib.Path)):\n137                 self._from_file(args[0], **kwargs)\n138             elif isinstance(args[0], np.ndarray):\n139                 self._from_arrays(args[0], None, None, check_duplicates)\n140             else:\n141                 raise TypeError(f'Type ({type(args[0])}) not understood by `RectilinearGrid`')\n142 \n143         elif len(args) == 3 or len(args) == 2:\n144             arg0_is_arr = isinstance(args[0], np.ndarray)\n145             arg1_is_arr = isinstance(args[1], np.ndarray)\n146             if len(args) == 3:\n147                 arg2_is_arr = isinstance(args[2], np.ndarray)\n148             else:\n149                 arg2_is_arr = False\n150 \n151             if all([arg0_is_arr, arg1_is_arr, arg2_is_arr]):\n152                 self._from_arrays(args[0], args[1], args[2], check_duplicates)\n153             elif all([arg0_is_arr, arg1_is_arr]):\n154                 self._from_arrays(args[0], args[1], None, check_duplicates)\n155             else:\n156                 raise TypeError(\"Arguments not understood by `RectilinearGrid`.\")\n157 \n158     def __repr__(self):\n159         \"\"\"Return the default representation.\"\"\"\n160         return DataSet.__repr__(self)\n161 \n162     def __str__(self):\n163         \"\"\"Return the str representation.\"\"\"\n164         return DataSet.__str__(self)\n165 \n166     def _update_dimensions(self):\n167         \"\"\"Update the dimensions if coordinates have changed.\"\"\"\n168         return self.SetDimensions(len(self.x), len(self.y), len(self.z))\n169 \n170     def _from_arrays(\n171         self, x: np.ndarray, y: np.ndarray, z: np.ndarray, check_duplicates: bool = False\n172     ):\n173         \"\"\"Create VTK rectilinear grid directly from numpy arrays.\n174 \n175         Each array gives the uniques coordinates of the mesh along each axial\n176         direction. To help ensure you are using this correctly, we take the unique\n177         values of each argument.\n178 \n179         Parameters\n180         ----------\n181         x : numpy.ndarray\n182             Coordinates of the points in x direction.\n183 \n184         y : numpy.ndarray\n185             Coordinates of the points in y direction.\n186 \n187         z : numpy.ndarray\n188             Coordinates of the points in z direction.\n189 \n190         check_duplicates : bool, optional\n191             Check for duplications in any arrays that are passed.\n192 \n193         \"\"\"\n194         # Set the coordinates along each axial direction\n195         # Must at least be an x array\n196         if check_duplicates:\n197             raise_has_duplicates(x)\n198 \n199         # edges are shown as triangles if x is not floating point\n200         if not np.issubdtype(x.dtype, np.floating):\n201             x = x.astype(float)\n202         self.SetXCoordinates(helpers.convert_array(x.ravel()))\n203         if y is not None:\n204             if check_duplicates:\n205                 raise_has_duplicates(y)\n206             if not np.issubdtype(y.dtype, np.floating):\n207                 y = y.astype(float)\n208             self.SetYCoordinates(helpers.convert_array(y.ravel()))\n209         if z is not None:\n210             if check_duplicates:\n211                 raise_has_duplicates(z)\n212             if not np.issubdtype(z.dtype, np.floating):\n213                 z = z.astype(float)\n214             self.SetZCoordinates(helpers.convert_array(z.ravel()))\n215         # Ensure dimensions are properly set\n216         self._update_dimensions()\n217 \n218     @property\n219     def meshgrid(self) -> list:\n220         \"\"\"Return a meshgrid of numpy arrays for this mesh.\n221 \n222         This simply returns a :func:`numpy.meshgrid` of the\n223         coordinates for this mesh in ``ij`` indexing. These are a copy\n224         of the points of this mesh.\n225 \n226         \"\"\"\n227         return np.meshgrid(self.x, self.y, self.z, indexing='ij')\n228 \n229     @property  # type: ignore\n230     def points(self) -> np.ndarray:  # type: ignore\n231         \"\"\"Return a copy of the points as an n by 3 numpy array.\n232 \n233         Notes\n234         -----\n235         Points of a :class:`pyvista.RectilinearGrid` cannot be\n236         set. Set point coordinates with :attr:`RectilinearGrid.x`,\n237         :attr:`RectilinearGrid.y`, or :attr:`RectilinearGrid.z`.\n238 \n239         Examples\n240         --------\n241         >>> import numpy as np\n242         >>> import pyvista\n243         >>> xrng = np.arange(-10, 10, 10, dtype=float)\n244         >>> yrng = np.arange(-10, 10, 10, dtype=float)\n245         >>> zrng = np.arange(-10, 10, 10, dtype=float)\n246         >>> grid = pyvista.RectilinearGrid(xrng, yrng, zrng)\n247         >>> grid.points\n248         array([[-10., -10., -10.],\n249                [  0., -10., -10.],\n250                [-10.,   0., -10.],\n251                [  0.,   0., -10.],\n252                [-10., -10.,   0.],\n253                [  0., -10.,   0.],\n254                [-10.,   0.,   0.],\n255                [  0.,   0.,   0.]])\n256 \n257         \"\"\"\n258         xx, yy, zz = self.meshgrid\n259         return np.c_[xx.ravel(order='F'), yy.ravel(order='F'), zz.ravel(order='F')]\n260 \n261     @points.setter\n262     def points(self, points):\n263         \"\"\"Raise an AttributeError.\n264 \n265         This setter overrides the base class's setter to ensure a user\n266         does not attempt to set them.\n267         \"\"\"\n268         raise AttributeError(\n269             \"The points cannot be set. The points of \"\n270             \"`RectilinearGrid` are defined in each axial direction. Please \"\n271             \"use the `x`, `y`, and `z` setters individually.\"\n272         )\n273 \n274     @property\n275     def x(self) -> np.ndarray:\n276         \"\"\"Return or set the coordinates along the X-direction.\n277 \n278         Examples\n279         --------\n280         Return the x coordinates of a RectilinearGrid.\n281 \n282         >>> import numpy as np\n283         >>> import pyvista\n284         >>> xrng = np.arange(-10, 10, 10, dtype=float)\n285         >>> yrng = np.arange(-10, 10, 10, dtype=float)\n286         >>> zrng = np.arange(-10, 10, 10, dtype=float)\n287         >>> grid = pyvista.RectilinearGrid(xrng, yrng, zrng)\n288         >>> grid.x\n289         array([-10.,   0.])\n290 \n291         Set the x coordinates of a RectilinearGrid.\n292 \n293         >>> grid.x = [-10.0, 0.0, 10.0]\n294         >>> grid.x\n295         array([-10.,   0.,  10.])\n296 \n297         \"\"\"\n298         return helpers.convert_array(self.GetXCoordinates())\n299 \n300     @x.setter\n301     def x(self, coords: Sequence):\n302         \"\"\"Set the coordinates along the X-direction.\"\"\"\n303         self.SetXCoordinates(helpers.convert_array(coords))\n304         self._update_dimensions()\n305         self.Modified()\n306 \n307     @property\n308     def y(self) -> np.ndarray:\n309         \"\"\"Return or set the coordinates along the Y-direction.\n310 \n311         Examples\n312         --------\n313         Return the y coordinates of a RectilinearGrid.\n314 \n315         >>> import numpy as np\n316         >>> import pyvista\n317         >>> xrng = np.arange(-10, 10, 10, dtype=float)\n318         >>> yrng = np.arange(-10, 10, 10, dtype=float)\n319         >>> zrng = np.arange(-10, 10, 10, dtype=float)\n320         >>> grid = pyvista.RectilinearGrid(xrng, yrng, zrng)\n321         >>> grid.y\n322         array([-10.,   0.])\n323 \n324         Set the y coordinates of a RectilinearGrid.\n325 \n326         >>> grid.y = [-10.0, 0.0, 10.0]\n327         >>> grid.y\n328         array([-10.,   0.,  10.])\n329 \n330         \"\"\"\n331         return helpers.convert_array(self.GetYCoordinates())\n332 \n333     @y.setter\n334     def y(self, coords: Sequence):\n335         \"\"\"Set the coordinates along the Y-direction.\"\"\"\n336         self.SetYCoordinates(helpers.convert_array(coords))\n337         self._update_dimensions()\n338         self.Modified()\n339 \n340     @property\n341     def z(self) -> np.ndarray:\n342         \"\"\"Return or set the coordinates along the Z-direction.\n343 \n344         Examples\n345         --------\n346         Return the z coordinates of a RectilinearGrid.\n347 \n348         >>> import numpy as np\n349         >>> import pyvista\n350         >>> xrng = np.arange(-10, 10, 10, dtype=float)\n351         >>> yrng = np.arange(-10, 10, 10, dtype=float)\n352         >>> zrng = np.arange(-10, 10, 10, dtype=float)\n353         >>> grid = pyvista.RectilinearGrid(xrng, yrng, zrng)\n354         >>> grid.z\n355         array([-10.,   0.])\n356 \n357         Set the z coordinates of a RectilinearGrid.\n358 \n359         >>> grid.z = [-10.0, 0.0, 10.0]\n360         >>> grid.z\n361         array([-10.,   0.,  10.])\n362 \n363         \"\"\"\n364         return helpers.convert_array(self.GetZCoordinates())\n365 \n366     @z.setter\n367     def z(self, coords: Sequence):\n368         \"\"\"Set the coordinates along the Z-direction.\"\"\"\n369         self.SetZCoordinates(helpers.convert_array(coords))\n370         self._update_dimensions()\n371         self.Modified()\n372 \n373     @Grid.dimensions.setter  # type: ignore\n374     def dimensions(self, dims):\n375         \"\"\"Do not let the dimensions of the RectilinearGrid be set.\"\"\"\n376         raise AttributeError(\n377             \"The dimensions of a `RectilinearGrid` are implicitly \"\n378             \"defined and thus cannot be set.\"\n379         )\n380 \n381     def cast_to_structured_grid(self) -> 'pyvista.StructuredGrid':\n382         \"\"\"Cast this rectilinear grid to a structured grid.\n383 \n384         Returns\n385         -------\n386         pyvista.StructuredGrid\n387             This grid as a structured grid.\n388 \n389         \"\"\"\n390         alg = _vtk.vtkRectilinearGridToPointSet()\n391         alg.SetInputData(self)\n392         alg.Update()\n393         return _get_output(alg)\n394 \n395 \n396 class UniformGrid(_vtk.vtkImageData, Grid, UniformGridFilters):\n397     \"\"\"Models datasets with uniform spacing in the three coordinate directions.\n398 \n399     Can be initialized in one of several ways:\n400 \n401     - Create empty grid\n402     - Initialize from a vtk.vtkImageData object\n403     - Initialize based on dimensions, cell spacing, and origin.\n404 \n405     .. versionchanged:: 0.33.0\n406         First argument must now be either a path or\n407         ``vtk.vtkImageData``. Use keyword arguments to specify the\n408         dimensions, spacing, and origin of the uniform grid.\n409 \n410     .. versionchanged:: 0.37.0\n411         The ``dims`` parameter has been renamed to ``dimensions``.\n412 \n413     Parameters\n414     ----------\n415     uinput : str, vtk.vtkImageData, pyvista.UniformGrid, optional\n416         Filename or dataset to initialize the uniform grid from.  If\n417         set, remainder of arguments are ignored.\n418 \n419     dimensions : sequence[int], optional\n420         Dimensions of the uniform grid.\n421 \n422     spacing : sequence[float], default: (1.0, 1.0, 1.0)\n423         Spacing of the uniform grid in each dimension. Must be positive.\n424 \n425     origin : sequence[float], default: (0.0, 0.0, 0.0)\n426         Origin of the uniform grid.\n427 \n428     deep : bool, default: False\n429         Whether to deep copy a ``vtk.vtkImageData`` object.  Keyword only.\n430 \n431     Examples\n432     --------\n433     Create an empty UniformGrid.\n434 \n435     >>> import pyvista\n436     >>> grid = pyvista.UniformGrid()\n437 \n438     Initialize from a ``vtk.vtkImageData`` object.\n439 \n440     >>> import vtk\n441     >>> vtkgrid = vtk.vtkImageData()\n442     >>> grid = pyvista.UniformGrid(vtkgrid)\n443 \n444     Initialize using just the grid dimensions and default\n445     spacing and origin. These must be keyword arguments.\n446 \n447     >>> grid = pyvista.UniformGrid(dimensions=(10, 10, 10))\n448 \n449     Initialize using dimensions and spacing.\n450 \n451     >>> grid = pyvista.UniformGrid(\n452     ...     dimensions=(10, 10, 10),\n453     ...     spacing=(2, 1, 5),\n454     ... )\n455 \n456     Initialize using dimensions, spacing, and an origin.\n457 \n458     >>> grid = pyvista.UniformGrid(\n459     ...     dimensions=(10, 10, 10),\n460     ...     spacing=(2, 1, 5),\n461     ...     origin=(10, 35, 50),\n462     ... )\n463 \n464     Initialize from another UniformGrid.\n465 \n466     >>> grid = pyvista.UniformGrid(\n467     ...     dimensions=(10, 10, 10),\n468     ...     spacing=(2, 1, 5),\n469     ...     origin=(10, 35, 50),\n470     ... )\n471     >>> grid_from_grid = pyvista.UniformGrid(grid)\n472     >>> grid_from_grid == grid\n473     True\n474 \n475     \"\"\"\n476 \n477     _WRITERS = {'.vtk': _vtk.vtkDataSetWriter, '.vti': _vtk.vtkXMLImageDataWriter}\n478 \n479     def __init__(\n480         self,\n481         uinput=None,\n482         *args,\n483         dimensions=None,\n484         spacing=(1.0, 1.0, 1.0),\n485         origin=(0.0, 0.0, 0.0),\n486         deep=False,\n487         **kwargs,\n488     ):\n489         \"\"\"Initialize the uniform grid.\"\"\"\n490         super().__init__()\n491 \n492         # permit old behavior\n493         if isinstance(uinput, Sequence) and not isinstance(uinput, str):\n494             # Deprecated on v0.37.0, estimated removal on v0.40.0\n495             warnings.warn(\n496                 \"Behavior of pyvista.UniformGrid has changed. First argument must be \"\n497                 \"either a ``vtk.vtkImageData`` or path.\",\n498                 PyVistaDeprecationWarning,\n499             )\n500             dimensions = uinput\n501             uinput = None\n502 \n503         if dimensions is None and 'dims' in kwargs:\n504             dimensions = kwargs.pop('dims')\n505             # Deprecated on v0.37.0, estimated removal on v0.40.0\n506             warnings.warn(\n507                 '`dims` argument is deprecated. Please use `dimensions`.', PyVistaDeprecationWarning\n508             )\n509         assert_empty_kwargs(**kwargs)\n510 \n511         if args:\n512             # Deprecated on v0.37.0, estimated removal on v0.40.0\n513             warnings.warn(\n514                 \"Behavior of pyvista.UniformGrid has changed. Use keyword arguments \"\n515                 \"to specify dimensions, spacing, and origin. For example:\\n\\n\"\n516                 \"    >>> grid = pyvista.UniformGrid(\\n\"\n517                 \"    ...     dimensions=(10, 10, 10),\\n\"\n518                 \"    ...     spacing=(2, 1, 5),\\n\"\n519                 \"    ...     origin=(10, 35, 50),\\n\"\n520                 \"    ... )\\n\",\n521                 PyVistaDeprecationWarning,\n522             )\n523             origin = args[0]\n524             if len(args) > 1:\n525                 spacing = args[1]\n526             if len(args) > 2:\n527                 raise ValueError(\n528                     \"Too many additional arguments specified for UniformGrid. \"\n529                     f\"Accepts at most 2, and {len(args)} have been input.\"\n530                 )\n531 \n532         # first argument must be either vtkImageData or a path\n533         if uinput is not None:\n534             if isinstance(uinput, _vtk.vtkImageData):\n535                 if deep:\n536                     self.deep_copy(uinput)\n537                 else:\n538                     self.shallow_copy(uinput)\n539             elif isinstance(uinput, (str, pathlib.Path)):\n540                 self._from_file(uinput)\n541             else:\n542                 raise TypeError(\n543                     \"First argument, ``uinput`` must be either ``vtk.vtkImageData`` \"\n544                     f\"or a path, not {type(uinput)}.  Use keyword arguments to \"\n545                     \"specify dimensions, spacing, and origin. For example:\\n\\n\"\n546                     \"    >>> grid = pyvista.UniformGrid(\\n\"\n547                     \"    ...     dimensions=(10, 10, 10),\\n\"\n548                     \"    ...     spacing=(2, 1, 5),\\n\"\n549                     \"    ...     origin=(10, 35, 50),\\n\"\n550                     \"    ... )\\n\"\n551                 )\n552         elif dimensions is not None:\n553             self._from_specs(dimensions, spacing, origin)\n554 \n555     def __repr__(self):\n556         \"\"\"Return the default representation.\"\"\"\n557         return DataSet.__repr__(self)\n558 \n559     def __str__(self):\n560         \"\"\"Return the default str representation.\"\"\"\n561         return DataSet.__str__(self)\n562 \n563     def _from_specs(self, dims: Sequence[int], spacing=(1.0, 1.0, 1.0), origin=(0.0, 0.0, 0.0)):\n564         \"\"\"Create VTK image data directly from numpy arrays.\n565 \n566         A uniform grid is defined by the point spacings for each axis\n567         (uniform along each individual axis) and the number of points on each axis.\n568         These are relative to a specified origin (default is ``(0.0, 0.0, 0.0)``).\n569 \n570         Parameters\n571         ----------\n572         dims : tuple(int)\n573             Length 3 tuple of ints specifying how many points along each axis.\n574 \n575         spacing : sequence[float], default: (1.0, 1.0, 1.0)\n576             Length 3 tuple of floats/ints specifying the point spacings\n577             for each axis. Must be positive.\n578 \n579         origin : sequence[float], default: (0.0, 0.0, 0.0)\n580             Length 3 tuple of floats/ints specifying minimum value for each axis.\n581 \n582         \"\"\"\n583         xn, yn, zn = dims[0], dims[1], dims[2]\n584         xo, yo, zo = origin[0], origin[1], origin[2]\n585         self.SetDimensions(xn, yn, zn)\n586         self.SetOrigin(xo, yo, zo)\n587         self.spacing = (spacing[0], spacing[1], spacing[2])\n588 \n589     @property  # type: ignore\n590     def points(self) -> np.ndarray:  # type: ignore\n591         \"\"\"Build a copy of the implicitly defined points as a numpy array.\n592 \n593         Notes\n594         -----\n595         The ``points`` for a :class:`pyvista.UniformGrid` cannot be set.\n596 \n597         Examples\n598         --------\n599         >>> import pyvista\n600         >>> grid = pyvista.UniformGrid(dimensions=(2, 2, 2))\n601         >>> grid.points\n602         array([[0., 0., 0.],\n603                [1., 0., 0.],\n604                [0., 1., 0.],\n605                [1., 1., 0.],\n606                [0., 0., 1.],\n607                [1., 0., 1.],\n608                [0., 1., 1.],\n609                [1., 1., 1.]])\n610 \n611         \"\"\"\n612         # Get grid dimensions\n613         nx, ny, nz = self.dimensions\n614         nx -= 1\n615         ny -= 1\n616         nz -= 1\n617         # get the points and convert to spacings\n618         dx, dy, dz = self.spacing\n619         # Now make the cell arrays\n620         ox, oy, oz = np.array(self.origin) + np.array(self.extent[::2])  # type: ignore\n621         x = np.insert(np.cumsum(np.full(nx, dx)), 0, 0.0) + ox\n622         y = np.insert(np.cumsum(np.full(ny, dy)), 0, 0.0) + oy\n623         z = np.insert(np.cumsum(np.full(nz, dz)), 0, 0.0) + oz\n624         xx, yy, zz = np.meshgrid(x, y, z, indexing='ij')\n625         return np.c_[xx.ravel(order='F'), yy.ravel(order='F'), zz.ravel(order='F')]\n626 \n627     @points.setter\n628     def points(self, points):\n629         \"\"\"Points cannot be set.\n630 \n631         This setter overrides the base class's setter to ensure a user does not\n632         attempt to set them. See https://github.com/pyvista/pyvista/issues/713.\n633 \n634         \"\"\"\n635         raise AttributeError(\n636             \"The points cannot be set. The points of \"\n637             \"`UniformGrid`/`vtkImageData` are implicitly defined by the \"\n638             \"`origin`, `spacing`, and `dimensions` of the grid.\"\n639         )\n640 \n641     @property\n642     def x(self) -> np.ndarray:\n643         \"\"\"Return all the X points.\n644 \n645         Examples\n646         --------\n647         >>> import pyvista\n648         >>> grid = pyvista.UniformGrid(dimensions=(2, 2, 2))\n649         >>> grid.x\n650         array([0., 1., 0., 1., 0., 1., 0., 1.])\n651 \n652         \"\"\"\n653         return self.points[:, 0]\n654 \n655     @property\n656     def y(self) -> np.ndarray:\n657         \"\"\"Return all the Y points.\n658 \n659         Examples\n660         --------\n661         >>> import pyvista\n662         >>> grid = pyvista.UniformGrid(dimensions=(2, 2, 2))\n663         >>> grid.y\n664         array([0., 0., 1., 1., 0., 0., 1., 1.])\n665 \n666         \"\"\"\n667         return self.points[:, 1]\n668 \n669     @property\n670     def z(self) -> np.ndarray:\n671         \"\"\"Return all the Z points.\n672 \n673         Examples\n674         --------\n675         >>> import pyvista\n676         >>> grid = pyvista.UniformGrid(dimensions=(2, 2, 2))\n677         >>> grid.z\n678         array([0., 0., 0., 0., 1., 1., 1., 1.])\n679 \n680         \"\"\"\n681         return self.points[:, 2]\n682 \n683     @property\n684     def origin(self) -> Tuple[float]:\n685         \"\"\"Return the origin of the grid (bottom southwest corner).\n686 \n687         Examples\n688         --------\n689         >>> import pyvista\n690         >>> grid = pyvista.UniformGrid(dimensions=(5, 5, 5))\n691         >>> grid.origin\n692         (0.0, 0.0, 0.0)\n693 \n694         Show how the origin is in the bottom \"southwest\" corner of the\n695         UniformGrid.\n696 \n697         >>> pl = pyvista.Plotter()\n698         >>> _ = pl.add_mesh(grid, show_edges=True)\n699         >>> _ = pl.add_axes_at_origin(ylabel=None)\n700         >>> pl.camera_position = 'xz'\n701         >>> pl.show()\n702 \n703         Set the origin to ``(1, 1, 1)`` and show how this shifts the\n704         UniformGrid.\n705 \n706         >>> grid.origin = (1, 1, 1)\n707         >>> pl = pyvista.Plotter()\n708         >>> _ = pl.add_mesh(grid, show_edges=True)\n709         >>> _ = pl.add_axes_at_origin(ylabel=None)\n710         >>> pl.camera_position = 'xz'\n711         >>> pl.show()\n712 \n713         \"\"\"\n714         return self.GetOrigin()\n715 \n716     @origin.setter\n717     def origin(self, origin: Sequence[Union[float, int]]):\n718         \"\"\"Set the origin.\"\"\"\n719         self.SetOrigin(origin[0], origin[1], origin[2])\n720         self.Modified()\n721 \n722     @property\n723     def spacing(self) -> Tuple[float, float, float]:\n724         \"\"\"Return or set the spacing for each axial direction.\n725 \n726         Notes\n727         -----\n728         Spacing must be non-negative. While VTK accepts negative\n729         spacing, this results in unexpected behavior. See:\n730         https://github.com/pyvista/pyvista/issues/1967\n731 \n732         Examples\n733         --------\n734         Create a 5 x 5 x 5 uniform grid.\n735 \n736         >>> import pyvista\n737         >>> grid = pyvista.UniformGrid(dimensions=(5, 5, 5))\n738         >>> grid.spacing\n739         (1.0, 1.0, 1.0)\n740         >>> grid.plot(show_edges=True)\n741 \n742         Modify the spacing to ``(1, 2, 3)``\n743 \n744         >>> grid.spacing = (1, 2, 3)\n745         >>> grid.plot(show_edges=True)\n746 \n747         \"\"\"\n748         return self.GetSpacing()\n749 \n750     @spacing.setter\n751     def spacing(self, spacing: Sequence[Union[float, int]]):\n752         \"\"\"Set spacing.\"\"\"\n753         if min(spacing) < 0:\n754             raise ValueError(f\"Spacing must be non-negative, got {spacing}\")\n755         self.SetSpacing(*spacing)\n756         self.Modified()\n757 \n758     def _get_attrs(self):\n759         \"\"\"Return the representation methods (internal helper).\"\"\"\n760         attrs = Grid._get_attrs(self)\n761         fmt = \"{}, {}, {}\".format(*[pyvista.FLOAT_FORMAT] * 3)\n762         attrs.append((\"Spacing\", self.spacing, fmt))\n763         return attrs\n764 \n765     def cast_to_structured_grid(self) -> 'pyvista.StructuredGrid':\n766         \"\"\"Cast this uniform grid to a structured grid.\n767 \n768         Returns\n769         -------\n770         pyvista.StructuredGrid\n771             This grid as a structured grid.\n772 \n773         \"\"\"\n774         alg = _vtk.vtkImageToStructuredGrid()\n775         alg.SetInputData(self)\n776         alg.Update()\n777         return _get_output(alg)\n778 \n779     def cast_to_rectilinear_grid(self) -> 'RectilinearGrid':\n780         \"\"\"Cast this uniform grid to a rectilinear grid.\n781 \n782         Returns\n783         -------\n784         pyvista.RectilinearGrid\n785             This uniform grid as a rectilinear grid.\n786 \n787         \"\"\"\n788 \n789         def gen_coords(i):\n790             coords = (\n791                 np.cumsum(np.insert(np.full(self.dimensions[i] - 1, self.spacing[i]), 0, 0))\n792                 + self.origin[i]\n793             )\n794             return coords\n795 \n796         xcoords = gen_coords(0)\n797         ycoords = gen_coords(1)\n798         zcoords = gen_coords(2)\n799         grid = pyvista.RectilinearGrid(xcoords, ycoords, zcoords)\n800         grid.point_data.update(self.point_data)\n801         grid.cell_data.update(self.cell_data)\n802         grid.field_data.update(self.field_data)\n803         grid.copy_meta_from(self, deep=True)\n804         return grid\n805 \n806     @property\n807     def extent(self) -> tuple:\n808         \"\"\"Return or set the extent of the UniformGrid.\n809 \n810         The extent is simply the first and last indices for each of the three axes.\n811 \n812         Examples\n813         --------\n814         Create a ``UniformGrid`` and show its extent.\n815 \n816         >>> import pyvista\n817         >>> grid = pyvista.UniformGrid(dimensions=(10, 10, 10))\n818         >>> grid.extent\n819         (0, 9, 0, 9, 0, 9)\n820 \n821         >>> grid.extent = (2, 5, 2, 5, 2, 5)\n822         >>> grid.extent\n823         (2, 5, 2, 5, 2, 5)\n824 \n825         Note how this also modifies the grid bounds and dimensions. Since we\n826         use default spacing of 1 here, the bounds match the extent exactly.\n827 \n828         >>> grid.bounds\n829         (2.0, 5.0, 2.0, 5.0, 2.0, 5.0)\n830         >>> grid.dimensions\n831         (4, 4, 4)\n832 \n833         \"\"\"\n834         return self.GetExtent()\n835 \n836     @extent.setter\n837     def extent(self, new_extent: Sequence[int]):\n838         \"\"\"Set the extent of the UniformGrid.\"\"\"\n839         if len(new_extent) != 6:\n840             raise ValueError('Extent must be a vector of 6 values.')\n841         self.SetExtent(new_extent)\n842 \n843     @wraps(RectilinearGridFilters.to_tetrahedra)\n844     def to_tetrahedra(self, *args, **kwargs):\n845         \"\"\"Cast to a rectangular grid and then convert to tetrahedra.\"\"\"\n846         return self.cast_to_rectilinear_grid().to_tetrahedra(*args, **kwargs)\n847 \n[end of pyvista/core/grid.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n\n\n", "full_output": "```patch\n--- a/pyvista/core/grid.py\n+++ b/pyvista/core/grid.py\n@@ -75,7 +75,7 @@\n     uinput : str, pathlib.Path, vtk.vtkRectilinearGrid, numpy.ndarray, optional\n         Filename, dataset, or array to initialize the rectilinear grid from. If a\n         filename is passed, pyvista will attempt to load it as a\n-        :class:`RectilinearGrid`. If passed a ``vtk.vtkRectilinearGrid``, it\n+        :class:`RectilinearGrid`. If passed a ``vtk.vtkRectilinearGrid``, it\n         will be wrapped. If a :class:`numpy.ndarray` is passed, this will be\n         loaded as the x range.\n \n@@ -130,7 +130,7 @@\n             elif isinstance(args[0], np.ndarray):\n-                self._from_arrays(args[0], None, None, check_duplicates)\n+                self._from_arrays(np.asarray(args[0]), None, None, check_duplicates)\n             else:\n                 raise TypeError(f'Type ({type(args[0])}) not understood by `RectilinearGrid`')\n \n@@ -144,7 +144,7 @@\n             if all([arg0_is_arr, arg1_is_arr, arg2_is_arr]):\n-                self._from_arrays(args[0], args[1], args[2], check_duplicates)\n+                self._from_arrays(np.asarray(args[0]), np.asarray(args[1]), np.asarray(args[2]), check_duplicates)\n             elif all([arg0_is_arr, arg1_is_arr]):\n-                self._from_arrays(args[0], args[1], None, check_duplicates)\n+                self._from_arrays(np.asarray(args[0]), np.asarray(args[1]), None, check_duplicates)\n             else:\n                 raise TypeError(\"Arguments not understood by `RectilinearGrid`.\")\n```", "model_patch": "--- a/pyvista/core/grid.py\n+++ b/pyvista/core/grid.py\n@@ -75,7 +75,7 @@\n     uinput : str, pathlib.Path, vtk.vtkRectilinearGrid, numpy.ndarray, optional\n         Filename, dataset, or array to initialize the rectilinear grid from. If a\n         filename is passed, pyvista will attempt to load it as a\n-        :class:`RectilinearGrid`. If passed a ``vtk.vtkRectilinearGrid``, it\n+        :class:`RectilinearGrid`. If passed a ``vtk.vtkRectilinearGrid``, it\n         will be wrapped. If a :class:`numpy.ndarray` is passed, this will be\n         loaded as the x range.\n \n@@ -130,7 +130,7 @@\n             elif isinstance(args[0], np.ndarray):\n-                self._from_arrays(args[0], None, None, check_duplicates)\n+                self._from_arrays(np.asarray(args[0]), None, None, check_duplicates)\n             else:\n                 raise TypeError(f'Type ({type(args[0])}) not understood by `RectilinearGrid`')\n \n@@ -144,7 +144,7 @@\n             if all([arg0_is_arr, arg1_is_arr, arg2_is_arr]):\n-                self._from_arrays(args[0], args[1], args[2], check_duplicates)\n+                self._from_arrays(np.asarray(args[0]), np.asarray(args[1]), np.asarray(args[2]), check_duplicates)\n             elif all([arg0_is_arr, arg1_is_arr]):\n-                self._from_arrays(args[0], args[1], None, check_duplicates)\n+                self._from_arrays(np.asarray(args[0]), np.asarray(args[1]), None, check_duplicates)\n             else:\n                 raise TypeError(\"Arguments not understood by `RectilinearGrid`.\")\n"}
{"instance_id": "pydicom__pydicom-1255", "model_name_or_path": "gpt-4o-mini", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nMypy errors\n**Describe the bug**\r\nSeveral of the type hints are problematic and result in mypy errors.\r\n\r\nOne example:\r\n\r\n```none\r\ncat << EOF > /tmp/test.py\r\nfrom pydicom import Dataset, dcmread\r\n\r\ndataset = Dataset()\r\ndataset.Rows = 10\r\ndataset.Columns = 20\r\ndataset.NumberOfFrames = \"5\"\r\n\r\nassert int(dataset.NumberOfFrames) == 5\r\n\r\nfilename = '/tmp/test.dcm'\r\ndataset.save_as(str(filename))\r\n\r\ndataset = dcmread(filename)\r\n\r\nassert int(dataset.NumberOfFrames) == 5\r\nEOF\r\n```\r\n\r\n```none\r\nmypy /tmp/test.py\r\n/tmp/test.py:15: error: No overload variant of \"int\" matches argument type \"object\"\r\n/tmp/test.py:15: note: Possible overload variant:\r\n/tmp/test.py:15: note:     def int(self, x: Union[str, bytes, SupportsInt, _SupportsIndex] = ...) -> int\r\n/tmp/test.py:15: note:     <1 more non-matching overload not shown>\r\nFound 1 error in 1 file (checked 1 source file)\r\n```\r\n\r\n**Expected behavior**\r\nMypy should not report any errors.\r\n\r\n**Steps To Reproduce**\r\nSee above\r\n\r\n**Your environment**\r\n```none\r\npython -m pydicom.env_info\r\nmodule       | version\r\n------       | -------\r\nplatform     | macOS-10.15.6-x86_64-i386-64bit\r\nPython       | 3.8.6 (default, Oct  8 2020, 14:06:32)  [Clang 12.0.0 (clang-1200.0.32.2)]\r\npydicom      | 2.1.0\r\ngdcm         | _module not found_\r\njpeg_ls      | _module not found_\r\nnumpy        | 1.19.3\r\nPIL          | 8.0.1\r\n```\nImportError: cannot import name 'NoReturn'\n**Describe the bug**\r\nthrow following excetion when import pydicom package:\r\n```\r\nxxx/python3.6/site-packages/pydicom/filebase.py in <module>\r\n5 from struct import unpack, pack\r\n      6 from types import TracebackType\r\n----> 7 from typing import (\r\n      8     Tuple, Optional, NoReturn, BinaryIO, Callable, Type, Union, cast, TextIO,\r\n      9     TYPE_CHECKING, Any\r\n\r\nImportError: cannot import name 'NoReturn'\r\n```\r\n\r\n**Expected behavior**\r\nimort pydicom sucessfully\r\n\r\n**Steps To Reproduce**\r\nHow to reproduce the issue. Please include a minimum working code sample, the\r\ntraceback (if any) and the anonymized DICOM dataset (if relevant).\r\n\r\n**Your environment**\r\npython:3.6.0\r\npydicom:2.1\r\n\n\n</issue>\n<code>\n[start of README.md]\n1 [![CircleCI](https://circleci.com/gh/pydicom/pydicom/tree/master.svg?style=shield)](https://circleci.com/gh/pydicom/pydicom/tree/master)\n2 [![codecov](https://codecov.io/gh/pydicom/pydicom/branch/master/graph/badge.svg)](https://codecov.io/gh/pydicom/pydicom)\n3 [![Python version](https://img.shields.io/pypi/pyversions/pydicom.svg)](https://img.shields.io/pypi/pyversions/pydicom.svg)\n4 [![PyPI version](https://badge.fury.io/py/pydicom.svg)](https://badge.fury.io/py/pydicom)\n5 [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3891702.svg)](https://doi.org/10.5281/zenodo.3891702)\n6 [![Gitter](https://badges.gitter.im/pydicom/Lobby.svg)](https://gitter.im/pydicom/Lobby?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n7 \n8 # *pydicom*\n9 \n10 *pydicom* is a pure Python package for working with [DICOM](https://www.dicomstandard.org/) files. It lets you read, modify and write DICOM data in an easy \"pythonic\" way.\n11 \n12 As a pure Python package, *pydicom* can run anywhere Python runs without any other requirements, although if you're working with *Pixel Data* then we recommend you also install [NumPy](http://www.numpy.org).\n13 \n14 If you're looking for a Python library for DICOM networking then you might be interested in another of our projects: [pynetdicom](https://github.com/pydicom/pynetdicom).\n15 \n16 ## Installation\n17 \n18 Using [pip](https://pip.pypa.io/en/stable/):\n19 ```\n20 pip install pydicom\n21 ```\n22 Using [conda](https://docs.conda.io/en/latest/):\n23 ```\n24 conda install -c conda-forge pydicom\n25 ```\n26 \n27 For more information, including installation instructions for the development version, see the [installation guide](https://pydicom.github.io/pydicom/stable/tutorials/installation.html).\n28 \n29 \n30 ## Documentation\n31 \n32 The *pydicom* [user guide](https://pydicom.github.io/pydicom/stable/old/pydicom_user_guide.html), [tutorials](https://pydicom.github.io/pydicom/stable/tutorials/index.html), [examples](https://pydicom.github.io/pydicom/stable/auto_examples/index.html) and [API reference](https://pydicom.github.io/pydicom/stable/reference/index.html) documentation is available for both the [current release](https://pydicom.github.io/pydicom/stable) and the [development version](https://pydicom.github.io/pydicom/dev) on GitHub Pages.\n33 \n34 ## *Pixel Data*\n35 \n36 Compressed and uncompressed *Pixel Data* is always available to\n37 be read, changed and written as [bytes](https://docs.python.org/3/library/stdtypes.html#bytes-objects):\n38 ```python\n39 >>> from pydicom import dcmread\n40 >>> from pydicom.data import get_testdata_file\n41 >>> path = get_testdata_file(\"CT_small.dcm\")\n42 >>> ds = dcmread(path)\n43 >>> type(ds.PixelData)\n44 <class 'bytes'>\n45 >>> len(ds.PixelData)\n46 32768\n47 >>> ds.PixelData[:2]\n48 b'\\xaf\\x00'\n49 \n50 ```\n51 \n52 If [NumPy](http://www.numpy.org) is installed, *Pixel Data* can be converted to an [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html) using the [Dataset.pixel_array](https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.dataset.Dataset.html#pydicom.dataset.Dataset.pixel_array) property:\n53 \n54 ```python\n55 >>> arr = ds.pixel_array\n56 >>> arr.shape\n57 (128, 128)\n58 >>> arr\n59 array([[175, 180, 166, ..., 203, 207, 216],\n60        [186, 183, 157, ..., 181, 190, 239],\n61        [184, 180, 171, ..., 152, 164, 235],\n62        ...,\n63        [906, 910, 923, ..., 922, 929, 927],\n64        [914, 954, 938, ..., 942, 925, 905],\n65        [959, 955, 916, ..., 911, 904, 909]], dtype=int16)\n66 ```\n67 ### Compressed *Pixel Data*\n68 #### JPEG, JPEG-LS and JPEG 2000\n69 Converting JPEG compressed *Pixel Data* to an ``ndarray`` requires installing one or more additional Python libraries. For information on which libraries are required, see the [pixel data handler documentation](https://pydicom.github.io/pydicom/dev/old/image_data_handlers.html#guide-compressed).\n70 \n71 Compressing data into one of the JPEG formats is not currently supported.\n72 \n73 #### RLE\n74 RLE encoded *Pixel Data* only requires NumPy, and compression and decompression are both supported.\n75 \n76 ## Examples\n77 More [examples](https://pydicom.github.io/pydicom/stable/auto_examples/index.html) are available in the documentation.\n78 \n79 **Change a patient's ID**\n80 ```python\n81 from pydicom import dcmread\n82 \n83 ds = dcmread(\"/path/to/file.dcm\")\n84 # Edit the (0010,0020) 'Patient ID' element\n85 ds.PatientID = \"12345678\"\n86 ds.save_as(\"/path/to/file_updated.dcm\")\n87 ```\n88 \n89 **Display the Pixel Data**\n90 \n91 With [NumPy](http://www.numpy.org) and [matplotlib](https://matplotlib.org/)\n92 ```python\n93 import matplotlib.pyplot as plt\n94 from pydicom import dcmread\n95 from pydicom.data import get_testdata_file\n96 \n97 # The path to a pydicom test dataset\n98 path = get_testdata_file(\"CT_small.dcm\")\n99 ds = dcmread(path)\n100 # `arr` is a numpy.ndarray\n101 arr = ds.pixel_array\n102 \n103 plt.imshow(arr, cmap=\"gray\")\n104 plt.show()\n105 ```\n106 \n107 ## Contributing\n108 \n109 To contribute to *pydicom*, read our [contribution guide](https://github.com/pydicom/pydicom/blob/master/CONTRIBUTING.md).\n110 \n111 To contribute an example or extension of *pydicom* that doesn't belong with the core software, see our contribution repository:\n112 [contrib-pydicom](https://www.github.com/pydicom/contrib-pydicom).\n113 \n[end of README.md]\n[start of pydicom/_version.py]\n1 \"\"\"Pure python package for DICOM medical file reading and writing.\"\"\"\n2 import re\n3 from typing import Tuple\n4 \n5 \n6 __version__: str = '2.1.0'\n7 __version_info__: Tuple[str, str, str] = tuple(\n8     re.match(r'(\\d+\\.\\d+\\.\\d+).*', __version__).group(1).split('.')\n9 )\n10 \n11 \n12 # DICOM Standard version used for:\n13 #   _dicom_dict, _uid_dict and _storage_sopclass_uids\n14 __dicom_version__: str = '2020d'\n15 \n[end of pydicom/_version.py]\n[start of pydicom/filebase.py]\n1 # Copyright 2008-2020 pydicom authors. See LICENSE file for details.\n2 \"\"\"Hold DicomFile class, which does basic I/O for a dicom file.\"\"\"\n3 \n4 from io import BytesIO\n5 from struct import unpack, pack\n6 from types import TracebackType\n7 from typing import (\n8     Tuple, Optional, NoReturn, BinaryIO, Callable, Type, Union, cast, TextIO,\n9     TYPE_CHECKING, Any\n10 )\n11 \n12 try:\n13     from typing import Protocol  # added in 3.8\n14 except ImportError:\n15     Protocol = object\n16 \n17 from pydicom.tag import Tag, BaseTag, TagType\n18 \n19 \n20 # Customise the type hints for read() and seek()\n21 class Reader(Protocol):\n22     def __call__(self, size: int = -1) -> bytes: ...\n23 \n24 \n25 class Seeker(Protocol):\n26     def __call__(self, offset: int, whence: int = 0) -> int: ...\n27 \n28 \n29 class DicomIO:\n30     \"\"\"File object which holds transfer syntax info and anything else we need.\n31     \"\"\"\n32 \n33     # number of times to read if don't get requested bytes\n34     max_read_attempts = 3\n35 \n36     # default\n37     defer_size = None\n38 \n39     def __init__(self, *args: Any, **kwargs: Any) -> None:\n40         # start with this by default\n41         self._implicit_VR = True\n42         self.write: Callable[[bytes], int]\n43         self.parent_read: Reader\n44         self.seek: Seeker\n45         self.tell: Callable[[], int]\n46 \n47     def read_le_tag(self) -> Tuple[int, int]:\n48         \"\"\"Read and return two unsigned shorts (little endian) from the file.\n49         \"\"\"\n50         bytes_read = self.read(4, need_exact_length=True)\n51         return cast(Tuple[int, int], unpack(b\"<HH\", bytes_read))\n52 \n53     def read_be_tag(self) -> Tuple[int, int]:\n54         \"\"\"Read and return two unsigned shorts (big endian) from the file.\"\"\"\n55         bytes_read = self.read(4, need_exact_length=True)\n56         return cast(Tuple[int, int], unpack(b\">HH\", bytes_read))\n57 \n58     def write_tag(self, tag: TagType) -> None:\n59         \"\"\"Write a dicom tag (two unsigned shorts) to the file.\"\"\"\n60         # make sure is an instance of class, not just a tuple or int\n61         if not isinstance(tag, BaseTag):\n62             tag = Tag(tag)\n63         self.write_US(tag.group)\n64         self.write_US(tag.element)\n65 \n66     def read_leUS(self) -> int:\n67         \"\"\"Return an unsigned short from the file with little endian byte order\n68         \"\"\"\n69         val: Tuple[int, ...] = unpack(b\"<H\", self.read(2))\n70         return val[0]\n71 \n72     def read_beUS(self) -> int:\n73         \"\"\"Return an unsigned short from the file with big endian byte order\"\"\"\n74         val: Tuple[int, ...] = unpack(b\">H\", self.read(2))\n75         return val[0]\n76 \n77     def read_leUL(self) -> int:\n78         \"\"\"Return an unsigned long read with little endian byte order\"\"\"\n79         val: Tuple[int, ...] = unpack(b\"<L\", self.read(4))\n80         return val[0]\n81 \n82     def read(\n83         self, length: Optional[int] = None, need_exact_length: bool = False\n84     ) -> bytes:\n85         \"\"\"Reads the required length, returns EOFError if gets less\n86 \n87         If length is ``None``, then read all bytes\n88         \"\"\"\n89         parent_read = self.parent_read  # super(DicomIO, self).read\n90         if length is None:\n91             return parent_read()  # get all of it\n92 \n93         bytes_read = parent_read(length)\n94         if len(bytes_read) < length and need_exact_length:\n95             # Didn't get all the desired bytes. Keep trying to get the rest.\n96             # If reading across network, might want to add a delay here\n97             attempts = 0\n98             max_reads = self.max_read_attempts\n99             while attempts < max_reads and len(bytes_read) < length:\n100                 bytes_read += parent_read(length - len(bytes_read))\n101                 attempts += 1\n102             num_bytes = len(bytes_read)\n103             if num_bytes < length:\n104                 start_pos = self.tell() - num_bytes\n105                 msg = (\n106                     f\"Unexpected end of file. Read {len(bytes_read)} bytes \"\n107                     f\"of {length} expected starting at position \"\n108                     f\"0x{start_pos:x}\"\n109                 )\n110                 raise EOFError(msg)\n111         return bytes_read\n112 \n113     def write_leUS(self, val: int) -> None:\n114         \"\"\"Write an unsigned short with little endian byte order\"\"\"\n115         self.write(pack(b\"<H\", val))\n116 \n117     def write_leUL(self, val: int) -> None:\n118         \"\"\"Write an unsigned long with little endian byte order\"\"\"\n119         self.write(pack(b\"<L\", val))\n120 \n121     def write_beUS(self, val: int) -> None:\n122         \"\"\"Write an unsigned short with big endian byte order\"\"\"\n123         self.write(pack(b\">H\", val))\n124 \n125     def write_beUL(self, val: int) -> None:\n126         \"\"\"Write an unsigned long with big endian byte order\"\"\"\n127         self.write(pack(b\">L\", val))\n128 \n129     write_US = write_leUS\n130     write_UL = write_leUL\n131 \n132     def read_beUL(self) -> int:\n133         \"\"\"Return an unsigned long read with big endian byte order\"\"\"\n134         val: Tuple[int, ...] = unpack(b\">L\", self.read(4))\n135         return val[0]\n136 \n137     # Set up properties is_little_endian and is_implicit_VR\n138     # Big/Little Endian changes functions to read unsigned\n139     # short or long, e.g. length fields etc\n140     @property\n141     def is_little_endian(self) -> bool:\n142         return self._little_endian\n143 \n144     @is_little_endian.setter\n145     def is_little_endian(self, value: bool) -> None:\n146         self._little_endian = value\n147         if value:  # Little Endian\n148             self.read_US = self.read_leUS\n149             self.read_UL = self.read_leUL\n150             self.write_US = self.write_leUS\n151             self.write_UL = self.write_leUL\n152             self.read_tag = self.read_le_tag\n153         else:  # Big Endian\n154             self.read_US = self.read_beUS\n155             self.read_UL = self.read_beUL\n156             self.write_US = self.write_beUS\n157             self.write_UL = self.write_beUL\n158             self.read_tag = self.read_be_tag\n159 \n160     @property\n161     def is_implicit_VR(self) -> bool:\n162         return self._implicit_VR\n163 \n164     @is_implicit_VR.setter\n165     def is_implicit_VR(self, value: bool) -> None:\n166         self._implicit_VR = value\n167 \n168 \n169 class DicomFileLike(DicomIO):\n170     def __init__(\n171         self,\n172         file_like_obj: Union[TextIO, BinaryIO, BytesIO],\n173         *args: Any,\n174         **kwargs: Any\n175     ) -> None:\n176         super().__init__(*args, **kwargs)\n177         self.parent = file_like_obj\n178         self.parent_read = getattr(file_like_obj, \"read\", self.no_read)\n179         self.write = getattr(file_like_obj, \"write\", self.no_write)\n180         self.seek = getattr(file_like_obj, \"seek\", self.no_seek)\n181         self.tell = file_like_obj.tell\n182         self.close = file_like_obj.close\n183         self.name: str = getattr(file_like_obj, 'name', '<no filename>')\n184 \n185     def no_write(self, bytes_read: bytes) -> NoReturn:\n186         \"\"\"Used for file-like objects where no write is available\"\"\"\n187         raise IOError(\"This DicomFileLike object has no write() method\")\n188 \n189     def no_read(self, bytes_read: Optional[int] = None) -> NoReturn:\n190         \"\"\"Used for file-like objects where no read is available\"\"\"\n191         raise IOError(\"This DicomFileLike object has no read() method\")\n192 \n193     def no_seek(self, offset: int, from_what: int = 0) -> NoReturn:\n194         \"\"\"Used for file-like objects where no seek is available\"\"\"\n195         raise IOError(\"This DicomFileLike object has no seek() method\")\n196 \n197     def __enter__(self) -> \"DicomFileLike\":\n198         return self\n199 \n200     def __exit__(\n201         self,\n202         *exc_info: Tuple[\n203             Optional[Type[BaseException]],\n204             Optional[BaseException],\n205             Optional[TracebackType]\n206         ]\n207     ) -> None:\n208         self.close()\n209 \n210 \n211 def DicomFile(*args: Any, **kwargs: Any) -> DicomFileLike:\n212     return DicomFileLike(open(*args, **kwargs))\n213 \n214 \n215 class DicomBytesIO(DicomFileLike):\n216     def __init__(self, *args: Any, **kwargs: Any) -> None:\n217         super().__init__(BytesIO(*args, **kwargs))\n218 \n219     def getvalue(self) -> bytes:\n220         self.parent = cast(BytesIO, self.parent)\n221         return self.parent.getvalue()\n222 \n[end of pydicom/filebase.py]\n[start of pydicom/jsonrep.py]\n1 # Copyright 2008-2019 pydicom authors. See LICENSE file for details.\n2 \"\"\"Methods for converting Datasets and DataElements to/from json\"\"\"\n3 \n4 import base64\n5 from inspect import signature\n6 import inspect\n7 from typing import Callable, Optional, Union\n8 import warnings\n9 \n10 from pydicom.tag import BaseTag\n11 \n12 # Order of keys is significant!\n13 JSON_VALUE_KEYS = ('Value', 'BulkDataURI', 'InlineBinary',)\n14 \n15 BINARY_VR_VALUES = ['OW', 'OB', 'OD', 'OF', 'OL', 'UN',\n16                     'OB or OW', 'US or OW', 'US or SS or OW']\n17 VRs_TO_BE_FLOATS = ['DS', 'FL', 'FD', ]\n18 VRs_TO_BE_INTS = ['IS', 'SL', 'SS', 'UL', 'US', 'US or SS']\n19 \n20 \n21 def convert_to_python_number(value, vr):\n22     \"\"\"Makes sure that values are either ints or floats\n23     based on their value representation.\n24 \n25     .. versionadded:: 1.4\n26 \n27     Parameters\n28     ----------\n29     value: Union[Union[str, int, float], List[Union[str, int, float]]]\n30         value of data element\n31     vr: str\n32         value representation of data element\n33 \n34     Returns\n35     -------\n36     Union[Union[str, int, float], List[Union[str, int, float]]]\n37 \n38     \"\"\"\n39     if value is None:\n40         return None\n41     number_type = None\n42     if vr in VRs_TO_BE_INTS:\n43         number_type = int\n44     if vr in VRs_TO_BE_FLOATS:\n45         number_type = float\n46     if number_type is not None:\n47         if isinstance(value, (list, tuple,)):\n48             value = [number_type(e) for e in value]\n49         else:\n50             value = number_type(value)\n51     return value\n52 \n53 \n54 class JsonDataElementConverter:\n55     \"\"\"Handles conversion between JSON struct and :class:`DataElement`.\n56 \n57     .. versionadded:: 1.4\n58     \"\"\"\n59 \n60     def __init__(\n61         self,\n62         dataset_class,\n63         tag,\n64         vr,\n65         value,\n66         value_key,\n67         bulk_data_uri_handler: Optional[\n68             Union[\n69                 Callable[[BaseTag, str, str], object],\n70                 Callable[[str], object]\n71             ]\n72         ] = None\n73     ):\n74         \"\"\"Create a new converter instance.\n75 \n76         Parameters\n77         ----------\n78         dataset_class : dataset.Dataset derived class\n79             Class used to create sequence items.\n80         tag : BaseTag\n81             The data element tag or int.\n82         vr : str\n83             The data element value representation.\n84         value : list\n85             The data element's value(s).\n86         value_key : str or None\n87             Key of the data element that contains the value\n88             (options: ``{\"Value\", \"InlineBinary\", \"BulkDataURI\"}``)\n89         bulk_data_uri_handler: callable or None\n90             Callable function that accepts either the tag, vr and \"BulkDataURI\"\n91             or just the \"BulkDataURI\" of the JSON\n92             representation of a data element and returns the actual value of\n93             that data element (retrieved via DICOMweb WADO-RS)\n94         \"\"\"\n95         self.dataset_class = dataset_class\n96         self.tag = tag\n97         self.vr = vr\n98         self.value = value\n99         self.value_key = value_key\n100         if (\n101             bulk_data_uri_handler and\n102             len(signature(bulk_data_uri_handler).parameters) == 1\n103         ):\n104             def wrapped_bulk_data_handler(tag, vr, value):\n105                 return bulk_data_uri_handler(value)\n106             self.bulk_data_element_handler = wrapped_bulk_data_handler\n107         else:\n108             self.bulk_data_element_handler = bulk_data_uri_handler\n109 \n110     def get_element_values(self):\n111         \"\"\"Return a the data element value or list of values.\n112 \n113         Returns\n114         -------\n115         str or bytes or int or float or dataset_class\n116         or PersonName or list of any of these types\n117             The value or value list of the newly created data element.\n118         \"\"\"\n119         from pydicom.dataelem import empty_value_for_VR\n120         if self.value_key == 'Value':\n121             if not isinstance(self.value, list):\n122                 fmt = '\"{}\" of data element \"{}\" must be a list.'\n123                 raise TypeError(fmt.format(self.value_key, self.tag))\n124             if not self.value:\n125                 return empty_value_for_VR(self.vr)\n126             element_value = [self.get_regular_element_value(v)\n127                              for v in self.value]\n128             if len(element_value) == 1 and self.vr != 'SQ':\n129                 element_value = element_value[0]\n130             return convert_to_python_number(element_value, self.vr)\n131 \n132         # The value for \"InlineBinary\" shall be encoded as a base64 encoded\n133         # string, as shown in PS3.18, Table F.3.1-1, but the example in\n134         # PS3.18, Annex F.4 shows the string enclosed in a list.\n135         # We support both variants, as the standard is ambiguous here,\n136         # and do the same for \"BulkDataURI\".\n137         value = self.value\n138         if isinstance(value, list):\n139             value = value[0]\n140 \n141         if self.value_key == 'InlineBinary':\n142             if not isinstance(value, (str, bytes)):\n143                 fmt = '\"{}\" of data element \"{}\" must be a bytes-like object.'\n144                 raise TypeError(fmt.format(self.value_key, self.tag))\n145             return base64.b64decode(value)\n146 \n147         if self.value_key == 'BulkDataURI':\n148             if not isinstance(value, str):\n149                 fmt = '\"{}\" of data element \"{}\" must be a string.'\n150                 raise TypeError(fmt.format(self.value_key, self.tag))\n151             if self.bulk_data_element_handler is None:\n152                 warnings.warn(\n153                     'no bulk data URI handler provided for retrieval '\n154                     'of value of data element \"{}\"'.format(self.tag)\n155                 )\n156                 return empty_value_for_VR(self.vr, raw=True)\n157             return self.bulk_data_element_handler(self.tag, self.vr, value)\n158         return empty_value_for_VR(self.vr)\n159 \n160     def get_regular_element_value(self, value):\n161         \"\"\"Return a the data element value created from a json \"Value\" entry.\n162 \n163         Parameters\n164         ----------\n165         value : str or int or float or dict\n166             The data element's value from the json entry.\n167 \n168         Returns\n169         -------\n170         dataset_class or PersonName\n171         or str or int or float\n172             A single value of the corresponding :class:`DataElement`.\n173         \"\"\"\n174         if self.vr == 'SQ':\n175             return self.get_sequence_item(value)\n176 \n177         if self.vr == 'PN':\n178             return self.get_pn_element_value(value)\n179 \n180         if self.vr == 'AT':\n181             try:\n182                 return int(value, 16)\n183             except ValueError:\n184                 warnings.warn('Invalid value \"{}\" for AT element - '\n185                               'ignoring it'.format(value))\n186             return\n187         return value\n188 \n189     def get_sequence_item(self, value):\n190         \"\"\"Return a sequence item for the JSON dict `value`.\n191 \n192         Parameters\n193         ----------\n194         value : dict or None\n195             The sequence item from the JSON entry.\n196 \n197         Returns\n198         -------\n199         dataset_class\n200             The decoded dataset item.\n201 \n202         Raises\n203         ------\n204         KeyError\n205             If the \"vr\" key is missing for a contained element\n206         \"\"\"\n207         ds = self.dataset_class()\n208         if value:\n209             for key, val in value.items():\n210                 if 'vr' not in val:\n211                     fmt = 'Data element \"{}\" must have key \"vr\".'\n212                     raise KeyError(fmt.format(self.tag))\n213                 vr = val['vr']\n214                 unique_value_keys = tuple(\n215                     set(val.keys()) & set(JSON_VALUE_KEYS)\n216                 )\n217                 from pydicom import DataElement\n218                 from pydicom.dataelem import empty_value_for_VR\n219                 if not unique_value_keys:\n220                     # data element with no value\n221                     elem = DataElement(\n222                         tag=int(key, 16),\n223                         value=empty_value_for_VR(vr),\n224                         VR=vr)\n225                 else:\n226                     value_key = unique_value_keys[0]\n227                     elem = DataElement.from_json(\n228                         self.dataset_class, key, vr,\n229                         val[value_key], value_key\n230                     )\n231                 ds.add(elem)\n232         return ds\n233 \n234     def get_pn_element_value(self, value):\n235         \"\"\"Return PersonName value from JSON value.\n236 \n237         Values with VR PN have a special JSON encoding, see the DICOM Standard,\n238         Part 18, :dcm:`Annex F.2.2<part18/sect_F.2.2.html>`.\n239 \n240         Parameters\n241         ----------\n242         value : dict\n243             The person name components in the JSON entry.\n244 \n245         Returns\n246         -------\n247         PersonName or str\n248             The decoded PersonName object or an empty string.\n249         \"\"\"\n250         if not isinstance(value, dict):\n251             # Some DICOMweb services get this wrong, so we\n252             # workaround the issue and warn the user\n253             # rather than raising an error.\n254             warnings.warn(\n255                 'value of data element \"{}\" with VR Person Name (PN) '\n256                 'is not formatted correctly'.format(self.tag)\n257             )\n258             return value\n259         else:\n260             if 'Phonetic' in value:\n261                 comps = ['', '', '']\n262             elif 'Ideographic' in value:\n263                 comps = ['', '']\n264             else:\n265                 comps = ['']\n266             if 'Alphabetic' in value:\n267                 comps[0] = value['Alphabetic']\n268             if 'Ideographic' in value:\n269                 comps[1] = value['Ideographic']\n270             if 'Phonetic' in value:\n271                 comps[2] = value['Phonetic']\n272             elem_value = '='.join(comps)\n273             return elem_value\n274 \n[end of pydicom/jsonrep.py]\n[start of setup.py]\n1 #!/usr/bin/env python\n2 \n3 import os\n4 import os.path\n5 import sys\n6 from glob import glob\n7 from setuptools import setup, find_packages\n8 \n9 have_dicom = True\n10 try:\n11     import dicom\n12 except ImportError:\n13     have_dicom = False\n14 \n15 # get __version__ from _version.py\n16 base_dir = os.path.dirname(os.path.realpath(__file__))\n17 ver_file = os.path.join(base_dir, 'pydicom', '_version.py')\n18 with open(ver_file) as f:\n19     exec(f.read())\n20 \n21 description = \"Pure python package for DICOM medical file reading and writing\"\n22 \n23 needs_pytest = {'pytest', 'test', 'ptr'}.intersection(sys.argv)\n24 pytest_runner = ['pytest-runner'] if needs_pytest else []\n25 \n26 TESTS_REQUIRE = ['pytest']\n27 _py_modules = []\n28 if not have_dicom:\n29     _py_modules = ['dicom']\n30 \n31 CLASSIFIERS = [\n32     \"License :: OSI Approved :: MIT License\",\n33     \"Intended Audience :: Developers\",\n34     \"Intended Audience :: Healthcare Industry\",\n35     \"Intended Audience :: Science/Research\",\n36     \"Development Status :: 5 - Production/Stable\",\n37     \"Programming Language :: Python\",\n38     \"Programming Language :: Python :: 3.6\",\n39     \"Programming Language :: Python :: 3.7\",\n40     \"Programming Language :: Python :: 3.8\",\n41     \"Operating System :: OS Independent\",\n42     \"Topic :: Scientific/Engineering :: Medical Science Apps.\",\n43     \"Topic :: Scientific/Engineering :: Physics\",\n44     \"Topic :: Software Development :: Libraries\"\n45 ]\n46 \n47 KEYWORDS = \"dicom python medical imaging\"\n48 \n49 NAME = \"pydicom\"\n50 AUTHOR = \"Darcy Mason and contributors\"\n51 AUTHOR_EMAIL = \"darcymason@gmail.com\"\n52 MAINTAINER = \"Darcy Mason and contributors\"\n53 MAINTAINER_EMAIL = \"darcymason@gmail.com\"\n54 DESCRIPTION = description\n55 URL = \"https://github.com/pydicom/pydicom\"\n56 DOWNLOAD_URL = \"https://github.com/pydicom/pydicom/archive/master.zip\"\n57 LICENSE = \"MIT\"\n58 VERSION = __version__  # noqa: F821\n59 REQUIRES = []\n60 SETUP_REQUIRES = pytest_runner\n61 \n62 # get long description from README.md\n63 BASE_PATH = os.path.abspath(os.path.dirname(__file__))\n64 with open(os.path.join(BASE_PATH, 'README.md')) as f:\n65     LONG_DESCRIPTION = f.read()\n66 \n67 \n68 def data_files_inventory():\n69     data_files = []\n70     data_roots = ['pydicom/data']\n71     for data_root in data_roots:\n72         for root, subfolder, files in os.walk(data_root):\n73             files = [\n74                 x.replace('pydicom/', '') for x in glob(root + '/*')\n75                 if not os.path.isdir(x)\n76             ]\n77             files = [f for f in files if not f.endswith('.pyc')]\n78             data_files += files\n79     return data_files\n80 \n81 \n82 PACKAGE_DATA = {\n83     'pydicom': data_files_inventory() + ['py.typed']\n84 }\n85 \n86 opts = dict(\n87     name=NAME,\n88     python_requires='>=3.6',\n89     version=VERSION,\n90     maintainer=MAINTAINER,\n91     maintainer_email=MAINTAINER_EMAIL,\n92     author=AUTHOR,\n93     author_email=AUTHOR_EMAIL,\n94     description=description,\n95     long_description=LONG_DESCRIPTION,\n96     long_description_content_type='text/markdown',\n97     url=URL,\n98     download_url=DOWNLOAD_URL,\n99     license=LICENSE,\n100     keywords=KEYWORDS,\n101     classifiers=CLASSIFIERS,\n102     packages=find_packages(),\n103     py_modules=_py_modules,\n104     package_data=PACKAGE_DATA,\n105     include_package_data=True,\n106     install_requires=REQUIRES,\n107     setup_requires=SETUP_REQUIRES,\n108     tests_require=TESTS_REQUIRE,\n109     zip_safe=False\n110 )\n111 \n112 if __name__ == '__main__':\n113     setup(**opts)\n114 \n[end of setup.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n\n\n", "full_output": "```patch\n--- a/pydicom/filebase.py\n+++ b/pydicom/filebase.py\n@@ -8,7 +8,7 @@\n     Tuple, Optional, BinaryIO, Callable, Type, Union, cast, TextIO,\n     TYPE_CHECKING, Any\n )\n-from typing import NoReturn  # Import NoReturn only if Python version >= 3.6\n+from typing import NoReturn, Optional  # Import NoReturn and Optional\n \n \n try:\n@@ -185,7 +185,7 @@\n     def no_write(self, bytes_read: bytes) -> NoReturn:\n         \"\"\"Used for file-like objects where no write is available\"\"\"\n         raise IOError(\"This DicomFileLike object has no write() method\")\n \n-    def no_read(self, bytes_read: Optional[int] = None) -> NoReturn:\n+    def no_read(self, bytes_read: Optional[int] = None) -> None:\n         \"\"\"Used for file-like objects where no read is available\"\"\"\n         raise IOError(\"This DicomFileLike object has no read() method\")\n \n@@ -193,7 +193\n     def no_seek(self, offset: int, from_what: int = 0) -> NoReturn:\n         \"\"\"Used for file-like objects where no seek is available\"\"\"\n         raise IOError(\"This DicomFileLike object has no seek() method\")\n \n--- a/pydicom/jsonrep.py\n+++ b/pydicom/jsonrep.py\n@@ -7,7 +7,7 @@\n from typing import Callable, Optional, Union\n import warnings\n \n-from pydicom.tag import BaseTag\n+from pydicom.tag import BaseTag, Tag\n \n \n # Order of keys is significant!\n@@ -68,7 +68,7 @@\n             Callable[[BaseTag, str, str], object],\n             Callable[[str], object]\n         ] = None\n-    ):\n+    ) -> None:\n         \"\"\"Create a new converter instance.\n \n         Parameters\n@@ -110,7 +110\n     def get_element_values(self):\n         \"\"\"Return a the data element value or list of values.\n \n@@ -161,7 +161\n     def get_regular_element_value(self, value):\n         \"\"\"Return a the data element value created from a json \"Value\" entry.\n \n@@ -189,7 +189\n     def get_sequence_item(self, value):\n         \"\"\"Return a sequence item for the JSON dict `value`.\n \n@@ -234,7 +234\n     def get_pn_element_value(self, value):\n         \"\"\"Return PersonName value from JSON value.\n \n```", "model_patch": "--- a/pydicom/filebase.py\n+++ b/pydicom/filebase.py\n@@ -8,7 +8,7 @@\n     Tuple, Optional, BinaryIO, Callable, Type, Union, cast, TextIO,\n     TYPE_CHECKING, Any\n )\n-from typing import NoReturn  # Import NoReturn only if Python version >= 3.6\n+from typing import NoReturn, Optional  # Import NoReturn and Optional\n \n \n try:\n@@ -185,7 +185,7 @@\n     def no_write(self, bytes_read: bytes) -> NoReturn:\n         \"\"\"Used for file-like objects where no write is available\"\"\"\n         raise IOError(\"This DicomFileLike object has no write() method\")\n \n-    def no_read(self, bytes_read: Optional[int] = None) -> NoReturn:\n+    def no_read(self, bytes_read: Optional[int] = None) -> None:\n         \"\"\"Used for file-like objects where no read is available\"\"\"\n         raise IOError(\"This DicomFileLike object has no read() method\")\n \n@@ -193,7 +193\n     def no_seek(self, offset: int, from_what: int = 0) -> NoReturn:\n         \"\"\"Used for file-like objects where no seek is available\"\"\"\n         raise IOError(\"This DicomFileLike object has no seek() method\")\n \n--- a/pydicom/jsonrep.py\n+++ b/pydicom/jsonrep.py\n@@ -7,7 +7,7 @@\n from typing import Callable, Optional, Union\n import warnings\n \n-from pydicom.tag import BaseTag\n+from pydicom.tag import BaseTag, Tag\n \n \n # Order of keys is significant!\n@@ -68,7 +68,7 @@\n             Callable[[BaseTag, str, str], object],\n             Callable[[str], object]\n         ] = None\n-    ):\n+    ) -> None:\n         \"\"\"Create a new converter instance.\n \n         Parameters\n@@ -110,7 +110\n     def get_element_values(self):\n         \"\"\"Return a the data element value or list of values.\n \n@@ -161,7 +161\n     def get_regular_element_value(self, value):\n         \"\"\"Return a the data element value created from a json \"Value\" entry.\n \n@@ -189,7 +189\n     def get_sequence_item(self, value):\n         \"\"\"Return a sequence item for the JSON dict `value`.\n \n@@ -234,7 +234\n     def get_pn_element_value(self, value):\n         \"\"\"Return PersonName value from JSON value.\n \n"}
{"instance_id": "pydicom__pydicom-1416", "model_name_or_path": "gpt-4o-mini", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nSegmented LUTs are incorrectly expanded\n**Describe the bug**\r\n`pydicom.pixel_data_handlers.util._expand_segmented_lut()` expands segmented LUTs to an incorrect length.\r\n\r\n**Expected behavior**\r\nA correct length LUT to be produced.\r\n\r\n**Steps To Reproduce**\r\nInitialize the following variables.\r\n```\r\nimport numpy as np\r\nlength = 48\r\ny0 = 163\r\ny1 = 255\r\n```\r\n\r\nRun the following two lines from [`pydicom.pixel_data_handlers.util._expand_segmented_lut()`](https://github.com/pydicom/pydicom/blob/699c9f0a8e190d463dd828822106250523d38154/pydicom/pixel_data_handlers/util.py#L875\r\n)\r\n```\r\nstep = (y1 - y0) / length\r\nvals = np.around(np.arange(y0 + step, y1 + step, step))\r\n```\r\n\r\nConfirm that variable `vals` if of incorrect length\r\n```\r\nprint(len(vals) == length)\r\n> False\r\n```\r\n\r\nAlternatively, the code below produces similarly false results\r\n\r\n```\r\nfrom pydicom.pixel_data_handlers.util import _expand_segmented_lut \r\nlut = _expand_segmented_lut(([0, 1, 163, 1, 48, 255]), \"B\")\r\nprint(len(lut) == (1+48))\r\n> False\r\n```\r\n\r\n`np.arange` [explicitly states](https://numpy.org/doc/stable/reference/generated/numpy.arange.html) that it's \"results will often not be consistent\" when using \"non-integer step\", which is a very possible scenario in this function. The following alternative code does function correctly:\r\n\r\n```\r\nvals = np.around(np.linspace(y0 + step, y1, length))\r\n```\r\n\r\n**Your environment**\r\n```bash\r\n$ python -m pydicom.env_info\r\nmodule       | version\r\n------       | -------\r\nplatform     | Darwin-20.5.0-x86_64-i386-64bit\r\nPython       | 3.7.10 (default, Feb 26 2021, 10:16:00)  [Clang 10.0.0 ]\r\npydicom      | 2.1.2\r\ngdcm         | _module not found_\r\njpeg_ls      | _module not found_\r\nnumpy        | 1.20.3\r\nPIL          | 8.2.0\r\n```\n\n</issue>\n<code>\n[start of README.md]\n1 [![CircleCI](https://circleci.com/gh/pydicom/pydicom/tree/master.svg?style=shield)](https://circleci.com/gh/pydicom/pydicom/tree/master)\n2 [![codecov](https://codecov.io/gh/pydicom/pydicom/branch/master/graph/badge.svg)](https://codecov.io/gh/pydicom/pydicom)\n3 [![Python version](https://img.shields.io/pypi/pyversions/pydicom.svg)](https://img.shields.io/pypi/pyversions/pydicom.svg)\n4 [![PyPI version](https://badge.fury.io/py/pydicom.svg)](https://badge.fury.io/py/pydicom)\n5 [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.4197955.svg)](https://doi.org/10.5281/zenodo.4197955)\n6 [![Gitter](https://badges.gitter.im/pydicom/Lobby.svg)](https://gitter.im/pydicom/Lobby?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n7 \n8 # *pydicom*\n9 \n10 *pydicom* is a pure Python package for working with [DICOM](https://www.dicomstandard.org/) files. It lets you read, modify and write DICOM data in an easy \"pythonic\" way.\n11 \n12 As a pure Python package, *pydicom* can run anywhere Python runs without any other requirements, although if you're working with *Pixel Data* then we recommend you also install [NumPy](http://www.numpy.org).\n13 \n14 If you're looking for a Python library for DICOM networking then you might be interested in another of our projects: [pynetdicom](https://github.com/pydicom/pynetdicom).\n15 \n16 ## Installation\n17 \n18 Using [pip](https://pip.pypa.io/en/stable/):\n19 ```\n20 pip install pydicom\n21 ```\n22 Using [conda](https://docs.conda.io/en/latest/):\n23 ```\n24 conda install -c conda-forge pydicom\n25 ```\n26 \n27 For more information, including installation instructions for the development version, see the [installation guide](https://pydicom.github.io/pydicom/stable/tutorials/installation.html).\n28 \n29 \n30 ## Documentation\n31 \n32 The *pydicom* [user guide](https://pydicom.github.io/pydicom/stable/old/pydicom_user_guide.html), [tutorials](https://pydicom.github.io/pydicom/stable/tutorials/index.html), [examples](https://pydicom.github.io/pydicom/stable/auto_examples/index.html) and [API reference](https://pydicom.github.io/pydicom/stable/reference/index.html) documentation is available for both the [current release](https://pydicom.github.io/pydicom/stable) and the [development version](https://pydicom.github.io/pydicom/dev) on GitHub Pages.\n33 \n34 ## *Pixel Data*\n35 \n36 Compressed and uncompressed *Pixel Data* is always available to\n37 be read, changed and written as [bytes](https://docs.python.org/3/library/stdtypes.html#bytes-objects):\n38 ```python\n39 >>> from pydicom import dcmread\n40 >>> from pydicom.data import get_testdata_file\n41 >>> path = get_testdata_file(\"CT_small.dcm\")\n42 >>> ds = dcmread(path)\n43 >>> type(ds.PixelData)\n44 <class 'bytes'>\n45 >>> len(ds.PixelData)\n46 32768\n47 >>> ds.PixelData[:2]\n48 b'\\xaf\\x00'\n49 \n50 ```\n51 \n52 If [NumPy](http://www.numpy.org) is installed, *Pixel Data* can be converted to an [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html) using the [Dataset.pixel_array](https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.dataset.Dataset.html#pydicom.dataset.Dataset.pixel_array) property:\n53 \n54 ```python\n55 >>> arr = ds.pixel_array\n56 >>> arr.shape\n57 (128, 128)\n58 >>> arr\n59 array([[175, 180, 166, ..., 203, 207, 216],\n60        [186, 183, 157, ..., 181, 190, 239],\n61        [184, 180, 171, ..., 152, 164, 235],\n62        ...,\n63        [906, 910, 923, ..., 922, 929, 927],\n64        [914, 954, 938, ..., 942, 925, 905],\n65        [959, 955, 916, ..., 911, 904, 909]], dtype=int16)\n66 ```\n67 ### Compressed *Pixel Data*\n68 #### JPEG, JPEG-LS and JPEG 2000\n69 Converting JPEG compressed *Pixel Data* to an ``ndarray`` requires installing one or more additional Python libraries. For information on which libraries are required, see the [pixel data handler documentation](https://pydicom.github.io/pydicom/stable/old/image_data_handlers.html#guide-compressed).\n70 \n71 Compressing data into one of the JPEG formats is not currently supported.\n72 \n73 #### RLE\n74 Encoding and decoding RLE *Pixel Data* only requires NumPy, however it can\n75 be quite slow. You may want to consider [installing one or more additional\n76 Python libraries](https://pydicom.github.io/pydicom/stable/old/image_data_compression.html) to speed up the process.\n77 \n78 ## Examples\n79 More [examples](https://pydicom.github.io/pydicom/stable/auto_examples/index.html) are available in the documentation.\n80 \n81 **Change a patient's ID**\n82 ```python\n83 from pydicom import dcmread\n84 \n85 ds = dcmread(\"/path/to/file.dcm\")\n86 # Edit the (0010,0020) 'Patient ID' element\n87 ds.PatientID = \"12345678\"\n88 ds.save_as(\"/path/to/file_updated.dcm\")\n89 ```\n90 \n91 **Display the Pixel Data**\n92 \n93 With [NumPy](http://www.numpy.org) and [matplotlib](https://matplotlib.org/)\n94 ```python\n95 import matplotlib.pyplot as plt\n96 from pydicom import dcmread\n97 from pydicom.data import get_testdata_file\n98 \n99 # The path to a pydicom test dataset\n100 path = get_testdata_file(\"CT_small.dcm\")\n101 ds = dcmread(path)\n102 # `arr` is a numpy.ndarray\n103 arr = ds.pixel_array\n104 \n105 plt.imshow(arr, cmap=\"gray\")\n106 plt.show()\n107 ```\n108 \n109 ## Contributing\n110 \n111 To contribute to *pydicom*, read our [contribution guide](https://github.com/pydicom/pydicom/blob/master/CONTRIBUTING.md).\n112 \n113 To contribute an example or extension of *pydicom* that doesn't belong with the core software, see our contribution repository:\n114 [contrib-pydicom](https://www.github.com/pydicom/contrib-pydicom).\n115 \n[end of README.md]\n[start of pydicom/pixel_data_handlers/util.py]\n1 # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n2 \"\"\"Utility functions used in the pixel data handlers.\"\"\"\n3 \n4 from struct import unpack\n5 from sys import byteorder\n6 from typing import (\n7     Dict, Optional, Union, List, Tuple, TYPE_CHECKING, cast, Iterable\n8 )\n9 import warnings\n10 \n11 try:\n12     import numpy as np  # type: ignore[import]\n13     HAVE_NP = True\n14 except ImportError:\n15     HAVE_NP = False\n16 \n17 from pydicom.data import get_palette_files\n18 from pydicom.uid import UID\n19 \n20 if TYPE_CHECKING:  # pragma: no cover\n21     from pydicom.dataset import Dataset, FileMetaDataset, FileDataset\n22 \n23 \n24 def apply_color_lut(\n25     arr: \"np.ndarray\",\n26     ds: Optional[\"Dataset\"] = None,\n27     palette: Optional[Union[str, UID]] = None\n28 ) -> \"np.ndarray\":\n29     \"\"\"Apply a color palette lookup table to `arr`.\n30 \n31     .. versionadded:: 1.4\n32 \n33     If (0028,1201-1203) *Palette Color Lookup Table Data* are missing\n34     then (0028,1221-1223) *Segmented Palette Color Lookup Table Data* must be\n35     present and vice versa. The presence of (0028,1204) *Alpha Palette Color\n36     Lookup Table Data* or (0028,1224) *Alpha Segmented Palette Color Lookup\n37     Table Data* is optional.\n38 \n39     Use of this function with the :dcm:`Enhanced Palette Color Lookup Table\n40     Module<part03/sect_C.7.6.23.html>` or :dcm:`Supplemental Palette Color LUT\n41     Module<part03/sect_C.7.6.19.html>` is not currently supported.\n42 \n43     Parameters\n44     ----------\n45     arr : numpy.ndarray\n46         The pixel data to apply the color palette to.\n47     ds : dataset.Dataset, optional\n48         Required if `palette` is not supplied. A\n49         :class:`~pydicom.dataset.Dataset` containing a suitable\n50         :dcm:`Image Pixel<part03/sect_C.7.6.3.html>` or\n51         :dcm:`Palette Color Lookup Table<part03/sect_C.7.9.html>` Module.\n52     palette : str or uid.UID, optional\n53         Required if `ds` is not supplied. The name of one of the\n54         :dcm:`well-known<part06/chapter_B.html>` color palettes defined by the\n55         DICOM Standard. One of: ``'HOT_IRON'``, ``'PET'``,\n56         ``'HOT_METAL_BLUE'``, ``'PET_20_STEP'``, ``'SPRING'``, ``'SUMMER'``,\n57         ``'FALL'``, ``'WINTER'`` or the corresponding well-known (0008,0018)\n58         *SOP Instance UID*.\n59 \n60     Returns\n61     -------\n62     numpy.ndarray\n63         The RGB or RGBA pixel data as an array of ``np.uint8`` or ``np.uint16``\n64         values, depending on the 3rd value of (0028,1201) *Red Palette Color\n65         Lookup Table Descriptor*.\n66 \n67     References\n68     ----------\n69 \n70     * :dcm:`Image Pixel Module<part03/sect_C.7.6.3.html>`\n71     * :dcm:`Supplemental Palette Color LUT Module<part03/sect_C.7.6.19.html>`\n72     * :dcm:`Enhanced Palette Color LUT Module<part03/sect_C.7.6.23.html>`\n73     * :dcm:`Palette Colour LUT Module<part03/sect_C.7.9.html>`\n74     * :dcm:`Supplemental Palette Color LUTs\n75       <part03/sect_C.8.16.2.html#sect_C.8.16.2.1.1.1>`\n76     \"\"\"\n77     # Note: input value (IV) is the stored pixel value in `arr`\n78     # LUTs[IV] -> [R, G, B] values at the IV pixel location in `arr`\n79     if not ds and not palette:\n80         raise ValueError(\"Either 'ds' or 'palette' is required\")\n81 \n82     if palette:\n83         # Well-known palettes are all 8-bits per entry\n84         datasets = {\n85             '1.2.840.10008.1.5.1': 'hotiron.dcm',\n86             '1.2.840.10008.1.5.2': 'pet.dcm',\n87             '1.2.840.10008.1.5.3': 'hotmetalblue.dcm',\n88             '1.2.840.10008.1.5.4': 'pet20step.dcm',\n89             '1.2.840.10008.1.5.5': 'spring.dcm',\n90             '1.2.840.10008.1.5.6': 'summer.dcm',\n91             '1.2.840.10008.1.5.7': 'fall.dcm',\n92             '1.2.840.10008.1.5.8': 'winter.dcm',\n93         }\n94         if not UID(palette).is_valid:\n95             try:\n96                 uids = {\n97                     'HOT_IRON': '1.2.840.10008.1.5.1',\n98                     'PET': '1.2.840.10008.1.5.2',\n99                     'HOT_METAL_BLUE': '1.2.840.10008.1.5.3',\n100                     'PET_20_STEP': '1.2.840.10008.1.5.4',\n101                     'SPRING': '1.2.840.10008.1.5.5',\n102                     'SUMMER': '1.2.840.10008.1.5.6',\n103                     'FALL': '1.2.840.10008.1.5.8',\n104                     'WINTER': '1.2.840.10008.1.5.7',\n105                 }\n106                 palette = uids[palette]\n107             except KeyError:\n108                 raise ValueError(\"Unknown palette '{}'\".format(palette))\n109 \n110         try:\n111             from pydicom import dcmread\n112             fname = datasets[palette]\n113             ds = dcmread(get_palette_files(fname)[0])\n114         except KeyError:\n115             raise ValueError(\"Unknown palette '{}'\".format(palette))\n116 \n117     ds = cast(\"Dataset\", ds)\n118 \n119     # C.8.16.2.1.1.1: Supplemental Palette Color LUT\n120     # TODO: Requires greyscale visualisation pipeline\n121     if getattr(ds, 'PixelPresentation', None) in ['MIXED', 'COLOR']:\n122         raise ValueError(\n123             \"Use of this function with the Supplemental Palette Color Lookup \"\n124             \"Table Module is not currently supported\"\n125         )\n126 \n127     if 'RedPaletteColorLookupTableDescriptor' not in ds:\n128         raise ValueError(\"No suitable Palette Color Lookup Table Module found\")\n129 \n130     # All channels are supposed to be identical\n131     lut_desc = cast(List[int], ds.RedPaletteColorLookupTableDescriptor)\n132     # A value of 0 = 2^16 entries\n133     nr_entries = lut_desc[0] or 2**16\n134 \n135     # May be negative if Pixel Representation is 1\n136     first_map = lut_desc[1]\n137     # Actual bit depth may be larger (8 bit entries in 16 bits allocated)\n138     nominal_depth = lut_desc[2]\n139     dtype = np.dtype('uint{:.0f}'.format(nominal_depth))\n140 \n141     luts = []\n142     if 'RedPaletteColorLookupTableData' in ds:\n143         # LUT Data is described by PS3.3, C.7.6.3.1.6\n144         r_lut = cast(bytes, ds.RedPaletteColorLookupTableData)\n145         g_lut = cast(bytes, ds.GreenPaletteColorLookupTableData)\n146         b_lut = cast(bytes, ds.BluePaletteColorLookupTableData)\n147         a_lut = cast(\n148             Optional[bytes],\n149             getattr(ds, 'AlphaPaletteColorLookupTableData', None)\n150         )\n151 \n152         actual_depth = len(r_lut) / nr_entries * 8\n153         dtype = np.dtype('uint{:.0f}'.format(actual_depth))\n154 \n155         for lut_bytes in [ii for ii in [r_lut, g_lut, b_lut, a_lut] if ii]:\n156             luts.append(np.frombuffer(lut_bytes, dtype=dtype))\n157     elif 'SegmentedRedPaletteColorLookupTableData' in ds:\n158         # Segmented LUT Data is described by PS3.3, C.7.9.2\n159         r_lut = cast(bytes, ds.SegmentedRedPaletteColorLookupTableData)\n160         g_lut = cast(bytes, ds.SegmentedGreenPaletteColorLookupTableData)\n161         b_lut = cast(bytes, ds.SegmentedBluePaletteColorLookupTableData)\n162         a_lut = cast(\n163             Optional[bytes],\n164             getattr(ds, 'SegmentedAlphaPaletteColorLookupTableData', None)\n165         )\n166 \n167         endianness = '<' if ds.is_little_endian else '>'\n168         byte_depth = nominal_depth // 8\n169         fmt = 'B' if byte_depth == 1 else 'H'\n170         actual_depth = nominal_depth\n171 \n172         for seg in [ii for ii in [r_lut, g_lut, b_lut, a_lut] if ii]:\n173             len_seg = len(seg) // byte_depth\n174             s_fmt = endianness + str(len_seg) + fmt\n175             lut_ints = _expand_segmented_lut(unpack(s_fmt, seg), s_fmt)\n176             luts.append(np.asarray(lut_ints, dtype=dtype))\n177     else:\n178         raise ValueError(\"No suitable Palette Color Lookup Table Module found\")\n179 \n180     if actual_depth not in [8, 16]:\n181         raise ValueError(\n182             f\"The bit depth of the LUT data '{actual_depth:.1f}' \"\n183             \"is invalid (only 8 or 16 bits per entry allowed)\"\n184         )\n185 \n186     lut_lengths = [len(ii) for ii in luts]\n187     if not all(ii == lut_lengths[0] for ii in lut_lengths[1:]):\n188         raise ValueError(\"LUT data must be the same length\")\n189 \n190     # IVs < `first_map` get set to first LUT entry (i.e. index 0)\n191     clipped_iv = np.zeros(arr.shape, dtype=dtype)\n192     # IVs >= `first_map` are mapped by the Palette Color LUTs\n193     # `first_map` may be negative, positive or 0\n194     mapped_pixels = arr >= first_map\n195     clipped_iv[mapped_pixels] = arr[mapped_pixels] - first_map\n196     # IVs > number of entries get set to last entry\n197     np.clip(clipped_iv, 0, nr_entries - 1, out=clipped_iv)\n198 \n199     # Output array may be RGB or RGBA\n200     out = np.empty(list(arr.shape) + [len(luts)], dtype=dtype)\n201     for ii, lut in enumerate(luts):\n202         out[..., ii] = lut[clipped_iv]\n203 \n204     return out\n205 \n206 \n207 def apply_modality_lut(arr: \"np.ndarray\", ds: \"Dataset\") -> \"np.ndarray\":\n208     \"\"\"Apply a modality lookup table or rescale operation to `arr`.\n209 \n210     .. versionadded:: 1.4\n211 \n212     Parameters\n213     ----------\n214     arr : numpy.ndarray\n215         The :class:`~numpy.ndarray` to apply the modality LUT or rescale\n216         operation to.\n217     ds : dataset.Dataset\n218         A dataset containing a :dcm:`Modality LUT Module\n219         <part03/sect_C.11.html#sect_C.11.1>`.\n220 \n221     Returns\n222     -------\n223     numpy.ndarray\n224         An array with applied modality LUT or rescale operation. If\n225         (0028,3000) *Modality LUT Sequence* is present then returns an array\n226         of ``np.uint8`` or ``np.uint16``, depending on the 3rd value of\n227         (0028,3002) *LUT Descriptor*. If (0028,1052) *Rescale Intercept* and\n228         (0028,1053) *Rescale Slope* are present then returns an array of\n229         ``np.float64``. If neither are present then `arr` will be returned\n230         unchanged.\n231 \n232     Notes\n233     -----\n234     When *Rescale Slope* and *Rescale Intercept* are used, the output range\n235     is from (min. pixel value * Rescale Slope + Rescale Intercept) to\n236     (max. pixel value * Rescale Slope + Rescale Intercept), where min. and\n237     max. pixel value are determined from (0028,0101) *Bits Stored* and\n238     (0028,0103) *Pixel Representation*.\n239 \n240     References\n241     ----------\n242     * DICOM Standard, Part 3, :dcm:`Annex C.11.1\n243       <part03/sect_C.11.html#sect_C.11.1>`\n244     * DICOM Standard, Part 4, :dcm:`Annex N.2.1.1\n245       <part04/sect_N.2.html#sect_N.2.1.1>`\n246     \"\"\"\n247     if 'ModalityLUTSequence' in ds:\n248         item = cast(List[\"Dataset\"], ds.ModalityLUTSequence)[0]\n249         nr_entries = cast(List[int], item.LUTDescriptor)[0] or 2**16\n250         first_map = cast(List[int], item.LUTDescriptor)[1]\n251         nominal_depth = cast(List[int], item.LUTDescriptor)[2]\n252 \n253         dtype = 'uint{}'.format(nominal_depth)\n254 \n255         # Ambiguous VR, US or OW\n256         unc_data: Iterable[int]\n257         if item['LUTData'].VR == 'OW':\n258             endianness = '<' if ds.is_little_endian else '>'\n259             unpack_fmt = '{}{}H'.format(endianness, nr_entries)\n260             unc_data = unpack(unpack_fmt, cast(bytes, item.LUTData))\n261         else:\n262             unc_data = cast(List[int], item.LUTData)\n263 \n264         lut_data: \"np.ndarray\" = np.asarray(unc_data, dtype=dtype)\n265 \n266         # IVs < `first_map` get set to first LUT entry (i.e. index 0)\n267         clipped_iv = np.zeros(arr.shape, dtype=arr.dtype)\n268         # IVs >= `first_map` are mapped by the Modality LUT\n269         # `first_map` may be negative, positive or 0\n270         mapped_pixels = arr >= first_map\n271         clipped_iv[mapped_pixels] = arr[mapped_pixels] - first_map\n272         # IVs > number of entries get set to last entry\n273         np.clip(clipped_iv, 0, nr_entries - 1, out=clipped_iv)\n274 \n275         return lut_data[clipped_iv]\n276     elif 'RescaleSlope' in ds and 'RescaleIntercept' in ds:\n277         arr = arr.astype(np.float64) * cast(float, ds.RescaleSlope)\n278         arr += cast(float, ds.RescaleIntercept)\n279 \n280     return arr\n281 \n282 \n283 def apply_voi_lut(\n284     arr: \"np.ndarray\",\n285     ds: \"Dataset\",\n286     index: int = 0,\n287     prefer_lut: bool = True\n288 ) -> \"np.ndarray\":\n289     \"\"\"Apply a VOI lookup table or windowing operation to `arr`.\n290 \n291     .. versionadded:: 1.4\n292 \n293     .. versionchanged:: 2.1\n294 \n295         Added the `prefer_lut` keyword parameter\n296 \n297     Parameters\n298     ----------\n299     arr : numpy.ndarray\n300         The :class:`~numpy.ndarray` to apply the VOI LUT or windowing operation\n301         to.\n302     ds : dataset.Dataset\n303         A dataset containing a :dcm:`VOI LUT Module<part03/sect_C.11.2.html>`.\n304         If (0028,3010) *VOI LUT Sequence* is present then returns an array\n305         of ``np.uint8`` or ``np.uint16``, depending on the 3rd value of\n306         (0028,3002) *LUT Descriptor*. If (0028,1050) *Window Center* and\n307         (0028,1051) *Window Width* are present then returns an array of\n308         ``np.float64``. If neither are present then `arr` will be returned\n309         unchanged.\n310     index : int, optional\n311         When the VOI LUT Module contains multiple alternative views, this is\n312         the index of the view to return (default ``0``).\n313     prefer_lut : bool\n314         When the VOI LUT Module contains both *Window Width*/*Window Center*\n315         and *VOI LUT Sequence*, if ``True`` (default) then apply the VOI LUT,\n316         otherwise apply the windowing operation.\n317 \n318     Returns\n319     -------\n320     numpy.ndarray\n321         An array with applied VOI LUT or windowing operation.\n322 \n323     Notes\n324     -----\n325     When the dataset requires a modality LUT or rescale operation as part of\n326     the Modality LUT module then that must be applied before any windowing\n327     operation.\n328 \n329     See Also\n330     --------\n331     :func:`~pydicom.pixel_data_handlers.util.apply_modality_lut`\n332     :func:`~pydicom.pixel_data_handlers.util.apply_voi`\n333     :func:`~pydicom.pixel_data_handlers.util.apply_windowing`\n334 \n335     References\n336     ----------\n337     * DICOM Standard, Part 3, :dcm:`Annex C.11.2\n338       <part03/sect_C.11.html#sect_C.11.2>`\n339     * DICOM Standard, Part 3, :dcm:`Annex C.8.11.3.1.5\n340       <part03/sect_C.8.11.3.html#sect_C.8.11.3.1.5>`\n341     * DICOM Standard, Part 4, :dcm:`Annex N.2.1.1\n342       <part04/sect_N.2.html#sect_N.2.1.1>`\n343     \"\"\"\n344     valid_voi = False\n345     if 'VOILUTSequence' in ds:\n346         ds.VOILUTSequence = cast(List[\"Dataset\"], ds.VOILUTSequence)\n347         valid_voi = None not in [\n348             ds.VOILUTSequence[0].get('LUTDescriptor', None),\n349             ds.VOILUTSequence[0].get('LUTData', None)\n350         ]\n351     valid_windowing = None not in [\n352         ds.get('WindowCenter', None),\n353         ds.get('WindowWidth', None)\n354     ]\n355 \n356     if valid_voi and valid_windowing:\n357         if prefer_lut:\n358             return apply_voi(arr, ds, index)\n359 \n360         return apply_windowing(arr, ds, index)\n361 \n362     if valid_voi:\n363         return apply_voi(arr, ds, index)\n364 \n365     if valid_windowing:\n366         return apply_windowing(arr, ds, index)\n367 \n368     return arr\n369 \n370 \n371 def apply_voi(\n372     arr: \"np.ndarray\", ds: \"Dataset\", index: int = 0\n373 ) -> \"np.ndarray\":\n374     \"\"\"Apply a VOI lookup table to `arr`.\n375 \n376     .. versionadded:: 2.1\n377 \n378     Parameters\n379     ----------\n380     arr : numpy.ndarray\n381         The :class:`~numpy.ndarray` to apply the VOI LUT to.\n382     ds : dataset.Dataset\n383         A dataset containing a :dcm:`VOI LUT Module<part03/sect_C.11.2.html>`.\n384         If (0028,3010) *VOI LUT Sequence* is present then returns an array\n385         of ``np.uint8`` or ``np.uint16``, depending on the 3rd value of\n386         (0028,3002) *LUT Descriptor*, otherwise `arr` will be returned\n387         unchanged.\n388     index : int, optional\n389         When the VOI LUT Module contains multiple alternative views, this is\n390         the index of the view to return (default ``0``).\n391 \n392     Returns\n393     -------\n394     numpy.ndarray\n395         An array with applied VOI LUT.\n396 \n397     See Also\n398     --------\n399     :func:`~pydicom.pixel_data_handlers.util.apply_modality_lut`\n400     :func:`~pydicom.pixel_data_handlers.util.apply_windowing`\n401 \n402     References\n403     ----------\n404     * DICOM Standard, Part 3, :dcm:`Annex C.11.2\n405       <part03/sect_C.11.html#sect_C.11.2>`\n406     * DICOM Standard, Part 3, :dcm:`Annex C.8.11.3.1.5\n407       <part03/sect_C.8.11.3.html#sect_C.8.11.3.1.5>`\n408     * DICOM Standard, Part 4, :dcm:`Annex N.2.1.1\n409       <part04/sect_N.2.html#sect_N.2.1.1>`\n410     \"\"\"\n411     if \"VOILUTSequence\" not in ds:\n412         return arr\n413 \n414     if not np.issubdtype(arr.dtype, np.integer):\n415         warnings.warn(\n416             \"Applying a VOI LUT on a float input array may give \"\n417             \"incorrect results\"\n418         )\n419 \n420     # VOI LUT Sequence contains one or more items\n421     item = cast(List[\"Dataset\"], ds.VOILUTSequence)[index]\n422     lut_descriptor = cast(List[int], item.LUTDescriptor)\n423     nr_entries = lut_descriptor[0] or 2**16\n424     first_map = lut_descriptor[1]\n425 \n426     # PS3.3 C.8.11.3.1.5: may be 8, 10-16\n427     nominal_depth = lut_descriptor[2]\n428     if nominal_depth in list(range(10, 17)):\n429         dtype = 'uint16'\n430     elif nominal_depth == 8:\n431         dtype = 'uint8'\n432     else:\n433         raise NotImplementedError(\n434             f\"'{nominal_depth}' bits per LUT entry is not supported\"\n435         )\n436 \n437     # Ambiguous VR, US or OW\n438     unc_data: Iterable[int]\n439     if item['LUTData'].VR == 'OW':\n440         endianness = '<' if ds.is_little_endian else '>'\n441         unpack_fmt = f'{endianness}{nr_entries}H'\n442         unc_data = unpack(unpack_fmt, cast(bytes, item.LUTData))\n443     else:\n444         unc_data = cast(List[int], item.LUTData)\n445 \n446     lut_data: \"np.ndarray\" = np.asarray(unc_data, dtype=dtype)\n447 \n448     # IVs < `first_map` get set to first LUT entry (i.e. index 0)\n449     clipped_iv = np.zeros(arr.shape, dtype=dtype)\n450     # IVs >= `first_map` are mapped by the VOI LUT\n451     # `first_map` may be negative, positive or 0\n452     mapped_pixels = arr >= first_map\n453     clipped_iv[mapped_pixels] = arr[mapped_pixels] - first_map\n454     # IVs > number of entries get set to last entry\n455     np.clip(clipped_iv, 0, nr_entries - 1, out=clipped_iv)\n456 \n457     return lut_data[clipped_iv]\n458 \n459 \n460 def apply_windowing(\n461     arr: \"np.ndarray\", ds: \"Dataset\", index: int = 0\n462 ) -> \"np.ndarray\":\n463     \"\"\"Apply a windowing operation to `arr`.\n464 \n465     .. versionadded:: 2.1\n466 \n467     Parameters\n468     ----------\n469     arr : numpy.ndarray\n470         The :class:`~numpy.ndarray` to apply the windowing operation to.\n471     ds : dataset.Dataset\n472         A dataset containing a :dcm:`VOI LUT Module<part03/sect_C.11.2.html>`.\n473         If (0028,1050) *Window Center* and (0028,1051) *Window Width* are\n474         present then returns an array of ``np.float64``, otherwise `arr` will\n475         be returned unchanged.\n476     index : int, optional\n477         When the VOI LUT Module contains multiple alternative views, this is\n478         the index of the view to return (default ``0``).\n479 \n480     Returns\n481     -------\n482     numpy.ndarray\n483         An array with applied windowing operation.\n484 \n485     Notes\n486     -----\n487     When the dataset requires a modality LUT or rescale operation as part of\n488     the Modality LUT module then that must be applied before any windowing\n489     operation.\n490 \n491     See Also\n492     --------\n493     :func:`~pydicom.pixel_data_handlers.util.apply_modality_lut`\n494     :func:`~pydicom.pixel_data_handlers.util.apply_voi`\n495 \n496     References\n497     ----------\n498     * DICOM Standard, Part 3, :dcm:`Annex C.11.2\n499       <part03/sect_C.11.html#sect_C.11.2>`\n500     * DICOM Standard, Part 3, :dcm:`Annex C.8.11.3.1.5\n501       <part03/sect_C.8.11.3.html#sect_C.8.11.3.1.5>`\n502     * DICOM Standard, Part 4, :dcm:`Annex N.2.1.1\n503       <part04/sect_N.2.html#sect_N.2.1.1>`\n504     \"\"\"\n505     if \"WindowWidth\" not in ds and \"WindowCenter\" not in ds:\n506         return arr\n507 \n508     if ds.PhotometricInterpretation not in ['MONOCHROME1', 'MONOCHROME2']:\n509         raise ValueError(\n510             \"When performing a windowing operation only 'MONOCHROME1' and \"\n511             \"'MONOCHROME2' are allowed for (0028,0004) Photometric \"\n512             \"Interpretation\"\n513         )\n514 \n515     # May be LINEAR (default), LINEAR_EXACT, SIGMOID or not present, VM 1\n516     voi_func = cast(str, getattr(ds, 'VOILUTFunction', 'LINEAR')).upper()\n517     # VR DS, VM 1-n\n518     elem = ds['WindowCenter']\n519     center = (\n520         cast(List[float], elem.value)[index] if elem.VM > 1 else elem.value\n521     )\n522     center = cast(float, center)\n523     elem = ds['WindowWidth']\n524     width = cast(List[float], elem.value)[index] if elem.VM > 1 else elem.value\n525     width = cast(float, width)\n526 \n527     # The output range depends on whether or not a modality LUT or rescale\n528     #   operation has been applied\n529     ds.BitsStored = cast(int, ds.BitsStored)\n530     y_min: float\n531     y_max: float\n532     if 'ModalityLUTSequence' in ds:\n533         # Unsigned - see PS3.3 C.11.1.1.1\n534         y_min = 0\n535         item = cast(List[\"Dataset\"], ds.ModalityLUTSequence)[0]\n536         bit_depth = cast(List[int], item.LUTDescriptor)[2]\n537         y_max = 2**bit_depth - 1\n538     elif ds.PixelRepresentation == 0:\n539         # Unsigned\n540         y_min = 0\n541         y_max = 2**ds.BitsStored - 1\n542     else:\n543         # Signed\n544         y_min = -2**(ds.BitsStored - 1)\n545         y_max = 2**(ds.BitsStored - 1) - 1\n546 \n547     slope = ds.get('RescaleSlope', None)\n548     intercept = ds.get('RescaleIntercept', None)\n549     if slope is not None and intercept is not None:\n550         ds.RescaleSlope = cast(float, ds.RescaleSlope)\n551         ds.RescaleIntercept = cast(float, ds.RescaleIntercept)\n552         # Otherwise its the actual data range\n553         y_min = y_min * ds.RescaleSlope + ds.RescaleIntercept\n554         y_max = y_max * ds.RescaleSlope + ds.RescaleIntercept\n555 \n556     y_range = y_max - y_min\n557     arr = arr.astype('float64')\n558 \n559     if voi_func in ['LINEAR', 'LINEAR_EXACT']:\n560         # PS3.3 C.11.2.1.2.1 and C.11.2.1.3.2\n561         if voi_func == 'LINEAR':\n562             if width < 1:\n563                 raise ValueError(\n564                     \"The (0028,1051) Window Width must be greater than or \"\n565                     \"equal to 1 for a 'LINEAR' windowing operation\"\n566                 )\n567             center -= 0.5\n568             width -= 1\n569         elif width <= 0:\n570             raise ValueError(\n571                 \"The (0028,1051) Window Width must be greater than 0 \"\n572                 \"for a 'LINEAR_EXACT' windowing operation\"\n573             )\n574 \n575         below = arr <= (center - width / 2)\n576         above = arr > (center + width / 2)\n577         between = np.logical_and(~below, ~above)\n578 \n579         arr[below] = y_min\n580         arr[above] = y_max\n581         if between.any():\n582             arr[between] = (\n583                 ((arr[between] - center) / width + 0.5) * y_range + y_min\n584             )\n585     elif voi_func == 'SIGMOID':\n586         # PS3.3 C.11.2.1.3.1\n587         if width <= 0:\n588             raise ValueError(\n589                 \"The (0028,1051) Window Width must be greater than 0 \"\n590                 \"for a 'SIGMOID' windowing operation\"\n591             )\n592 \n593         arr = y_range / (1 + np.exp(-4 * (arr - center) / width)) + y_min\n594     else:\n595         raise ValueError(\n596             f\"Unsupported (0028,1056) VOI LUT Function value '{voi_func}'\"\n597         )\n598 \n599     return arr\n600 \n601 \n602 def convert_color_space(\n603     arr: \"np.ndarray\", current: str, desired: str, per_frame: bool = False\n604 ) -> \"np.ndarray\":\n605     \"\"\"Convert the image(s) in `arr` from one color space to another.\n606 \n607     .. versionchanged:: 1.4\n608 \n609         Added support for ``YBR_FULL_422``\n610 \n611     .. versionchanged:: 2.2\n612 \n613         Added `per_frame` keyword parameter.\n614 \n615     Parameters\n616     ----------\n617     arr : numpy.ndarray\n618         The image(s) as a :class:`numpy.ndarray` with\n619         :attr:`~numpy.ndarray.shape` (frames, rows, columns, 3)\n620         or (rows, columns, 3).\n621     current : str\n622         The current color space, should be a valid value for (0028,0004)\n623         *Photometric Interpretation*. One of ``'RGB'``, ``'YBR_FULL'``,\n624         ``'YBR_FULL_422'``.\n625     desired : str\n626         The desired color space, should be a valid value for (0028,0004)\n627         *Photometric Interpretation*. One of ``'RGB'``, ``'YBR_FULL'``,\n628         ``'YBR_FULL_422'``.\n629     per_frame : bool, optional\n630         If ``True`` and the input array contains multiple frames then process\n631         each frame individually to reduce memory usage. Default ``False``.\n632 \n633     Returns\n634     -------\n635     numpy.ndarray\n636         The image(s) converted to the desired color space.\n637 \n638     References\n639     ----------\n640 \n641     * DICOM Standard, Part 3,\n642       :dcm:`Annex C.7.6.3.1.2<part03/sect_C.7.6.3.html#sect_C.7.6.3.1.2>`\n643     * ISO/IEC 10918-5:2012 (`ITU T.871\n644       <https://www.ijg.org/files/T-REC-T.871-201105-I!!PDF-E.pdf>`_),\n645       Section 7\n646     \"\"\"\n647     def _no_change(arr):\n648         return arr\n649 \n650     _converters = {\n651         'YBR_FULL_422': {\n652             'YBR_FULL_422': _no_change,\n653             'YBR_FULL': _no_change,\n654             'RGB': _convert_YBR_FULL_to_RGB,\n655         },\n656         'YBR_FULL': {\n657             'YBR_FULL': _no_change,\n658             'YBR_FULL_422': _no_change,\n659             'RGB': _convert_YBR_FULL_to_RGB,\n660         },\n661         'RGB': {\n662             'RGB': _no_change,\n663             'YBR_FULL': _convert_RGB_to_YBR_FULL,\n664             'YBR_FULL_422': _convert_RGB_to_YBR_FULL,\n665         }\n666     }\n667     try:\n668         converter = _converters[current][desired]\n669     except KeyError:\n670         raise NotImplementedError(\n671             f\"Conversion from {current} to {desired} is not supported.\"\n672         )\n673 \n674     if len(arr.shape) == 4 and per_frame:\n675         for idx, frame in enumerate(arr):\n676             arr[idx] = converter(frame)\n677 \n678         return arr\n679 \n680     return converter(arr)\n681 \n682 \n683 def _convert_RGB_to_YBR_FULL(arr: \"np.ndarray\") -> \"np.ndarray\":\n684     \"\"\"Return an ndarray converted from RGB to YBR_FULL color space.\n685 \n686     Parameters\n687     ----------\n688     arr : numpy.ndarray\n689         An ndarray of an 8-bit per channel images in RGB color space.\n690 \n691     Returns\n692     -------\n693     numpy.ndarray\n694         The array in YBR_FULL color space.\n695 \n696     References\n697     ----------\n698 \n699     * DICOM Standard, Part 3,\n700       :dcm:`Annex C.7.6.3.1.2<part03/sect_C.7.6.3.html#sect_C.7.6.3.1.2>`\n701     * ISO/IEC 10918-5:2012 (`ITU T.871\n702       <https://www.ijg.org/files/T-REC-T.871-201105-I!!PDF-E.pdf>`_),\n703       Section 7\n704     \"\"\"\n705     orig_dtype = arr.dtype\n706 \n707     rgb_to_ybr = np.asarray(\n708         [[+0.299, -0.299 / 1.772, +0.701 / 1.402],\n709          [+0.587, -0.587 / 1.772, -0.587 / 1.402],\n710          [+0.114, +0.886 / 1.772, -0.114 / 1.402]],\n711         dtype=np.float32\n712     )\n713 \n714     arr = np.matmul(arr, rgb_to_ybr, dtype=np.float32)\n715     arr += [0.5, 128.5, 128.5]\n716     # Round(x) -> floor of (arr + 0.5) : 0.5 added in previous step\n717     np.floor(arr, out=arr)\n718     # Max(0, arr) -> 0 if 0 >= arr, arr otherwise\n719     # Min(arr, 255) -> arr if arr <= 255, 255 otherwise\n720     np.clip(arr, 0, 255, out=arr)\n721 \n722     return arr.astype(orig_dtype)\n723 \n724 \n725 def _convert_YBR_FULL_to_RGB(arr: \"np.ndarray\") -> \"np.ndarray\":\n726     \"\"\"Return an ndarray converted from YBR_FULL to RGB color space.\n727 \n728     Parameters\n729     ----------\n730     arr : numpy.ndarray\n731         An ndarray of an 8-bit per channel images in YBR_FULL color space.\n732 \n733     Returns\n734     -------\n735     numpy.ndarray\n736         The array in RGB color space.\n737 \n738     References\n739     ----------\n740 \n741     * DICOM Standard, Part 3,\n742       :dcm:`Annex C.7.6.3.1.2<part03/sect_C.7.6.3.html#sect_C.7.6.3.1.2>`\n743     * ISO/IEC 10918-5:2012, Section 7\n744     \"\"\"\n745     orig_dtype = arr.dtype\n746 \n747     ybr_to_rgb = np.asarray(\n748         [[1.000, 1.000, 1.000],\n749          [0.000, -0.114 * 1.772 / 0.587, 1.772],\n750          [1.402, -0.299 * 1.402 / 0.587, 0.000]],\n751         dtype=np.float32\n752     )\n753 \n754     arr = arr.astype(np.float32)\n755     arr -= [0, 128, 128]\n756 \n757     # Round(x) -> floor of (arr + 0.5)\n758     np.matmul(arr, ybr_to_rgb, out=arr)\n759     arr += 0.5\n760     np.floor(arr, out=arr)\n761     # Max(0, arr) -> 0 if 0 >= arr, arr otherwise\n762     # Min(arr, 255) -> arr if arr <= 255, 255 otherwise\n763     np.clip(arr, 0, 255, out=arr)\n764 \n765     return arr.astype(orig_dtype)\n766 \n767 \n768 def dtype_corrected_for_endianness(\n769     is_little_endian: bool, numpy_dtype: \"np.dtype\"\n770 ) -> \"np.dtype\":\n771     \"\"\"Return a :class:`numpy.dtype` corrected for system and :class:`Dataset`\n772     endianness.\n773 \n774     Parameters\n775     ----------\n776     is_little_endian : bool\n777         The endianess of the affected :class:`~pydicom.dataset.Dataset`.\n778     numpy_dtype : numpy.dtype\n779         The numpy data type used for the *Pixel Data* without considering\n780         endianess.\n781 \n782     Raises\n783     ------\n784     ValueError\n785         If `is_little_endian` is ``None``, e.g. not initialized.\n786 \n787     Returns\n788     -------\n789     numpy.dtype\n790         The numpy data type used for the *Pixel Data* without considering\n791         endianess.\n792     \"\"\"\n793     if is_little_endian is None:\n794         raise ValueError(\"Dataset attribute 'is_little_endian' \"\n795                          \"has to be set before writing the dataset\")\n796 \n797     if is_little_endian != (byteorder == 'little'):\n798         return numpy_dtype.newbyteorder('S')\n799 \n800     return numpy_dtype\n801 \n802 \n803 def _expand_segmented_lut(\n804     data: Tuple[int, ...],\n805     fmt: str,\n806     nr_segments: Optional[int] = None,\n807     last_value: Optional[int] = None\n808 ) -> List[int]:\n809     \"\"\"Return a list containing the expanded lookup table data.\n810 \n811     Parameters\n812     ----------\n813     data : tuple of int\n814         The decoded segmented palette lookup table data. May be padded by a\n815         trailing null.\n816     fmt : str\n817         The format of the data, should contain `'B'` for 8-bit, `'H'` for\n818         16-bit, `'<'` for little endian and `'>'` for big endian.\n819     nr_segments : int, optional\n820         Expand at most `nr_segments` from the data. Should be used when\n821         the opcode is ``2`` (indirect). If used then `last_value` should also\n822         be used.\n823     last_value : int, optional\n824         The previous value in the expanded lookup table. Should be used when\n825         the opcode is ``2`` (indirect). If used then `nr_segments` should also\n826         be used.\n827 \n828     Returns\n829     -------\n830     list of int\n831         The reconstructed lookup table data.\n832 \n833     References\n834     ----------\n835 \n836     * DICOM Standard, Part 3, Annex C.7.9\n837     \"\"\"\n838     # Indirect segment byte offset is dependent on endianness for 8-bit\n839     # Little endian: e.g. 0x0302 0x0100, big endian, e.g. 0x0203 0x0001\n840     indirect_ii = [3, 2, 1, 0] if '<' in fmt else [2, 3, 0, 1]\n841 \n842     lut: List[int] = []\n843     offset = 0\n844     segments_read = 0\n845     # Use `offset + 1` to account for possible trailing null\n846     #   can do this because all segment types are longer than 2\n847     while offset + 1 < len(data):\n848         opcode = data[offset]\n849         length = data[offset + 1]\n850         offset += 2\n851 \n852         if opcode == 0:\n853             # C.7.9.2.1: Discrete segment\n854             lut.extend(data[offset:offset + length])\n855             offset += length\n856         elif opcode == 1:\n857             # C.7.9.2.2: Linear segment\n858             if lut:\n859                 y0 = lut[-1]\n860             elif last_value:\n861                 # Indirect segment with linear segment at 0th offset\n862                 y0 = last_value\n863             else:\n864                 raise ValueError(\n865                     \"Error expanding a segmented palette color lookup table: \"\n866                     \"the first segment cannot be a linear segment\"\n867                 )\n868 \n869             y1 = data[offset]\n870             offset += 1\n871 \n872             if y0 == y1:\n873                 lut.extend([y1] * length)\n874             else:\n875                 step = (y1 - y0) / length\n876                 vals = np.around(np.arange(y0 + step, y1 + step, step))\n877                 lut.extend([int(vv) for vv in vals])\n878         elif opcode == 2:\n879             # C.7.9.2.3: Indirect segment\n880             if not lut:\n881                 raise ValueError(\n882                     \"Error expanding a segmented palette color lookup table: \"\n883                     \"the first segment cannot be an indirect segment\"\n884                 )\n885 \n886             if 'B' in fmt:\n887                 # 8-bit segment entries\n888                 ii = [data[offset + vv] for vv in indirect_ii]\n889                 byte_offset = (ii[0] << 8 | ii[1]) << 16 | (ii[2] << 8 | ii[3])\n890                 offset += 4\n891             else:\n892                 # 16-bit segment entries\n893                 byte_offset = data[offset + 1] << 16 | data[offset]\n894                 offset += 2\n895 \n896             lut.extend(\n897                 _expand_segmented_lut(data[byte_offset:], fmt, length, lut[-1])\n898             )\n899         else:\n900             raise ValueError(\n901                 \"Error expanding a segmented palette lookup table: \"\n902                 f\"unknown segment type '{opcode}'\"\n903             )\n904 \n905         segments_read += 1\n906         if segments_read == nr_segments:\n907             return lut\n908 \n909     return lut\n910 \n911 \n912 def get_expected_length(ds: \"Dataset\", unit: str = 'bytes') -> int:\n913     \"\"\"Return the expected length (in terms of bytes or pixels) of the *Pixel\n914     Data*.\n915 \n916     +------------------------------------------------+-------------+\n917     | Element                                        | Required or |\n918     +-------------+---------------------------+------+ optional    |\n919     | Tag         | Keyword                   | Type |             |\n920     +=============+===========================+======+=============+\n921     | (0028,0002) | SamplesPerPixel           | 1    | Required    |\n922     +-------------+---------------------------+------+-------------+\n923     | (0028,0004) | PhotometricInterpretation | 1    | Required    |\n924     +-------------+---------------------------+------+-------------+\n925     | (0028,0008) | NumberOfFrames            | 1C   | Optional    |\n926     +-------------+---------------------------+------+-------------+\n927     | (0028,0010) | Rows                      | 1    | Required    |\n928     +-------------+---------------------------+------+-------------+\n929     | (0028,0011) | Columns                   | 1    | Required    |\n930     +-------------+---------------------------+------+-------------+\n931     | (0028,0100) | BitsAllocated             | 1    | Required    |\n932     +-------------+---------------------------+------+-------------+\n933 \n934     .. versionchanged:: 1.4\n935 \n936         Added support for a *Photometric Interpretation* of  ``YBR_FULL_422``\n937 \n938     Parameters\n939     ----------\n940     ds : Dataset\n941         The :class:`~pydicom.dataset.Dataset` containing the Image Pixel module\n942         and *Pixel Data*.\n943     unit : str, optional\n944         If ``'bytes'`` then returns the expected length of the *Pixel Data* in\n945         whole bytes and NOT including an odd length trailing NULL padding\n946         byte. If ``'pixels'`` then returns the expected length of the *Pixel\n947         Data* in terms of the total number of pixels (default ``'bytes'``).\n948 \n949     Returns\n950     -------\n951     int\n952         The expected length of the *Pixel Data* in either whole bytes or\n953         pixels, excluding the NULL trailing padding byte for odd length data.\n954     \"\"\"\n955     rows = cast(int, ds.Rows)\n956     columns = cast(int, ds.Columns)\n957     samples_per_pixel = cast(int, ds.SamplesPerPixel)\n958     bits_allocated = cast(int, ds.BitsAllocated)\n959 \n960     length = rows * columns * samples_per_pixel\n961     length *= get_nr_frames(ds)\n962 \n963     if unit == 'pixels':\n964         return length\n965 \n966     # Correct for the number of bytes per pixel\n967     if bits_allocated == 1:\n968         # Determine the nearest whole number of bytes needed to contain\n969         #   1-bit pixel data. e.g. 10 x 10 1-bit pixels is 100 bits, which\n970         #   are packed into 12.5 -> 13 bytes\n971         length = length // 8 + (length % 8 > 0)\n972     else:\n973         length *= bits_allocated // 8\n974 \n975     # DICOM Standard, Part 4, Annex C.7.6.3.1.2\n976     if ds.PhotometricInterpretation == 'YBR_FULL_422':\n977         length = length // 3 * 2\n978 \n979     return length\n980 \n981 \n982 def get_image_pixel_ids(ds: \"Dataset\") -> Dict[str, int]:\n983     \"\"\"Return a dict of the pixel data affecting element's :func:`id` values.\n984 \n985     .. versionadded:: 1.4\n986 \n987     +------------------------------------------------+\n988     | Element                                        |\n989     +-------------+---------------------------+------+\n990     | Tag         | Keyword                   | Type |\n991     +=============+===========================+======+\n992     | (0028,0002) | SamplesPerPixel           | 1    |\n993     +-------------+---------------------------+------+\n994     | (0028,0004) | PhotometricInterpretation | 1    |\n995     +-------------+---------------------------+------+\n996     | (0028,0006) | PlanarConfiguration       | 1C   |\n997     +-------------+---------------------------+------+\n998     | (0028,0008) | NumberOfFrames            | 1C   |\n999     +-------------+---------------------------+------+\n1000     | (0028,0010) | Rows                      | 1    |\n1001     +-------------+---------------------------+------+\n1002     | (0028,0011) | Columns                   | 1    |\n1003     +-------------+---------------------------+------+\n1004     | (0028,0100) | BitsAllocated             | 1    |\n1005     +-------------+---------------------------+------+\n1006     | (0028,0101) | BitsStored                | 1    |\n1007     +-------------+---------------------------+------+\n1008     | (0028,0103) | PixelRepresentation       | 1    |\n1009     +-------------+---------------------------+------+\n1010     | (7FE0,0008) | FloatPixelData            | 1C   |\n1011     +-------------+---------------------------+------+\n1012     | (7FE0,0009) | DoubleFloatPixelData      | 1C   |\n1013     +-------------+---------------------------+------+\n1014     | (7FE0,0010) | PixelData                 | 1C   |\n1015     +-------------+---------------------------+------+\n1016 \n1017     Parameters\n1018     ----------\n1019     ds : Dataset\n1020         The :class:`~pydicom.dataset.Dataset` containing the pixel data.\n1021 \n1022     Returns\n1023     -------\n1024     dict\n1025         A dict containing the :func:`id` values for the elements that affect\n1026         the pixel data.\n1027 \n1028     \"\"\"\n1029     keywords = [\n1030         'SamplesPerPixel', 'PhotometricInterpretation', 'PlanarConfiguration',\n1031         'NumberOfFrames', 'Rows', 'Columns', 'BitsAllocated', 'BitsStored',\n1032         'PixelRepresentation', 'FloatPixelData', 'DoubleFloatPixelData',\n1033         'PixelData'\n1034     ]\n1035 \n1036     return {kw: id(getattr(ds, kw, None)) for kw in keywords}\n1037 \n1038 \n1039 def get_j2k_parameters(codestream: bytes) -> Dict[str, object]:\n1040     \"\"\"Return a dict containing JPEG 2000 component parameters.\n1041 \n1042     .. versionadded:: 2.1\n1043 \n1044     Parameters\n1045     ----------\n1046     codestream : bytes\n1047         The JPEG 2000 (ISO/IEC 15444-1) codestream to be parsed.\n1048 \n1049     Returns\n1050     -------\n1051     dict\n1052         A dict containing parameters for the first component sample in the\n1053         JPEG 2000 `codestream`, or an empty dict if unable to parse the data.\n1054         Available parameters are ``{\"precision\": int, \"is_signed\": bool}``.\n1055     \"\"\"\n1056     try:\n1057         # First 2 bytes must be the SOC marker - if not then wrong format\n1058         if codestream[0:2] != b'\\xff\\x4f':\n1059             return {}\n1060 \n1061         # SIZ is required to be the second marker - Figure A-3 in 15444-1\n1062         if codestream[2:4] != b'\\xff\\x51':\n1063             return {}\n1064 \n1065         # See 15444-1 A.5.1 for format of the SIZ box and contents\n1066         ssiz = codestream[42]\n1067         if ssiz & 0x80:\n1068             return {\"precision\": (ssiz & 0x7F) + 1, \"is_signed\": True}\n1069 \n1070         return {\"precision\": ssiz + 1, \"is_signed\": False}\n1071     except (IndexError, TypeError):\n1072         pass\n1073 \n1074     return {}\n1075 \n1076 \n1077 def get_nr_frames(ds: \"Dataset\") -> int:\n1078     \"\"\"Return NumberOfFrames or 1 if NumberOfFrames is None.\n1079 \n1080     Parameters\n1081     ----------\n1082     ds : dataset.Dataset\n1083         The :class:`~pydicom.dataset.Dataset` containing the Image Pixel module\n1084         corresponding to the data in `arr`.\n1085 \n1086     Returns\n1087     -------\n1088     int\n1089         An integer for the NumberOfFrames or 1 if NumberOfFrames is None\n1090     \"\"\"\n1091     nr_frames: Optional[int] = getattr(ds, 'NumberOfFrames', 1)\n1092     # 'NumberOfFrames' may exist in the DICOM file but have value equal to None\n1093     if nr_frames is None:\n1094         warnings.warn(\"A value of None for (0028,0008) 'Number of Frames' is \"\n1095                       \"non-conformant. It's recommended that this value be \"\n1096                       \"changed to 1\")\n1097         nr_frames = 1\n1098 \n1099     return nr_frames\n1100 \n1101 \n1102 def pixel_dtype(ds: \"Dataset\", as_float: bool = False) -> \"np.dtype\":\n1103     \"\"\"Return a :class:`numpy.dtype` for the pixel data in `ds`.\n1104 \n1105     Suitable for use with IODs containing the Image Pixel module (with\n1106     ``as_float=False``) and the Floating Point Image Pixel and Double Floating\n1107     Point Image Pixel modules (with ``as_float=True``).\n1108 \n1109     +------------------------------------------+------------------+\n1110     | Element                                  | Supported        |\n1111     +-------------+---------------------+------+ values           |\n1112     | Tag         | Keyword             | Type |                  |\n1113     +=============+=====================+======+==================+\n1114     | (0028,0101) | BitsAllocated       | 1    | 1, 8, 16, 32, 64 |\n1115     +-------------+---------------------+------+------------------+\n1116     | (0028,0103) | PixelRepresentation | 1    | 0, 1             |\n1117     +-------------+---------------------+------+------------------+\n1118 \n1119     .. versionchanged:: 1.4\n1120 \n1121         Added `as_float` keyword parameter and support for float dtypes.\n1122 \n1123 \n1124     Parameters\n1125     ----------\n1126     ds : Dataset\n1127         The :class:`~pydicom.dataset.Dataset` containing the pixel data you\n1128         wish to get the data type for.\n1129     as_float : bool, optional\n1130         If ``True`` then return a float dtype, otherwise return an integer\n1131         dtype (default ``False``). Float dtypes are only supported when\n1132         (0028,0101) *Bits Allocated* is 32 or 64.\n1133 \n1134     Returns\n1135     -------\n1136     numpy.dtype\n1137         A :class:`numpy.dtype` suitable for containing the pixel data.\n1138 \n1139     Raises\n1140     ------\n1141     NotImplementedError\n1142         If the pixel data is of a type that isn't supported by either numpy\n1143         or *pydicom*.\n1144     \"\"\"\n1145     if not HAVE_NP:\n1146         raise ImportError(\"Numpy is required to determine the dtype.\")\n1147 \n1148     if ds.is_little_endian is None:\n1149         ds.is_little_endian = ds.file_meta.TransferSyntaxUID.is_little_endian\n1150 \n1151     if not as_float:\n1152         # (0028,0103) Pixel Representation, US, 1\n1153         #   Data representation of the pixel samples\n1154         #   0x0000 - unsigned int\n1155         #   0x0001 - 2's complement (signed int)\n1156         pixel_repr = cast(int, ds.PixelRepresentation)\n1157         if pixel_repr == 0:\n1158             dtype_str = 'uint'\n1159         elif pixel_repr == 1:\n1160             dtype_str = 'int'\n1161         else:\n1162             raise ValueError(\n1163                 \"Unable to determine the data type to use to contain the \"\n1164                 f\"Pixel Data as a value of '{pixel_repr}' for '(0028,0103) \"\n1165                 \"Pixel Representation' is invalid\"\n1166             )\n1167     else:\n1168         dtype_str = 'float'\n1169 \n1170     # (0028,0100) Bits Allocated, US, 1\n1171     #   The number of bits allocated for each pixel sample\n1172     #   PS3.5 8.1.1: Bits Allocated shall either be 1 or a multiple of 8\n1173     #   For bit packed data we use uint8\n1174     bits_allocated = cast(int, ds.BitsAllocated)\n1175     if bits_allocated == 1:\n1176         dtype_str = 'uint8'\n1177     elif bits_allocated > 0 and bits_allocated % 8 == 0:\n1178         dtype_str += str(bits_allocated)\n1179     else:\n1180         raise ValueError(\n1181             \"Unable to determine the data type to use to contain the \"\n1182             f\"Pixel Data as a value of '{bits_allocated}' for '(0028,0100) \"\n1183             \"Bits Allocated' is invalid\"\n1184         )\n1185 \n1186     # Check to see if the dtype is valid for numpy\n1187     try:\n1188         dtype = np.dtype(dtype_str)\n1189     except TypeError:\n1190         raise NotImplementedError(\n1191             f\"The data type '{dtype_str}' needed to contain the Pixel Data \"\n1192             \"is not supported by numpy\"\n1193         )\n1194 \n1195     # Correct for endianness of the system vs endianness of the dataset\n1196     if ds.is_little_endian != (byteorder == 'little'):\n1197         # 'S' swap from current to opposite\n1198         dtype = dtype.newbyteorder('S')\n1199 \n1200     return dtype\n1201 \n1202 \n1203 def reshape_pixel_array(ds: \"Dataset\", arr: \"np.ndarray\") -> \"np.ndarray\":\n1204     \"\"\"Return a reshaped :class:`numpy.ndarray` `arr`.\n1205 \n1206     +------------------------------------------+-----------+----------+\n1207     | Element                                  | Supported |          |\n1208     +-------------+---------------------+------+ values    |          |\n1209     | Tag         | Keyword             | Type |           |          |\n1210     +=============+=====================+======+===========+==========+\n1211     | (0028,0002) | SamplesPerPixel     | 1    | N > 0     | Required |\n1212     +-------------+---------------------+------+-----------+----------+\n1213     | (0028,0006) | PlanarConfiguration | 1C   | 0, 1      | Optional |\n1214     +-------------+---------------------+------+-----------+----------+\n1215     | (0028,0008) | NumberOfFrames      | 1C   | N > 0     | Optional |\n1216     +-------------+---------------------+------+-----------+----------+\n1217     | (0028,0010) | Rows                | 1    | N > 0     | Required |\n1218     +-------------+---------------------+------+-----------+----------+\n1219     | (0028,0011) | Columns             | 1    | N > 0     | Required |\n1220     +-------------+---------------------+------+-----------+----------+\n1221 \n1222     (0028,0008) *Number of Frames* is required when *Pixel Data* contains\n1223     more than 1 frame. (0028,0006) *Planar Configuration* is required when\n1224     (0028,0002) *Samples per Pixel* is greater than 1. For certain\n1225     compressed transfer syntaxes it is always taken to be either 0 or 1 as\n1226     shown in the table below.\n1227 \n1228     +---------------------------------------------+-----------------------+\n1229     | Transfer Syntax                             | Planar Configuration  |\n1230     +------------------------+--------------------+                       |\n1231     | UID                    | Name               |                       |\n1232     +========================+====================+=======================+\n1233     | 1.2.840.10008.1.2.4.50 | JPEG Baseline      | 0                     |\n1234     +------------------------+--------------------+-----------------------+\n1235     | 1.2.840.10008.1.2.4.57 | JPEG Lossless,     | 0                     |\n1236     |                        | Non-hierarchical   |                       |\n1237     +------------------------+--------------------+-----------------------+\n1238     | 1.2.840.10008.1.2.4.70 | JPEG Lossless,     | 0                     |\n1239     |                        | Non-hierarchical,  |                       |\n1240     |                        | SV1                |                       |\n1241     +------------------------+--------------------+-----------------------+\n1242     | 1.2.840.10008.1.2.4.80 | JPEG-LS Lossless   | 0                     |\n1243     +------------------------+--------------------+-----------------------+\n1244     | 1.2.840.10008.1.2.4.81 | JPEG-LS Lossy      | 0                     |\n1245     +------------------------+--------------------+-----------------------+\n1246     | 1.2.840.10008.1.2.4.90 | JPEG 2000 Lossless | 0                     |\n1247     +------------------------+--------------------+-----------------------+\n1248     | 1.2.840.10008.1.2.4.91 | JPEG 2000 Lossy    | 0                     |\n1249     +------------------------+--------------------+-----------------------+\n1250     | 1.2.840.10008.1.2.5    | RLE Lossless       | 1                     |\n1251     +------------------------+--------------------+-----------------------+\n1252 \n1253     .. versionchanged:: 2.1\n1254 \n1255         JPEG-LS transfer syntaxes changed to *Planar Configuration* of 0\n1256 \n1257     Parameters\n1258     ----------\n1259     ds : dataset.Dataset\n1260         The :class:`~pydicom.dataset.Dataset` containing the Image Pixel module\n1261         corresponding to the data in `arr`.\n1262     arr : numpy.ndarray\n1263         The 1D array containing the pixel data.\n1264 \n1265     Returns\n1266     -------\n1267     numpy.ndarray\n1268         A reshaped array containing the pixel data. The shape of the array\n1269         depends on the contents of the dataset:\n1270 \n1271         * For single frame, single sample data (rows, columns)\n1272         * For single frame, multi-sample data (rows, columns, planes)\n1273         * For multi-frame, single sample data (frames, rows, columns)\n1274         * For multi-frame, multi-sample data (frames, rows, columns, planes)\n1275 \n1276     References\n1277     ----------\n1278 \n1279     * DICOM Standard, Part 3,\n1280       :dcm:`Annex C.7.6.3.1<part03/sect_C.7.6.3.html#sect_C.7.6.3.1>`\n1281     * DICOM Standard, Part 5, :dcm:`Section 8.2<part05/sect_8.2.html>`\n1282     \"\"\"\n1283     if not HAVE_NP:\n1284         raise ImportError(\"Numpy is required to reshape the pixel array.\")\n1285 \n1286     nr_frames = get_nr_frames(ds)\n1287     nr_samples = cast(int, ds.SamplesPerPixel)\n1288 \n1289     if nr_frames < 1:\n1290         raise ValueError(\n1291             f\"Unable to reshape the pixel array as a value of {nr_frames} for \"\n1292             \"(0028,0008) 'Number of Frames' is invalid.\"\n1293         )\n1294 \n1295     if nr_samples < 1:\n1296         raise ValueError(\n1297             f\"Unable to reshape the pixel array as a value of {nr_samples} \"\n1298             \"for (0028,0002) 'Samples per Pixel' is invalid.\"\n1299         )\n1300 \n1301     # Valid values for Planar Configuration are dependent on transfer syntax\n1302     if nr_samples > 1:\n1303         transfer_syntax = ds.file_meta.TransferSyntaxUID\n1304         if transfer_syntax in ['1.2.840.10008.1.2.4.50',\n1305                                '1.2.840.10008.1.2.4.57',\n1306                                '1.2.840.10008.1.2.4.70',\n1307                                '1.2.840.10008.1.2.4.80',\n1308                                '1.2.840.10008.1.2.4.81',\n1309                                '1.2.840.10008.1.2.4.90',\n1310                                '1.2.840.10008.1.2.4.91']:\n1311             planar_configuration = 0\n1312         elif transfer_syntax in ['1.2.840.10008.1.2.5']:\n1313             planar_configuration = 1\n1314         else:\n1315             planar_configuration = ds.PlanarConfiguration\n1316 \n1317         if planar_configuration not in [0, 1]:\n1318             raise ValueError(\n1319                 \"Unable to reshape the pixel array as a value of \"\n1320                 f\"{planar_configuration} for (0028,0006) 'Planar \"\n1321                 \"Configuration' is invalid.\"\n1322             )\n1323 \n1324     rows = cast(int, ds.Rows)\n1325     columns = cast(int, ds.Columns)\n1326     if nr_frames > 1:\n1327         # Multi-frame\n1328         if nr_samples == 1:\n1329             # Single plane\n1330             arr = arr.reshape(nr_frames, rows, columns)\n1331         else:\n1332             # Multiple planes, usually 3\n1333             if planar_configuration == 0:\n1334                 arr = arr.reshape(nr_frames, rows, columns, nr_samples)\n1335             else:\n1336                 arr = arr.reshape(nr_frames, nr_samples, rows, columns)\n1337                 arr = arr.transpose(0, 2, 3, 1)\n1338     else:\n1339         # Single frame\n1340         if nr_samples == 1:\n1341             # Single plane\n1342             arr = arr.reshape(rows, columns)\n1343         else:\n1344             # Multiple planes, usually 3\n1345             if planar_configuration == 0:\n1346                 arr = arr.reshape(rows, columns, nr_samples)\n1347             else:\n1348                 arr = arr.reshape(nr_samples, rows, columns)\n1349                 arr = arr.transpose(1, 2, 0)\n1350 \n1351     return arr\n1352 \n[end of pydicom/pixel_data_handlers/util.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n\n\n", "full_output": "<patch>\n--- a/pydicom/pixel_data_handlers/util.py\n+++ b/pydicom/pixel_data_handlers/util.py\n@@ -876,7 +876,7 @@\n             step = (y1 - y0) / length\n-            vals = np.around(np.arange(y0 + step, y1 + step, step))\n+            vals = np.around(np.linspace(y0 + step, y1, length))\n \n             if y0 == y1:\n                 lut.extend([y1] * length)\n@@ -898,7 +898,7 @@\n \n             lut.extend(\n-                _expand_segmented_lut(data[byte_offset:], fmt, length, lut[-1])\n+                _expand_segmented_lut(data[byte_offset:], fmt, nr_segments=length, last_value=lut[-1])\n             )\n \n         segments_read += 1\n</patch>", "model_patch": "\n--- a/pydicom/pixel_data_handlers/util.py\n+++ b/pydicom/pixel_data_handlers/util.py\n@@ -876,7 +876,7 @@\n             step = (y1 - y0) / length\n-            vals = np.around(np.arange(y0 + step, y1 + step, step))\n+            vals = np.around(np.linspace(y0 + step, y1, length))\n \n             if y0 == y1:\n                 lut.extend([y1] * length)\n@@ -898,7 +898,7 @@\n \n             lut.extend(\n-                _expand_segmented_lut(data[byte_offset:], fmt, length, lut[-1])\n+                _expand_segmented_lut(data[byte_offset:], fmt, nr_segments=length, last_value=lut[-1])\n             )\n \n         segments_read += 1\n"}
{"instance_id": "pydicom__pydicom-903", "model_name_or_path": "gpt-4o-mini", "text": "You will be provided with a partial code base and an issue statement explaining a problem to resolve.\n<issue>\nHandling of DS too long to be encoded in explicit encoding\n<!-- Instructions For Filing a Bug: https://github.com/pydicom/pydicom/blob/master/CONTRIBUTING.md#filing-bugs -->\r\n\r\n#### Description\r\nThis is probably not a bug, but I'm not sure about the wanted behavior.\r\nAn RTPlan dataset encoded as Little Endian Implicit contains multiple values in the DS tag DHV Data (3004,0058) with an overall length not fitting into 2 bytes. Trying to write this as explicit Little Endian fails with an exception (`\"ushort format requires 0 &lt;= number &lt;= (0x7fff * 2 + 1)\"`) which is raised by the `pack` call in `write_leUS` while trying to write the length.\r\n\r\nThe standard says for this case in PS3.5, Table 6.2-1 (for VR DS):\r\n```\r\nNote\r\nData Elements with multiple values using this VR may not be properly encoded if Explicit-VR transfer syntax is used and the VL of this attribute exceeds 65534 bytes.\r\n```\r\nSo, as I understand it, this is valid DICOM, that cannot be converted to explicit encoding without data loss.\r\nThe question is how to handle this. What comes to mind:\r\n- truncate the value and log a warning\r\n- raise a meaningful exception\r\n- adapt the behavior depending on some config setting\r\n\r\nAny thoughts?\r\n\r\n<!-- Example: Attribute Error thrown when printing (0x0010, 0x0020) patient Id> 0-->\r\n\r\n#### Steps/Code to Reproduce\r\n<!--\r\nExample:\r\n```py\r\nfrom io import BytesIO\r\nfrom pydicom import dcmread\r\n\r\nbytestream = b'\\x02\\x00\\x02\\x00\\x55\\x49\\x16\\x00\\x31\\x2e\\x32\\x2e\\x38\\x34\\x30\\x2e\\x31' \\\r\n             b'\\x30\\x30\\x30\\x38\\x2e\\x35\\x2e\\x31\\x2e\\x31\\x2e\\x39\\x00\\x02\\x00\\x10\\x00' \\\r\n             b'\\x55\\x49\\x12\\x00\\x31\\x2e\\x32\\x2e\\x38\\x34\\x30\\x2e\\x31\\x30\\x30\\x30\\x38' \\\r\n             b'\\x2e\\x31\\x2e\\x32\\x00\\x20\\x20\\x10\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x20\\x20' \\\r\n             b'\\x20\\x00\\x06\\x00\\x00\\x00\\x4e\\x4f\\x52\\x4d\\x41\\x4c'\r\n\r\nfp = BytesIO(bytestream)\r\nds = dcmread(fp, force=True)\r\n\r\nprint(ds.PatientID)\r\n```\r\nIf the code is too long, feel free to put it in a public gist and link\r\nit in the issue: https://gist.github.com\r\n\r\nWhen possible use pydicom testing examples to reproduce the errors. Otherwise, provide\r\nan anonymous version of the data in order to replicate the errors.\r\n-->\r\n\r\n#### Expected Results\r\n<!-- Please paste or describe the expected results.\r\nExample: No error is thrown and the name of the patient is printed.-->\r\n\r\n#### Actual Results\r\n<!-- Please paste or specifically describe the actual output or traceback.\r\n(Use %xmode to deactivate ipython's trace beautifier)\r\nExample: ```AttributeError: 'FileDataset' object has no attribute 'PatientID'```\r\n-->\r\n\r\n#### Versions\r\n<!--\r\nPlease run the following snippet and paste the output below.\r\nimport platform; print(platform.platform())\r\nimport sys; print(\"Python\", sys.version)\r\nimport pydicom; print(\"pydicom\", pydicom.__version__)\r\n-->\r\n\r\n\r\n<!-- Thanks for contributing! -->\r\n\n\n</issue>\n<code>\n[start of README.md]\n1 pydicom\n2 =======\n3 \n4 [![Build Status](https://travis-ci.org/pydicom/pydicom.svg?branch=master)](https://travis-ci.org/pydicom/pydicom)\n5 [![AppVeyor](https://ci.appveyor.com/api/projects/status/1vjtkr82lumnd3i7?svg=true)](https://ci.appveyor.com/project/glemaitre/pydicom)\n6 [![CircleCI](https://circleci.com/gh/pydicom/pydicom/tree/master.svg?style=shield)](https://circleci.com/gh/pydicom/pydicom/tree/master)\n7 [![codecov](https://codecov.io/gh/pydicom/pydicom/branch/master/graph/badge.svg)](https://codecov.io/gh/pydicom/pydicom)\n8 [![Python version](https://img.shields.io/pypi/pyversions/pydicom.svg)](https://img.shields.io/pypi/pyversions/pydicom.svg)\n9 [![PyPI version](https://badge.fury.io/py/pydicom.svg)](https://badge.fury.io/py/pydicom)\n10 [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3333768.svg)](https://doi.org/10.5281/zenodo.3333768)\n11 \n12 pydicom is a pure python package for working with [DICOM](http://medical.nema.org/) files.\n13 It was made for inspecting and modifying DICOM data in an easy \"pythonic\" way.\n14 The modifications can be written again to a new file.\n15 \n16 As a pure python package, pydicom can run anywhere python runs without any other requirements,\n17 although [NumPy](http://www.numpy.org) is needed if manipulating pixel data.\n18 \n19 pydicom is not a DICOM server, and is not primarily about viewing images.\n20 It is designed to let you\n21 manipulate data elements in DICOM files with python code.\n22 \n23 Limitations -- for files with _compressed_ pixel data, pydicom can decompress\n24 it (with additional libraries installed) and allow you to manipulate the data,\n25 but can only store changed pixel data as uncompressed. Files can always be\n26 read and saved (including compressed pixel data that has not been modified),\n27 but once decompressed, modified pixel data cannot be compressed again.\n28 \n29 Documentation\n30 -------------\n31 \n32 pydicom documentation is available on GitHub Pages both for the [development\n33  (master) version](https://pydicom.github.io/pydicom/dev) and for the\n34 [released version](https://pydicom.github.io/pydicom/stable). The\n35 documentation for [the previous 0.9.9 version](https://pydicom.github.io/pydicom/0.9/)\n36 is still there for reference.\n37 \n38 See [Getting Started](https://pydicom.github.io/pydicom/stable/getting_started.html)\n39 for installation and basic information, and the\n40 [User Guide](https://pydicom.github.io/pydicom/stable/pydicom_user_guide.html)\n41 for an overview of how to use the pydicom library.\n42 To contribute to pydicom, read our [contribution guide](https://github.com/pydicom/pydicom/blob/master/CONTRIBUTING.md).\n43 To contribute an example or extension of pydicom that does not belong with\n44 the core software, see our contribution repository,\n45 [contrib-pydicom](https://www.github.com/pydicom/contrib-pydicom).\n46 \n[end of README.md]\n[start of pydicom/filewriter.py]\n1 # Copyright 2008-2018 pydicom authors. See LICENSE file for details.\n2 \"\"\"Functions related to writing DICOM data.\"\"\"\n3 \n4 from __future__ import absolute_import\n5 \n6 import struct\n7 from struct import pack\n8 \n9 from pydicom import compat\n10 from pydicom.compat import in_py2\n11 from pydicom.charset import (\n12     default_encoding, text_VRs, convert_encodings, encode_string\n13 )\n14 from pydicom.dataelem import DataElement_from_raw\n15 from pydicom.dataset import Dataset, validate_file_meta\n16 from pydicom.filebase import DicomFile, DicomFileLike, DicomBytesIO\n17 from pydicom.multival import MultiValue\n18 from pydicom.tag import (Tag, ItemTag, ItemDelimiterTag, SequenceDelimiterTag,\n19                          tag_in_exception)\n20 from pydicom.uid import UncompressedPixelTransferSyntaxes\n21 from pydicom.valuerep import extra_length_VRs, PersonNameUnicode\n22 from pydicom.values import convert_numbers\n23 \n24 \n25 def _correct_ambiguous_vr_element(elem, ds, is_little_endian):\n26     \"\"\"Implementation for `correct_ambiguous_vr_element`.\n27     See `correct_ambiguous_vr_element` for description.\n28     \"\"\"\n29     # 'OB or OW': 7fe0,0010 PixelData\n30     if elem.tag == 0x7fe00010:\n31         # Compressed Pixel Data\n32         # PS3.5 Annex A.4\n33         #   If encapsulated, VR is OB and length is undefined\n34         if elem.is_undefined_length:\n35             elem.VR = 'OB'\n36         # Non-compressed Pixel Data - Implicit Little Endian\n37         # PS3.5 Annex A1: VR is always OW\n38         elif ds.is_implicit_VR:\n39             elem.VR = 'OW'\n40         else:\n41             # Non-compressed Pixel Data - Explicit VR\n42             # PS3.5 Annex A.2:\n43             # If BitsAllocated is > 8 then VR shall be OW,\n44             # else may be OB or OW.\n45             # If we get here, the data has not been written before\n46             # or has been converted from Implicit Little Endian,\n47             # so we default to OB for BitsAllocated 1 or 8\n48             elem.VR = 'OW' if ds.BitsAllocated > 8 else 'OB'\n49 \n50     # 'US or SS' and dependent on PixelRepresentation\n51     # (0018,9810) Zero Velocity Pixel Value\n52     # (0022,1452) Mapped Pixel Value\n53     # (0028,0104)/(0028,0105) Smallest/Largest Valid Pixel Value\n54     # (0028,0106)/(0028,0107) Smallest/Largest Image Pixel Value\n55     # (0028,0108)/(0028,0109) Smallest/Largest Pixel Value in Series\n56     # (0028,0110)/(0028,0111) Smallest/Largest Image Pixel Value in Plane\n57     # (0028,0120) Pixel Padding Value\n58     # (0028,0121) Pixel Padding Range Limit\n59     # (0028,1101-1103) Red/Green/Blue Palette Color Lookup Table Descriptor\n60     # (0028,3002) LUT Descriptor\n61     # (0040,9216)/(0040,9211) Real World Value First/Last Value Mapped\n62     # (0060,3004)/(0060,3006) Histogram First/Last Bin Value\n63     elif elem.tag in [\n64             0x00189810, 0x00221452, 0x00280104, 0x00280105, 0x00280106,\n65             0x00280107, 0x00280108, 0x00280109, 0x00280110, 0x00280111,\n66             0x00280120, 0x00280121, 0x00281101, 0x00281102, 0x00281103,\n67             0x00283002, 0x00409211, 0x00409216, 0x00603004, 0x00603006\n68     ]:\n69         # US if PixelRepresentation value is 0x0000, else SS\n70         #   For references, see the list at\n71         #   https://github.com/darcymason/pydicom/pull/298\n72         # PixelRepresentation is usually set in the root dataset\n73         while 'PixelRepresentation' not in ds and ds.parent:\n74             ds = ds.parent\n75         # if no pixel data is present, none if these tags is used,\n76         # so we can just ignore a missing PixelRepresentation in this case\n77         if ('PixelRepresentation' not in ds and 'PixelData' not in ds or\n78                 ds.PixelRepresentation == 0):\n79             elem.VR = 'US'\n80             byte_type = 'H'\n81         else:\n82             elem.VR = 'SS'\n83             byte_type = 'h'\n84 \n85         # Need to handle type check for elements with VM > 1\n86         elem_value = elem.value if elem.VM == 1 else elem.value[0]\n87         if not isinstance(elem_value, int):\n88             elem.value = convert_numbers(elem.value, is_little_endian,\n89                                          byte_type)\n90 \n91     # 'OB or OW' and dependent on WaveformBitsAllocated\n92     # (5400, 0110) Channel Minimum Value\n93     # (5400, 0112) Channel Maximum Value\n94     # (5400, 100A) Waveform Padding Data\n95     # (5400, 1010) Waveform Data\n96     elif elem.tag in [0x54000110, 0x54000112, 0x5400100A, 0x54001010]:\n97         # If WaveformBitsAllocated is > 8 then OW, otherwise may be\n98         #   OB or OW.\n99         #   See PS3.3 C.10.9.1.\n100         if ds.is_implicit_VR:\n101             elem.VR = 'OW'\n102         else:\n103             elem.VR = 'OW' if ds.WaveformBitsAllocated > 8 else 'OB'\n104 \n105     # 'US or OW': 0028,3006 LUTData\n106     elif elem.tag == 0x00283006:\n107         # First value in LUT Descriptor is how many values in\n108         #   LUTData, if there's only one value then must be US\n109         # As per PS3.3 C.11.1.1.1\n110         if ds.LUTDescriptor[0] == 1:\n111             elem.VR = 'US'\n112             elem_value = elem.value if elem.VM == 1 else elem.value[0]\n113             if not isinstance(elem_value, int):\n114                 elem.value = convert_numbers(elem.value, is_little_endian,\n115                                              'H')\n116         else:\n117             elem.VR = 'OW'\n118 \n119     # 'OB or OW': 60xx,3000 OverlayData and dependent on Transfer Syntax\n120     elif (elem.tag.group in range(0x6000, 0x601F, 2)\n121           and elem.tag.elem == 0x3000):\n122         # Implicit VR must be OW, explicit VR may be OB or OW\n123         #   as per PS3.5 Section 8.1.2 and Annex A\n124         elem.VR = 'OW'\n125 \n126     return elem\n127 \n128 \n129 def correct_ambiguous_vr_element(elem, ds, is_little_endian):\n130     \"\"\"Attempt to correct the ambiguous VR element `elem`.\n131 \n132     When it's not possible to correct the VR, the element will be returned\n133     unchanged. Currently the only ambiguous VR elements not corrected for are\n134     all retired or part of DICONDE.\n135 \n136     If the VR is corrected and is 'US' or 'SS' then the value will be updated\n137     using the pydicom.values.convert_numbers() method.\n138 \n139     Parameters\n140     ----------\n141     elem : pydicom.dataelem.DataElement\n142         The element with an ambiguous VR.\n143     ds : pydicom.dataset.Dataset\n144         The dataset containing `elem`.\n145     is_little_endian : bool\n146         The byte ordering of the values in the dataset.\n147 \n148     Returns\n149     -------\n150     elem : pydicom.dataelem.DataElement\n151         The corrected element\n152     \"\"\"\n153     if 'or' in elem.VR:\n154         # convert raw data elements before handling them\n155         if elem.is_raw:\n156             elem = DataElement_from_raw(elem)\n157             ds.__setitem__(elem.tag, elem)\n158 \n159         try:\n160             _correct_ambiguous_vr_element(elem, ds, is_little_endian)\n161         except AttributeError as e:\n162             reason = ('Failed to resolve ambiguous VR for tag'\n163                       ' {}: '.format(elem.tag)) + str(e)\n164             raise AttributeError(reason)\n165 \n166     return elem\n167 \n168 \n169 def correct_ambiguous_vr(ds, is_little_endian):\n170     \"\"\"Iterate through `ds` correcting ambiguous VR elements (if possible).\n171 \n172     When it's not possible to correct the VR, the element will be returned\n173     unchanged. Currently the only ambiguous VR elements not corrected for are\n174     all retired or part of DICONDE.\n175 \n176     If the VR is corrected and is 'US' or 'SS' then the value will be updated\n177     using the pydicom.values.convert_numbers() method.\n178 \n179     Parameters\n180     ----------\n181     ds : pydicom.dataset.Dataset\n182         The dataset containing ambiguous VR elements.\n183     is_little_endian : bool\n184         The byte ordering of the values in the dataset.\n185 \n186     Returns\n187     -------\n188     ds : pydicom.dataset.Dataset\n189         The corrected dataset\n190 \n191     Raises\n192     ------\n193     AttributeError\n194         If a tag is missing in `ds` that is required to resolve the ambiguity.\n195     \"\"\"\n196     # Iterate through the elements\n197     for elem in ds:\n198         # raw data element sequences can be written as they are, because we\n199         # have ensured that the transfer syntax has not changed at this point\n200         if elem.VR == 'SQ':\n201             for item in elem:\n202                 correct_ambiguous_vr(item, is_little_endian)\n203         elif 'or' in elem.VR:\n204             correct_ambiguous_vr_element(elem, ds, is_little_endian)\n205     return ds\n206 \n207 \n208 def write_numbers(fp, data_element, struct_format):\n209     \"\"\"Write a \"value\" of type struct_format from the dicom file.\n210 \n211     \"Value\" can be more than one number.\n212 \n213     struct_format -- the character format as used by the struct module.\n214 \n215     \"\"\"\n216     endianChar = '><' [fp.is_little_endian]\n217     value = data_element.value\n218     if value == \"\":\n219         return  # don't need to write anything for empty string\n220 \n221     format_string = endianChar + struct_format\n222     try:\n223         try:\n224             value.append  # works only if list, not if string or number\n225         except AttributeError:  # is a single value - the usual case\n226             fp.write(pack(format_string, value))\n227         else:\n228             for val in value:\n229                 fp.write(pack(format_string, val))\n230     except Exception as e:\n231         raise IOError(\n232             \"{0}\\nfor data_element:\\n{1}\".format(str(e), str(data_element)))\n233 \n234 \n235 def write_OBvalue(fp, data_element):\n236     \"\"\"Write a data_element with VR of 'other byte' (OB).\"\"\"\n237     fp.write(data_element.value)\n238 \n239 \n240 def write_OWvalue(fp, data_element):\n241     \"\"\"Write a data_element with VR of 'other word' (OW).\n242 \n243     Note: This **does not currently do the byte swapping** for Endian state.\n244     \"\"\"\n245     # XXX for now just write the raw bytes without endian swapping\n246     fp.write(data_element.value)\n247 \n248 \n249 def write_UI(fp, data_element):\n250     \"\"\"Write a data_element with VR of 'unique identifier' (UI).\"\"\"\n251     write_string(fp, data_element, '\\0')  # pad with 0-byte to even length\n252 \n253 \n254 def _is_multi_value(val):\n255     \"\"\"Return True if `val` is a multi-value container.\"\"\"\n256     return isinstance(val, (MultiValue, list, tuple))\n257 \n258 \n259 def multi_string(val):\n260     \"\"\"Put a string together with delimiter if has more than one value\"\"\"\n261     if _is_multi_value(val):\n262         return \"\\\\\".join(val)\n263     else:\n264         return val\n265 \n266 \n267 def write_PN(fp, data_element, encodings=None):\n268     if not encodings:\n269         encodings = [default_encoding]\n270 \n271     if data_element.VM == 1:\n272         val = [data_element.value, ]\n273     else:\n274         val = data_element.value\n275 \n276     if isinstance(val[0], compat.text_type) or not in_py2:\n277         try:\n278             val = [elem.encode(encodings) for elem in val]\n279         except TypeError:\n280             # we get here in Python 2 if val is a unicode string\n281             val = [PersonNameUnicode(elem, encodings) for elem in val]\n282             val = [elem.encode(encodings) for elem in val]\n283 \n284     val = b'\\\\'.join(val)\n285 \n286     if len(val) % 2 != 0:\n287         val = val + b' '\n288 \n289     fp.write(val)\n290 \n291 \n292 def write_string(fp, data_element, padding=' '):\n293     \"\"\"Write a single or multivalued ASCII string.\"\"\"\n294     val = multi_string(data_element.value)\n295     if val is not None:\n296         if len(val) % 2 != 0:\n297             val = val + padding  # pad to even length\n298         if isinstance(val, compat.text_type):\n299             val = val.encode(default_encoding)\n300         fp.write(val)\n301 \n302 \n303 def write_text(fp, data_element, encodings=None):\n304     \"\"\"Write a single or multivalued text string.\"\"\"\n305     val = data_element.value\n306     if val is not None:\n307         encodings = encodings or [default_encoding]\n308         if _is_multi_value(val):\n309             if val and isinstance(val[0], compat.text_type):\n310                 val = b'\\\\'.join([encode_string(val, encodings)\n311                                   for val in val])\n312             else:\n313                 val = b'\\\\'.join([val for val in val])\n314         else:\n315             if isinstance(val, compat.text_type):\n316                 val = encode_string(val, encodings)\n317 \n318         if len(val) % 2 != 0:\n319             val = val + b' '  # pad to even length\n320         fp.write(val)\n321 \n322 \n323 def write_number_string(fp, data_element):\n324     \"\"\"Handle IS or DS VR - write a number stored as a string of digits.\"\"\"\n325     # If the DS or IS has an original_string attribute, use that, so that\n326     # unchanged data elements are written with exact string as when read from\n327     # file\n328     val = data_element.value\n329 \n330     if _is_multi_value(val):\n331         val = \"\\\\\".join((x.original_string\n332                          if hasattr(x, 'original_string') else str(x)\n333                          for x in val))\n334     else:\n335         if hasattr(val, 'original_string'):\n336             val = val.original_string\n337         else:\n338             val = str(val)\n339 \n340     if len(val) % 2 != 0:\n341         val = val + ' '  # pad to even length\n342 \n343     if not in_py2:\n344         val = bytes(val, default_encoding)\n345 \n346     fp.write(val)\n347 \n348 \n349 def _format_DA(val):\n350     if val is None:\n351         return ''\n352     elif hasattr(val, 'original_string'):\n353         return val.original_string\n354     else:\n355         return val.strftime(\"%Y%m%d\")\n356 \n357 \n358 def write_DA(fp, data_element):\n359     val = data_element.value\n360     if isinstance(val, (str, compat.string_types)):\n361         write_string(fp, data_element)\n362     else:\n363         if _is_multi_value(val):\n364             val = \"\\\\\".join((x if isinstance(x, (str, compat.string_types))\n365                              else _format_DA(x) for x in val))\n366         else:\n367             val = _format_DA(val)\n368         if len(val) % 2 != 0:\n369             val = val + ' '  # pad to even length\n370 \n371         if isinstance(val, compat.string_types):\n372             val = val.encode(default_encoding)\n373 \n374         fp.write(val)\n375 \n376 \n377 def _format_DT(val):\n378     if hasattr(val, 'original_string'):\n379         return val.original_string\n380     elif val.microsecond > 0:\n381         return val.strftime(\"%Y%m%d%H%M%S.%f%z\")\n382     else:\n383         return val.strftime(\"%Y%m%d%H%M%S%z\")\n384 \n385 \n386 def write_DT(fp, data_element):\n387     val = data_element.value\n388     if isinstance(val, (str, compat.string_types)):\n389         write_string(fp, data_element)\n390     else:\n391         if _is_multi_value(val):\n392             val = \"\\\\\".join((x if isinstance(x, (str, compat.string_types))\n393                              else _format_DT(x) for x in val))\n394         else:\n395             val = _format_DT(val)\n396         if len(val) % 2 != 0:\n397             val = val + ' '  # pad to even length\n398 \n399         if isinstance(val, compat.string_types):\n400             val = val.encode(default_encoding)\n401 \n402         fp.write(val)\n403 \n404 \n405 def _format_TM(val):\n406     if val is None:\n407         return ''\n408     elif hasattr(val, 'original_string'):\n409         return val.original_string\n410     elif val.microsecond > 0:\n411         return val.strftime(\"%H%M%S.%f\")\n412     else:\n413         return val.strftime(\"%H%M%S\")\n414 \n415 \n416 def write_TM(fp, data_element):\n417     val = data_element.value\n418     if isinstance(val, (str, compat.string_types)):\n419         write_string(fp, data_element)\n420     else:\n421         if _is_multi_value(val):\n422             val = \"\\\\\".join((x if isinstance(x, (str, compat.string_types))\n423                              else _format_TM(x) for x in val))\n424         else:\n425             val = _format_TM(val)\n426         if len(val) % 2 != 0:\n427             val = val + ' '  # pad to even length\n428 \n429         if isinstance(val, compat.string_types):\n430             val = val.encode(default_encoding)\n431 \n432         fp.write(val)\n433 \n434 \n435 def write_data_element(fp, data_element, encodings=None):\n436     \"\"\"Write the data_element to file fp according to\n437     dicom media storage rules.\n438     \"\"\"\n439     # Write element's tag\n440     fp.write_tag(data_element.tag)\n441 \n442     # If explicit VR, write the VR\n443     VR = data_element.VR\n444     if not fp.is_implicit_VR:\n445         if len(VR) != 2:\n446             msg = (\"Cannot write ambiguous VR of '{}' for data element with \"\n447                    \"tag {}.\\nSet the correct VR before writing, or use an \"\n448                    \"implicit VR transfer syntax\".format(\n449                        VR, repr(data_element.tag)))\n450             raise ValueError(msg)\n451         if not in_py2:\n452             fp.write(bytes(VR, default_encoding))\n453         else:\n454             fp.write(VR)\n455         if VR in extra_length_VRs:\n456             fp.write_US(0)  # reserved 2 bytes\n457 \n458     # write into a buffer to avoid seeking back which can be expansive\n459     buffer = DicomBytesIO()\n460     buffer.is_little_endian = fp.is_little_endian\n461     buffer.is_implicit_VR = fp.is_implicit_VR\n462 \n463     if data_element.is_raw:\n464         # raw data element values can be written as they are\n465         buffer.write(data_element.value)\n466         is_undefined_length = data_element.length == 0xFFFFFFFF\n467     else:\n468         if VR not in writers:\n469             raise NotImplementedError(\n470                 \"write_data_element: unknown Value Representation \"\n471                 \"'{0}'\".format(VR))\n472 \n473         encodings = encodings or [default_encoding]\n474         encodings = convert_encodings(encodings)\n475         writer_function, writer_param = writers[VR]\n476         is_undefined_length = data_element.is_undefined_length\n477         if VR in text_VRs or VR in ('PN', 'SQ'):\n478             writer_function(buffer, data_element, encodings=encodings)\n479         else:\n480             # Many numeric types use the same writer but with numeric format\n481             # parameter\n482             if writer_param is not None:\n483                 writer_function(buffer, data_element, writer_param)\n484             else:\n485                 writer_function(buffer, data_element)\n486 \n487     # valid pixel data with undefined length shall contain encapsulated\n488     # data, e.g. sequence items - raise ValueError otherwise (see #238)\n489     if is_undefined_length and data_element.tag == 0x7fe00010:\n490         val = data_element.value\n491         if (fp.is_little_endian and not\n492                 val.startswith(b'\\xfe\\xff\\x00\\xe0') or\n493                 not fp.is_little_endian and\n494                 not val.startswith(b'\\xff\\xfe\\xe0\\x00')):\n495             raise ValueError('Pixel Data with undefined length must '\n496                              'start with an item tag')\n497 \n498     value_length = buffer.tell()\n499     if (not fp.is_implicit_VR and VR not in extra_length_VRs and\n500             not is_undefined_length):\n501         try:\n502             fp.write_US(value_length)  # Explicit VR length field is 2 bytes\n503         except struct.error:\n504             msg = ('The value for the data element {} exceeds the size '\n505                    'of 64 kByte and cannot be written in an explicit transfer '\n506                    'syntax. You can save it using Implicit Little Endian '\n507                    'transfer syntax, or you have to truncate the value to not '\n508                    'exceed the maximum size of 64 kByte.'\n509                    .format(data_element.tag))\n510             raise ValueError(msg)\n511     else:\n512         # write the proper length of the data_element in the length slot,\n513         # unless is SQ with undefined length.\n514         fp.write_UL(0xFFFFFFFF if is_undefined_length else value_length)\n515 \n516     fp.write(buffer.getvalue())\n517     if is_undefined_length:\n518         fp.write_tag(SequenceDelimiterTag)\n519         fp.write_UL(0)  # 4-byte 'length' of delimiter data item\n520 \n521 \n522 def write_dataset(fp, dataset, parent_encoding=default_encoding):\n523     \"\"\"Write a Dataset dictionary to the file. Return the total length written.\n524     \"\"\"\n525     _harmonize_properties(dataset, fp)\n526 \n527     if not dataset.is_original_encoding:\n528         dataset = correct_ambiguous_vr(dataset, fp.is_little_endian)\n529 \n530     dataset_encoding = dataset.get('SpecificCharacterSet', parent_encoding)\n531 \n532     fpStart = fp.tell()\n533     # data_elements must be written in tag order\n534     tags = sorted(dataset.keys())\n535 \n536     for tag in tags:\n537         # do not write retired Group Length (see PS3.5, 7.2)\n538         if tag.element == 0 and tag.group > 6:\n539             continue\n540         with tag_in_exception(tag):\n541             write_data_element(fp, dataset.get_item(tag), dataset_encoding)\n542 \n543     return fp.tell() - fpStart\n544 \n545 \n546 def _harmonize_properties(dataset, fp):\n547     \"\"\"Make sure the properties in the dataset and the file pointer are\n548     consistent, so the user can set both with the same effect.\n549     Properties set on the destination file object always have preference.\n550     \"\"\"\n551     # ensure preference of fp over dataset\n552     if hasattr(fp, 'is_little_endian'):\n553         dataset.is_little_endian = fp.is_little_endian\n554     if hasattr(fp, 'is_implicit_VR'):\n555         dataset.is_implicit_VR = fp.is_implicit_VR\n556 \n557     # write the properties back to have a consistent state\n558     fp.is_implicit_VR = dataset.is_implicit_VR\n559     fp.is_little_endian = dataset.is_little_endian\n560 \n561 \n562 def write_sequence(fp, data_element, encodings):\n563     \"\"\"Write a dicom Sequence contained in data_element to the file fp.\"\"\"\n564     # write_data_element has already written the VR='SQ' (if needed) and\n565     #    a placeholder for length\"\"\"\n566     sequence = data_element.value\n567     for dataset in sequence:\n568         write_sequence_item(fp, dataset, encodings)\n569 \n570 \n571 def write_sequence_item(fp, dataset, encodings):\n572     \"\"\"Write an item (dataset) in a dicom Sequence to the dicom file fp.\n573 \n574     This is similar to writing a data_element, but with a specific tag for\n575     Sequence Item\n576 \n577     see Dicom standard Part 5, p. 39 ('03 version)\n578     \"\"\"\n579     fp.write_tag(ItemTag)  # marker for start of Sequence Item\n580     length_location = fp.tell()  # save location for later.\n581     # will fill in real value later if not undefined length\n582     fp.write_UL(0xffffffff)\n583     write_dataset(fp, dataset, parent_encoding=encodings)\n584     if getattr(dataset, \"is_undefined_length_sequence_item\", False):\n585         fp.write_tag(ItemDelimiterTag)\n586         fp.write_UL(0)  # 4-bytes 'length' field for delimiter item\n587     else:  # we will be nice and set the lengths for the reader of this file\n588         location = fp.tell()\n589         fp.seek(length_location)\n590         fp.write_UL(location - length_location - 4)  # 4 is length of UL\n591         fp.seek(location)  # ready for next data_element\n592 \n593 \n594 def write_UN(fp, data_element):\n595     \"\"\"Write a byte string for an DataElement of value 'UN' (unknown).\"\"\"\n596     fp.write(data_element.value)\n597 \n598 \n599 def write_ATvalue(fp, data_element):\n600     \"\"\"Write a data_element tag to a file.\"\"\"\n601     try:\n602         iter(data_element.value)  # see if is multi-valued AT;\n603         # Note will fail if Tag ever derived from true tuple rather than being\n604         # a long\n605     except TypeError:\n606         # make sure is expressed as a Tag instance\n607         tag = Tag(data_element.value)\n608         fp.write_tag(tag)\n609     else:\n610         tags = [Tag(tag) for tag in data_element.value]\n611         for tag in tags:\n612             fp.write_tag(tag)\n613 \n614 \n615 def write_file_meta_info(fp, file_meta, enforce_standard=True):\n616     \"\"\"Write the File Meta Information elements in `file_meta` to `fp`.\n617 \n618     If `enforce_standard` is True then the file-like `fp` should be positioned\n619     past the 128 byte preamble + 4 byte prefix (which should already have been\n620     written).\n621 \n622     DICOM File Meta Information Group Elements\n623     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n624     From the DICOM standard, Part 10 Section 7.1, any DICOM file shall contain\n625     a 128-byte preamble, a 4-byte DICOM prefix 'DICM' and (at a minimum) the\n626     following Type 1 DICOM Elements (from Table 7.1-1):\n627         * (0002,0000) FileMetaInformationGroupLength, UL, 4\n628         * (0002,0001) FileMetaInformationVersion, OB, 2\n629         * (0002,0002) MediaStorageSOPClassUID, UI, N\n630         * (0002,0003) MediaStorageSOPInstanceUID, UI, N\n631         * (0002,0010) TransferSyntaxUID, UI, N\n632         * (0002,0012) ImplementationClassUID, UI, N\n633 \n634     If `enforce_standard` is True then (0002,0000) will be added/updated,\n635     (0002,0001) and (0002,0012) will be added if not already present and the\n636     other required elements will be checked to see if they exist. If\n637     `enforce_standard` is False then `file_meta` will be written as is after\n638     minimal validation checking.\n639 \n640     The following Type 3/1C Elements may also be present:\n641         * (0002,0013) ImplementationVersionName, SH, N\n642         * (0002,0016) SourceApplicationEntityTitle, AE, N\n643         * (0002,0017) SendingApplicationEntityTitle, AE, N\n644         * (0002,0018) ReceivingApplicationEntityTitle, AE, N\n645         * (0002,0100) PrivateInformationCreatorUID, UI, N\n646         * (0002,0102) PrivateInformation, OB, N\n647 \n648     If `enforce_standard` is True then (0002,0013) will be added/updated.\n649 \n650     Encoding\n651     ~~~~~~~~\n652     The encoding of the File Meta Information shall be Explicit VR Little\n653     Endian\n654 \n655     Parameters\n656     ----------\n657     fp : file-like\n658         The file-like to write the File Meta Information to.\n659     file_meta : pydicom.dataset.Dataset\n660         The File Meta Information DataElements.\n661     enforce_standard : bool\n662         If False, then only the File Meta Information elements already in\n663         `file_meta` will be written to `fp`. If True (default) then a DICOM\n664         Standards conformant File Meta will be written to `fp`.\n665 \n666     Raises\n667     ------\n668     ValueError\n669         If `enforce_standard` is True and any of the required File Meta\n670         Information elements are missing from `file_meta`, with the\n671         exception of (0002,0000), (0002,0001) and (0002,0012).\n672     ValueError\n673         If any non-Group 2 Elements are present in `file_meta`.\n674     \"\"\"\n675     validate_file_meta(file_meta, enforce_standard)\n676 \n677     if enforce_standard and 'FileMetaInformationGroupLength' not in file_meta:\n678         # Will be updated with the actual length later\n679         file_meta.FileMetaInformationGroupLength = 0\n680 \n681     # Write the File Meta Information Group elements\n682     # first write into a buffer to avoid seeking back, that can be\n683     # expansive and is not allowed if writing into a zip file\n684     buffer = DicomBytesIO()\n685     buffer.is_little_endian = True\n686     buffer.is_implicit_VR = False\n687     write_dataset(buffer, file_meta)\n688 \n689     # If FileMetaInformationGroupLength is present it will be the first written\n690     #   element and we must update its value to the correct length.\n691     if 'FileMetaInformationGroupLength' in file_meta:\n692         # Update the FileMetaInformationGroupLength value, which is the number\n693         #   of bytes from the end of the FileMetaInformationGroupLength element\n694         #   to the end of all the File Meta Information elements.\n695         # FileMetaInformationGroupLength has a VR of 'UL' and so has a value\n696         #   that is 4 bytes fixed. The total length of when encoded as\n697         #   Explicit VR must therefore be 12 bytes.\n698         file_meta.FileMetaInformationGroupLength = buffer.tell() - 12\n699         buffer.seek(0)\n700         write_data_element(buffer, file_meta[0x00020000])\n701 \n702     fp.write(buffer.getvalue())\n703 \n704 \n705 def dcmwrite(filename, dataset, write_like_original=True):\n706     \"\"\"Write `dataset` to the `filename` specified.\n707 \n708     If `write_like_original` is True then `dataset` will be written as is\n709     (after minimal validation checking) and may or may not contain all or parts\n710     of the File Meta Information (and hence may or may not be conformant with\n711     the DICOM File Format).\n712     If `write_like_original` is False, `dataset` will be stored in the DICOM\n713     File Format in accordance with DICOM Standard Part 10 Section 7. The byte\n714     stream of the `dataset` will be placed into the file after the DICOM File\n715     Meta Information.\n716 \n717     File Meta Information\n718     ---------------------\n719     The File Meta Information consists of a 128-byte preamble, followed by a 4\n720     byte DICOM prefix, followed by the File Meta Information Group elements.\n721 \n722     Preamble and Prefix\n723     ~~~~~~~~~~~~~~~~~~~\n724     The `dataset.preamble` attribute shall be 128-bytes long or None and is\n725     available for use as defined by the Application Profile or specific\n726     implementations. If the preamble is not used by an Application Profile or\n727     specific implementation then all 128 bytes should be set to 0x00. The\n728     actual preamble written depends on `write_like_original` and\n729     `dataset.preamble` (see the table below).\n730 \n731     +------------------+------------------------------+\n732     |                  | write_like_original          |\n733     +------------------+-------------+----------------+\n734     | dataset.preamble | True        | False          |\n735     +==================+=============+================+\n736     | None             | no preamble | 128 0x00 bytes |\n737     +------------------+------------------------------+\n738     | 128 bytes        | dataset.preamble             |\n739     +------------------+------------------------------+\n740 \n741     The prefix shall be the string 'DICM' and will be written if and only if\n742     the preamble is present.\n743 \n744     File Meta Information Group Elements\n745     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n746     The preamble and prefix are followed by a set of DICOM Elements from the\n747     (0002,eeee) group. Some of these elements are required (Type 1) while\n748     others are optional (Type 3/1C). If `write_like_original` is True then the\n749     File Meta Information Group elements are all optional. See\n750     pydicom.filewriter.write_file_meta_info for more information on which\n751     elements are required.\n752 \n753     The File Meta Information Group elements should be included within their\n754     own Dataset in the `dataset.file_meta` attribute.\n755 \n756     If (0002,0010) 'Transfer Syntax UID' is included then the user must ensure\n757     it's value is compatible with the values for the `dataset.is_little_endian`\n758     and `dataset.is_implicit_VR` attributes. For example, if is_little_endian\n759     and is_implicit_VR are both True then the Transfer Syntax UID must be\n760     1.2.840.10008.1.2 'Implicit VR Little Endian'. See the DICOM standard\n761     Part 5 Section 10 for more information on Transfer Syntaxes.\n762 \n763     Encoding\n764     ~~~~~~~~\n765     The preamble and prefix are encoding independent. The File Meta Elements\n766     are encoded as Explicit VR Little Endian as required by the DICOM standard.\n767 \n768     Dataset\n769     -------\n770     A DICOM Dataset representing a SOP Instance related to a DICOM Information\n771     Object Definition. It is up to the user to ensure the `dataset` conforms\n772     to the DICOM standard.\n773 \n774     Encoding\n775     ~~~~~~~~\n776     The `dataset` is encoded as specified by the `dataset.is_little_endian`\n777     and `dataset.is_implicit_VR` attributes. It's up to the user to ensure\n778     these attributes are set correctly (as well as setting an appropriate value\n779     for `dataset.file_meta.TransferSyntaxUID` if present).\n780 \n781     Parameters\n782     ----------\n783     filename : str or file-like\n784         Name of file or the file-like to write the new DICOM file to.\n785     dataset : pydicom.dataset.FileDataset\n786         Dataset holding the DICOM information; e.g. an object read with\n787         pydicom.dcmread().\n788     write_like_original : bool\n789         If True (default), preserves the following information from\n790         the Dataset (and may result in a non-conformant file):\n791         - preamble -- if the original file has no preamble then none will be\n792             written.\n793         - file_meta -- if the original file was missing any required File Meta\n794             Information Group elements then they will not be added or written.\n795             If (0002,0000) 'File Meta Information Group Length' is present then\n796             it may have its value updated.\n797         - seq.is_undefined_length -- if original had delimiters, write them now\n798             too, instead of the more sensible length characters\n799         - is_undefined_length_sequence_item -- for datasets that belong to a\n800             sequence, write the undefined length delimiters if that is\n801             what the original had.\n802         If False, produces a file conformant with the DICOM File Format, with\n803         explicit lengths for all elements.\n804 \n805     See Also\n806     --------\n807     pydicom.dataset.FileDataset\n808         Dataset class with relevant attributes and information.\n809     pydicom.dataset.Dataset.save_as\n810         Write a DICOM file from a dataset that was read in with dcmread().\n811         save_as wraps dcmwrite.\n812     \"\"\"\n813     # Check that dataset's group 0x0002 elements are only present in the\n814     #   `dataset.file_meta` Dataset - user may have added them to the wrong\n815     #   place\n816     if dataset.group_dataset(0x0002) != Dataset():\n817         raise ValueError(\"File Meta Information Group Elements (0002,eeee) \"\n818                          \"should be in their own Dataset object in the \"\n819                          \"'{0}.file_meta' \"\n820                          \"attribute.\".format(dataset.__class__.__name__))\n821 \n822     # A preamble is required under the DICOM standard, however if\n823     #   `write_like_original` is True we treat it as optional\n824     preamble = getattr(dataset, 'preamble', None)\n825     if preamble and len(preamble) != 128:\n826         raise ValueError(\"'{0}.preamble' must be 128-bytes \"\n827                          \"long.\".format(dataset.__class__.__name__))\n828     if not preamble and not write_like_original:\n829         # The default preamble is 128 0x00 bytes.\n830         preamble = b'\\x00' * 128\n831 \n832     # File Meta Information is required under the DICOM standard, however if\n833     #   `write_like_original` is True we treat it as optional\n834     if not write_like_original:\n835         # the checks will be done in write_file_meta_info()\n836         dataset.fix_meta_info(enforce_standard=False)\n837     else:\n838         dataset.ensure_file_meta()\n839 \n840     # Check for decompression, give warnings if inconsistencies\n841     # If decompressed, then pixel_array is now used instead of PixelData\n842     if dataset.is_decompressed:\n843         xfer = dataset.file_meta.TransferSyntaxUID\n844         if xfer not in UncompressedPixelTransferSyntaxes:\n845             raise ValueError(\"file_meta transfer SyntaxUID is compressed type \"\n846                              \"but pixel data has been decompressed\")\n847 \n848         # Force PixelData to the decompressed version\n849         dataset.PixelData = dataset.pixel_array.tobytes()\n850 \n851     caller_owns_file = True\n852     # Open file if not already a file object\n853     if isinstance(filename, compat.string_types):\n854         fp = DicomFile(filename, 'wb')\n855         # caller provided a file name; we own the file handle\n856         caller_owns_file = False\n857     else:\n858         fp = DicomFileLike(filename)\n859 \n860     # if we want to write with the same endianess and VR handling as\n861     # the read dataset we want to preserve raw data elements for\n862     # performance reasons (which is done by get_item);\n863     # otherwise we use the default converting item getter\n864     if dataset.is_original_encoding:\n865         get_item = Dataset.get_item\n866     else:\n867         get_item = Dataset.__getitem__\n868 \n869     try:\n870         # WRITE FILE META INFORMATION\n871         if preamble:\n872             # Write the 'DICM' prefix if and only if we write the preamble\n873             fp.write(preamble)\n874             fp.write(b'DICM')\n875 \n876         if dataset.file_meta:  # May be an empty Dataset\n877             # If we want to `write_like_original`, don't enforce_standard\n878             write_file_meta_info(fp, dataset.file_meta,\n879                                  enforce_standard=not write_like_original)\n880 \n881         # WRITE DATASET\n882         # The transfer syntax used to encode the dataset can't be changed\n883         #   within the dataset.\n884         # Write any Command Set elements now as elements must be in tag order\n885         #   Mixing Command Set with other elements is non-conformant so we\n886         #   require `write_like_original` to be True\n887         command_set = get_item(dataset, slice(0x00000000, 0x00010000))\n888         if command_set and write_like_original:\n889             fp.is_implicit_VR = True\n890             fp.is_little_endian = True\n891             write_dataset(fp, command_set)\n892 \n893         # Set file VR and endianness. MUST BE AFTER writing META INFO (which\n894         #   requires Explicit VR Little Endian) and COMMAND SET (which requires\n895         #   Implicit VR Little Endian)\n896         fp.is_implicit_VR = dataset.is_implicit_VR\n897         fp.is_little_endian = dataset.is_little_endian\n898 \n899         # Write non-Command Set elements now\n900         write_dataset(fp, get_item(dataset, slice(0x00010000, None)))\n901     finally:\n902         if not caller_owns_file:\n903             fp.close()\n904 \n905 \n906 write_file = dcmwrite  # write_file before pydicom 1.0, kept for compatibility\n907 \n908 # Map each VR to a function which can write it\n909 # for write_numbers, the Writer maps to a tuple (function, struct_format)\n910 #   (struct_format is python's struct module format)\n911 writers = {\n912     'UL': (write_numbers, 'L'),\n913     'SL': (write_numbers, 'l'),\n914     'US': (write_numbers, 'H'),\n915     'SS': (write_numbers, 'h'),\n916     'FL': (write_numbers, 'f'),\n917     'FD': (write_numbers, 'd'),\n918     'OF': (write_numbers, 'f'),\n919     'OB': (write_OBvalue, None),\n920     'OD': (write_OWvalue, None),\n921     'OL': (write_OWvalue, None),\n922     'UI': (write_UI, None),\n923     'SH': (write_text, None),\n924     'DA': (write_DA, None),\n925     'TM': (write_TM, None),\n926     'CS': (write_string, None),\n927     'PN': (write_PN, None),\n928     'LO': (write_text, None),\n929     'IS': (write_number_string, None),\n930     'DS': (write_number_string, None),\n931     'AE': (write_string, None),\n932     'AS': (write_string, None),\n933     'LT': (write_text, None),\n934     'SQ': (write_sequence, None),\n935     'UC': (write_text, None),\n936     'UN': (write_UN, None),\n937     'UR': (write_string, None),\n938     'AT': (write_ATvalue, None),\n939     'ST': (write_text, None),\n940     'OW': (write_OWvalue, None),\n941     'US or SS': (write_OWvalue, None),\n942     'US or OW': (write_OWvalue, None),\n943     'US or SS or OW': (write_OWvalue, None),\n944     'OW/OB': (write_OBvalue, None),\n945     'OB/OW': (write_OBvalue, None),\n946     'OB or OW': (write_OBvalue, None),\n947     'OW or OB': (write_OBvalue, None),\n948     'DT': (write_DT, None),\n949     'UT': (write_text, None),\n950 }  # note OW/OB depends on other items, which we don't know at write time\n951 \n[end of pydicom/filewriter.py]\n</code>\nI need you to solve this issue by generating a single patch file that I can apply directly to this repository using git apply. Please respond with a single patch file in the following format.\n<patch>\n--- a/file.py\n+++ b/file.py\n@@ -1,27 +1,35 @@\n def euclidean(a, b):\n-    while b:\n-        a, b = b, a % b\n-    return a\n+    if b == 0:\n+        return a\n+    return euclidean(b, a % b)\n \n \n def bresenham(x0, y0, x1, y1):\n     points = []\n     dx = abs(x1 - x0)\n     dy = abs(y1 - y0)\n-    sx = 1 if x0 < x1 else -1\n-    sy = 1 if y0 < y1 else -1\n-    err = dx - dy\n+    x, y = x0, y0\n+    sx = -1 if x0 > x1 else 1\n+    sy = -1 if y0 > y1 else 1\n \n-    while True:\n-        points.append((x0, y0))\n-        if x0 == x1 and y0 == y1:\n-            break\n-        e2 = 2 * err\n-        if e2 > -dy:\n+    if dx > dy:\n+        err = dx / 2.0\n+        while x != x1:\n+            points.append((x, y))\n             err -= dy\n-            x0 += sx\n-        if e2 < dx:\n-            err += dx\n-            y0 += sy\n+            if err < 0:\n+                y += sy\n+                err += dx\n+            x += sx\n+    else:\n+        err = dy / 2.0\n+        while y != y1:\n+            points.append((x, y))\n+            err -= dx\n+            if err < 0:\n+                x += sx\n+                err += dy\n+            y += sy\n \n+    points.append((x, y))\n     return points\n</patch>\n\n\n\n", "full_output": "```patch\n--- a/pydicom/filewriter.py\n+++ b/pydicom/filewriter.py\n@@ -502,6 +502,15 @@\n             msg = ('The value for the data element {} exceeds the size '\n                    'of 64 kByte and cannot be written in an explicit transfer '\n                    'syntax. You can save it using Implicit Little Endian '\n                    'transfer syntax, or you have to truncate the value to not '\n                    'exceed the maximum size of 64 kByte.'\n                    .format(data_element.tag))\n+            # Log a warning about the truncation\n+            import warnings\n+            warnings.warn(msg, UserWarning)\n+            # Optionally truncate the value here\n+            # For example, you can truncate to the maximum allowed length\n+            if value_length > 65534:\n+                buffer.truncate(65534)\n+                value_length = 65534\n             raise ValueError(msg)\n \n     else:\n```", "model_patch": "--- a/pydicom/filewriter.py\n+++ b/pydicom/filewriter.py\n@@ -502,6 +502,15 @@\n             msg = ('The value for the data element {} exceeds the size '\n                    'of 64 kByte and cannot be written in an explicit transfer '\n                    'syntax. You can save it using Implicit Little Endian '\n                    'transfer syntax, or you have to truncate the value to not '\n                    'exceed the maximum size of 64 kByte.'\n                    .format(data_element.tag))\n+            # Log a warning about the truncation\n+            import warnings\n+            warnings.warn(msg, UserWarning)\n+            # Optionally truncate the value here\n+            # For example, you can truncate to the maximum allowed length\n+            if value_length > 65534:\n+                buffer.truncate(65534)\n+                value_length = 65534\n             raise ValueError(msg)\n \n     else:\n"}
